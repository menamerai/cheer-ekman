[
    {
        "body_part_token_idx": 7,
        "sentence_id": "bf2719b4-78ba-335c-8f2c-e4ead16fc60d",
        "tokens": [
            "Apollo",
            "had",
            "a",
            "confused",
            "look",
            "on",
            "his",
            "face",
            ",",
            "and",
            "he",
            "scratched",
            "at",
            "the",
            "stubble",
            "on",
            "his",
            "face",
            "some",
            "before",
            "asking",
            ",",
            "What",
            "the",
            "hell",
            "are",
            "you",
            "two",
            "talking",
            "about",
            "?"
        ],
        "lemmatized_tokens": [
            "Apollo",
            "have",
            "a",
            "confused",
            "look",
            "on",
            "he",
            "face",
            ",",
            "and",
            "he",
            "scratch",
            "at",
            "the",
            "stubble",
            "on",
            "he",
            "face",
            "some",
            "before",
            "ask",
            ",",
            "what",
            "the",
            "hell",
            "be",
            "you",
            "two",
            "talk",
            "about",
            "?"
        ],
        "preceding_context_tokens": [
            [
                "What",
                "'s",
                "on",
                "ya",
                "'",
                "mind?",
                "he",
                "asked",
                "her",
                ",",
                "bending",
                "slightly",
                "to",
                "look",
                "her",
                "in",
                "the",
                "face",
                "."
            ],
            [
                "This",
                "is",
                "n't",
                "right",
                ",",
                "this",
                "is",
                "n't",
                "how",
                "we",
                "'re",
                "supposed",
                "to",
                "do",
                "things",
                "she",
                "replied",
                "softly",
                ",",
                "almost",
                "in",
                "tears",
                "."
            ],
            [
                "That",
                "'s",
                "what",
                "I",
                "'ve",
                "been",
                "trying",
                "to",
                "tell",
                "you!",
                "Analise",
                "threw",
                "her",
                "hands",
                "in",
                "the",
                "air",
                ",",
                "still",
                "clutching",
                "her",
                "Sidekick",
                "-LRB-",
                "she",
                "was",
                "in",
                "the",
                "middle",
                "of",
                "a",
                "text",
                ")",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "what",
                "be",
                "on",
                "ya",
                "'",
                "mind?",
                "he",
                "ask",
                "she",
                ",",
                "bend",
                "slightly",
                "to",
                "look",
                "she",
                "in",
                "the",
                "face",
                "."
            ],
            [
                "this",
                "be",
                "not",
                "right",
                ",",
                "this",
                "be",
                "not",
                "how",
                "we",
                "be",
                "suppose",
                "to",
                "do",
                "thing",
                "she",
                "reply",
                "softly",
                ",",
                "almost",
                "in",
                "tear",
                "."
            ],
            [
                "that",
                "be",
                "what",
                "I",
                "have",
                "be",
                "try",
                "to",
                "tell",
                "you!",
                "Analise",
                "throw",
                "she",
                "hand",
                "in",
                "the",
                "air",
                ",",
                "still",
                "clutch",
                "she",
                "sidekick",
                "-lrb-",
                "she",
                "be",
                "in",
                "the",
                "middle",
                "of",
                "a",
                "text",
                ")",
                "."
            ]
        ],
        "label": "Surprise"
    },
    {
        "body_part_token_idx": 17,
        "sentence_id": "bf2719b4-78ba-335c-8f2c-e4ead16fc60d",
        "tokens": [
            "Apollo",
            "had",
            "a",
            "confused",
            "look",
            "on",
            "his",
            "face",
            ",",
            "and",
            "he",
            "scratched",
            "at",
            "the",
            "stubble",
            "on",
            "his",
            "face",
            "some",
            "before",
            "asking",
            ",",
            "What",
            "the",
            "hell",
            "are",
            "you",
            "two",
            "talking",
            "about",
            "?"
        ],
        "lemmatized_tokens": [
            "Apollo",
            "have",
            "a",
            "confused",
            "look",
            "on",
            "he",
            "face",
            ",",
            "and",
            "he",
            "scratch",
            "at",
            "the",
            "stubble",
            "on",
            "he",
            "face",
            "some",
            "before",
            "ask",
            ",",
            "what",
            "the",
            "hell",
            "be",
            "you",
            "two",
            "talk",
            "about",
            "?"
        ],
        "preceding_context_tokens": [
            [
                "What",
                "'s",
                "on",
                "ya",
                "'",
                "mind?",
                "he",
                "asked",
                "her",
                ",",
                "bending",
                "slightly",
                "to",
                "look",
                "her",
                "in",
                "the",
                "face",
                "."
            ],
            [
                "This",
                "is",
                "n't",
                "right",
                ",",
                "this",
                "is",
                "n't",
                "how",
                "we",
                "'re",
                "supposed",
                "to",
                "do",
                "things",
                "she",
                "replied",
                "softly",
                ",",
                "almost",
                "in",
                "tears",
                "."
            ],
            [
                "That",
                "'s",
                "what",
                "I",
                "'ve",
                "been",
                "trying",
                "to",
                "tell",
                "you!",
                "Analise",
                "threw",
                "her",
                "hands",
                "in",
                "the",
                "air",
                ",",
                "still",
                "clutching",
                "her",
                "Sidekick",
                "-LRB-",
                "she",
                "was",
                "in",
                "the",
                "middle",
                "of",
                "a",
                "text",
                ")",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "what",
                "be",
                "on",
                "ya",
                "'",
                "mind?",
                "he",
                "ask",
                "she",
                ",",
                "bend",
                "slightly",
                "to",
                "look",
                "she",
                "in",
                "the",
                "face",
                "."
            ],
            [
                "this",
                "be",
                "not",
                "right",
                ",",
                "this",
                "be",
                "not",
                "how",
                "we",
                "be",
                "suppose",
                "to",
                "do",
                "thing",
                "she",
                "reply",
                "softly",
                ",",
                "almost",
                "in",
                "tear",
                "."
            ],
            [
                "that",
                "be",
                "what",
                "I",
                "have",
                "be",
                "try",
                "to",
                "tell",
                "you!",
                "Analise",
                "throw",
                "she",
                "hand",
                "in",
                "the",
                "air",
                ",",
                "still",
                "clutch",
                "she",
                "sidekick",
                "-lrb-",
                "she",
                "be",
                "in",
                "the",
                "middle",
                "of",
                "a",
                "text",
                ")",
                "."
            ]
        ],
        "label": "Surprise"
    },
    {
        "body_part_token_idx": 1,
        "sentence_id": "5f42bafa-da70-3956-966a-9676738f6b51",
        "tokens": [
            "Her",
            "eyebrows",
            "drew",
            "together",
            "in",
            "thought",
            ",",
            "Allura",
            "wondering",
            "why",
            "they",
            "were",
            "accompanied",
            "by",
            "so",
            "many",
            "of",
            "the",
            "fleet.This",
            "was",
            "a",
            "mystery",
            "she",
            "sank",
            "her",
            "teeth",
            "into",
            ",",
            "strolling",
            "along",
            "the",
            "corridor",
            ",",
            "occasionally",
            "pausing",
            "to",
            "stare",
            "at",
            "the",
            "ships",
            "once",
            "more",
            "."
        ],
        "lemmatized_tokens": [
            "she",
            "eyebrow",
            "draw",
            "together",
            "in",
            "thought",
            ",",
            "Allura",
            "wonder",
            "why",
            "they",
            "be",
            "accompany",
            "by",
            "so",
            "many",
            "of",
            "the",
            "fleet.this",
            "be",
            "a",
            "mystery",
            "she",
            "sink",
            "she",
            "tooth",
            "into",
            ",",
            "stroll",
            "along",
            "the",
            "corridor",
            ",",
            "occasionally",
            "pause",
            "to",
            "stare",
            "at",
            "the",
            "ship",
            "once",
            "more",
            "."
        ],
        "preceding_context_tokens": [
            [
                "But",
                "still",
                "she",
                "knew",
                "her",
                "rejection",
                "of",
                "him",
                "had",
                "to",
                "have",
                "bothered",
                "him",
                ",",
                "the",
                "proof",
                "was",
                "right",
                "there",
                "in",
                "his",
                "staying",
                "away",
                "for",
                "so",
                "long",
                "!"
            ],
            [
                "It",
                "made",
                "her",
                "sigh",
                ",",
                "wondering",
                "if",
                "she",
                "should",
                "apologize",
                "to",
                "him",
                ",",
                "Allura",
                "walking",
                "along",
                "the",
                "hallway",
                ",",
                "listening",
                "to",
                "the",
                "sound",
                "of",
                "her",
                "heels",
                "echoing.The",
                "sides",
                "of",
                "the",
                "ship",
                "were",
                "open",
                "with",
                "heavy",
                "panes",
                "of",
                "glass",
                ",",
                "letting",
                "her",
                "look",
                "out",
                "into",
                "the",
                "loneliness",
                "of",
                "space",
                "."
            ],
            [
                "Only",
                "...",
                "it",
                "was",
                "n't",
                "as",
                "empty",
                "as",
                "she",
                "had",
                "expected",
                "it",
                "to",
                "be",
                ",",
                "seeing",
                "many",
                "Drule",
                "designed",
                "war",
                "ships",
                "floating",
                "alongside",
                "the",
                "one",
                "she",
                "was",
                "on",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "but",
                "still",
                "she",
                "know",
                "she",
                "rejection",
                "of",
                "he",
                "have",
                "to",
                "have",
                "bother",
                "he",
                ",",
                "the",
                "proof",
                "be",
                "right",
                "there",
                "in",
                "he",
                "stay",
                "away",
                "for",
                "so",
                "long",
                "!"
            ],
            [
                "it",
                "make",
                "she",
                "sigh",
                ",",
                "wonder",
                "if",
                "she",
                "should",
                "apologize",
                "to",
                "he",
                ",",
                "Allura",
                "walk",
                "along",
                "the",
                "hallway",
                ",",
                "listen",
                "to",
                "the",
                "sound",
                "of",
                "she",
                "heel",
                "echoing.the",
                "side",
                "of",
                "the",
                "ship",
                "be",
                "open",
                "with",
                "heavy",
                "pane",
                "of",
                "glass",
                ",",
                "let",
                "she",
                "look",
                "out",
                "into",
                "the",
                "loneliness",
                "of",
                "space",
                "."
            ],
            [
                "only",
                "...",
                "it",
                "be",
                "not",
                "as",
                "empty",
                "as",
                "she",
                "have",
                "expect",
                "it",
                "to",
                "be",
                ",",
                "see",
                "many",
                "Drule",
                "design",
                "war",
                "ship",
                "float",
                "alongside",
                "the",
                "one",
                "she",
                "be",
                "on",
                "."
            ]
        ],
        "label": "Fear"
    },
    {
        "body_part_token_idx": 30,
        "sentence_id": "3978608d-cbdb-3f0d-840c-573cb64ccfdc",
        "tokens": [
            "And",
            "he",
            "even",
            "got",
            "into",
            "it",
            "and",
            "was",
            "screaming",
            "cheers",
            "like",
            "the",
            "other",
            "older",
            "kids",
            "that",
            "were",
            "sitting",
            "around",
            "us",
            ",",
            "putting",
            "his",
            "two",
            "hands",
            "on",
            "either",
            "side",
            "of",
            "his",
            "mouth",
            "."
        ],
        "lemmatized_tokens": [
            "and",
            "he",
            "even",
            "get",
            "into",
            "it",
            "and",
            "be",
            "scream",
            "cheer",
            "like",
            "the",
            "other",
            "older",
            "kid",
            "that",
            "be",
            "sit",
            "around",
            "we",
            ",",
            "put",
            "he",
            "two",
            "hand",
            "on",
            "either",
            "side",
            "of",
            "he",
            "mouth",
            "."
        ],
        "preceding_context_tokens": [
            [
                "Campbell",
                "was",
                "blown",
                "away",
                "."
            ],
            [
                "I",
                "am",
                "not",
                "sure",
                "what",
                "was",
                "more",
                "exciting",
                "for",
                "him",
                "the",
                "hockey",
                "or",
                "the",
                "big",
                "arena",
                "with",
                "all",
                "the",
                "people",
                "."
            ],
            [
                "But",
                "I",
                "do",
                "not",
                "think",
                "that",
                "he",
                "blinked",
                "the",
                "whole",
                "time",
                "we",
                "were",
                "there",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "Campbell",
                "be",
                "blow",
                "away",
                "."
            ],
            [
                "I",
                "be",
                "not",
                "sure",
                "what",
                "be",
                "more",
                "exciting",
                "for",
                "he",
                "the",
                "hockey",
                "or",
                "the",
                "big",
                "arena",
                "with",
                "all",
                "the",
                "people",
                "."
            ],
            [
                "but",
                "I",
                "do",
                "not",
                "think",
                "that",
                "he",
                "blink",
                "the",
                "whole",
                "time",
                "we",
                "be",
                "there",
                "."
            ]
        ],
        "label": "Surprise"
    },
    {
        "body_part_token_idx": 1,
        "sentence_id": "c7183bfb-89f1-3403-8b72-bd2f6d29eefe",
        "tokens": [
            "His",
            "eyes",
            "shone",
            "when",
            "his",
            "friend",
            "arrived",
            "and",
            "he",
            "was",
            "a",
            "great",
            "sport",
            "when",
            "his",
            "buddy",
            "won",
            "at",
            "Monopoly",
            "."
        ],
        "lemmatized_tokens": [
            "he",
            "eye",
            "shine",
            "when",
            "he",
            "friend",
            "arrive",
            "and",
            "he",
            "be",
            "a",
            "great",
            "sport",
            "when",
            "he",
            "buddy",
            "win",
            "at",
            "Monopoly",
            "."
        ],
        "preceding_context_tokens": [
            [
                "Yesterday",
                "was",
                "different",
                "."
            ],
            [
                "Owen",
                "had",
                "a",
                "friend",
                "over",
                "from",
                "school",
                "to",
                "play",
                "."
            ],
            [
                "He",
                "was",
                "so",
                "excited",
                "that",
                "he",
                "could",
                "n't",
                "stop",
                "bouncing",
                "around",
                "the",
                "room",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "yesterday",
                "be",
                "different",
                "."
            ],
            [
                "Owen",
                "have",
                "a",
                "friend",
                "over",
                "from",
                "school",
                "to",
                "play",
                "."
            ],
            [
                "he",
                "be",
                "so",
                "excited",
                "that",
                "he",
                "could",
                "not",
                "stop",
                "bounce",
                "around",
                "the",
                "room",
                "."
            ]
        ],
        "label": "Surprise"
    },
    {
        "body_part_token_idx": 12,
        "sentence_id": "b40aa852-63d6-360a-8883-93b78beb4cc2",
        "tokens": [
            "That",
            "glance",
            ",",
            "a",
            "glance",
            "which",
            "met",
            "my",
            "eyes",
            "has",
            "made",
            "my",
            "heart",
            "pounding",
            "."
        ],
        "lemmatized_tokens": [
            "that",
            "glance",
            ",",
            "a",
            "glance",
            "which",
            "meet",
            "my",
            "eye",
            "have",
            "make",
            "my",
            "heart",
            "pound",
            "."
        ],
        "preceding_context_tokens": [
            [
                "A",
                "glance",
                ",",
                "even",
                "a",
                "very",
                "quick",
                "glance",
                "from",
                "someone",
                "special",
                "could",
                "perfectly",
                "lighten",
                "your",
                "day",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "a",
                "glance",
                ",",
                "even",
                "a",
                "very",
                "quick",
                "glance",
                "from",
                "someone",
                "special",
                "could",
                "perfectly",
                "lighten",
                "you",
                "day",
                "."
            ]
        ],
        "label": "Joy"
    },
    {
        "body_part_token_idx": 24,
        "sentence_id": "ecff72f6-851f-3f6b-a8bf-2cb74a709dab",
        "tokens": [
            "What",
            "mortal",
            "could",
            "make",
            "her",
            "skin",
            "tingle",
            "like",
            "cold",
            "fire",
            ",",
            "her",
            "mind",
            "quake",
            "as",
            "though",
            "it",
            "simply",
            "could",
            "not",
            "work",
            ",",
            "and",
            "her",
            "heart",
            "skip",
            "several",
            "beats",
            "at",
            "a",
            "time",
            "?"
        ],
        "lemmatized_tokens": [
            "what",
            "mortal",
            "could",
            "make",
            "she",
            "skin",
            "tingle",
            "like",
            "cold",
            "fire",
            ",",
            "she",
            "mind",
            "quake",
            "as",
            "though",
            "it",
            "simply",
            "could",
            "not",
            "work",
            ",",
            "and",
            "she",
            "heart",
            "skip",
            "several",
            "beat",
            "at",
            "a",
            "time",
            "?"
        ],
        "preceding_context_tokens": [
            [
                "Maybe",
                "maybe",
                "it",
                "was",
                "a",
                "spirit",
                ",",
                "or",
                "or",
                "a",
                "god",
                "!"
            ],
            [
                "Andriana",
                "'s",
                "mind",
                "was",
                "racing",
                "overtime",
                "."
            ],
            [
                "What",
                "if",
                "it",
                "was",
                "a",
                "god",
                "?"
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "maybe",
                "maybe",
                "it",
                "be",
                "a",
                "spirit",
                ",",
                "or",
                "or",
                "a",
                "god",
                "!"
            ],
            [
                "Andriana",
                "'s",
                "mind",
                "be",
                "race",
                "overtime",
                "."
            ],
            [
                "what",
                "if",
                "it",
                "be",
                "a",
                "god",
                "?"
            ]
        ],
        "label": "Surprise"
    },
    {
        "body_part_token_idx": 12,
        "sentence_id": "15683061-7f16-385a-ba1b-265cb778ee5f",
        "tokens": [
            "What",
            "else",
            "could",
            "I",
            "do?",
            "I",
            "do",
            "n't",
            "know.",
            "Giles",
            "closed",
            "his",
            "eyes",
            "and",
            "he",
            "took",
            "an",
            "audible",
            "deep",
            "breath",
            "."
        ],
        "lemmatized_tokens": [
            "what",
            "else",
            "could",
            "I",
            "do?",
            "I",
            "do",
            "not",
            "know.",
            "Giles",
            "close",
            "he",
            "eye",
            "and",
            "he",
            "take",
            "a",
            "audible",
            "deep",
            "breath",
            "."
        ],
        "preceding_context_tokens": [
            [
                "Your",
                "reconnaissance",
                "is",
                "dangerous.",
                "Xander",
                "threw",
                "up",
                "his",
                "arms",
                "."
            ],
            [
                "They",
                "had",
                "done",
                "all",
                "the",
                "research",
                "they",
                "could",
                "a",
                "few",
                "days",
                "after",
                "Willow",
                "disappeared",
                "."
            ],
            [
                "Somebody",
                "had",
                "to",
                "figure",
                "out",
                "what",
                "was",
                "going",
                "on",
                "in",
                "there",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "you",
                "reconnaissance",
                "be",
                "dangerous.",
                "Xander",
                "throw",
                "up",
                "he",
                "arm",
                "."
            ],
            [
                "they",
                "have",
                "do",
                "all",
                "the",
                "research",
                "they",
                "could",
                "a",
                "few",
                "day",
                "after",
                "Willow",
                "disappear",
                "."
            ],
            [
                "somebody",
                "have",
                "to",
                "figure",
                "out",
                "what",
                "be",
                "go",
                "on",
                "in",
                "there",
                "."
            ]
        ],
        "label": "Sadness"
    },
    {
        "body_part_token_idx": 9,
        "sentence_id": "01a02cf5-7500-3a7b-a233-98d6655d7aff",
        "tokens": [
            "Sophie",
            "was",
            "extremely",
            "animated",
            "when",
            "she",
            "talked",
            ",",
            "her",
            "eyes",
            "lighting",
            "up",
            "when",
            "she",
            "was",
            "recounting",
            "something",
            "that",
            "was",
            "particularly",
            "funny",
            "."
        ],
        "lemmatized_tokens": [
            "Sophie",
            "be",
            "extremely",
            "animate",
            "when",
            "she",
            "talk",
            ",",
            "she",
            "eye",
            "light",
            "up",
            "when",
            "she",
            "be",
            "recount",
            "something",
            "that",
            "be",
            "particularly",
            "funny",
            "."
        ],
        "preceding_context_tokens": [
            [
                "They",
                "had",
                "spent",
                "the",
                "majority",
                "of",
                "the",
                "time",
                "walking",
                "as",
                "the",
                "sun",
                "rose",
                ",",
                "exchanging",
                "silly",
                "stories",
                "."
            ],
            [
                "Sophie",
                "made",
                "Joe",
                "laugh",
                "."
            ],
            [
                "Not",
                "in",
                "a",
                "girly",
                ",",
                "watch",
                "-",
                "me",
                "-",
                "be-cute-and-flip-my-hair-laugh",
                "kind",
                "of",
                "way",
                "either",
                "``",
                "Joe",
                "actually",
                "found",
                "himself",
                "doubled",
                "over",
                "at",
                "some",
                "of",
                "the",
                "things",
                "she",
                "said",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "they",
                "have",
                "spend",
                "the",
                "majority",
                "of",
                "the",
                "time",
                "walk",
                "as",
                "the",
                "sun",
                "rise",
                ",",
                "exchange",
                "silly",
                "story",
                "."
            ],
            [
                "Sophie",
                "make",
                "Joe",
                "laugh",
                "."
            ],
            [
                "not",
                "in",
                "a",
                "girly",
                ",",
                "watch",
                "-",
                "I",
                "-",
                "be-cute-and-flip-my-hair-laugh",
                "kind",
                "of",
                "way",
                "either",
                "``",
                "Joe",
                "actually",
                "find",
                "himself",
                "double",
                "over",
                "at",
                "some",
                "of",
                "the",
                "thing",
                "she",
                "say",
                "."
            ]
        ],
        "label": "Joy"
    },
    {
        "body_part_token_idx": 7,
        "sentence_id": "3c165825-58a7-3572-afaf-48545fc3f0bb",
        "tokens": [
            "I",
            "could",
            "see",
            "the",
            "look",
            "in",
            "his",
            "eyes",
            "!"
        ],
        "lemmatized_tokens": [
            "I",
            "could",
            "see",
            "the",
            "look",
            "in",
            "he",
            "eye",
            "!"
        ],
        "preceding_context_tokens": [
            [
                "*",
                "When",
                "he",
                "came",
                "to",
                "the",
                "door",
                ",",
                "I",
                "greeted",
                "him",
                "in",
                "what",
                "looked",
                "like",
                "nothing",
                "but",
                "the",
                "jersey",
                "."
            ],
            [
                ";",
                "--",
                "RRB",
                "-",
                "Of",
                "course",
                ",",
                "with",
                "the",
                "boys",
                "here",
                ",",
                "I",
                "had",
                "to",
                "wear",
                "something",
                "underneath",
                "-",
                "but",
                "you",
                "could",
                "n't",
                "tell",
                "-LRB-",
                "you",
                "could",
                "n't",
                "tell",
                "in",
                "the",
                "photo",
                ",",
                "right",
                "?",
                ")"
            ],
            [
                "I",
                "already",
                "got",
                "a",
                "reaction",
                "from",
                "him",
                ",",
                "immediately",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "*",
                "when",
                "he",
                "come",
                "to",
                "the",
                "door",
                ",",
                "I",
                "greet",
                "he",
                "in",
                "what",
                "look",
                "like",
                "nothing",
                "but",
                "the",
                "jersey",
                "."
            ],
            [
                ";",
                "--",
                "RRB",
                "-",
                "of",
                "course",
                ",",
                "with",
                "the",
                "boy",
                "here",
                ",",
                "I",
                "have",
                "to",
                "wear",
                "something",
                "underneath",
                "-",
                "but",
                "you",
                "could",
                "not",
                "tell",
                "-LRB-",
                "you",
                "could",
                "not",
                "tell",
                "in",
                "the",
                "photo",
                ",",
                "right",
                "?",
                ")"
            ],
            [
                "I",
                "already",
                "get",
                "a",
                "reaction",
                "from",
                "he",
                ",",
                "immediately",
                "."
            ]
        ],
        "label": "Surprise"
    },
    {
        "body_part_token_idx": 17,
        "sentence_id": "760b2ec4-824d-3df3-ab81-1bf8c7965114",
        "tokens": [
            "The",
            "male",
            "detective",
            "hid",
            "a",
            "smile",
            "at",
            "the",
            "mixture",
            "of",
            "relief",
            ",",
            "confusion",
            "and",
            "disbelief",
            "on",
            "her",
            "face",
            "."
        ],
        "lemmatized_tokens": [
            "the",
            "male",
            "detective",
            "hide",
            "a",
            "smile",
            "at",
            "the",
            "mixture",
            "of",
            "relief",
            ",",
            "confusion",
            "and",
            "disbelief",
            "on",
            "she",
            "face",
            "."
        ],
        "preceding_context_tokens": [
            [
                "Lilly",
                "asked",
                "in",
                "a",
                "small",
                "voice",
                "."
            ],
            [
                "He",
                "shook",
                "his",
                "head",
                "."
            ],
            [
                "``",
                "No",
                ".",
                "''"
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "Lilly",
                "ask",
                "in",
                "a",
                "small",
                "voice",
                "."
            ],
            [
                "he",
                "shake",
                "he",
                "head",
                "."
            ],
            [
                "``",
                "no",
                ".",
                "''"
            ]
        ],
        "label": "Surprise"
    },
    {
        "body_part_token_idx": 56,
        "sentence_id": "c7aa810e-4d69-3f11-b5a5-4db67eb87d25",
        "tokens": [
            "mita",
            "koto",
            "mo",
            "nai",
            "fuukei",
            "/",
            "soko",
            "ga",
            "kaeru",
            "basho",
            "/",
            "tatta",
            "hitotsu",
            "no",
            "inochi",
            "ni",
            "/",
            "tadoritsuku",
            "basho",
            "-LRB-",
            "Not",
            "even",
            "looking",
            "at",
            "the",
            "scenery",
            "/",
            "There",
            "is",
            "the",
            "place",
            "you",
            "'re",
            "going",
            "/",
            "With",
            "merely",
            "a",
            "single",
            "life",
            "/",
            "You",
            "struggle",
            "to",
            "reach",
            "that",
            "place",
            ")",
            "*",
            "Ash",
            "shook",
            "hard",
            ",",
            "so",
            "hard",
            "her",
            "hands",
            "were",
            "n't",
            "even",
            "able",
            "to",
            "steady",
            "her",
            "against",
            "the",
            "smooth",
            "marble",
            "of",
            "the",
            "name",
            "plate",
            "."
        ],
        "lemmatized_tokens": [
            "mita",
            "koto",
            "mo",
            "nai",
            "fuukei",
            "/",
            "soko",
            "ga",
            "kaeru",
            "basho",
            "/",
            "tatta",
            "hitotsu",
            "no",
            "inochi",
            "ni",
            "/",
            "tadoritsuku",
            "basho",
            "-LRB-",
            "not",
            "even",
            "look",
            "at",
            "the",
            "scenery",
            "/",
            "there",
            "be",
            "the",
            "place",
            "you",
            "be",
            "go",
            "/",
            "with",
            "merely",
            "a",
            "single",
            "life",
            "/",
            "you",
            "struggle",
            "to",
            "reach",
            "that",
            "place",
            ")",
            "*",
            "Ash",
            "shake",
            "hard",
            ",",
            "so",
            "hard",
            "she",
            "hand",
            "be",
            "not",
            "even",
            "able",
            "to",
            "steady",
            "she",
            "against",
            "the",
            "smooth",
            "marble",
            "of",
            "the",
            "name",
            "plate",
            "."
        ],
        "preceding_context_tokens": [
            [
                "But",
                "holding",
                "onto",
                "the",
                "past",
                "is",
                "only",
                "going",
                "to",
                "hurt",
                "me",
                "more",
                "."
            ],
            [
                "Forgive",
                "me",
                "...",
                "^",
                "tokete",
                "itta",
                "kanashii",
                "koto",
                "wo",
                "/",
                "kazoeru",
                "you",
                "ni",
                "/",
                "kin",
                "`",
                "iro",
                "no",
                "ringo",
                "ga",
                "/",
                "mata",
                "hitotsu",
                "ochiru",
                "-LRB-",
                "As",
                "if",
                "counting",
                "/",
                "the",
                "melting",
                "sorrows",
                "/",
                "Yet",
                "another",
                "golden",
                "/",
                "apple",
                "fell",
                ")",
                "*",
                "Kerrin",
                "looks",
                "down",
                "at",
                "Ash",
                ",",
                "and",
                "sees",
                "how",
                "hard",
                "she",
                "is",
                "shaking",
                ",",
                "fighting",
                "to",
                "keep",
                "her",
                "tears",
                "and",
                "anger",
                "inside",
                "."
            ],
            [
                "She",
                "decides",
                "that",
                "it",
                "would",
                "be",
                "best",
                "for",
                "her",
                "to",
                "leave",
                "and",
                "she",
                "turns",
                "walking",
                "out",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "but",
                "hold",
                "onto",
                "the",
                "past",
                "be",
                "only",
                "go",
                "to",
                "hurt",
                "I",
                "more",
                "."
            ],
            [
                "forgive",
                "I",
                "...",
                "^",
                "tokete",
                "itta",
                "kanashii",
                "koto",
                "will",
                "/",
                "kazoeru",
                "you",
                "ni",
                "/",
                "kin",
                "`",
                "iro",
                "no",
                "ringo",
                "ga",
                "/",
                "mata",
                "hitotsu",
                "ochiru",
                "-lrb-",
                "as",
                "if",
                "counting",
                "/",
                "the",
                "melting",
                "sorrow",
                "/",
                "yet",
                "another",
                "golden",
                "/",
                "apple",
                "fall",
                ")",
                "*",
                "Kerrin",
                "look",
                "down",
                "at",
                "Ash",
                ",",
                "and",
                "see",
                "how",
                "hard",
                "she",
                "be",
                "shake",
                ",",
                "fight",
                "to",
                "keep",
                "she",
                "tear",
                "and",
                "anger",
                "inside",
                "."
            ],
            [
                "she",
                "decide",
                "that",
                "it",
                "would",
                "be",
                "best",
                "for",
                "she",
                "to",
                "leave",
                "and",
                "she",
                "turn",
                "walk",
                "out",
                "."
            ]
        ],
        "label": "Anger"
    },
    {
        "body_part_token_idx": 12,
        "sentence_id": "5cb9be51-7177-341f-ab64-862668138a19",
        "tokens": [
            "I",
            "was",
            "just",
            "crying",
            "so",
            "hard",
            "that",
            "the",
            "tears",
            "dripped",
            "off",
            "my",
            "chin",
            "and",
            "into",
            "the",
            "sink",
            ")",
            "."
        ],
        "lemmatized_tokens": [
            "I",
            "be",
            "just",
            "cry",
            "so",
            "hard",
            "that",
            "the",
            "tear",
            "drip",
            "off",
            "my",
            "chin",
            "and",
            "into",
            "the",
            "sink",
            ")",
            "."
        ],
        "preceding_context_tokens": [
            [
                "`",
                "Me",
                ":",
                "`",
                "I",
                "'m",
                "getting",
                "too",
                "long",
                "in",
                "the",
                "tooth",
                "anyway",
                "."
            ],
            [
                "My",
                "path",
                "lies",
                "elsewhere",
                "."
            ],
            [
                "'",
                "I",
                "left",
                "the",
                "livingroom",
                ",",
                "went",
                "out",
                "to",
                "the",
                "kitchen",
                ",",
                "and",
                "quietly",
                "cried",
                "in",
                "the",
                "sink",
                "-LRB-",
                "no",
                "I",
                "did",
                "n't",
                "have",
                "my",
                "head",
                "in",
                "the",
                "sink",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "`",
                "I",
                ":",
                "`",
                "I",
                "be",
                "get",
                "too",
                "long",
                "in",
                "the",
                "tooth",
                "anyway",
                "."
            ],
            [
                "my",
                "path",
                "lie",
                "elsewhere",
                "."
            ],
            [
                "'",
                "I",
                "leave",
                "the",
                "livingroom",
                ",",
                "go",
                "out",
                "to",
                "the",
                "kitchen",
                ",",
                "and",
                "quietly",
                "cry",
                "in",
                "the",
                "sink",
                "-lrb-_VBZ",
                "no",
                "I",
                "do",
                "not",
                "have",
                "my",
                "head",
                "in",
                "the",
                "sink",
                "."
            ]
        ],
        "label": "Sadness"
    },
    {
        "body_part_token_idx": 21,
        "sentence_id": "14f9ad8a-2296-3b63-9f1a-eca2e4ed820e",
        "tokens": [
            "It",
            "'s",
            "okay",
            "now",
            ",",
            "son",
            ",",
            "Iori",
            "rumbled",
            "at",
            "last",
            ",",
            "and",
            "Theodore",
            "exhaled",
            "a",
            "shaky",
            "little",
            "breath",
            "against",
            "his",
            "neck",
            "."
        ],
        "lemmatized_tokens": [
            "it",
            "be",
            "okay",
            "now",
            ",",
            "son",
            ",",
            "Iori",
            "rumble",
            "at",
            "last",
            ",",
            "and",
            "Theodore",
            "exhale",
            "a",
            "shaky",
            "little",
            "breath",
            "against",
            "he",
            "neck",
            "."
        ],
        "preceding_context_tokens": [
            [
                "He",
                "hoped",
                "they",
                "'d",
                "gotten",
                "there",
                "in",
                "time",
                "to",
                "keep",
                "Theo",
                "'s",
                "fragile",
                "little",
                "mind",
                "from",
                "snapping",
                "."
            ],
            [
                "They",
                "had",
                "no",
                "clue",
                "what",
                "had",
                "prompted",
                "this",
                "."
            ],
            [
                "It",
                "did",
                "n't",
                "matter",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "he",
                "hope",
                "they",
                "would",
                "get",
                "there",
                "in",
                "time",
                "to",
                "keep",
                "Theo",
                "'s",
                "fragile",
                "little",
                "mind",
                "from",
                "snap",
                "."
            ],
            [
                "they",
                "have",
                "no",
                "clue",
                "what",
                "have",
                "prompt",
                "this",
                "."
            ],
            [
                "it",
                "do",
                "not",
                "matter",
                "."
            ]
        ],
        "label": "Fear"
    },
    {
        "body_part_token_idx": 14,
        "sentence_id": "21859d01-ffdc-38e1-bce4-478739eafd16",
        "tokens": [
            "I",
            "'ve",
            "missed",
            "you",
            "more",
            "than",
            "you",
            "know.",
            "He",
            "said",
            "with",
            "tears",
            "in",
            "his",
            "eyes",
            "."
        ],
        "lemmatized_tokens": [
            "I",
            "have",
            "miss",
            "you",
            "more",
            "than",
            "you",
            "know.",
            "he",
            "say",
            "with",
            "tear",
            "in",
            "he",
            "eye",
            "."
        ],
        "preceding_context_tokens": [
            [
                "One",
                "day",
                "when",
                "Susie",
                "was",
                "out",
                ",",
                "I",
                "lost",
                "it",
                "."
            ],
            [
                "I",
                "began",
                "to",
                "touch",
                "him",
                "in",
                "that",
                "old",
                "familiar",
                "way",
                ",",
                "he",
                "did",
                "n't",
                "cringe",
                "at",
                "all",
                "."
            ],
            [
                "He",
                "touched",
                "me",
                "back",
                "and",
                "caressed",
                "my",
                "face",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "one",
                "day",
                "when",
                "Susie",
                "be",
                "out",
                ",",
                "I",
                "lose",
                "it",
                "."
            ],
            [
                "I",
                "begin",
                "to",
                "touch",
                "he",
                "in",
                "that",
                "old",
                "familiar",
                "way",
                ",",
                "he",
                "do",
                "not",
                "cringe",
                "at",
                "all",
                "."
            ],
            [
                "he",
                "touch",
                "I",
                "back",
                "and",
                "caress",
                "my",
                "face",
                "."
            ]
        ],
        "label": "Joy"
    },
    {
        "body_part_token_idx": 3,
        "sentence_id": "2aaa0669-8896-30e2-9441-f3b8480dd044",
        "tokens": [
            "Kyuhyun",
            "narrowed",
            "his",
            "eyes",
            "and",
            "sat",
            "across",
            "from",
            "him",
            ",",
            "shoving",
            "a",
            "spoonful",
            "of",
            "cereal",
            "into",
            "his",
            "mouth",
            "."
        ],
        "lemmatized_tokens": [
            "Kyuhyun",
            "narrow",
            "he",
            "eye",
            "and",
            "sit",
            "across",
            "from",
            "he",
            ",",
            "shove",
            "a",
            "spoonful",
            "of",
            "cereal",
            "into",
            "he",
            "mouth",
            "."
        ],
        "preceding_context_tokens": [
            [
                "He",
                "grabbed",
                "an",
                "apple",
                "out",
                "of",
                "the",
                "fruit",
                "bowl",
                "in",
                "front",
                "of",
                "him",
                "and",
                "took",
                "a",
                "bite",
                "."
            ],
            [
                "``",
                "Satisfied",
                "?",
                "''"
            ],
            [
                "he",
                "said",
                ",",
                "taking",
                "another",
                "bite",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "he",
                "grab",
                "a",
                "apple",
                "out",
                "of",
                "the",
                "fruit",
                "bowl",
                "in",
                "front",
                "of",
                "he",
                "and",
                "take",
                "a",
                "bite",
                "."
            ],
            [
                "``",
                "satisfied",
                "?",
                "''"
            ],
            [
                "he",
                "say",
                ",",
                "take",
                "another",
                "bite",
                "."
            ]
        ],
        "label": "Anger"
    },
    {
        "body_part_token_idx": 9,
        "sentence_id": "659a6a6f-feb5-3fba-8937-3bf810892db5",
        "tokens": [
            "He",
            "heard",
            "the",
            "siren",
            "switch",
            "on",
            ",",
            "felt",
            "his",
            "stomach",
            "lurch",
            "and",
            "the",
            "roar",
            "of",
            "the",
            "engine",
            "coming",
            "to",
            "life",
            "."
        ],
        "lemmatized_tokens": [
            "he",
            "hear",
            "the",
            "siren",
            "switch",
            "on",
            ",",
            "feel",
            "he",
            "stomach",
            "lurch",
            "and",
            "the",
            "roar",
            "of",
            "the",
            "engine",
            "come",
            "to",
            "life",
            "."
        ],
        "preceding_context_tokens": [
            [
                "``",
                "Sir",
                ",",
                "''",
                "Robert",
                "gestured",
                "to",
                "Harry",
                "to",
                "come",
                "forward",
                "."
            ],
            [
                "Harry",
                "followed",
                "the",
                "paramedic",
                "up",
                "into",
                "the",
                "back",
                "of",
                "the",
                "truck",
                ",",
                "watching",
                "as",
                "they",
                "strapped",
                "the",
                "trolley",
                "up",
                "to",
                "the",
                "floor",
                "locks",
                "."
            ],
            [
                "He",
                "then",
                "took",
                "a",
                "seat",
                "on",
                "the",
                "opposite",
                "trolley",
                "and",
                "reached",
                "for",
                "Louis",
                "'s",
                "hand",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "``",
                "Sir",
                ",",
                "''",
                "Robert",
                "gesture",
                "to",
                "Harry",
                "to",
                "come",
                "forward",
                "."
            ],
            [
                "Harry",
                "follow",
                "the",
                "paramedic",
                "up",
                "into",
                "the",
                "back",
                "of",
                "the",
                "truck",
                ",",
                "watch",
                "as",
                "they",
                "strap",
                "the",
                "trolley",
                "up",
                "to",
                "the",
                "floor",
                "lock",
                "."
            ],
            [
                "he",
                "then",
                "take",
                "a",
                "seat",
                "on",
                "the",
                "opposite",
                "trolley",
                "and",
                "reach",
                "for",
                "Louis",
                "'s",
                "hand",
                "."
            ]
        ],
        "label": "Surprise"
    },
    {
        "body_part_token_idx": 6,
        "sentence_id": "56810dc8-09f7-3bcb-b3fe-e02d31ad96ee",
        "tokens": [
            "Silence",
            "ensued",
            "and",
            "he",
            "felt",
            "his",
            "face",
            "flush",
            "again",
            "."
        ],
        "lemmatized_tokens": [
            "silence",
            "ensue",
            "and",
            "he",
            "feel",
            "he",
            "face",
            "flush",
            "again",
            "."
        ],
        "preceding_context_tokens": [
            [
                "Kyuhyun",
                "shrugged",
                "and",
                "opened",
                "his",
                "door",
                ",",
                "stepping",
                "out",
                "of",
                "the",
                "car",
                "easily",
                "."
            ],
            [
                "Jino",
                "glared",
                "at",
                "his",
                "back",
                "and",
                "attempted",
                "to",
                "get",
                "out",
                "the",
                "car",
                "again",
                ",",
                "only",
                "to",
                "fail",
                "."
            ],
            [
                "He",
                "looked",
                "up",
                "in",
                "surprise",
                "when",
                "Kyuhyun",
                "grabbed",
                "his",
                "arm",
                "and",
                "pulled",
                "him",
                "out",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "Kyuhyun",
                "shrug",
                "and",
                "open",
                "he",
                "door",
                ",",
                "step",
                "out",
                "of",
                "the",
                "car",
                "easily",
                "."
            ],
            [
                "Jino",
                "glare",
                "at",
                "he",
                "back",
                "and",
                "attempt",
                "to",
                "get",
                "out",
                "the",
                "car",
                "again",
                ",",
                "only",
                "to",
                "fail",
                "."
            ],
            [
                "he",
                "look",
                "up",
                "in",
                "surprise",
                "when",
                "Kyuhyun",
                "grab",
                "he",
                "arm",
                "and",
                "pull",
                "he",
                "out",
                "."
            ]
        ],
        "label": "Surprise"
    },
    {
        "body_part_token_idx": 12,
        "sentence_id": "b6fece79-8f37-3b35-91f4-e04675fcf20a",
        "tokens": [
            "Hannibal",
            "'s",
            "frown",
            "deepened",
            "and",
            "he",
            "turned",
            "to",
            "BA",
            "who",
            "shook",
            "his",
            "head",
            "at",
            "Murdock",
            "'s",
            "attempt",
            "at",
            "an",
            "explanation",
            "before",
            "having",
            "a",
            "go",
            "himself",
            ",",
            "``",
            "Remember",
            "that",
            "old",
            "priest",
            "boss",
            "?"
        ],
        "lemmatized_tokens": [
            "Hannibal",
            "'s",
            "frown",
            "deepen",
            "and",
            "he",
            "turn",
            "to",
            "BA",
            "who",
            "shake",
            "he",
            "head",
            "at",
            "Murdock",
            "'s",
            "attempt",
            "at",
            "a",
            "explanation",
            "before",
            "have",
            "a",
            "go",
            "himself",
            ",",
            "``",
            "remember",
            "that",
            "old",
            "priest",
            "boss",
            "?"
        ],
        "preceding_context_tokens": [
            [
                "Was",
                "that",
                "a",
                "trick",
                "question",
                "?"
            ],
            [
                "``",
                "Yes",
                "!",
                "''"
            ],
            [
                "Murdock",
                "looked",
                "thrilled",
                ",",
                "``",
                "January",
                "4th",
                "!",
                "''"
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "be",
                "that",
                "a",
                "trick",
                "question",
                "?"
            ],
            [
                "``",
                "yes",
                "!",
                "''"
            ],
            [
                "Murdock",
                "look",
                "thrilled",
                ",",
                "``",
                "January",
                "4th",
                "!",
                "''"
            ]
        ],
        "label": "Disgust"
    },
    {
        "body_part_token_idx": 8,
        "sentence_id": "bf331198-adf1-3099-ab81-b14f96e6b0b6",
        "tokens": [
            "``",
            "Slowly",
            ",",
            "a",
            "smile",
            "spread",
            "across",
            "her",
            "face",
            "."
        ],
        "lemmatized_tokens": [
            "``",
            "slowly",
            ",",
            "a",
            "smile",
            "spread",
            "across",
            "she",
            "face",
            "."
        ],
        "preceding_context_tokens": [
            [
                "Deavy",
                "was",
                "at",
                "a",
                "loss",
                "."
            ],
            [
                "Looking",
                "at",
                "his",
                "reuben",
                ",",
                "he",
                "picked",
                "up",
                "a",
                "pickle",
                "and",
                "took",
                "a",
                "bite",
                ",",
                "chewing",
                "a",
                "little",
                "thoughtfully",
                "."
            ],
            [
                "``",
                "Well",
                ",",
                "I",
                "would",
                "n't",
                "let",
                "them",
                "take",
                "you",
                "back",
                ",",
                "if",
                "you",
                "did",
                "n't",
                "want",
                "to",
                "go",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "Deavy",
                "be",
                "at",
                "a",
                "loss",
                "."
            ],
            [
                "look",
                "at",
                "he",
                "reuben",
                ",",
                "he",
                "pick",
                "up",
                "a",
                "pickle",
                "and",
                "take",
                "a",
                "bite",
                ",",
                "chew",
                "a",
                "little",
                "thoughtfully",
                "."
            ],
            [
                "``",
                "well",
                ",",
                "I",
                "would",
                "not",
                "let",
                "they",
                "take",
                "you",
                "back",
                ",",
                "if",
                "you",
                "do",
                "not",
                "want",
                "to",
                "go",
                "."
            ]
        ],
        "label": "Joy"
    },
    {
        "body_part_token_idx": 21,
        "sentence_id": "4c386961-4a5d-3e2a-b87a-1375b2ae45d1",
        "tokens": [
            "Although",
            "she",
            "was",
            "in",
            "there",
            "for",
            "only",
            "a",
            "couple",
            "of",
            "minutes",
            ",",
            "she",
            "probably",
            "thought",
            "it",
            "was",
            "eternity",
            "and",
            "cried",
            "her",
            "eyes",
            "out",
            "."
        ],
        "lemmatized_tokens": [
            "although",
            "she",
            "be",
            "in",
            "there",
            "for",
            "only",
            "a",
            "couple",
            "of",
            "minute",
            ",",
            "she",
            "probably",
            "think",
            "it",
            "be",
            "eternity",
            "and",
            "cry",
            "she",
            "eye",
            "out",
            "."
        ],
        "preceding_context_tokens": [
            [
                "She",
                "was",
                "ok",
                "for",
                "the",
                "rest",
                "of",
                "the",
                "English",
                "lesson",
                "but",
                "started",
                "to",
                "play",
                "punk",
                "again",
                "when",
                "the",
                "class",
                "came",
                "back",
                "to",
                "class",
                "for",
                "chinese",
                "lessons",
                "after",
                "the",
                "break.The",
                "teacher",
                "told",
                "her",
                "that",
                "if",
                "she",
                "is",
                "not",
                "interested",
                "in",
                "the",
                "chinese",
                "lesson",
                ",",
                "she",
                "can",
                "always",
                "go",
                "to",
                "the",
                "next",
                "class",
                "for",
                "english",
                "lesson",
                "."
            ],
            [
                "She",
                "continued",
                "to",
                "play",
                "instead",
                "of",
                "joining",
                "the",
                "class",
                "."
            ],
            [
                "So",
                ",",
                "the",
                "chinese",
                "teacher",
                "packed",
                "her",
                "bags",
                "and",
                "brought",
                "her",
                "to",
                "the",
                "next",
                "class",
                "and",
                "left",
                "her",
                "there",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "she",
                "be",
                "ok",
                "for",
                "the",
                "rest",
                "of",
                "the",
                "English",
                "lesson",
                "but",
                "start",
                "to",
                "play",
                "punk",
                "again",
                "when",
                "the",
                "class",
                "come",
                "back",
                "to",
                "class",
                "for",
                "chinese",
                "lesson",
                "after",
                "the",
                "break.the",
                "teacher",
                "tell",
                "she",
                "that",
                "if",
                "she",
                "be",
                "not",
                "interested",
                "in",
                "the",
                "chinese",
                "lesson",
                ",",
                "she",
                "can",
                "always",
                "go",
                "to",
                "the",
                "next",
                "class",
                "for",
                "english",
                "lesson",
                "."
            ],
            [
                "she",
                "continue",
                "to",
                "play",
                "instead",
                "of",
                "join",
                "the",
                "class",
                "."
            ],
            [
                "so",
                ",",
                "the",
                "chinese",
                "teacher",
                "pack",
                "she",
                "bag",
                "and",
                "bring",
                "she",
                "to",
                "the",
                "next",
                "class",
                "and",
                "leave",
                "she",
                "there",
                "."
            ]
        ],
        "label": "Fear"
    },
    {
        "body_part_token_idx": 26,
        "sentence_id": "cf6aa396-c8f7-3c47-9245-d28d9a483281",
        "tokens": [
            "Okay",
            ",",
            "come",
            "on",
            "Sammy",
            ",",
            "lets",
            "get",
            "Sleeping",
            "Beauty",
            "to",
            "his",
            "room.",
            "Sam",
            "who",
            "seemed",
            "to",
            "be",
            "still",
            "pissed",
            "at",
            "Dean",
            "answered",
            "by",
            "rolling",
            "his",
            "eyes",
            "but",
            "then",
            "went",
            "to",
            "help",
            "him",
            "get",
            "Chase",
            "out",
            "of",
            "the",
            "car",
            "."
        ],
        "lemmatized_tokens": [
            "okay",
            ",",
            "come",
            "on",
            "Sammy",
            ",",
            "let",
            "get",
            "sleep",
            "Beauty",
            "to",
            "he",
            "room.",
            "Sam",
            "who",
            "seem",
            "to",
            "be",
            "still",
            "piss",
            "at",
            "Dean",
            "answer",
            "by",
            "roll",
            "he",
            "eye",
            "but",
            "then",
            "go",
            "to",
            "help",
            "he",
            "get",
            "Chase",
            "out",
            "of",
            "the",
            "car",
            "."
        ],
        "preceding_context_tokens": [
            [
                "I",
                "then",
                "followed",
                "and",
                "got",
                "out",
                "of",
                "the",
                "car",
                "."
            ],
            [
                "I",
                "looked",
                "over",
                "to",
                "Chase",
                "who",
                "was",
                "now",
                "face",
                "first",
                "into",
                "the",
                "seat",
                "where",
                "I",
                "previously",
                "sat",
                "."
            ],
            [
                "Bobby",
                "slowly",
                "got",
                "out",
                "of",
                "the",
                "car",
                "still",
                "nursing",
                "his",
                "stomach",
                "with",
                "his",
                "hand",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "I",
                "then",
                "follow",
                "and",
                "get",
                "out",
                "of",
                "the",
                "car",
                "."
            ],
            [
                "I",
                "look",
                "over",
                "to",
                "Chase",
                "who",
                "be",
                "now",
                "face",
                "first",
                "into",
                "the",
                "seat",
                "where",
                "I",
                "previously",
                "sit",
                "."
            ],
            [
                "Bobby",
                "slowly",
                "get",
                "out",
                "of",
                "the",
                "car",
                "still",
                "nurse",
                "he",
                "stomach",
                "with",
                "he",
                "hand",
                "."
            ]
        ],
        "label": "Disgust"
    },
    {
        "body_part_token_idx": 3,
        "sentence_id": "ec894e76-5e24-32a8-8c86-f850bcb7c97f",
        "tokens": [
            "I",
            "rolled",
            "my",
            "eyes",
            "."
        ],
        "lemmatized_tokens": [
            "I",
            "roll",
            "my",
            "eye",
            "."
        ],
        "preceding_context_tokens": [
            [
                "She",
                "asked",
                "."
            ],
            [
                "``",
                "We",
                "are",
                "vampires",
                "now",
                "and",
                "much",
                "better",
                "equipped",
                "for",
                "the",
                "undertaking",
                "."
            ],
            [
                "Perhaps",
                ",",
                "you",
                "know",
                "where",
                "it",
                "is",
                "?",
                "''"
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "she",
                "ask",
                "."
            ],
            [
                "``",
                "we",
                "be",
                "vampire",
                "now",
                "and",
                "much",
                "better",
                "equip",
                "for",
                "the",
                "undertaking",
                "."
            ],
            [
                "perhaps",
                ",",
                "you",
                "know",
                "where",
                "it",
                "be",
                "?",
                "''"
            ]
        ],
        "label": "Disgust"
    },
    {
        "body_part_token_idx": 7,
        "sentence_id": "6e27ec8a-e992-3210-97d8-91d77ba98b2a",
        "tokens": [
            "Mikey",
            "stumbles",
            "backwards",
            "and",
            "rubs",
            "at",
            "his",
            "eyes",
            "."
        ],
        "lemmatized_tokens": [
            "Mikey",
            "stumble",
            "backwards",
            "and",
            "rub",
            "at",
            "he",
            "eye",
            "."
        ],
        "preceding_context_tokens": [
            [
                "But",
                "they",
                "do",
                "n't",
                "have",
                "anything",
                "to",
                "do",
                "until",
                "tomorrow",
                "night",
                "and",
                "Mikey",
                "never",
                "knows",
                "how",
                "to",
                "say",
                "no",
                "to",
                "a",
                "good",
                "time",
                ",",
                "so",
                "he",
                "drags",
                "his",
                "brother",
                "down",
                "the",
                "hall",
                "."
            ],
            [
                "Mikey",
                "only",
                "knocks",
                "once",
                "before",
                "Frank",
                "swings",
                "the",
                "door",
                "open",
                ",",
                "crowding",
                "him",
                "as",
                "he",
                "edges",
                "out",
                "and",
                "pulls",
                "it",
                "shut",
                "behind",
                "them",
                "."
            ],
            [
                "``",
                "Shh",
                ",",
                "''",
                "Frank",
                "says",
                ",",
                "way",
                "too",
                "loudly",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "but",
                "they",
                "do",
                "not",
                "have",
                "anything",
                "to",
                "do",
                "until",
                "tomorrow",
                "night",
                "and",
                "Mikey",
                "never",
                "know",
                "how",
                "to",
                "say",
                "no",
                "to",
                "a",
                "good",
                "time",
                ",",
                "so",
                "he",
                "drag",
                "he",
                "brother",
                "down",
                "the",
                "hall",
                "."
            ],
            [
                "Mikey",
                "only",
                "knock",
                "once",
                "before",
                "Frank",
                "swing",
                "the",
                "door",
                "open",
                ",",
                "crowd",
                "he",
                "as",
                "he",
                "edge",
                "out",
                "and",
                "pull",
                "it",
                "shut",
                "behind",
                "they",
                "."
            ],
            [
                "``",
                "shh",
                ",",
                "''",
                "Frank",
                "say",
                ",",
                "way",
                "too",
                "loudly",
                "."
            ]
        ],
        "label": "Surprise"
    },
    {
        "body_part_token_idx": 3,
        "sentence_id": "f034da0a-4b93-3b3f-a615-2a5efe66dddd",
        "tokens": [
            "He",
            "shook",
            "his",
            "head",
            "."
        ],
        "lemmatized_tokens": [
            "he",
            "shake",
            "he",
            "head",
            "."
        ],
        "preceding_context_tokens": [
            [
                "It",
                "was",
                "new",
                ",",
                "to",
                "do",
                "it",
                "this",
                "way",
                ",",
                "without",
                "the",
                "edge",
                "of",
                "desperation",
                ",",
                "without",
                "clawing",
                "and",
                "biting",
                "and",
                "shoving",
                "hard",
                "and",
                "frantic",
                "against",
                "one",
                "another",
                "."
            ],
            [
                "This",
                "care",
                "was",
                "new",
                "and",
                "Dean",
                "$",
                "he",
                "liked",
                "it",
                "very",
                "much",
                ",",
                "and",
                "at",
                "the",
                "same",
                "time",
                "wondered",
                "what",
                "brought",
                "it",
                "on",
                "-",
                "Sam",
                "was",
                "n't",
                "usually",
                "so",
                "careful",
                ",",
                "or",
                "so",
                "thorough",
                "."
            ],
            [
                "``",
                "C'mon",
                ",",
                "Sam",
                ",",
                "move",
                "--",
                "you",
                "wo",
                "n't",
                "hurt",
                "me",
                ".",
                "''"
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "it",
                "be",
                "new",
                ",",
                "to",
                "do",
                "it",
                "this",
                "way",
                ",",
                "without",
                "the",
                "edge",
                "of",
                "desperation",
                ",",
                "without",
                "claw",
                "and",
                "bite",
                "and",
                "shove",
                "hard",
                "and",
                "frantic",
                "against",
                "one",
                "another",
                "."
            ],
            [
                "this",
                "care",
                "be",
                "new",
                "and",
                "Dean",
                "$",
                "he",
                "like",
                "it",
                "very",
                "much",
                ",",
                "and",
                "at",
                "the",
                "same",
                "time",
                "wonder",
                "what",
                "bring",
                "it",
                "on",
                "-",
                "Sam",
                "be",
                "not",
                "usually",
                "so",
                "careful",
                ",",
                "or",
                "so",
                "thorough",
                "."
            ],
            [
                "``",
                "C'mon",
                ",",
                "Sam",
                ",",
                "move",
                "--",
                "you",
                "will",
                "not",
                "hurt",
                "I",
                ".",
                "''"
            ]
        ],
        "label": "Disgust"
    },
    {
        "body_part_token_idx": 6,
        "sentence_id": "0b5c78f3-1fb5-3ea4-8e7a-6ab4aaa3e7e5",
        "tokens": [
            "Nineteen",
            "years",
            "old",
            ",",
            "beating",
            "my",
            "head",
            "against",
            "the",
            "wall",
            "for",
            "the",
            "last",
            "year",
            "or",
            "so",
            "in",
            "the",
            "confines",
            "of",
            "southern",
            "Ontario",
            ",",
            "a",
            "trip",
            "out",
            "west",
            "seemed",
            "like",
            "a",
            "good",
            "idea",
            ";",
            "given",
            "that",
            "this",
            "was",
            "a",
            "free",
            "ride",
            "I",
            "figured",
            "what",
            "the",
            "hell",
            "?"
        ],
        "lemmatized_tokens": [
            "nineteen",
            "year",
            "old",
            ",",
            "beat",
            "my",
            "head",
            "against",
            "the",
            "wall",
            "for",
            "the",
            "last",
            "year",
            "or",
            "so",
            "in",
            "the",
            "confines",
            "of",
            "southern",
            "Ontario",
            ",",
            "a",
            "trip",
            "out",
            "west",
            "seem",
            "like",
            "a",
            "good",
            "idea",
            ";",
            "give",
            "that",
            "this",
            "be",
            "a",
            "free",
            "ride",
            "I",
            "figure",
            "what",
            "the",
            "hell",
            "?"
        ],
        "preceding_context_tokens": [
            [
                "Vancouver",
                "was",
                "a",
                "trip",
                "to",
                "say",
                "the",
                "least",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "Vancouver",
                "be",
                "a",
                "trip",
                "to",
                "say",
                "the",
                "least",
                "."
            ]
        ],
        "label": "Anger"
    },
    {
        "body_part_token_idx": 3,
        "sentence_id": "71a9c711-e58a-3d67-8922-5dce2a39810a",
        "tokens": [
            "HyukJae",
            "fisted",
            "his",
            "hands",
            "and",
            "bit",
            "his",
            "bottom",
            "lip",
            ",",
            "lowering",
            "his",
            "head",
            "to",
            "hide",
            "his",
            "tears",
            "."
        ],
        "lemmatized_tokens": [
            "HyukJae",
            "fisted",
            "he",
            "hand",
            "and",
            "bite",
            "he",
            "bottom",
            "lip",
            ",",
            "lower",
            "he",
            "head",
            "to",
            "hide",
            "he",
            "tear",
            "."
        ],
        "preceding_context_tokens": [
            [
                "...",
                "In",
                "the",
                "car",
                "...",
                "after",
                "I",
                "told",
                "you",
                "to",
                "stop...y",
                "-",
                "you",
                "did",
                "n't",
                "listen",
                "."
            ],
            [
                "I",
                "begged",
                "you",
                ",",
                "I",
                "tried",
                ",",
                "I",
                "shouted",
                "and",
                "I",
                "screamed",
                "...",
                "you",
                "did",
                "n't",
                "stop",
                "."
            ],
            [
                "Why",
                "!?",
                "''"
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "...",
                "in",
                "the",
                "car",
                "...",
                "after",
                "I",
                "tell",
                "you",
                "to",
                "stop...y",
                "-",
                "you",
                "do",
                "not",
                "listen",
                "."
            ],
            [
                "I",
                "beg",
                "you",
                ",",
                "I",
                "try",
                ",",
                "I",
                "shout",
                "and",
                "I",
                "scream",
                "...",
                "you",
                "do",
                "not",
                "stop",
                "."
            ],
            [
                "why",
                "!?",
                "''"
            ]
        ],
        "label": "Sadness"
    },
    {
        "body_part_token_idx": 12,
        "sentence_id": "71a9c711-e58a-3d67-8922-5dce2a39810a",
        "tokens": [
            "HyukJae",
            "fisted",
            "his",
            "hands",
            "and",
            "bit",
            "his",
            "bottom",
            "lip",
            ",",
            "lowering",
            "his",
            "head",
            "to",
            "hide",
            "his",
            "tears",
            "."
        ],
        "lemmatized_tokens": [
            "HyukJae",
            "fisted",
            "he",
            "hand",
            "and",
            "bite",
            "he",
            "bottom",
            "lip",
            ",",
            "lower",
            "he",
            "head",
            "to",
            "hide",
            "he",
            "tear",
            "."
        ],
        "preceding_context_tokens": [
            [
                "...",
                "In",
                "the",
                "car",
                "...",
                "after",
                "I",
                "told",
                "you",
                "to",
                "stop...y",
                "-",
                "you",
                "did",
                "n't",
                "listen",
                "."
            ],
            [
                "I",
                "begged",
                "you",
                ",",
                "I",
                "tried",
                ",",
                "I",
                "shouted",
                "and",
                "I",
                "screamed",
                "...",
                "you",
                "did",
                "n't",
                "stop",
                "."
            ],
            [
                "Why",
                "!?",
                "''"
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "...",
                "in",
                "the",
                "car",
                "...",
                "after",
                "I",
                "tell",
                "you",
                "to",
                "stop...y",
                "-",
                "you",
                "do",
                "not",
                "listen",
                "."
            ],
            [
                "I",
                "beg",
                "you",
                ",",
                "I",
                "try",
                ",",
                "I",
                "shout",
                "and",
                "I",
                "scream",
                "...",
                "you",
                "do",
                "not",
                "stop",
                "."
            ],
            [
                "why",
                "!?",
                "''"
            ]
        ],
        "label": "Sadness"
    },
    {
        "body_part_token_idx": 25,
        "sentence_id": "1df46fbf-d924-3417-8228-84dfd8f1cf1d",
        "tokens": [
            "The",
            "whole",
            "class",
            "turned",
            "to",
            "look",
            "at",
            "me",
            "and",
            "i",
            "felt",
            "my",
            "cheeks",
            "flame",
            "up",
            "a",
            "wonderul",
            "crimson",
            "colour",
            "as",
            "I",
            "tried",
            "to",
            "bury",
            "my",
            "head",
            "back",
            "into",
            "my",
            "book",
            ",",
            "i",
            "wanted",
            "to",
            "look",
            "back",
            "up",
            "take",
            "one",
            "more",
            "glimpse",
            "at",
            "her",
            "but",
            "I",
            "dare",
            "n't",
            "."
        ],
        "lemmatized_tokens": [
            "the",
            "whole",
            "class",
            "turn",
            "to",
            "look",
            "at",
            "I",
            "and",
            "i",
            "feel",
            "my",
            "cheek",
            "flame",
            "up",
            "a",
            "wonderul",
            "crimson",
            "colour",
            "as",
            "I",
            "try",
            "to",
            "bury",
            "my",
            "head",
            "back",
            "into",
            "my",
            "book",
            ",",
            "i",
            "want",
            "to",
            "look",
            "back",
            "up",
            "take",
            "one",
            "more",
            "glimpse",
            "at",
            "she",
            "but",
            "I",
            "dare",
            "not",
            "."
        ],
        "preceding_context_tokens": [
            [
                "When",
                "my",
                "eyes",
                "found",
                "their",
                "way",
                "back",
                "up",
                "to",
                "her",
                "beautiful",
                "face",
                "I",
                "locked",
                "into",
                "her",
                "deep",
                "blue",
                "eyes",
                "I",
                "could",
                "feel",
                "myself",
                "getting",
                "lost",
                "already",
                "I",
                "was",
                "drowning",
                "and",
                "needed",
                "saving",
                "quickly",
                "."
            ],
            [
                "``",
                "Miss",
                "Powers",
                "ar",
                "n't",
                "you",
                "supposed",
                "to",
                "be",
                "working",
                "?",
                "''"
            ],
            [
                "Deputy",
                "dickhead",
                "said",
                "pulling",
                "me",
                "out",
                "of",
                "her",
                "deep",
                "eyes",
                "immediately",
                ",",
                "talk",
                "about",
                "a",
                "mood",
                "killer",
                "!"
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "when",
                "my",
                "eye",
                "find",
                "they",
                "way",
                "back",
                "up",
                "to",
                "she",
                "beautiful",
                "face",
                "I",
                "lock",
                "into",
                "she",
                "deep",
                "blue",
                "eye",
                "I",
                "could",
                "feel",
                "myself",
                "get",
                "lose",
                "already",
                "I",
                "be",
                "drown",
                "and",
                "need",
                "save",
                "quickly",
                "."
            ],
            [
                "``",
                "Miss",
                "Powers",
                "ar",
                "not",
                "you",
                "suppose",
                "to",
                "be",
                "work",
                "?",
                "''"
            ],
            [
                "Deputy",
                "dickhead",
                "say",
                "pull",
                "I",
                "out",
                "of",
                "she",
                "deep",
                "eye",
                "immediately",
                ",",
                "talk",
                "about",
                "a",
                "mood",
                "killer",
                "!"
            ]
        ],
        "label": "Fear"
    },
    {
        "body_part_token_idx": 14,
        "sentence_id": "51538783-28d8-3ac5-bedf-84a67a91e0d4",
        "tokens": [
            "He",
            "wiped",
            "at",
            "the",
            "sweat",
            "on",
            "his",
            "upper",
            "lip",
            "with",
            "the",
            "back",
            "of",
            "his",
            "hand",
            ",",
            "and",
            "then",
            ",",
            "a",
            "sigh",
            "catching",
            "in",
            "his",
            "throat",
            ",",
            "he",
            "blotted",
            "the",
            "sweat",
            "from",
            "his",
            "temple",
            "."
        ],
        "lemmatized_tokens": [
            "he",
            "wipe",
            "at",
            "the",
            "sweat",
            "on",
            "he",
            "upper",
            "lip",
            "with",
            "the",
            "back",
            "of",
            "he",
            "hand",
            ",",
            "and",
            "then",
            ",",
            "a",
            "sigh",
            "catch",
            "in",
            "he",
            "throat",
            ",",
            "he",
            "blot",
            "the",
            "sweat",
            "from",
            "he",
            "temple",
            "."
        ],
        "preceding_context_tokens": [
            [
                "Such",
                "as",
                "tear",
                "his",
                "servant",
                "to",
                "pieces",
                "if",
                "he",
                "'d",
                "a",
                "mind",
                "to",
                "."
            ],
            [
                "Or",
                "bend",
                "him",
                "over",
                "the",
                "kitchen",
                "table",
                "and",
                "exact",
                "payment",
                "out",
                "of",
                "his",
                "hide",
                "for",
                "a",
                "ruined",
                "room",
                "."
            ],
            [
                "Or",
                "press",
                "him",
                "close",
                "and",
                "fold",
                "down",
                "the",
                "collar",
                "of",
                "his",
                "shirt",
                "to",
                "''",
                "For",
                "Christ",
                "'s",
                "sake",
                ",",
                "Loomis",
                ",",
                "knock",
                "it",
                "off",
                "!"
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "such",
                "as",
                "tear",
                "he",
                "servant",
                "to",
                "piece",
                "if",
                "he",
                "have",
                "a",
                "mind",
                "to",
                "."
            ],
            [
                "or",
                "bend",
                "he",
                "over",
                "the",
                "kitchen",
                "table",
                "and",
                "exact",
                "payment",
                "out",
                "of",
                "he",
                "hide",
                "for",
                "a",
                "ruin",
                "room",
                "."
            ],
            [
                "or",
                "press",
                "he",
                "close",
                "and",
                "fold",
                "down",
                "the",
                "collar",
                "of",
                "he",
                "shirt",
                "to",
                "''",
                "for",
                "Christ",
                "'s",
                "sake",
                ",",
                "Loomis",
                ",",
                "knock",
                "it",
                "off",
                "!"
            ]
        ],
        "label": "Anger"
    },
    {
        "body_part_token_idx": 24,
        "sentence_id": "51538783-28d8-3ac5-bedf-84a67a91e0d4",
        "tokens": [
            "He",
            "wiped",
            "at",
            "the",
            "sweat",
            "on",
            "his",
            "upper",
            "lip",
            "with",
            "the",
            "back",
            "of",
            "his",
            "hand",
            ",",
            "and",
            "then",
            ",",
            "a",
            "sigh",
            "catching",
            "in",
            "his",
            "throat",
            ",",
            "he",
            "blotted",
            "the",
            "sweat",
            "from",
            "his",
            "temple",
            "."
        ],
        "lemmatized_tokens": [
            "he",
            "wipe",
            "at",
            "the",
            "sweat",
            "on",
            "he",
            "upper",
            "lip",
            "with",
            "the",
            "back",
            "of",
            "he",
            "hand",
            ",",
            "and",
            "then",
            ",",
            "a",
            "sigh",
            "catch",
            "in",
            "he",
            "throat",
            ",",
            "he",
            "blot",
            "the",
            "sweat",
            "from",
            "he",
            "temple",
            "."
        ],
        "preceding_context_tokens": [
            [
                "Such",
                "as",
                "tear",
                "his",
                "servant",
                "to",
                "pieces",
                "if",
                "he",
                "'d",
                "a",
                "mind",
                "to",
                "."
            ],
            [
                "Or",
                "bend",
                "him",
                "over",
                "the",
                "kitchen",
                "table",
                "and",
                "exact",
                "payment",
                "out",
                "of",
                "his",
                "hide",
                "for",
                "a",
                "ruined",
                "room",
                "."
            ],
            [
                "Or",
                "press",
                "him",
                "close",
                "and",
                "fold",
                "down",
                "the",
                "collar",
                "of",
                "his",
                "shirt",
                "to",
                "''",
                "For",
                "Christ",
                "'s",
                "sake",
                ",",
                "Loomis",
                ",",
                "knock",
                "it",
                "off",
                "!"
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "such",
                "as",
                "tear",
                "he",
                "servant",
                "to",
                "piece",
                "if",
                "he",
                "have",
                "a",
                "mind",
                "to",
                "."
            ],
            [
                "or",
                "bend",
                "he",
                "over",
                "the",
                "kitchen",
                "table",
                "and",
                "exact",
                "payment",
                "out",
                "of",
                "he",
                "hide",
                "for",
                "a",
                "ruin",
                "room",
                "."
            ],
            [
                "or",
                "press",
                "he",
                "close",
                "and",
                "fold",
                "down",
                "the",
                "collar",
                "of",
                "he",
                "shirt",
                "to",
                "''",
                "for",
                "Christ",
                "'s",
                "sake",
                ",",
                "Loomis",
                ",",
                "knock",
                "it",
                "off",
                "!"
            ]
        ],
        "label": "Anger"
    },
    {
        "body_part_token_idx": 32,
        "sentence_id": "51538783-28d8-3ac5-bedf-84a67a91e0d4",
        "tokens": [
            "He",
            "wiped",
            "at",
            "the",
            "sweat",
            "on",
            "his",
            "upper",
            "lip",
            "with",
            "the",
            "back",
            "of",
            "his",
            "hand",
            ",",
            "and",
            "then",
            ",",
            "a",
            "sigh",
            "catching",
            "in",
            "his",
            "throat",
            ",",
            "he",
            "blotted",
            "the",
            "sweat",
            "from",
            "his",
            "temple",
            "."
        ],
        "lemmatized_tokens": [
            "he",
            "wipe",
            "at",
            "the",
            "sweat",
            "on",
            "he",
            "upper",
            "lip",
            "with",
            "the",
            "back",
            "of",
            "he",
            "hand",
            ",",
            "and",
            "then",
            ",",
            "a",
            "sigh",
            "catch",
            "in",
            "he",
            "throat",
            ",",
            "he",
            "blot",
            "the",
            "sweat",
            "from",
            "he",
            "temple",
            "."
        ],
        "preceding_context_tokens": [
            [
                "Such",
                "as",
                "tear",
                "his",
                "servant",
                "to",
                "pieces",
                "if",
                "he",
                "'d",
                "a",
                "mind",
                "to",
                "."
            ],
            [
                "Or",
                "bend",
                "him",
                "over",
                "the",
                "kitchen",
                "table",
                "and",
                "exact",
                "payment",
                "out",
                "of",
                "his",
                "hide",
                "for",
                "a",
                "ruined",
                "room",
                "."
            ],
            [
                "Or",
                "press",
                "him",
                "close",
                "and",
                "fold",
                "down",
                "the",
                "collar",
                "of",
                "his",
                "shirt",
                "to",
                "''",
                "For",
                "Christ",
                "'s",
                "sake",
                ",",
                "Loomis",
                ",",
                "knock",
                "it",
                "off",
                "!"
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "such",
                "as",
                "tear",
                "he",
                "servant",
                "to",
                "piece",
                "if",
                "he",
                "have",
                "a",
                "mind",
                "to",
                "."
            ],
            [
                "or",
                "bend",
                "he",
                "over",
                "the",
                "kitchen",
                "table",
                "and",
                "exact",
                "payment",
                "out",
                "of",
                "he",
                "hide",
                "for",
                "a",
                "ruin",
                "room",
                "."
            ],
            [
                "or",
                "press",
                "he",
                "close",
                "and",
                "fold",
                "down",
                "the",
                "collar",
                "of",
                "he",
                "shirt",
                "to",
                "''",
                "for",
                "Christ",
                "'s",
                "sake",
                ",",
                "Loomis",
                ",",
                "knock",
                "it",
                "off",
                "!"
            ]
        ],
        "label": "Anger"
    },
    {
        "body_part_token_idx": 12,
        "sentence_id": "235ba18e-bb8f-3f34-af84-3c2abd82fb45",
        "tokens": [
            "I",
            "ca",
            "n't",
            "imagine!",
            "He",
            "started",
            "to",
            "reply",
            "and",
            "then",
            "snapped",
            "his",
            "mouth",
            "shut",
            ",",
            "looking",
            "annoyed",
            "."
        ],
        "lemmatized_tokens": [
            "I",
            "can",
            "not",
            "imagine!",
            "he",
            "start",
            "to",
            "reply",
            "and",
            "then",
            "snap",
            "he",
            "mouth",
            "shut",
            ",",
            "look",
            "annoyed",
            "."
        ],
        "preceding_context_tokens": [
            [
                "My",
                "first",
                "me",
                ",",
                "before",
                "I",
                "ever",
                "regenerated",
                ",",
                "used",
                "to",
                "say",
                "hmmm",
                "all",
                "of",
                "the",
                "time",
                "."
            ],
            [
                "I",
                "could",
                "n't",
                "seem",
                "to",
                "stop",
                "myself.",
                "Rose",
                "chuckled",
                "."
            ],
            [
                "Could",
                "n't",
                "stop",
                "yourself",
                "?"
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "my",
                "first",
                "I",
                ",",
                "before",
                "I",
                "ever",
                "regenerate",
                ",",
                "use",
                "to",
                "say",
                "hmmm",
                "all",
                "of",
                "the",
                "time",
                "."
            ],
            [
                "I",
                "could",
                "not",
                "seem",
                "to",
                "stop",
                "myself.",
                "Rose",
                "chuckle",
                "."
            ],
            [
                "could",
                "not",
                "stop",
                "yourself",
                "?"
            ]
        ],
        "label": "Anger"
    },
    {
        "body_part_token_idx": 5,
        "sentence_id": "87321c90-5714-3b42-897d-10ec6a95804c",
        "tokens": [
            "Joanna",
            "nodded",
            ",",
            "biting",
            "her",
            "lip",
            "."
        ],
        "lemmatized_tokens": [
            "Joanna",
            "nod",
            ",",
            "bite",
            "she",
            "lip",
            "."
        ],
        "preceding_context_tokens": [
            [
                "Jo",
                "put",
                "her",
                "hand",
                "on",
                "his",
                "wrist",
                "."
            ],
            [
                "``",
                "Want",
                "to",
                "try",
                "these",
                "on",
                "?",
                "''"
            ],
            [
                "Lucifer",
                "barely",
                "made",
                "a",
                "sound",
                ",",
                "but",
                "his",
                "shoulders",
                "started",
                "to",
                "quake",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "Jo",
                "put",
                "she",
                "hand",
                "on",
                "he",
                "wrist",
                "."
            ],
            [
                "``",
                "want",
                "to",
                "try",
                "these",
                "on",
                "?",
                "''"
            ],
            [
                "Lucifer",
                "barely",
                "make",
                "a",
                "sound",
                ",",
                "but",
                "he",
                "shoulder",
                "start",
                "to",
                "quake",
                "."
            ]
        ],
        "label": "Fear"
    },
    {
        "body_part_token_idx": 3,
        "sentence_id": "c0af321a-2d0e-3895-a8f2-e096f73d13f2",
        "tokens": [
            "I",
            "covered",
            "my",
            "face",
            "with",
            "my",
            "hands",
            "."
        ],
        "lemmatized_tokens": [
            "I",
            "cover",
            "my",
            "face",
            "with",
            "my",
            "hand",
            "."
        ],
        "preceding_context_tokens": [
            [
                "I",
                "ca",
                "n't",
                ".",
                "''"
            ],
            [
                "``",
                "Yes",
                ",",
                "you",
                "can",
                ".",
                "''"
            ],
            [
                "He",
                "laughed",
                "a",
                "little",
                "again",
                ",",
                "moving",
                "back",
                "so",
                "I",
                "would",
                "have",
                "to",
                "pick",
                "my",
                "head",
                "up",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "I",
                "can",
                "not",
                ".",
                "''"
            ],
            [
                "``",
                "yes",
                ",",
                "you",
                "can",
                ".",
                "''"
            ],
            [
                "he",
                "laugh",
                "a",
                "little",
                "again",
                ",",
                "move",
                "back",
                "so",
                "I",
                "would",
                "have",
                "to",
                "pick",
                "my",
                "head",
                "up",
                "."
            ]
        ],
        "label": "Fear"
    },
    {
        "body_part_token_idx": 6,
        "sentence_id": "c0af321a-2d0e-3895-a8f2-e096f73d13f2",
        "tokens": [
            "I",
            "covered",
            "my",
            "face",
            "with",
            "my",
            "hands",
            "."
        ],
        "lemmatized_tokens": [
            "I",
            "cover",
            "my",
            "face",
            "with",
            "my",
            "hand",
            "."
        ],
        "preceding_context_tokens": [
            [
                "I",
                "ca",
                "n't",
                ".",
                "''"
            ],
            [
                "``",
                "Yes",
                ",",
                "you",
                "can",
                ".",
                "''"
            ],
            [
                "He",
                "laughed",
                "a",
                "little",
                "again",
                ",",
                "moving",
                "back",
                "so",
                "I",
                "would",
                "have",
                "to",
                "pick",
                "my",
                "head",
                "up",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "I",
                "can",
                "not",
                ".",
                "''"
            ],
            [
                "``",
                "yes",
                ",",
                "you",
                "can",
                ".",
                "''"
            ],
            [
                "he",
                "laugh",
                "a",
                "little",
                "again",
                ",",
                "move",
                "back",
                "so",
                "I",
                "would",
                "have",
                "to",
                "pick",
                "my",
                "head",
                "up",
                "."
            ]
        ],
        "label": "Fear"
    },
    {
        "body_part_token_idx": 11,
        "sentence_id": "8fe616e5-0d09-3d12-a046-39c470ac08d7",
        "tokens": [
            "``",
            "Warren",
            "''",
            "He",
            "said",
            "with",
            "a",
            "shaky",
            "voice",
            "and",
            "my",
            "face",
            "dropped",
            "."
        ],
        "lemmatized_tokens": [
            "``",
            "Warren",
            "''",
            "he",
            "say",
            "with",
            "a",
            "shaky",
            "voice",
            "and",
            "my",
            "face",
            "drop",
            "."
        ],
        "preceding_context_tokens": [
            [
                "I",
                "tried",
                "to",
                "comfort",
                "him",
                "as",
                "best",
                "I",
                "could",
                "until",
                "his",
                "sobs",
                "died",
                "down",
                "and",
                "he",
                "said",
                "something",
                "inaudible",
                "."
            ],
            [
                "``",
                "What",
                "?",
                "''"
            ],
            [
                "I",
                "asked",
                "while",
                "pushing",
                "him",
                "away",
                "until",
                "he",
                "was",
                "at",
                "arms",
                "length",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "I",
                "try",
                "to",
                "comfort",
                "he",
                "as",
                "best",
                "I",
                "could",
                "until",
                "he",
                "sob",
                "die",
                "down",
                "and",
                "he",
                "say",
                "something",
                "inaudible",
                "."
            ],
            [
                "``",
                "what",
                "?",
                "''"
            ],
            [
                "I",
                "ask",
                "while",
                "push",
                "he",
                "away",
                "until",
                "he",
                "be",
                "at",
                "arm",
                "length",
                "."
            ]
        ],
        "label": "Sadness"
    },
    {
        "body_part_token_idx": 17,
        "sentence_id": "c8b7c53f-3d98-3da8-937f-fb1887f88b35",
        "tokens": [
            "``",
            "Ah",
            ",",
            "but",
            "$",
            "the",
            "meeting",
            "is",
            "n't",
            "over",
            "yet",
            "$",
            "''",
            "Francis",
            "smiled",
            "over",
            "his",
            "shoulder",
            "."
        ],
        "lemmatized_tokens": [
            "``",
            "ah",
            ",",
            "but",
            "$",
            "the",
            "meeting",
            "be",
            "not",
            "over",
            "yet",
            "$",
            "''",
            "Francis",
            "smile",
            "over",
            "he",
            "shoulder",
            "."
        ],
        "preceding_context_tokens": [
            [
                "He",
                "paused",
                "after",
                "a",
                "moment",
                "however",
                ",",
                "and",
                "for",
                "once",
                "hesitated",
                "."
            ],
            [
                "He",
                "lowered",
                "the",
                "hand",
                ",",
                "squeezed",
                "it",
                "and",
                "lifted",
                "his",
                "other",
                "hand",
                "to",
                "pat",
                "at",
                "Matthew",
                "'s",
                "cheek",
                "."
            ],
            [
                "``",
                "Au",
                "revoir",
                ",",
                "''",
                "he",
                "said",
                ",",
                "still",
                "smiling",
                ",",
                "and",
                "made",
                "his",
                "exit",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "he",
                "pause",
                "after",
                "a",
                "moment",
                "however",
                ",",
                "and",
                "for",
                "once",
                "hesitate",
                "."
            ],
            [
                "he",
                "lower",
                "the",
                "hand",
                ",",
                "squeeze",
                "it",
                "and",
                "lift",
                "he",
                "other",
                "hand",
                "to",
                "pat",
                "at",
                "Matthew",
                "'s",
                "cheek",
                "."
            ],
            [
                "``",
                "au",
                "revoir",
                ",",
                "''",
                "he",
                "say",
                ",",
                "still",
                "smile",
                ",",
                "and",
                "make",
                "he",
                "exit",
                "."
            ]
        ],
        "label": "Joy"
    },
    {
        "body_part_token_idx": 10,
        "sentence_id": "401d09da-429d-3d75-98ad-6f5a4c8b31ea",
        "tokens": [
            "Cursing",
            "aloud",
            ",",
            "he",
            "swiped",
            "an",
            "impatient",
            "hand",
            "across",
            "his",
            "forehead",
            ",",
            "smearing",
            "grime",
            "across",
            "his",
            "already",
            "beaten",
            "face",
            ",",
            "and",
            "fixed",
            "dark",
            "eyes",
            "towards",
            "the",
            "horizon",
            "once",
            "again",
            "when",
            "the",
            "guns",
            "spoke",
            "in",
            "thunderous",
            "voices",
            "."
        ],
        "lemmatized_tokens": [
            "curse",
            "aloud",
            ",",
            "he",
            "swipe",
            "a",
            "impatient",
            "hand",
            "across",
            "he",
            "forehead",
            ",",
            "smear",
            "grime",
            "across",
            "he",
            "already",
            "beat",
            "face",
            ",",
            "and",
            "fix",
            "dark",
            "eye",
            "towards",
            "the",
            "horizon",
            "once",
            "again",
            "when",
            "the",
            "gun",
            "speak",
            "in",
            "thunderous",
            "voice",
            "."
        ],
        "preceding_context_tokens": [
            [
                "They",
                "moved",
                "as",
                "one",
                ",",
                "organised",
                ",",
                "quick",
                ",",
                "tidy",
                "."
            ],
            [
                "Up",
                "out",
                "of",
                "the",
                "coulee",
                "and",
                "to",
                "Custer",
                "."
            ],
            [
                "Captain",
                "Weir",
                "kicked",
                "at",
                "the",
                "dust",
                "at",
                "his",
                "feet",
                ",",
                "spluttering",
                "as",
                "he",
                "breathed",
                "it",
                "in",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "they",
                "move",
                "as",
                "one",
                ",",
                "organise",
                ",",
                "quick",
                ",",
                "tidy",
                "."
            ],
            [
                "up",
                "out",
                "of",
                "the",
                "coulee",
                "and",
                "to",
                "Custer",
                "."
            ],
            [
                "Captain",
                "Weir",
                "kick",
                "at",
                "the",
                "dust",
                "at",
                "he",
                "foot",
                ",",
                "splutter",
                "as",
                "he",
                "breathe",
                "it",
                "in",
                "."
            ]
        ],
        "label": "Anger"
    },
    {
        "body_part_token_idx": 1,
        "sentence_id": "f364724d-0969-33fd-8ca3-81f72bb4438d",
        "tokens": [
            "My",
            "heart",
            "jumped",
            "."
        ],
        "lemmatized_tokens": [
            "my",
            "heart",
            "jump",
            "."
        ],
        "preceding_context_tokens": [
            [
                "I",
                "stole",
                "my",
                "mom",
                "'s",
                "bank",
                "card",
                "and",
                "my",
                "dad",
                "'s",
                "car",
                "and",
                "went",
                "out",
                "to",
                "buy",
                "dope",
                "."
            ],
            [
                "They",
                "told",
                "me",
                "I",
                "could",
                "either",
                "leave",
                "or",
                "come",
                "to",
                "rehab",
                ".",
                "''"
            ],
            [
                "He",
                "looked",
                "down",
                "at",
                "his",
                "hands",
                ",",
                "almost",
                "embarrassed",
                ",",
                "laughed",
                "nervously",
                "and",
                "smiled",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "I",
                "steal",
                "my",
                "mom",
                "'s",
                "bank",
                "card",
                "and",
                "my",
                "dad",
                "'s",
                "car",
                "and",
                "go",
                "out",
                "to",
                "buy",
                "dope",
                "."
            ],
            [
                "they",
                "tell",
                "I",
                "I",
                "could",
                "either",
                "leave",
                "or",
                "come",
                "to",
                "rehab",
                ".",
                "''"
            ],
            [
                "he",
                "look",
                "down",
                "at",
                "he",
                "hand",
                ",",
                "almost",
                "embarrassed",
                ",",
                "laugh",
                "nervously",
                "and",
                "smile",
                "."
            ]
        ],
        "label": "Sadness"
    },
    {
        "body_part_token_idx": 5,
        "sentence_id": "d9948084-51fb-3448-8c80-2d423b71e65d",
        "tokens": [
            "Sam",
            "wants",
            "to",
            "roll",
            "his",
            "eyes",
            ",",
            "but",
            "he",
            "'s",
            "feeling",
            "less",
            "than",
            "solid",
            "right",
            "now",
            "and",
            "he",
            "just",
            "waves",
            "his",
            "brother",
            "in",
            "."
        ],
        "lemmatized_tokens": [
            "Sam",
            "want",
            "to",
            "roll",
            "he",
            "eye",
            ",",
            "but",
            "he",
            "be",
            "feel",
            "less",
            "than",
            "solid",
            "right",
            "now",
            "and",
            "he",
            "just",
            "wave",
            "he",
            "brother",
            "in",
            "."
        ],
        "preceding_context_tokens": [
            [
                "He",
                "wakes",
                "up",
                "with",
                "a",
                "gasp",
                ",",
                "swallowing",
                "great",
                "gulps",
                "of",
                "air",
                ",",
                "grimacing",
                "at",
                "the",
                "force",
                "of",
                "his",
                "breathing",
                "."
            ],
            [
                "Dean",
                "is",
                "hovering",
                "in",
                "the",
                "doorway",
                ",",
                "looking",
                "torn",
                "."
            ],
            [
                "He",
                "starts",
                "when",
                "Sam",
                "notices",
                "him",
                ",",
                "like",
                "a",
                "spooked",
                "cat",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "he",
                "wake",
                "up",
                "with",
                "a",
                "gasp",
                ",",
                "swallow",
                "great",
                "gulp",
                "of",
                "air",
                ",",
                "grimace",
                "at",
                "the",
                "force",
                "of",
                "he",
                "breathing",
                "."
            ],
            [
                "Dean",
                "be",
                "hover",
                "in",
                "the",
                "doorway",
                ",",
                "look",
                "tear",
                "."
            ],
            [
                "he",
                "start",
                "when",
                "Sam",
                "notice",
                "he",
                ",",
                "like",
                "a",
                "spook",
                "cat",
                "."
            ]
        ],
        "label": "Disgust"
    },
    {
        "body_part_token_idx": 3,
        "sentence_id": "0fbdb3b7-f8cb-3292-b14f-f0e29752cc7d",
        "tokens": [
            "Ruki",
            "cleared",
            "his",
            "throat",
            "."
        ],
        "lemmatized_tokens": [
            "Ruki",
            "clear",
            "he",
            "throat",
            "."
        ],
        "preceding_context_tokens": [
            [
                "``",
                "Well",
                ",",
                "Ruki",
                "was",
                "$",
                "I",
                "do",
                "n't",
                "know",
                "$",
                "eh",
                "$",
                ".",
                "''"
            ],
            [
                "Reita",
                "was",
                "n't",
                "sure",
                "what",
                "to",
                "say",
                "."
            ],
            [
                "``",
                "Do",
                "n't",
                "worry",
                "Rei",
                ",",
                "I",
                "'ll",
                "tell",
                "them",
                ".",
                "''"
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "``",
                "well",
                ",",
                "Ruki",
                "be",
                "$",
                "I",
                "do",
                "not",
                "know",
                "$",
                "eh",
                "$",
                ".",
                "''"
            ],
            [
                "Reita",
                "be",
                "not",
                "sure",
                "what",
                "to",
                "say",
                "."
            ],
            [
                "``",
                "do",
                "not",
                "worry",
                "Rei",
                ",",
                "I",
                "will",
                "tell",
                "they",
                ".",
                "''"
            ]
        ],
        "label": "Fear"
    },
    {
        "body_part_token_idx": 6,
        "sentence_id": "656e87ee-69cc-3cae-aabf-3e9c79d11d95",
        "tokens": [
            "Is",
            "something",
            "wrong?",
            "She",
            "shook",
            "her",
            "head",
            "."
        ],
        "lemmatized_tokens": [
            "be",
            "something",
            "wrong?",
            "she",
            "shake",
            "she",
            "head",
            "."
        ],
        "preceding_context_tokens": [
            [
                "I",
                "shall",
                "not",
                "keep",
                "you",
                "so",
                "late",
                "this",
                "night.",
                "He",
                "shook",
                "his",
                "head",
                "."
            ],
            [
                "Nay",
                ",",
                "I",
                "was",
                "simply",
                "busy",
                "."
            ],
            [
                "I",
                "I",
                "spoke",
                "to",
                "the",
                "Lady",
                "of",
                "the",
                "Wood.",
                "This",
                "time",
                "when",
                "Legolas",
                "'",
                "face",
                "paled",
                "Boromir",
                "noticed",
                "it",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "I",
                "shall",
                "not",
                "keep",
                "you",
                "so",
                "late",
                "this",
                "night.",
                "he",
                "shake",
                "he",
                "head",
                "."
            ],
            [
                "nay",
                ",",
                "I",
                "be",
                "simply",
                "busy",
                "."
            ],
            [
                "I",
                "I",
                "speak",
                "to",
                "the",
                "Lady",
                "of",
                "the",
                "Wood.",
                "this",
                "time",
                "when",
                "Legolas",
                "'",
                "face",
                "pale",
                "Boromir",
                "notice",
                "it",
                "."
            ]
        ],
        "label": "Fear"
    },
    {
        "body_part_token_idx": 1,
        "sentence_id": "22830de5-5a7c-31b0-83ac-93da47041115",
        "tokens": [
            "My",
            "heart",
            "beat",
            "so",
            "fast",
            "when",
            "the",
            "beautiful",
            "man",
            "give",
            "Yunho",
            "a",
            "peck",
            "on",
            "his",
            "left",
            "cheek",
            "."
        ],
        "lemmatized_tokens": [
            "my",
            "heart",
            "beat",
            "so",
            "fast",
            "when",
            "the",
            "beautiful",
            "man",
            "give",
            "Yunho",
            "a",
            "peck",
            "on",
            "he",
            "left",
            "cheek",
            "."
        ],
        "preceding_context_tokens": [
            [
                "He",
                "is",
                "Heechul",
                "??"
            ],
            [
                "I",
                "look",
                "at",
                "Yunho",
                "he",
                "smile",
                "sweetly",
                "at",
                "the",
                "man",
                "."
            ],
            [
                "I",
                "feel",
                "guilty",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "he",
                "be",
                "Heechul",
                "??"
            ],
            [
                "I",
                "look",
                "at",
                "Yunho",
                "he",
                "smile",
                "sweetly",
                "at",
                "the",
                "man",
                "."
            ],
            [
                "I",
                "feel",
                "guilty",
                "."
            ]
        ],
        "label": "Surprise"
    },
    {
        "body_part_token_idx": 16,
        "sentence_id": "badf1307-90a5-3e8d-8946-05019c60e8fb",
        "tokens": [
            "The",
            "bus",
            "is",
            "good",
            "enough",
            "today.",
            "I",
            "hate",
            "the",
            "bus",
            ",",
            "she",
            "whined",
            ",",
            "stopping",
            "her",
            "foot",
            "on",
            "the",
            "floor",
            "once",
            "again",
            "."
        ],
        "lemmatized_tokens": [
            "the",
            "bus",
            "be",
            "good",
            "enough",
            "today.",
            "I",
            "hate",
            "the",
            "bus",
            ",",
            "she",
            "whine",
            ",",
            "stop",
            "she",
            "foot",
            "on",
            "the",
            "floor",
            "once",
            "again",
            "."
        ],
        "preceding_context_tokens": [
            [
                "We",
                "'re",
                "not",
                "supposed",
                "to",
                "lie.",
                "Tell",
                "them",
                "I",
                "'m",
                "taking",
                "you",
                "tomorrow",
                "."
            ],
            [
                "Something",
                "came",
                "up",
                "."
            ],
            [
                "I",
                "'m",
                "sorry.",
                "I",
                "patted",
                "her",
                "on",
                "the",
                "head",
                "and",
                "lifted",
                "her",
                "chin",
                "so",
                "I",
                "could",
                "dry",
                "her",
                "eyes",
                "with",
                "my",
                "sleeve",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "we",
                "be",
                "not",
                "suppose",
                "to",
                "lie.",
                "tell",
                "they",
                "I",
                "be",
                "take",
                "you",
                "tomorrow",
                "."
            ],
            [
                "something",
                "come",
                "up",
                "."
            ],
            [
                "I",
                "be",
                "sorry.",
                "I",
                "pat",
                "she",
                "on",
                "the",
                "head",
                "and",
                "lift",
                "she",
                "chin",
                "so",
                "I",
                "could",
                "dry",
                "she",
                "eye",
                "with",
                "my",
                "sleeve",
                "."
            ]
        ],
        "label": "Disgust"
    },
    {
        "body_part_token_idx": 3,
        "sentence_id": "f21e1b63-0d5c-3a9f-aebe-7f0793b5c3ae",
        "tokens": [
            "I",
            "hung",
            "my",
            "head",
            "in",
            "shame",
            ",",
            "feeling",
            "like",
            "the",
            "lowest",
            "of",
            "mothers",
            "."
        ],
        "lemmatized_tokens": [
            "I",
            "hang",
            "my",
            "head",
            "in",
            "shame",
            ",",
            "feel",
            "like",
            "the",
            "lowest",
            "of",
            "mother",
            "."
        ],
        "preceding_context_tokens": [
            [
                "Then",
                "I",
                "felt",
                "horrible",
                "for",
                "my",
                "behavior",
                "."
            ],
            [
                "How",
                "could",
                "I",
                "have",
                "done",
                "that",
                "to",
                "my",
                "son",
                "!"
            ],
            [
                "He",
                "would",
                "probably",
                "be",
                "mortified",
                "with",
                "me",
                "now",
                ",",
                "and",
                "he",
                "would",
                "probably",
                "be",
                "made",
                "fun",
                "of",
                "the",
                "whole",
                "bus",
                "trip",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "then",
                "I",
                "feel",
                "horrible",
                "for",
                "my",
                "behavior",
                "."
            ],
            [
                "how",
                "could",
                "I",
                "have",
                "do",
                "that",
                "to",
                "my",
                "son",
                "!"
            ],
            [
                "he",
                "would",
                "probably",
                "be",
                "mortify",
                "with",
                "I",
                "now",
                ",",
                "and",
                "he",
                "would",
                "probably",
                "be",
                "make",
                "fun",
                "of",
                "the",
                "whole",
                "bus",
                "trip",
                "."
            ]
        ],
        "label": "Sadness"
    },
    {
        "body_part_token_idx": 12,
        "sentence_id": "11af517d-19e1-3a10-91a2-a5d6059a4ced",
        "tokens": [
            "Being",
            "a",
            "``",
            "part",
            "-",
            "time",
            "vampire",
            "''",
            ",",
            "hanging",
            "by",
            "my",
            "toes",
            "during",
            "the",
            "morning",
            "hours",
            "during",
            "vacation",
            ",",
            "I",
            "spent",
            "a",
            "few",
            "hours",
            "that",
            "early",
            "morning",
            "loading",
            "stuff",
            "."
        ],
        "lemmatized_tokens": [
            "be",
            "a",
            "``",
            "part",
            "-",
            "time",
            "vampire",
            "''",
            ",",
            "hang",
            "by",
            "my",
            "toe",
            "during",
            "the",
            "morning",
            "hour",
            "during",
            "vacation",
            ",",
            "I",
            "spend",
            "a",
            "few",
            "hour",
            "that",
            "early",
            "morning",
            "loading",
            "stuff",
            "."
        ],
        "preceding_context_tokens": [
            [
                "What",
                "is",
                "it",
                "about",
                "this",
                "cache",
                "and",
                "our",
                "refusal",
                "to",
                "give",
                "up",
                "?"
            ],
            [
                "Is",
                "it",
                "that",
                "the",
                "coordinates",
                "are",
                "still",
                "incorrect",
                "-LRB-",
                "the",
                "owner",
                "said",
                "that",
                "he",
                "changed",
                "them",
                ",",
                "but",
                "they",
                "look",
                "the",
                "same",
                "to",
                "me",
                ")",
                ",",
                "or",
                "are",
                "we",
                "just",
                "blind",
                "?"
            ],
            [
                "It",
                "probably",
                "would",
                "help",
                "if",
                "we",
                "went",
                "after",
                "it",
                "during",
                "daylight",
                "hours",
                "at",
                "some",
                "point.GG",
                "hands",
                "me",
                "her",
                "mp3",
                "before",
                "we",
                "part",
                "company",
                "for",
                "the",
                "evening",
                ",",
                "so",
                "I",
                "can",
                "load",
                "music",
                "onto",
                "it",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "what",
                "be",
                "it",
                "about",
                "this",
                "cache",
                "and",
                "we",
                "refusal",
                "to",
                "give",
                "up",
                "?"
            ],
            [
                "be",
                "it",
                "that",
                "the",
                "coordinate",
                "be",
                "still",
                "incorrect",
                "-lrb-",
                "the",
                "owner",
                "say",
                "that",
                "he",
                "change",
                "they",
                ",",
                "but",
                "they",
                "look",
                "the",
                "same",
                "to",
                "I",
                ")",
                ",",
                "or",
                "be",
                "we",
                "just",
                "blind",
                "?"
            ],
            [
                "it",
                "probably",
                "would",
                "help",
                "if",
                "we",
                "go",
                "after",
                "it",
                "during",
                "daylight",
                "hour",
                "at",
                "some",
                "point.gg",
                "hand",
                "I",
                "she",
                "mp3",
                "before",
                "we",
                "part",
                "company",
                "for",
                "the",
                "evening",
                ",",
                "so",
                "I",
                "can",
                "load",
                "music",
                "onto",
                "it",
                "."
            ]
        ],
        "label": "Fear"
    },
    {
        "body_part_token_idx": 1,
        "sentence_id": "3bd85b22-c20c-39c4-8ddd-14e3a62a4d9b",
        "tokens": [
            "My",
            "heart",
            "hurts",
            "from",
            "it",
            "and",
            "I",
            "have",
            "a",
            "headache",
            "."
        ],
        "lemmatized_tokens": [
            "my",
            "heart",
            "hurt",
            "from",
            "it",
            "and",
            "I",
            "have",
            "a",
            "headache",
            "."
        ],
        "preceding_context_tokens": [
            [
                "`",
                "Bout",
                "time",
                "I",
                "posted",
                "an",
                "entry",
                "and",
                "I",
                "finally",
                "have",
                "a",
                "reason.I",
                "'ve",
                "been",
                "feeling",
                "very",
                "unloved",
                "by",
                "everyone",
                "lately",
                "."
            ],
            [
                "Examples",
                ",",
                "parents",
                ",",
                "some",
                "friends",
                "...",
                "it",
                "'s",
                "not",
                "fun",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "`",
                "Bout",
                "time",
                "I",
                "post",
                "a",
                "entry",
                "and",
                "I",
                "finally",
                "have",
                "a",
                "reason.i",
                "have",
                "be",
                "feel",
                "very",
                "unloved",
                "by",
                "everyone",
                "lately",
                "."
            ],
            [
                "example",
                ",",
                "parent",
                ",",
                "some",
                "friend",
                "...",
                "it",
                "be",
                "not",
                "fun",
                "."
            ]
        ],
        "label": "Sadness"
    },
    {
        "body_part_token_idx": 8,
        "sentence_id": "a548a5b2-b29d-37cc-9500-9416c688e4f9",
        "tokens": [
            "It",
            "made",
            "me",
            "feel",
            "weird",
            ",",
            "like",
            "my",
            "stomach",
            "was",
            "tightening",
            "and",
            "I",
            "could",
            "feel",
            "that",
            "stupid",
            "blush",
            "again",
            "on",
            "the",
            "back",
            "of",
            "my",
            "neck",
            "and",
            "yet",
            "I",
            "could",
            "n't",
            "look",
            "away.I",
            "do",
            "n't",
            "know",
            "how",
            "long",
            "I",
            "stood",
            "there",
            ",",
            "staring",
            "into",
            "his",
            "eyes",
            "like",
            "that",
            "."
        ],
        "lemmatized_tokens": [
            "it",
            "make",
            "I",
            "feel",
            "weird",
            ",",
            "like",
            "my",
            "stomach",
            "be",
            "tighten",
            "and",
            "I",
            "could",
            "feel",
            "that",
            "stupid",
            "blush",
            "again",
            "on",
            "the",
            "back",
            "of",
            "my",
            "neck",
            "and",
            "yet",
            "I",
            "could",
            "not",
            "look",
            "away.i",
            "do",
            "not",
            "know",
            "how",
            "long",
            "I",
            "stand",
            "there",
            ",",
            "stare",
            "into",
            "he",
            "eye",
            "like",
            "that",
            "."
        ],
        "preceding_context_tokens": [
            [
                "He",
                "kept",
                "running",
                "his",
                "hand",
                "through",
                "my",
                "hair",
                "and",
                "I",
                "could",
                "n't",
                "deny",
                "that",
                "I",
                "liked",
                "it",
                "."
            ],
            [
                "His",
                "touch",
                "seemed",
                "to",
                "ease",
                "my",
                "embarrassment",
                "and",
                "the",
                "awkwardness",
                "I",
                "felt",
                "from",
                "being",
                "in",
                "a",
                "room",
                "full",
                "of",
                "people",
                "I",
                "did",
                "n't",
                "really",
                "know",
                "."
            ],
            [
                "I",
                "looked",
                "up",
                "then",
                "and",
                "saw",
                "that",
                "he",
                "was",
                "still",
                "staring",
                "at",
                "me",
                "in",
                "that",
                "way",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "he",
                "keep",
                "run",
                "he",
                "hand",
                "through",
                "my",
                "hair",
                "and",
                "I",
                "could",
                "not",
                "deny",
                "that",
                "I",
                "like",
                "it",
                "."
            ],
            [
                "he",
                "touch",
                "seem",
                "to",
                "ease",
                "my",
                "embarrassment",
                "and",
                "the",
                "awkwardness",
                "I",
                "feel",
                "from",
                "be",
                "in",
                "a",
                "room",
                "full",
                "of",
                "people",
                "I",
                "do",
                "not",
                "really",
                "know",
                "."
            ],
            [
                "I",
                "look",
                "up",
                "then",
                "and",
                "see",
                "that",
                "he",
                "be",
                "still",
                "stare",
                "at",
                "I",
                "in",
                "that",
                "way",
                "."
            ]
        ],
        "label": "Surprise"
    },
    {
        "body_part_token_idx": 24,
        "sentence_id": "a548a5b2-b29d-37cc-9500-9416c688e4f9",
        "tokens": [
            "It",
            "made",
            "me",
            "feel",
            "weird",
            ",",
            "like",
            "my",
            "stomach",
            "was",
            "tightening",
            "and",
            "I",
            "could",
            "feel",
            "that",
            "stupid",
            "blush",
            "again",
            "on",
            "the",
            "back",
            "of",
            "my",
            "neck",
            "and",
            "yet",
            "I",
            "could",
            "n't",
            "look",
            "away.I",
            "do",
            "n't",
            "know",
            "how",
            "long",
            "I",
            "stood",
            "there",
            ",",
            "staring",
            "into",
            "his",
            "eyes",
            "like",
            "that",
            "."
        ],
        "lemmatized_tokens": [
            "it",
            "make",
            "I",
            "feel",
            "weird",
            ",",
            "like",
            "my",
            "stomach",
            "be",
            "tighten",
            "and",
            "I",
            "could",
            "feel",
            "that",
            "stupid",
            "blush",
            "again",
            "on",
            "the",
            "back",
            "of",
            "my",
            "neck",
            "and",
            "yet",
            "I",
            "could",
            "not",
            "look",
            "away.i",
            "do",
            "not",
            "know",
            "how",
            "long",
            "I",
            "stand",
            "there",
            ",",
            "stare",
            "into",
            "he",
            "eye",
            "like",
            "that",
            "."
        ],
        "preceding_context_tokens": [
            [
                "He",
                "kept",
                "running",
                "his",
                "hand",
                "through",
                "my",
                "hair",
                "and",
                "I",
                "could",
                "n't",
                "deny",
                "that",
                "I",
                "liked",
                "it",
                "."
            ],
            [
                "His",
                "touch",
                "seemed",
                "to",
                "ease",
                "my",
                "embarrassment",
                "and",
                "the",
                "awkwardness",
                "I",
                "felt",
                "from",
                "being",
                "in",
                "a",
                "room",
                "full",
                "of",
                "people",
                "I",
                "did",
                "n't",
                "really",
                "know",
                "."
            ],
            [
                "I",
                "looked",
                "up",
                "then",
                "and",
                "saw",
                "that",
                "he",
                "was",
                "still",
                "staring",
                "at",
                "me",
                "in",
                "that",
                "way",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "he",
                "keep",
                "run",
                "he",
                "hand",
                "through",
                "my",
                "hair",
                "and",
                "I",
                "could",
                "not",
                "deny",
                "that",
                "I",
                "like",
                "it",
                "."
            ],
            [
                "he",
                "touch",
                "seem",
                "to",
                "ease",
                "my",
                "embarrassment",
                "and",
                "the",
                "awkwardness",
                "I",
                "feel",
                "from",
                "be",
                "in",
                "a",
                "room",
                "full",
                "of",
                "people",
                "I",
                "do",
                "not",
                "really",
                "know",
                "."
            ],
            [
                "I",
                "look",
                "up",
                "then",
                "and",
                "see",
                "that",
                "he",
                "be",
                "still",
                "stare",
                "at",
                "I",
                "in",
                "that",
                "way",
                "."
            ]
        ],
        "label": "Surprise"
    },
    {
        "body_part_token_idx": 18,
        "sentence_id": "41a3ceb9-7d79-3faa-b606-9e7b11897a5d",
        "tokens": [
            "I",
            "tried",
            "my",
            "best",
            "to",
            "keep",
            "my",
            "revulsion",
            "hidden",
            ",",
            "for",
            "things",
            "like",
            "that",
            "tend",
            "to",
            "turn",
            "my",
            "stomach",
            ",",
            "especially",
            "when",
            "the",
            "vendors",
            "claim",
            "that",
            "it",
            "is",
            "art",
            "."
        ],
        "lemmatized_tokens": [
            "I",
            "try",
            "my",
            "best",
            "to",
            "keep",
            "my",
            "revulsion",
            "hide",
            ",",
            "for",
            "thing",
            "like",
            "that",
            "tend",
            "to",
            "turn",
            "my",
            "stomach",
            ",",
            "especially",
            "when",
            "the",
            "vendor",
            "claim",
            "that",
            "it",
            "be",
            "art",
            "."
        ],
        "preceding_context_tokens": [
            [
                "Kinda",
                "hints",
                "that",
                "there",
                "really",
                "is",
                "n't",
                "much",
                "else",
                "to",
                "do",
                "in",
                "that",
                "town",
                "And",
                "there",
                "I",
                "was",
                ",",
                "strolling",
                "around",
                "by",
                "myself",
                ",",
                "looking",
                "around",
                "at",
                "the",
                "sites",
                "."
            ],
            [
                "Not",
                "much",
                ",",
                "as",
                "I",
                "'ve",
                "said",
                "before",
                ",",
                "so",
                "I",
                "moved",
                "off",
                "to",
                "the",
                "pub",
                "in",
                "the",
                "tourist",
                "square",
                "and",
                "decided",
                "to",
                "empty",
                "a",
                "few",
                "Black",
                "Labels",
                "down",
                "my",
                "throat",
                "."
            ],
            [
                "Two",
                "hours",
                "later",
                "the",
                "shops",
                "looked",
                "a",
                "little",
                "bit",
                "more",
                "interesting",
                "and",
                "I",
                "ended",
                "up",
                "strolling",
                ",",
                "albeit",
                "a",
                "bit",
                "erratically",
                ",",
                "through",
                "the",
                "small",
                "isles",
                "filled",
                "with",
                "expensive",
                "and",
                "mostly",
                "kitsch",
                "items",
                "for",
                "the",
                "more",
                "rustically",
                "inclined",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "Kinda",
                "hint",
                "that",
                "there",
                "really",
                "be",
                "not",
                "much",
                "else",
                "to",
                "do",
                "in",
                "that",
                "town",
                "and",
                "there",
                "I",
                "be",
                ",",
                "stroll",
                "around",
                "by",
                "myself",
                ",",
                "look",
                "around",
                "at",
                "the",
                "site",
                "."
            ],
            [
                "not",
                "much",
                ",",
                "as",
                "I",
                "have",
                "say",
                "before",
                ",",
                "so",
                "I",
                "move",
                "off",
                "to",
                "the",
                "pub",
                "in",
                "the",
                "tourist",
                "square",
                "and",
                "decide",
                "to",
                "empty",
                "a",
                "few",
                "black",
                "label",
                "down",
                "my",
                "throat",
                "."
            ],
            [
                "two",
                "hour",
                "later",
                "the",
                "shop",
                "look",
                "a",
                "little",
                "bit",
                "more",
                "interesting",
                "and",
                "I",
                "end",
                "up",
                "stroll",
                ",",
                "albeit",
                "a",
                "bit",
                "erratically",
                ",",
                "through",
                "the",
                "small",
                "isle",
                "fill",
                "with",
                "expensive",
                "and",
                "mostly",
                "kitsch",
                "item",
                "for",
                "the",
                "more",
                "rustically",
                "incline",
                "."
            ]
        ],
        "label": "Disgust"
    },
    {
        "body_part_token_idx": 19,
        "sentence_id": "05906510-80d9-3bc7-ae3f-0ba14e850ed7",
        "tokens": [
            "He",
            "is",
            "able",
            "to",
            "move",
            "around",
            "and",
            "grab",
            "the",
            "different",
            "rings",
            ",",
            "and",
            "when",
            "he",
            "does",
            "he",
            "kicks",
            "his",
            "legs",
            "up",
            "into",
            "the",
            "air",
            "with",
            "excitement",
            "."
        ],
        "lemmatized_tokens": [
            "he",
            "be",
            "able",
            "to",
            "move",
            "around",
            "and",
            "grab",
            "the",
            "different",
            "ring",
            ",",
            "and",
            "when",
            "he",
            "do",
            "he",
            "kick",
            "he",
            "leg",
            "up",
            "into",
            "the",
            "air",
            "with",
            "excitement",
            "."
        ],
        "preceding_context_tokens": [
            [
                "I",
                "will",
                "take",
                "``",
                "Super",
                "Awesome",
                "''",
                "any",
                "day",
                "."
            ],
            [
                "Tater",
                "is",
                "down",
                "for",
                "his",
                "second",
                "nap",
                "of",
                "the",
                "day",
                ",",
                "but",
                "he",
                "had",
                "some",
                "really",
                "great",
                "playtime",
                "beforehand",
                "."
            ],
            [
                "He",
                "is",
                "loving",
                "his",
                "little",
                "playmat",
                "that",
                "has",
                "all",
                "kinds",
                "of",
                "rings",
                "and",
                "toys",
                "dangling",
                "down",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "I",
                "will",
                "take",
                "``",
                "super",
                "awesome",
                "''",
                "any",
                "day",
                "."
            ],
            [
                "Tater",
                "be",
                "down",
                "for",
                "he",
                "second",
                "nap",
                "of",
                "the",
                "day",
                ",",
                "but",
                "he",
                "have",
                "some",
                "really",
                "great",
                "playtime",
                "beforehand",
                "."
            ],
            [
                "he",
                "be",
                "love",
                "he",
                "little",
                "playmat",
                "that",
                "have",
                "all",
                "kind",
                "of",
                "ring",
                "and",
                "toy",
                "dangle",
                "down",
                "."
            ]
        ],
        "label": "Surprise"
    },
    {
        "body_part_token_idx": 9,
        "sentence_id": "75c12076-0799-3b5d-9b7b-7a0b3866b4f5",
        "tokens": [
            "When",
            "it",
            "was",
            "pointed",
            "out",
            "to",
            "him",
            ",",
            "his",
            "eyes",
            "lit",
            "up",
            "and",
            "he",
            "ran",
            "to",
            "Bob",
            ",",
            "saying",
            ",",
            "``",
            "Look",
            "Daddy",
            ",",
            "you",
            "got",
            "the",
            "bike",
            "you",
            "wanted",
            "!",
            "''"
        ],
        "lemmatized_tokens": [
            "when",
            "it",
            "be",
            "point",
            "out",
            "to",
            "he",
            ",",
            "he",
            "eye",
            "light",
            "up",
            "and",
            "he",
            "run",
            "to",
            "Bob",
            ",",
            "say",
            ",",
            "``",
            "look",
            "daddy",
            ",",
            "you",
            "get",
            "the",
            "bike",
            "you",
            "want",
            "!",
            "''"
        ],
        "preceding_context_tokens": [
            [
                "We",
                "had",
                "enough",
                "seating",
                "Christmas",
                "morning",
                "and",
                "Mac",
                "was",
                "the",
                "facilitator",
                ",",
                "handing",
                "out",
                "presents",
                "to",
                "everyone",
                "after",
                "reading",
                "the",
                "tags",
                "."
            ],
            [
                "It",
                "was",
                "fun",
                "to",
                "see",
                "him",
                "read",
                "a",
                "tag",
                "that",
                "said",
                "``",
                "Mom",
                "''",
                "and",
                "then",
                "hand",
                "it",
                "to",
                "me",
                "...",
                "I",
                "was",
                "n't",
                "the",
                "only",
                "Mom",
                "in",
                "the",
                "room",
                "and",
                "sometimes",
                "had",
                "to",
                "redirect",
                "."
            ],
            [
                "Mac",
                "also",
                "walked",
                "right",
                "past",
                "the",
                "bike",
                "that",
                "was",
                "left",
                ",",
                "unwrapped",
                ",",
                "in",
                "the",
                "middle",
                "of",
                "the",
                "dining",
                "room",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "we",
                "have",
                "enough",
                "seating",
                "Christmas",
                "morning",
                "and",
                "Mac",
                "be",
                "the",
                "facilitator",
                ",",
                "hand",
                "out",
                "present",
                "to",
                "everyone",
                "after",
                "read",
                "the",
                "tag",
                "."
            ],
            [
                "it",
                "be",
                "fun",
                "to",
                "see",
                "he",
                "read",
                "a",
                "tag",
                "that",
                "say",
                "``",
                "mom",
                "''",
                "and",
                "then",
                "hand",
                "it",
                "to",
                "I",
                "...",
                "I",
                "be",
                "not",
                "the",
                "only",
                "mom",
                "in",
                "the",
                "room",
                "and",
                "sometimes",
                "have",
                "to",
                "redirect",
                "."
            ],
            [
                "Mac",
                "also",
                "walk",
                "right",
                "past",
                "the",
                "bike",
                "that",
                "be",
                "leave",
                ",",
                "unwrapped",
                ",",
                "in",
                "the",
                "middle",
                "of",
                "the",
                "dining",
                "room",
                "."
            ]
        ],
        "label": "Surprise"
    },
    {
        "body_part_token_idx": 11,
        "sentence_id": "0e531db4-aa07-32c1-ad2c-509a07fbcb6e",
        "tokens": [
            "He",
            "did",
            "n't",
            "bother",
            "to",
            "hide",
            "the",
            "tears",
            "forming",
            "in",
            "his",
            "eyes",
            "."
        ],
        "lemmatized_tokens": [
            "he",
            "do",
            "not",
            "bother",
            "to",
            "hide",
            "the",
            "tear",
            "form",
            "in",
            "he",
            "eye",
            "."
        ],
        "preceding_context_tokens": [
            [
                "The",
                "boy",
                "frowned",
                "."
            ],
            [
                "``",
                "No",
                "."
            ],
            [
                "I",
                "'m",
                "not",
                "going",
                "anywhere",
                "without",
                "you",
                ".",
                "''"
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "the",
                "boy",
                "frown",
                "."
            ],
            [
                "``",
                "no",
                "."
            ],
            [
                "I",
                "be",
                "not",
                "go",
                "anywhere",
                "without",
                "you",
                ".",
                "''"
            ]
        ],
        "label": "Fear"
    },
    {
        "body_part_token_idx": 16,
        "sentence_id": "9d1981c3-6c96-33e7-bc43-8cbc7e583c9f",
        "tokens": [
            "His",
            "grip",
            "around",
            "his",
            "pen",
            "and",
            "notebook",
            "tightened",
            "until",
            "the",
            "metal",
            "binding",
            "pressed",
            "painfully",
            "against",
            "his",
            "palm",
            "."
        ],
        "lemmatized_tokens": [
            "he",
            "grip",
            "around",
            "he",
            "pen",
            "and",
            "notebook",
            "tighten",
            "until",
            "the",
            "metal",
            "binding",
            "press",
            "painfully",
            "against",
            "he",
            "palm",
            "."
        ],
        "preceding_context_tokens": [
            [
                "It",
                "was",
                "getting",
                "late",
                "and",
                "he",
                "should",
                "probably",
                "head",
                "home",
                "soon",
                "."
            ],
            [
                "His",
                "expression",
                "became",
                "downcast",
                "at",
                "the",
                "thought",
                "."
            ],
            [
                "I",
                "wonder",
                "if",
                "mom",
                "'s",
                "okay",
                "today",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "it",
                "be",
                "get",
                "late",
                "and",
                "he",
                "should",
                "probably",
                "head",
                "home",
                "soon",
                "."
            ],
            [
                "he",
                "expression",
                "become",
                "downcast",
                "at",
                "the",
                "thought",
                "."
            ],
            [
                "I",
                "wonder",
                "if",
                "mom",
                "'s",
                "okay",
                "today",
                "."
            ]
        ],
        "label": "Fear"
    },
    {
        "body_part_token_idx": 3,
        "sentence_id": "72af2cb1-9ca4-388c-95d1-68915b52c8c3",
        "tokens": [
            "He",
            "sunk",
            "his",
            "head",
            "down",
            "and",
            "walked",
            "away",
            ",",
            "never",
            "to",
            "say",
            "another",
            "word",
            "to",
            "me",
            "the",
            "rest",
            "of",
            "the",
            "party",
            "."
        ],
        "lemmatized_tokens": [
            "he",
            "sink",
            "he",
            "head",
            "down",
            "and",
            "walk",
            "away",
            ",",
            "never",
            "to",
            "say",
            "another",
            "word",
            "to",
            "I",
            "the",
            "rest",
            "of",
            "the",
            "party",
            "."
        ],
        "preceding_context_tokens": [
            [
                "I",
                "'m",
                "not",
                "going",
                "to",
                "risk",
                "it",
                "."
            ],
            [
                "I",
                "probably",
                "could",
                "have",
                "said",
                "`",
                "I",
                "'m",
                "not",
                "going",
                "to",
                "shake",
                "hands",
                "'",
                "instead",
                ",",
                "but",
                "I",
                "was",
                "so",
                "grossed",
                "out",
                "that",
                "he",
                "was",
                "that",
                "close",
                "to",
                "me",
                "that",
                "all",
                "I",
                "was",
                "thinking",
                "about",
                "was",
                "the",
                "personal",
                "space",
                "that",
                "he",
                "was",
                "invading",
                "."
            ],
            [
                "His",
                "reaction",
                "was",
                "exactly",
                "as",
                "I",
                "had",
                "hoped",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "I",
                "be",
                "not",
                "go",
                "to",
                "risk",
                "it",
                "."
            ],
            [
                "I",
                "probably",
                "could",
                "have",
                "say",
                "`",
                "I",
                "be",
                "not",
                "go",
                "to",
                "shake",
                "hand",
                "'",
                "instead",
                ",",
                "but",
                "I",
                "be",
                "so",
                "gross",
                "out",
                "that",
                "he",
                "be",
                "that",
                "close",
                "to",
                "I",
                "that",
                "all",
                "I",
                "be",
                "think",
                "about",
                "be",
                "the",
                "personal",
                "space",
                "that",
                "he",
                "be",
                "invade",
                "."
            ],
            [
                "he",
                "reaction",
                "be",
                "exactly",
                "as",
                "I",
                "have",
                "hope",
                "."
            ]
        ],
        "label": "Sadness"
    },
    {
        "body_part_token_idx": 1,
        "sentence_id": "2a6baf13-67a8-3305-a408-a5c9246c7bc1",
        "tokens": [
            "His",
            "face",
            "was",
            "composed",
            ",",
            "but",
            "his",
            "eyes",
            "were",
            "just",
            "as",
            "enraged",
            "as",
            "Caspian",
            "'s",
            "."
        ],
        "lemmatized_tokens": [
            "he",
            "face",
            "be",
            "compose",
            ",",
            "but",
            "he",
            "eye",
            "be",
            "just",
            "as",
            "enrage",
            "as",
            "Caspian",
            "'s",
            "."
        ],
        "preceding_context_tokens": [
            [
                "The",
                "younger",
                "council",
                "member",
                "spoke",
                "up",
                "once",
                "again",
                ",",
                "eyeing",
                "both",
                "Caspian",
                "and",
                "Glozelle",
                "with",
                "distain",
                "."
            ],
            [
                "A",
                "heavily",
                "silence",
                "formed",
                "in",
                "the",
                "large",
                "room",
                ",",
                "both",
                "Caspian",
                "and",
                "the",
                "outspoken",
                "Lord",
                "glaring",
                "at",
                "the",
                "other",
                "while",
                "the",
                "room",
                "'s",
                "other",
                "inhabitants",
                "were",
                "torn",
                "between",
                "observing",
                "the",
                "two",
                "."
            ],
            [
                "Before",
                "either",
                "youth",
                "could",
                "utter",
                "another",
                "argument",
                ",",
                "Glozelle",
                "strolled",
                "forward",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "the",
                "younger",
                "council",
                "member",
                "speak",
                "up",
                "once",
                "again",
                ",",
                "eye",
                "both",
                "Caspian",
                "and",
                "Glozelle",
                "with",
                "distain",
                "."
            ],
            [
                "a",
                "heavily",
                "silence",
                "form",
                "in",
                "the",
                "large",
                "room",
                ",",
                "both",
                "Caspian",
                "and",
                "the",
                "outspoken",
                "Lord",
                "glare",
                "at",
                "the",
                "other",
                "while",
                "the",
                "room",
                "'s",
                "other",
                "inhabitant",
                "be",
                "tear",
                "between",
                "observe",
                "the",
                "two",
                "."
            ],
            [
                "before",
                "either",
                "youth",
                "could",
                "utter",
                "another",
                "argument",
                ",",
                "Glozelle",
                "stroll",
                "forward",
                "."
            ]
        ],
        "label": "Anger"
    },
    {
        "body_part_token_idx": 7,
        "sentence_id": "2a6baf13-67a8-3305-a408-a5c9246c7bc1",
        "tokens": [
            "His",
            "face",
            "was",
            "composed",
            ",",
            "but",
            "his",
            "eyes",
            "were",
            "just",
            "as",
            "enraged",
            "as",
            "Caspian",
            "'s",
            "."
        ],
        "lemmatized_tokens": [
            "he",
            "face",
            "be",
            "compose",
            ",",
            "but",
            "he",
            "eye",
            "be",
            "just",
            "as",
            "enrage",
            "as",
            "Caspian",
            "'s",
            "."
        ],
        "preceding_context_tokens": [
            [
                "The",
                "younger",
                "council",
                "member",
                "spoke",
                "up",
                "once",
                "again",
                ",",
                "eyeing",
                "both",
                "Caspian",
                "and",
                "Glozelle",
                "with",
                "distain",
                "."
            ],
            [
                "A",
                "heavily",
                "silence",
                "formed",
                "in",
                "the",
                "large",
                "room",
                ",",
                "both",
                "Caspian",
                "and",
                "the",
                "outspoken",
                "Lord",
                "glaring",
                "at",
                "the",
                "other",
                "while",
                "the",
                "room",
                "'s",
                "other",
                "inhabitants",
                "were",
                "torn",
                "between",
                "observing",
                "the",
                "two",
                "."
            ],
            [
                "Before",
                "either",
                "youth",
                "could",
                "utter",
                "another",
                "argument",
                ",",
                "Glozelle",
                "strolled",
                "forward",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "the",
                "younger",
                "council",
                "member",
                "speak",
                "up",
                "once",
                "again",
                ",",
                "eye",
                "both",
                "Caspian",
                "and",
                "Glozelle",
                "with",
                "distain",
                "."
            ],
            [
                "a",
                "heavily",
                "silence",
                "form",
                "in",
                "the",
                "large",
                "room",
                ",",
                "both",
                "Caspian",
                "and",
                "the",
                "outspoken",
                "Lord",
                "glare",
                "at",
                "the",
                "other",
                "while",
                "the",
                "room",
                "'s",
                "other",
                "inhabitant",
                "be",
                "tear",
                "between",
                "observe",
                "the",
                "two",
                "."
            ],
            [
                "before",
                "either",
                "youth",
                "could",
                "utter",
                "another",
                "argument",
                ",",
                "Glozelle",
                "stroll",
                "forward",
                "."
            ]
        ],
        "label": "Anger"
    },
    {
        "body_part_token_idx": 1,
        "sentence_id": "7a6f7662-8c37-3cd3-9c1c-c776bb09ec32",
        "tokens": [
            "my",
            "stomach",
            "is",
            "all",
            "out",
            "of",
            "whack",
            "."
        ],
        "lemmatized_tokens": [
            "my",
            "stomach",
            "be",
            "all",
            "out",
            "of",
            "whack",
            "."
        ],
        "preceding_context_tokens": [
            [
                "i",
                "write",
                "short",
                "entries",
                "."
            ],
            [
                "for",
                "some",
                "reason",
                "i",
                "have",
                "n't",
                "been",
                "feeling",
                "like",
                "myself",
                "."
            ],
            [
                "not",
                "only",
                "am",
                "i",
                "depressed",
                "and",
                "overly",
                "-",
                "emotional",
                "for",
                "no",
                "apparent",
                "reason",
                ",",
                "i",
                "have",
                "been",
                "feeling",
                "kind",
                "of",
                "under",
                "the",
                "weather",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "i",
                "write",
                "short",
                "entry",
                "."
            ],
            [
                "for",
                "some",
                "reason",
                "i",
                "have",
                "not",
                "be",
                "feel",
                "like",
                "myself",
                "."
            ],
            [
                "not",
                "only",
                "be",
                "i",
                "depressed",
                "and",
                "overly",
                "-",
                "emotional",
                "for",
                "no",
                "apparent",
                "reason",
                ",",
                "i",
                "have",
                "be",
                "feel",
                "kind",
                "of",
                "under",
                "the",
                "weather",
                "."
            ]
        ],
        "label": "Sadness"
    },
    {
        "body_part_token_idx": 12,
        "sentence_id": "94c28df4-5e1c-31d5-b6c9-ff68aa184887",
        "tokens": [
            "So",
            ",",
            "again",
            ",",
            "I",
            "tried",
            "to",
            "eat",
            "my",
            "lunch",
            ",",
            "my",
            "stomach",
            "in",
            "knots",
            ",",
            "an",
            "unseen",
            "hand",
            "gripping",
            "my",
            "heart",
            "."
        ],
        "lemmatized_tokens": [
            "so",
            ",",
            "again",
            ",",
            "I",
            "try",
            "to",
            "eat",
            "my",
            "lunch",
            ",",
            "my",
            "stomach",
            "in",
            "knot",
            ",",
            "a",
            "unseen",
            "hand",
            "grip",
            "my",
            "heart",
            "."
        ],
        "preceding_context_tokens": [
            [
                "Did",
                "this",
                "woman",
                "'s",
                "behavior",
                "warrant",
                "intervention",
                ",",
                "yet",
                "?"
            ],
            [
                "I",
                "thought",
                "it",
                "did",
                ",",
                "but",
                "had",
                "no",
                "idea",
                "how",
                "to",
                "go",
                "about",
                "it",
                "."
            ],
            [
                "My",
                "mind",
                "raced",
                "through",
                "some",
                "possible",
                "scenarios",
                ",",
                "and",
                "not",
                "one",
                "of",
                "them",
                "looked",
                "good",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "do",
                "this",
                "woman",
                "'s",
                "behavior",
                "warrant",
                "intervention",
                ",",
                "yet",
                "?"
            ],
            [
                "I",
                "think",
                "it",
                "do",
                ",",
                "but",
                "have",
                "no",
                "idea",
                "how",
                "to",
                "go",
                "about",
                "it",
                "."
            ],
            [
                "my",
                "mind",
                "race",
                "through",
                "some",
                "possible",
                "scenario",
                ",",
                "and",
                "not",
                "one",
                "of",
                "they",
                "look",
                "good",
                "."
            ]
        ],
        "label": "Fear"
    },
    {
        "body_part_token_idx": 21,
        "sentence_id": "94c28df4-5e1c-31d5-b6c9-ff68aa184887",
        "tokens": [
            "So",
            ",",
            "again",
            ",",
            "I",
            "tried",
            "to",
            "eat",
            "my",
            "lunch",
            ",",
            "my",
            "stomach",
            "in",
            "knots",
            ",",
            "an",
            "unseen",
            "hand",
            "gripping",
            "my",
            "heart",
            "."
        ],
        "lemmatized_tokens": [
            "so",
            ",",
            "again",
            ",",
            "I",
            "try",
            "to",
            "eat",
            "my",
            "lunch",
            ",",
            "my",
            "stomach",
            "in",
            "knot",
            ",",
            "a",
            "unseen",
            "hand",
            "grip",
            "my",
            "heart",
            "."
        ],
        "preceding_context_tokens": [
            [
                "Did",
                "this",
                "woman",
                "'s",
                "behavior",
                "warrant",
                "intervention",
                ",",
                "yet",
                "?"
            ],
            [
                "I",
                "thought",
                "it",
                "did",
                ",",
                "but",
                "had",
                "no",
                "idea",
                "how",
                "to",
                "go",
                "about",
                "it",
                "."
            ],
            [
                "My",
                "mind",
                "raced",
                "through",
                "some",
                "possible",
                "scenarios",
                ",",
                "and",
                "not",
                "one",
                "of",
                "them",
                "looked",
                "good",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "do",
                "this",
                "woman",
                "'s",
                "behavior",
                "warrant",
                "intervention",
                ",",
                "yet",
                "?"
            ],
            [
                "I",
                "think",
                "it",
                "do",
                ",",
                "but",
                "have",
                "no",
                "idea",
                "how",
                "to",
                "go",
                "about",
                "it",
                "."
            ],
            [
                "my",
                "mind",
                "race",
                "through",
                "some",
                "possible",
                "scenario",
                ",",
                "and",
                "not",
                "one",
                "of",
                "they",
                "look",
                "good",
                "."
            ]
        ],
        "label": "Fear"
    },
    {
        "body_part_token_idx": 5,
        "sentence_id": "b7af762b-2ad4-35ad-8984-9035d37da21b",
        "tokens": [
            "There",
            "were",
            "tears",
            "in",
            "his",
            "eyes",
            "."
        ],
        "lemmatized_tokens": [
            "there",
            "be",
            "tear",
            "in",
            "he",
            "eye",
            "."
        ],
        "preceding_context_tokens": [
            [
                "I",
                "told",
                "him",
                "I",
                "tolded",
                "Fred",
                "and",
                "cried",
                "some",
                "more",
                "."
            ],
            [
                "He",
                "held",
                "me",
                "some",
                "more",
                "and",
                "then",
                "we",
                "heard",
                "a",
                "voice",
                ",",
                "Fred",
                "'s",
                "voice",
                ",",
                "at",
                "the",
                "bottom",
                "of",
                "the",
                "stairs",
                "."
            ],
            [
                "Fred",
                "took",
                "the",
                "stairs",
                "two",
                "at",
                "a",
                "time",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "I",
                "tell",
                "he",
                "I",
                "told",
                "Fred",
                "and",
                "cry",
                "some",
                "more",
                "."
            ],
            [
                "he",
                "hold",
                "I",
                "some",
                "more",
                "and",
                "then",
                "we",
                "hear",
                "a",
                "voice",
                ",",
                "Fred",
                "'s",
                "voice",
                ",",
                "at",
                "the",
                "bottom",
                "of",
                "the",
                "stair",
                "."
            ],
            [
                "Fred",
                "take",
                "the",
                "stair",
                "two",
                "at",
                "a",
                "time",
                "."
            ]
        ],
        "label": "Sadness"
    },
    {
        "body_part_token_idx": 30,
        "sentence_id": "b433bc52-7437-3f5d-b5d5-a7fb1cfd5b25",
        "tokens": [
            "I",
            "witnessed",
            "as",
            "the",
            "age",
            "old",
            "rock",
            "tradition",
            "of",
            "holding",
            "up",
            "lighters",
            "spread",
            "across",
            "the",
            "28,000",
            "person",
            "deep",
            "crowd",
            "...",
            "lighting",
            "up",
            "the",
            "entire",
            "audience",
            "...",
            "the",
            "hair",
            "on",
            "my",
            "arms",
            "started",
            "to",
            "raise",
            "until",
            "I",
            "noticed",
            "that",
            "...",
            "."
        ],
        "lemmatized_tokens": [
            "I",
            "witness",
            "as",
            "the",
            "age",
            "old",
            "rock",
            "tradition",
            "of",
            "hold",
            "up",
            "lighter",
            "spread",
            "across",
            "the",
            "28,000",
            "person",
            "deep",
            "crowd",
            "...",
            "light",
            "up",
            "the",
            "entire",
            "audience",
            "...",
            "the",
            "hair",
            "on",
            "my",
            "arm",
            "start",
            "to",
            "raise",
            "until",
            "I",
            "notice",
            "that",
            "...",
            "."
        ],
        "preceding_context_tokens": [
            [
                "-LRB-",
                "and",
                "then",
                "I",
                "had",
                "blood",
                "on",
                "my",
                "$",
                "30",
                "concert",
                "poster",
                "too",
                "!!!!",
                ")"
            ],
            [
                "But",
                "...",
                "...",
                "...",
                "...",
                "there",
                "was",
                "a",
                "moment",
                "that",
                "served",
                "as",
                "a",
                "perfect",
                "analogy",
                "for",
                "the",
                "evening",
                "...",
                "."
            ],
            [
                "When",
                "the",
                "first",
                "few",
                "bars",
                "of",
                "``",
                "Idioteque",
                "''",
                "started",
                "...",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "-lrb-",
                "and",
                "then",
                "I",
                "have",
                "blood",
                "on",
                "my",
                "$",
                "30",
                "concert",
                "poster",
                "too",
                "!!!!",
                ")"
            ],
            [
                "but",
                "...",
                "...",
                "...",
                "...",
                "there",
                "be",
                "a",
                "moment",
                "that",
                "serve",
                "as",
                "a",
                "perfect",
                "analogy",
                "for",
                "the",
                "evening",
                "...",
                "."
            ],
            [
                "when",
                "the",
                "first",
                "few",
                "bar",
                "of",
                "``",
                "Idioteque",
                "''",
                "start",
                "...",
                "."
            ]
        ],
        "label": "Surprise"
    },
    {
        "body_part_token_idx": 5,
        "sentence_id": "6f49956f-1212-3c1e-b916-76c401fc018a",
        "tokens": [
            "Meg",
            "smiled",
            "and",
            "cocked",
            "her",
            "head",
            "to",
            "the",
            "side",
            "."
        ],
        "lemmatized_tokens": [
            "Meg",
            "smile",
            "and",
            "cocked",
            "she",
            "head",
            "to",
            "the",
            "side",
            "."
        ],
        "preceding_context_tokens": [
            [
                "Tall",
                "?"
            ],
            [
                "Dark",
                "?"
            ],
            [
                "Handsome",
                "?",
                "''"
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "Tall",
                "?"
            ],
            [
                "Dark",
                "?"
            ],
            [
                "Handsome",
                "?",
                "''"
            ]
        ],
        "label": "Joy"
    },
    {
        "body_part_token_idx": 1,
        "sentence_id": "4eef9e8f-c10b-33c0-81f1-8e3fa6aeff4d",
        "tokens": [
            "His",
            "hands",
            "were",
            "tightly",
            "clenched",
            ",",
            "and",
            "his",
            "head",
            "was",
            "down",
            "."
        ],
        "lemmatized_tokens": [
            "he",
            "hand",
            "be",
            "tightly",
            "clench",
            ",",
            "and",
            "he",
            "head",
            "be",
            "down",
            "."
        ],
        "preceding_context_tokens": [
            [
                "``",
                "I",
                "have",
                "to",
                "go",
                "."
            ],
            [
                "It",
                "'s",
                "all",
                "right",
                ".",
                "''"
            ],
            [
                "But",
                "the",
                "young",
                "senior",
                "turned",
                "without",
                "a",
                "word",
                "and",
                "began",
                "heading",
                "toward",
                "the",
                "school",
                "gates",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "``",
                "I",
                "have",
                "to",
                "go",
                "."
            ],
            [
                "it",
                "be",
                "all",
                "right",
                ".",
                "''"
            ],
            [
                "but",
                "the",
                "young",
                "senior",
                "turn",
                "without",
                "a",
                "word",
                "and",
                "begin",
                "head",
                "toward",
                "the",
                "school",
                "gate",
                "."
            ]
        ],
        "label": "Anger"
    },
    {
        "body_part_token_idx": 8,
        "sentence_id": "4eef9e8f-c10b-33c0-81f1-8e3fa6aeff4d",
        "tokens": [
            "His",
            "hands",
            "were",
            "tightly",
            "clenched",
            ",",
            "and",
            "his",
            "head",
            "was",
            "down",
            "."
        ],
        "lemmatized_tokens": [
            "he",
            "hand",
            "be",
            "tightly",
            "clench",
            ",",
            "and",
            "he",
            "head",
            "be",
            "down",
            "."
        ],
        "preceding_context_tokens": [
            [
                "``",
                "I",
                "have",
                "to",
                "go",
                "."
            ],
            [
                "It",
                "'s",
                "all",
                "right",
                ".",
                "''"
            ],
            [
                "But",
                "the",
                "young",
                "senior",
                "turned",
                "without",
                "a",
                "word",
                "and",
                "began",
                "heading",
                "toward",
                "the",
                "school",
                "gates",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "``",
                "I",
                "have",
                "to",
                "go",
                "."
            ],
            [
                "it",
                "be",
                "all",
                "right",
                ".",
                "''"
            ],
            [
                "but",
                "the",
                "young",
                "senior",
                "turn",
                "without",
                "a",
                "word",
                "and",
                "begin",
                "head",
                "toward",
                "the",
                "school",
                "gate",
                "."
            ]
        ],
        "label": "Anger"
    },
    {
        "body_part_token_idx": 4,
        "sentence_id": "ec35030e-bc74-3b9c-9b7b-0ff962658e5f",
        "tokens": [
            "She",
            "bit",
            "into",
            "her",
            "cheek",
            "until",
            "she",
            "tasted",
            "blood",
            "."
        ],
        "lemmatized_tokens": [
            "she",
            "bite",
            "into",
            "she",
            "cheek",
            "until",
            "she",
            "taste",
            "blood",
            "."
        ],
        "preceding_context_tokens": [
            [
                "And",
                "when",
                "she",
                "'d",
                "done",
                "that",
                "$",
                "Her",
                "eyes",
                "opened",
                ",",
                "and",
                "she",
                "took",
                "him",
                "in",
                "."
            ],
            [
                "He",
                "was",
                "kneeling",
                ",",
                "his",
                "hands",
                "behind",
                "his",
                "head",
                ",",
                "brown",
                "eyes",
                "still",
                "steady",
                "on",
                "her",
                "."
            ],
            [
                "He",
                "'d",
                "stopped",
                "her",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "and",
                "when",
                "she",
                "would",
                "do",
                "that",
                "$",
                "she",
                "eye",
                "open",
                ",",
                "and",
                "she",
                "take",
                "he",
                "in",
                "."
            ],
            [
                "he",
                "be",
                "kneel",
                ",",
                "he",
                "hand",
                "behind",
                "he",
                "head",
                ",",
                "brown",
                "eye",
                "still",
                "steady",
                "on",
                "she",
                "."
            ],
            [
                "he",
                "have",
                "stop",
                "she",
                "."
            ]
        ],
        "label": "Anger"
    },
    {
        "body_part_token_idx": 9,
        "sentence_id": "3eae252f-cec7-34ca-bcfb-98ba2b46ca1c",
        "tokens": [
            "A",
            "happy",
            "grin",
            "from",
            "the",
            "Master",
            "even",
            "as",
            "his",
            "eyes",
            "rolled",
            "back",
            "."
        ],
        "lemmatized_tokens": [
            "a",
            "happy",
            "grin",
            "from",
            "the",
            "Master",
            "even",
            "as",
            "he",
            "eye",
            "roll",
            "back",
            "."
        ],
        "preceding_context_tokens": [
            [
                "On",
                "Christmas",
                ",",
                "''",
                "the",
                "Doctor",
                "panted",
                "."
            ],
            [
                "``",
                "Yeah",
                "."
            ],
            [
                "Just",
                "for",
                "you",
                ".",
                "''"
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "on",
                "Christmas",
                ",",
                "''",
                "the",
                "Doctor",
                "pant",
                "."
            ],
            [
                "``",
                "yeah",
                "."
            ],
            [
                "just",
                "for",
                "you",
                ".",
                "''"
            ]
        ],
        "label": "Joy"
    },
    {
        "body_part_token_idx": 3,
        "sentence_id": "26909958-338b-3e5a-891f-cf23264a28da",
        "tokens": [
            "She",
            "cocked",
            "her",
            "eyebrows",
            "."
        ],
        "lemmatized_tokens": [
            "she",
            "cocked",
            "she",
            "eyebrow",
            "."
        ],
        "preceding_context_tokens": [
            [
                "Damn",
                "."
            ],
            [
                "``",
                "I",
                "thought",
                "he",
                "might",
                ",",
                "but",
                "I",
                "'m",
                "quite",
                "busy",
                "here",
                "with",
                "cleaning",
                "and",
                "other",
                "customers",
                ",",
                "''",
                "she",
                "replied",
                ",",
                "motioning",
                "towards",
                "the",
                "spotless",
                "counter",
                "and",
                "the",
                "lone",
                "man",
                "sitting",
                "at",
                "it",
                "near",
                "the",
                "end",
                ",",
                "silent",
                "and",
                "staring",
                "into",
                "his",
                "beer",
                "."
            ],
            [
                "``",
                "Besides",
                ",",
                "I",
                "also",
                "need",
                "to",
                "watch",
                "the",
                "phones",
                ",",
                "the",
                "lunch",
                "rush",
                "will",
                "be",
                "starting",
                "so",
                "-",
                "''",
                "``",
                "He",
                "says",
                "he",
                "'ll",
                "make",
                "it",
                "worth",
                "my",
                "time",
                ".",
                "''"
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "damn",
                "."
            ],
            [
                "``",
                "I",
                "think",
                "he",
                "might",
                ",",
                "but",
                "I",
                "be",
                "quite",
                "busy",
                "here",
                "with",
                "cleaning",
                "and",
                "other",
                "customer",
                ",",
                "''",
                "she",
                "reply",
                ",",
                "motion",
                "towards",
                "the",
                "spotless",
                "counter",
                "and",
                "the",
                "lone",
                "man",
                "sit",
                "at",
                "it",
                "near",
                "the",
                "end",
                ",",
                "silent",
                "and",
                "stare",
                "into",
                "he",
                "beer",
                "."
            ],
            [
                "``",
                "besides",
                ",",
                "I",
                "also",
                "need",
                "to",
                "watch",
                "the",
                "phone",
                ",",
                "the",
                "lunch",
                "rush",
                "will",
                "be",
                "start",
                "so",
                "-",
                "''",
                "``",
                "he",
                "say",
                "he",
                "will",
                "make",
                "it",
                "worth",
                "my",
                "time",
                ".",
                "''"
            ]
        ],
        "label": "Surprise"
    },
    {
        "body_part_token_idx": 5,
        "sentence_id": "b659d433-9d96-3090-bac8-210617a25fc4",
        "tokens": [
            "i",
            "kind",
            "of",
            "bawled",
            "my",
            "eyes",
            "out",
            "at",
            "the",
            "end",
            ";",
            "i",
            "warn",
            "you",
            ",",
            "it",
            "is",
            "highly",
            "depressing",
            "!"
        ],
        "lemmatized_tokens": [
            "i",
            "kind",
            "of",
            "bawl",
            "my",
            "eye",
            "out",
            "at",
            "the",
            "end",
            ";",
            "i",
            "warn",
            "you",
            ",",
            "it",
            "be",
            "highly",
            "depressing",
            "!"
        ],
        "preceding_context_tokens": [
            [
                "kathy",
                "and",
                "tommy",
                "were",
                "absolutely",
                "beautiful",
                "."
            ],
            [
                "tommy",
                ",",
                "yeah",
                ",",
                "i",
                "kind",
                "of",
                "swooned",
                "whenever",
                "he",
                "was",
                "on",
                "the",
                "screen",
                "."
            ],
            [
                "carey",
                "mulligan",
                "and",
                "andrew",
                "garfield",
                "are",
                "perfect",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "kathy",
                "and",
                "tommy",
                "be",
                "absolutely",
                "beautiful",
                "."
            ],
            [
                "tommy",
                ",",
                "yeah",
                ",",
                "i",
                "kind",
                "of",
                "swoon",
                "whenever",
                "he",
                "be",
                "on",
                "the",
                "screen",
                "."
            ],
            [
                "carey",
                "mulligan",
                "and",
                "andrew",
                "garfield",
                "be",
                "perfect",
                "."
            ]
        ],
        "label": "Sadness"
    },
    {
        "body_part_token_idx": 16,
        "sentence_id": "32e204fc-d00f-367c-b468-1767ee250f72",
        "tokens": [
            "Please",
            "tell",
            "me",
            "that",
            "ai",
            "n't",
            "a",
            "candy",
            "shop",
            "''",
            "BA",
            "said",
            ",",
            "hand",
            "covering",
            "his",
            "eyes",
            "in",
            "dramatic",
            "horror",
            "."
        ],
        "lemmatized_tokens": [
            "please",
            "tell",
            "I",
            "that",
            "be",
            "not",
            "a",
            "candy",
            "shop",
            "''",
            "BA",
            "say",
            ",",
            "hand",
            "cover",
            "he",
            "eye",
            "in",
            "dramatic",
            "horror",
            "."
        ],
        "preceding_context_tokens": [
            [
                "The",
                "other",
                "three",
                "jumped",
                "as",
                "Murdock",
                "shrieked",
                "and",
                "ran",
                "towards",
                "one",
                "side",
                "of",
                "the",
                "street",
                "."
            ],
            [
                "``",
                "Oh",
                "hell",
                "...",
                "Oh",
                "HELL",
                "NO",
                "."
            ],
            [
                "There",
                "ai",
                "n't",
                "no",
                "way",
                "that",
                "'s",
                "a",
                "candy",
                "shop",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "the",
                "other",
                "three",
                "jump",
                "as",
                "Murdock",
                "shriek",
                "and",
                "run",
                "towards",
                "one",
                "side",
                "of",
                "the",
                "street",
                "."
            ],
            [
                "``",
                "oh",
                "hell",
                "...",
                "oh",
                "hell",
                "no",
                "."
            ],
            [
                "there",
                "be",
                "not",
                "no",
                "way",
                "that",
                "be",
                "a",
                "candy",
                "shop",
                "."
            ]
        ],
        "label": "Fear"
    },
    {
        "body_part_token_idx": 11,
        "sentence_id": "9642ac2b-3083-3495-907e-f499e0f85fb7",
        "tokens": [
            "Orophin",
            "'s",
            "heart",
            "broke",
            ",",
            "and",
            "tears",
            "threatened",
            "to",
            "fill",
            "his",
            "eyes",
            "again",
            "."
        ],
        "lemmatized_tokens": [
            "Orophin",
            "'s",
            "heart",
            "break",
            ",",
            "and",
            "tear",
            "threaten",
            "to",
            "fill",
            "he",
            "eye",
            "again",
            "."
        ],
        "preceding_context_tokens": [
            [
                "You",
                "are",
                "right",
                ",",
                "we",
                "are",
                "friends",
                ",",
                "Rohir",
                "."
            ],
            [
                "That",
                "'s",
                "better",
                ",",
                "Elrohir",
                "said",
                "."
            ],
            [
                "Then",
                "something",
                "seemed",
                "to",
                "change",
                "the",
                "Peredhel",
                "'s",
                "eyes",
                "and",
                "he",
                "reached",
                "out",
                "to",
                "smooth",
                "Orophin",
                "'s",
                "hair",
                "in",
                "a",
                "familiar",
                "gesture",
                "before",
                "his",
                "expression",
                "changed",
                "again",
                "to",
                "one",
                "less",
                "intense",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "you",
                "be",
                "right",
                ",",
                "we",
                "be",
                "friend",
                ",",
                "Rohir",
                "."
            ],
            [
                "that",
                "be",
                "better",
                ",",
                "Elrohir",
                "say",
                "."
            ],
            [
                "then",
                "something",
                "seem",
                "to",
                "change",
                "the",
                "Peredhel",
                "'s",
                "eye",
                "and",
                "he",
                "reach",
                "out",
                "to",
                "smooth",
                "Orophin",
                "'s",
                "hair",
                "in",
                "a",
                "familiar",
                "gesture",
                "before",
                "he",
                "expression",
                "change",
                "again",
                "to",
                "one",
                "less",
                "intense",
                "."
            ]
        ],
        "label": "Sadness"
    },
    {
        "body_part_token_idx": 24,
        "sentence_id": "b488a9c2-8d1f-32d1-a3c0-5c35c57fc059",
        "tokens": [
            "David",
            "closed",
            "his",
            "eyes",
            "for",
            "a",
            "second",
            "remembering",
            "that",
            "first",
            "jolt",
            ",",
            "the",
            "twinkle",
            "in",
            "Isaiah",
            "'s",
            "eyes",
            "and",
            "a",
            "knowing",
            "smirk",
            "on",
            "his",
            "lips",
            "."
        ],
        "lemmatized_tokens": [
            "David",
            "close",
            "he",
            "eye",
            "for",
            "a",
            "second",
            "remembering",
            "that",
            "first",
            "jolt",
            ",",
            "the",
            "twinkle",
            "in",
            "Isaiah",
            "'s",
            "eye",
            "and",
            "a",
            "know",
            "smirk",
            "on",
            "he",
            "lip",
            "."
        ],
        "preceding_context_tokens": [
            [
                "``",
                "First",
                "day",
                "at",
                "the",
                "office",
                ",",
                "just",
                "off",
                "training",
                "probation",
                ",",
                "still",
                "piss",
                "green",
                ",",
                "he",
                "was",
                "part",
                "of",
                "the",
                "tour",
                "."
            ],
            [
                "My",
                "new",
                "boss",
                "just",
                "said",
                "`",
                "this",
                "is",
                "Isaiah",
                "."
            ],
            [
                "He",
                "handles",
                "anything",
                "with",
                "a",
                "circuit",
                "board",
                ",",
                "'",
                "and",
                "we",
                "shook",
                "hands",
                "and",
                "there",
                "was",
                "...",
                "a",
                "spark",
                ".",
                "''"
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "``",
                "first",
                "day",
                "at",
                "the",
                "office",
                ",",
                "just",
                "off",
                "training",
                "probation",
                ",",
                "still",
                "piss",
                "green",
                ",",
                "he",
                "be",
                "part",
                "of",
                "the",
                "tour",
                "."
            ],
            [
                "my",
                "new",
                "boss",
                "just",
                "say",
                "`",
                "this",
                "be",
                "Isaiah",
                "."
            ],
            [
                "he",
                "handle",
                "anything",
                "with",
                "a",
                "circuit",
                "board",
                ",",
                "'",
                "and",
                "we",
                "shake",
                "hand",
                "and",
                "there",
                "be",
                "...",
                "a",
                "spark",
                ".",
                "''"
            ]
        ],
        "label": "Joy"
    },
    {
        "body_part_token_idx": 12,
        "sentence_id": "33234565-3ff6-3112-b5a1-b8b1af87eff0",
        "tokens": [
            "Kangin",
            "is",
            "standing",
            "in",
            "the",
            "doorway",
            "to",
            "Hankyung",
            "'s",
            "room",
            ",",
            "his",
            "arms",
            "crossed",
            "over",
            "his",
            "chest",
            "and",
            "a",
            "maniacal",
            "grin",
            "spread",
            "across",
            "his",
            "face",
            "."
        ],
        "lemmatized_tokens": [
            "Kangin",
            "be",
            "stand",
            "in",
            "the",
            "doorway",
            "to",
            "Hankyung",
            "'s",
            "room",
            ",",
            "he",
            "arm",
            "cross",
            "over",
            "he",
            "chest",
            "and",
            "a",
            "maniacal",
            "grin",
            "spread",
            "across",
            "he",
            "face",
            "."
        ],
        "preceding_context_tokens": [
            [
                "What",
                "felt",
                "like",
                "exactly",
                "six",
                "seconds",
                "later",
                ",",
                "I",
                "hear",
                "the",
                "sound",
                "of",
                "someone",
                "laughing",
                "."
            ],
            [
                "I",
                "drag",
                "open",
                "my",
                "eyelids",
                "and",
                "am",
                "stunned",
                "to",
                "see",
                "sunshine",
                "pouring",
                "through",
                "the",
                "window",
                "."
            ],
            [
                "Groggy",
                "and",
                "annoyed",
                ",",
                "I",
                "look",
                "up",
                "to",
                "see",
                "who",
                "is",
                "laughing",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "what",
                "feel",
                "like",
                "exactly",
                "six",
                "seconds",
                "later",
                ",",
                "I",
                "hear",
                "the",
                "sound",
                "of",
                "someone",
                "laugh",
                "."
            ],
            [
                "I",
                "drag",
                "open",
                "my",
                "eyelid",
                "and",
                "be",
                "stunned",
                "to",
                "see",
                "sunshine",
                "pour",
                "through",
                "the",
                "window",
                "."
            ],
            [
                "groggy",
                "and",
                "annoyed",
                ",",
                "I",
                "look",
                "up",
                "to",
                "see",
                "who",
                "be",
                "laugh",
                "."
            ]
        ],
        "label": "Joy"
    },
    {
        "body_part_token_idx": 16,
        "sentence_id": "33234565-3ff6-3112-b5a1-b8b1af87eff0",
        "tokens": [
            "Kangin",
            "is",
            "standing",
            "in",
            "the",
            "doorway",
            "to",
            "Hankyung",
            "'s",
            "room",
            ",",
            "his",
            "arms",
            "crossed",
            "over",
            "his",
            "chest",
            "and",
            "a",
            "maniacal",
            "grin",
            "spread",
            "across",
            "his",
            "face",
            "."
        ],
        "lemmatized_tokens": [
            "Kangin",
            "be",
            "stand",
            "in",
            "the",
            "doorway",
            "to",
            "Hankyung",
            "'s",
            "room",
            ",",
            "he",
            "arm",
            "cross",
            "over",
            "he",
            "chest",
            "and",
            "a",
            "maniacal",
            "grin",
            "spread",
            "across",
            "he",
            "face",
            "."
        ],
        "preceding_context_tokens": [
            [
                "What",
                "felt",
                "like",
                "exactly",
                "six",
                "seconds",
                "later",
                ",",
                "I",
                "hear",
                "the",
                "sound",
                "of",
                "someone",
                "laughing",
                "."
            ],
            [
                "I",
                "drag",
                "open",
                "my",
                "eyelids",
                "and",
                "am",
                "stunned",
                "to",
                "see",
                "sunshine",
                "pouring",
                "through",
                "the",
                "window",
                "."
            ],
            [
                "Groggy",
                "and",
                "annoyed",
                ",",
                "I",
                "look",
                "up",
                "to",
                "see",
                "who",
                "is",
                "laughing",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "what",
                "feel",
                "like",
                "exactly",
                "six",
                "seconds",
                "later",
                ",",
                "I",
                "hear",
                "the",
                "sound",
                "of",
                "someone",
                "laugh",
                "."
            ],
            [
                "I",
                "drag",
                "open",
                "my",
                "eyelid",
                "and",
                "be",
                "stunned",
                "to",
                "see",
                "sunshine",
                "pour",
                "through",
                "the",
                "window",
                "."
            ],
            [
                "groggy",
                "and",
                "annoyed",
                ",",
                "I",
                "look",
                "up",
                "to",
                "see",
                "who",
                "be",
                "laugh",
                "."
            ]
        ],
        "label": "Joy"
    },
    {
        "body_part_token_idx": 24,
        "sentence_id": "33234565-3ff6-3112-b5a1-b8b1af87eff0",
        "tokens": [
            "Kangin",
            "is",
            "standing",
            "in",
            "the",
            "doorway",
            "to",
            "Hankyung",
            "'s",
            "room",
            ",",
            "his",
            "arms",
            "crossed",
            "over",
            "his",
            "chest",
            "and",
            "a",
            "maniacal",
            "grin",
            "spread",
            "across",
            "his",
            "face",
            "."
        ],
        "lemmatized_tokens": [
            "Kangin",
            "be",
            "stand",
            "in",
            "the",
            "doorway",
            "to",
            "Hankyung",
            "'s",
            "room",
            ",",
            "he",
            "arm",
            "cross",
            "over",
            "he",
            "chest",
            "and",
            "a",
            "maniacal",
            "grin",
            "spread",
            "across",
            "he",
            "face",
            "."
        ],
        "preceding_context_tokens": [
            [
                "What",
                "felt",
                "like",
                "exactly",
                "six",
                "seconds",
                "later",
                ",",
                "I",
                "hear",
                "the",
                "sound",
                "of",
                "someone",
                "laughing",
                "."
            ],
            [
                "I",
                "drag",
                "open",
                "my",
                "eyelids",
                "and",
                "am",
                "stunned",
                "to",
                "see",
                "sunshine",
                "pouring",
                "through",
                "the",
                "window",
                "."
            ],
            [
                "Groggy",
                "and",
                "annoyed",
                ",",
                "I",
                "look",
                "up",
                "to",
                "see",
                "who",
                "is",
                "laughing",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "what",
                "feel",
                "like",
                "exactly",
                "six",
                "seconds",
                "later",
                ",",
                "I",
                "hear",
                "the",
                "sound",
                "of",
                "someone",
                "laugh",
                "."
            ],
            [
                "I",
                "drag",
                "open",
                "my",
                "eyelid",
                "and",
                "be",
                "stunned",
                "to",
                "see",
                "sunshine",
                "pour",
                "through",
                "the",
                "window",
                "."
            ],
            [
                "groggy",
                "and",
                "annoyed",
                ",",
                "I",
                "look",
                "up",
                "to",
                "see",
                "who",
                "be",
                "laugh",
                "."
            ]
        ],
        "label": "Joy"
    },
    {
        "body_part_token_idx": 13,
        "sentence_id": "548085f8-f53e-3271-873d-163a997308e3",
        "tokens": [
            "Oliver",
            "looked",
            "at",
            "the",
            "woman",
            "now",
            "curled",
            "up",
            "on",
            "the",
            "couch",
            "with",
            "her",
            "knees",
            "drawn",
            "up",
            "to",
            "her",
            "chest",
            "."
        ],
        "lemmatized_tokens": [
            "Oliver",
            "look",
            "at",
            "the",
            "woman",
            "now",
            "curl",
            "up",
            "on",
            "the",
            "couch",
            "with",
            "she",
            "knee",
            "draw",
            "up",
            "to",
            "she",
            "chest",
            "."
        ],
        "preceding_context_tokens": [
            [
                "She",
                "had",
                "the",
                "gist",
                "and",
                "would",
                "embellish",
                "as",
                "needed",
                "."
            ],
            [
                "It",
                "was",
                "what",
                "he",
                "paid",
                "her",
                "for",
                "."
            ],
            [
                "``",
                "When",
                "do",
                "you",
                "want",
                "this",
                "given",
                "to",
                "the",
                "press",
                "?",
                "''"
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "she",
                "have",
                "the",
                "gist",
                "and",
                "would",
                "embellish",
                "as",
                "need",
                "."
            ],
            [
                "it",
                "be",
                "what",
                "he",
                "pay",
                "she",
                "for",
                "."
            ],
            [
                "``",
                "when",
                "do",
                "you",
                "want",
                "this",
                "give",
                "to",
                "the",
                "press",
                "?",
                "''"
            ]
        ],
        "label": "Fear"
    },
    {
        "body_part_token_idx": 18,
        "sentence_id": "548085f8-f53e-3271-873d-163a997308e3",
        "tokens": [
            "Oliver",
            "looked",
            "at",
            "the",
            "woman",
            "now",
            "curled",
            "up",
            "on",
            "the",
            "couch",
            "with",
            "her",
            "knees",
            "drawn",
            "up",
            "to",
            "her",
            "chest",
            "."
        ],
        "lemmatized_tokens": [
            "Oliver",
            "look",
            "at",
            "the",
            "woman",
            "now",
            "curl",
            "up",
            "on",
            "the",
            "couch",
            "with",
            "she",
            "knee",
            "draw",
            "up",
            "to",
            "she",
            "chest",
            "."
        ],
        "preceding_context_tokens": [
            [
                "She",
                "had",
                "the",
                "gist",
                "and",
                "would",
                "embellish",
                "as",
                "needed",
                "."
            ],
            [
                "It",
                "was",
                "what",
                "he",
                "paid",
                "her",
                "for",
                "."
            ],
            [
                "``",
                "When",
                "do",
                "you",
                "want",
                "this",
                "given",
                "to",
                "the",
                "press",
                "?",
                "''"
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "she",
                "have",
                "the",
                "gist",
                "and",
                "would",
                "embellish",
                "as",
                "need",
                "."
            ],
            [
                "it",
                "be",
                "what",
                "he",
                "pay",
                "she",
                "for",
                "."
            ],
            [
                "``",
                "when",
                "do",
                "you",
                "want",
                "this",
                "give",
                "to",
                "the",
                "press",
                "?",
                "''"
            ]
        ],
        "label": "Fear"
    },
    {
        "body_part_token_idx": 16,
        "sentence_id": "0b33b612-20bb-34fd-9cd0-c08f1b876511",
        "tokens": [
            "That",
            "he",
            "could",
            "n't",
            "bear",
            "and",
            "with",
            "a",
            "great",
            "effort",
            "he",
            "put",
            "a",
            "smile",
            "on",
            "his",
            "face",
            "."
        ],
        "lemmatized_tokens": [
            "that",
            "he",
            "could",
            "not",
            "bear",
            "and",
            "with",
            "a",
            "great",
            "effort",
            "he",
            "put",
            "a",
            "smile",
            "on",
            "he",
            "face",
            "."
        ],
        "preceding_context_tokens": [
            [
                "When",
                "he",
                "finally",
                "did",
                "he",
                "was",
                "surprised",
                "by",
                "the",
                "saddened",
                "expression",
                "in",
                "Doojoon",
                "'",
                "s",
                "eyes",
                "."
            ],
            [
                "He",
                "felt",
                "a",
                "crack",
                "in",
                "his",
                "heart",
                "."
            ],
            [
                "He",
                "was",
                "supposed",
                "to",
                "be",
                "happy",
                "for",
                "him",
                ",",
                "he",
                "was",
                "supposed",
                "to",
                "support",
                "him",
                "no",
                "matter",
                "what",
                "...",
                "Was",
                "it",
                "his",
                "fault",
                "if",
                "Doojoon",
                "looked",
                "sad",
                "?"
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "when",
                "he",
                "finally",
                "do",
                "he",
                "be",
                "surprise",
                "by",
                "the",
                "sadden",
                "expression",
                "in",
                "Doojoon",
                "'",
                "s",
                "eye",
                "."
            ],
            [
                "he",
                "feel",
                "a",
                "crack",
                "in",
                "he",
                "heart",
                "."
            ],
            [
                "he",
                "be",
                "suppose",
                "to",
                "be",
                "happy",
                "for",
                "he",
                ",",
                "he",
                "be",
                "suppose",
                "to",
                "support",
                "he",
                "no",
                "matter",
                "what",
                "...",
                "be",
                "it",
                "he",
                "fault",
                "if",
                "Doojoon",
                "look",
                "sad",
                "?"
            ]
        ],
        "label": "Sadness"
    },
    {
        "body_part_token_idx": 5,
        "sentence_id": "95c5b189-77fd-3320-952d-9b0708d5dc40",
        "tokens": [
            "Donna",
            "was",
            "still",
            "shaking",
            "her",
            "head",
            "and",
            "muttering",
            "to",
            "herself",
            "about",
            "men",
            "and",
            "buses",
            "."
        ],
        "lemmatized_tokens": [
            "Donna",
            "be",
            "still",
            "shake",
            "she",
            "head",
            "and",
            "muttering",
            "to",
            "herself",
            "about",
            "man",
            "and",
            "bus",
            "."
        ],
        "preceding_context_tokens": [
            [
                "``",
                "The",
                "Doctor",
                "nodded",
                "."
            ],
            [
                "``",
                "Who",
                "'s",
                "Captain",
                "Jack",
                "?"
            ],
            [
                "``",
                "They",
                "turned",
                "to",
                "Jenny",
                "in",
                "unison",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "``",
                "the",
                "Doctor",
                "nod",
                "."
            ],
            [
                "``",
                "who",
                "be",
                "Captain",
                "Jack",
                "?"
            ],
            [
                "``",
                "they",
                "turn",
                "to",
                "Jenny",
                "in",
                "unison",
                "."
            ]
        ],
        "label": "Disgust"
    },
    {
        "body_part_token_idx": 19,
        "sentence_id": "6291ed4d-d215-3e84-869e-5604234ff261",
        "tokens": [
            "Nattallii",
            "'s",
            "stall",
            "door",
            "opened",
            "and",
            "revealed",
            "Nattallii",
            "'s",
            "tearstained",
            "face",
            ",",
            "with",
            "mascara",
            "and",
            "eyeliner",
            "dripping",
            "down",
            "her",
            "cheeks",
            "."
        ],
        "lemmatized_tokens": [
            "Nattallii",
            "'s",
            "stall",
            "door",
            "open",
            "and",
            "reveal",
            "Nattallii",
            "'s",
            "tearstained",
            "face",
            ",",
            "with",
            "mascara",
            "and",
            "eyeliner",
            "drip",
            "down",
            "she",
            "cheek",
            "."
        ],
        "preceding_context_tokens": [
            [
                "She",
                "would",
                "kill",
                "to",
                "see",
                "me",
                "shirtless",
                "."
            ],
            [
                "She",
                "'d",
                "spread",
                "it",
                "all",
                "around",
                "the",
                "school",
                ",",
                "and",
                "I",
                "'d",
                "be",
                "toast",
                "."
            ],
            [
                "I",
                "struggled",
                "to",
                "reach",
                "and",
                "yank",
                "the",
                "teeny",
                "point",
                "out",
                "of",
                "my",
                "back",
                ",",
                "and",
                "shoved",
                "my",
                "shirt",
                "back",
                "on",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "she",
                "would",
                "kill",
                "to",
                "see",
                "I",
                "shirtless",
                "."
            ],
            [
                "she",
                "would",
                "spread",
                "it",
                "all",
                "around",
                "the",
                "school",
                ",",
                "and",
                "I",
                "would",
                "be",
                "toast",
                "."
            ],
            [
                "I",
                "struggle",
                "to",
                "reach",
                "and",
                "yank",
                "the",
                "teeny",
                "point",
                "out",
                "of",
                "my",
                "back",
                ",",
                "and",
                "shove",
                "my",
                "shirt",
                "back",
                "on",
                "."
            ]
        ],
        "label": "Sadness"
    },
    {
        "body_part_token_idx": 31,
        "sentence_id": "f7044c33-e2be-357e-83ec-0ebf3bbc3a9e",
        "tokens": [
            "Dean",
            "swallowed",
            "hard",
            ",",
            "blinked",
            "back",
            "burning",
            "tears",
            "as",
            "he",
            "flinched",
            "at",
            "his",
            "brothers",
            "pitiful",
            "words",
            "as",
            "they",
            "sent",
            "chills",
            "down",
            "his",
            "spine",
            "and",
            "tore",
            "at",
            "the",
            "walls",
            "that",
            "guarded",
            "his",
            "heart",
            "."
        ],
        "lemmatized_tokens": [
            "Dean",
            "swallow",
            "hard",
            ",",
            "blink",
            "back",
            "burn",
            "tear",
            "as",
            "he",
            "flinch",
            "at",
            "he",
            "brother",
            "pitiful",
            "word",
            "as",
            "they",
            "send",
            "chill",
            "down",
            "he",
            "spine",
            "and",
            "tear",
            "at",
            "the",
            "wall",
            "that",
            "guard",
            "he",
            "heart",
            "."
        ],
        "preceding_context_tokens": [
            [
                "I",
                "'ll",
                "never",
                "die",
                "$",
                "''",
                "Sam",
                "shuddered",
                "against",
                "him",
                "and",
                "squeezed",
                "his",
                "eyes",
                "shut",
                ",",
                "tightly",
                "as",
                "he",
                "whispered",
                ",",
                "heartbreakingly",
                ".",
                "''"
            ],
            [
                "If",
                "anything",
                "ever",
                "happened",
                "to",
                "you",
                ",",
                "Dean",
                ",",
                "I",
                "do",
                "n't",
                "know",
                "what",
                "I",
                "'d",
                "do",
                "."
            ],
            [
                "I",
                "ca",
                "n't",
                "live",
                "in",
                "this",
                "world",
                "without",
                "you",
                ",",
                "I",
                "'d",
                "die",
                "too",
                ".",
                "''"
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "I",
                "will",
                "never",
                "die",
                "$",
                "''",
                "Sam",
                "shudder",
                "against",
                "he",
                "and",
                "squeeze",
                "he",
                "eye",
                "shut",
                ",",
                "tightly",
                "as",
                "he",
                "whisper",
                ",",
                "heartbreakingly",
                ".",
                "''"
            ],
            [
                "if",
                "anything",
                "ever",
                "happen",
                "to",
                "you",
                ",",
                "Dean",
                ",",
                "I",
                "do",
                "not",
                "know",
                "what",
                "I",
                "have",
                "do",
                "."
            ],
            [
                "I",
                "can",
                "not",
                "live",
                "in",
                "this",
                "world",
                "without",
                "you",
                ",",
                "I",
                "would",
                "die",
                "too",
                ".",
                "''"
            ]
        ],
        "label": "Sadness"
    },
    {
        "body_part_token_idx": 3,
        "sentence_id": "d48edbe5-f349-3e5b-9f50-37d2bd3c7b6a",
        "tokens": [
            "Seunghyun",
            "shook",
            "his",
            "head",
            "."
        ],
        "lemmatized_tokens": [
            "Seunghyun",
            "shake",
            "he",
            "head",
            "."
        ],
        "preceding_context_tokens": [
            [
                "Seunghyun",
                "managed",
                "to",
                "hail",
                "one",
                ",",
                "and",
                "as",
                "he",
                "moved",
                "to",
                "enter",
                "it",
                ",",
                "the",
                "secretary",
                "did",
                "as",
                "well",
                "."
            ],
            [
                "``",
                "Oh",
                ",",
                "no",
                "."
            ],
            [
                "Go",
                "ahead",
                ",",
                "''",
                "the",
                "secretary",
                "told",
                "him",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "Seunghyun",
                "manage",
                "to",
                "hail",
                "one",
                ",",
                "and",
                "as",
                "he",
                "move",
                "to",
                "enter",
                "it",
                ",",
                "the",
                "secretary",
                "do",
                "as",
                "well",
                "."
            ],
            [
                "``",
                "oh",
                ",",
                "no",
                "."
            ],
            [
                "go",
                "ahead",
                ",",
                "''",
                "the",
                "secretary",
                "tell",
                "he",
                "."
            ]
        ],
        "label": "Surprise"
    },
    {
        "body_part_token_idx": 3,
        "sentence_id": "6ca0e308-0f1a-3173-b2e4-0ceddec83adb",
        "tokens": [
            "Even",
            "though",
            "his",
            "hands",
            "were",
            "shaking",
            ",",
            "Kai",
            "kept",
            "a",
            "cloth",
            "pressed",
            "against",
            "his",
            "friend",
            "'s",
            "wound",
            "."
        ],
        "lemmatized_tokens": [
            "even",
            "though",
            "he",
            "hand",
            "be",
            "shake",
            ",",
            "Kai",
            "keep",
            "a",
            "cloth",
            "press",
            "against",
            "he",
            "friend",
            "'s",
            "wound",
            "."
        ],
        "preceding_context_tokens": [
            [
                "Aoi",
                "helped",
                "him",
                "up",
                "as",
                "the",
                "blonde",
                "helped",
                "their",
                "injured",
                "friend",
                "to",
                "his",
                "feet",
                "."
            ],
            [
                "They",
                "quickly",
                "got",
                "back",
                "into",
                "the",
                "truck",
                ",",
                "Byou",
                "got",
                "behind",
                "the",
                "wheel",
                "this",
                "time",
                ",",
                "and",
                "backed",
                "out",
                "."
            ],
            [
                "The",
                "blonde",
                "went",
                "around",
                "the",
                "house",
                "and",
                "sped",
                "through",
                "the",
                "street",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "Aoi",
                "help",
                "he",
                "up",
                "as",
                "the",
                "blonde",
                "help",
                "they",
                "injured",
                "friend",
                "to",
                "he",
                "foot",
                "."
            ],
            [
                "they",
                "quickly",
                "get",
                "back",
                "into",
                "the",
                "truck",
                ",",
                "Byou",
                "get",
                "behind",
                "the",
                "wheel",
                "this",
                "time",
                ",",
                "and",
                "back",
                "out",
                "."
            ],
            [
                "the",
                "blonde",
                "go",
                "around",
                "the",
                "house",
                "and",
                "speed",
                "through",
                "the",
                "street",
                "."
            ]
        ],
        "label": "Fear"
    },
    {
        "body_part_token_idx": 1,
        "sentence_id": "aebc9b74-88c9-3aa1-9074-9246bad80bec",
        "tokens": [
            "My",
            "hand",
            "was",
            "shaking",
            "so",
            "badly",
            "."
        ],
        "lemmatized_tokens": [
            "my",
            "hand",
            "be",
            "shake",
            "so",
            "badly",
            "."
        ],
        "preceding_context_tokens": [
            [
                "Then",
                "it",
                "was",
                "our",
                "turn",
                "to",
                "perform",
                "."
            ],
            [
                "I",
                "stepped",
                "on",
                "the",
                "stage",
                "."
            ],
            [
                "I",
                "remembered",
                "how",
                "nervous",
                "I",
                "was",
                "that",
                "I",
                "could",
                "n't",
                "hold",
                "the",
                "micro",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "then",
                "it",
                "be",
                "we",
                "turn",
                "to",
                "perform",
                "."
            ],
            [
                "I",
                "step",
                "on",
                "the",
                "stage",
                "."
            ],
            [
                "I",
                "remember",
                "how",
                "nervous",
                "I",
                "be",
                "that",
                "I",
                "could",
                "not",
                "hold",
                "the",
                "micro",
                "."
            ]
        ],
        "label": "Fear"
    },
    {
        "body_part_token_idx": 5,
        "sentence_id": "0cbd95f3-77ff-367a-aeaf-1bffaed071b8",
        "tokens": [
            "The",
            "breath",
            "stuck",
            "in",
            "her",
            "chest",
            "until",
            "she",
            "forced",
            "a",
            "painful",
            "cough",
            "."
        ],
        "lemmatized_tokens": [
            "the",
            "breath",
            "stick",
            "in",
            "she",
            "chest",
            "until",
            "she",
            "force",
            "a",
            "painful",
            "cough",
            "."
        ],
        "preceding_context_tokens": [
            [
                "We",
                "'ve",
                "already",
                "been",
                "over",
                "this",
                "''",
                "I",
                "never",
                "noticed",
                "that",
                "you",
                "have",
                "no",
                "bosom",
                "."
            ],
            [
                "No",
                "wonder",
                "you",
                "ca",
                "n't",
                "get",
                "a",
                "guy",
                "."
            ],
            [
                "Lex",
                "'s",
                "jaw",
                "felt",
                "like",
                "a",
                "loose",
                "hinge",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "we",
                "have",
                "already",
                "be",
                "over",
                "this",
                "''",
                "I",
                "never",
                "notice",
                "that",
                "you",
                "have",
                "no",
                "bosom",
                "."
            ],
            [
                "no",
                "wonder",
                "you",
                "can",
                "not",
                "get",
                "a",
                "guy",
                "."
            ],
            [
                "Lex",
                "'s",
                "jaw",
                "feel",
                "like",
                "a",
                "loose",
                "hinge",
                "."
            ]
        ],
        "label": "Surprise"
    },
    {
        "body_part_token_idx": 46,
        "sentence_id": "aab71080-7220-3e49-91ab-6be6aa0fa12c",
        "tokens": [
            "Why",
            "people",
            "remember",
            "what",
            "they",
            "remember",
            ",",
            "why",
            "they",
            "forget",
            "what",
            "they",
            "forget",
            "For",
            "now",
            "just",
            "introduce",
            "her",
            "to",
            "familiar",
            "situations",
            "Gently.",
            "Shankar",
            "said",
            "in",
            "a",
            "hard",
            ",",
            "warning",
            "tone",
            ",",
            "before",
            "adding",
            "in",
            "sympathy",
            ",",
            "And",
            "hope",
            "for",
            "the",
            "best.",
            "Logan",
            "sighed",
            ",",
            "rubbing",
            "his",
            "temples",
            "in",
            "sudden",
            "exhaustion",
            ",",
            "despite",
            "the",
            "fact",
            "it",
            "was",
            "only",
            "just",
            "now",
            "creeping",
            "up",
            "on",
            "midnight",
            "."
        ],
        "lemmatized_tokens": [
            "why",
            "people",
            "remember",
            "what",
            "they",
            "remember",
            ",",
            "why",
            "they",
            "forget",
            "what",
            "they",
            "forget",
            "for",
            "now",
            "just",
            "introduce",
            "she",
            "to",
            "familiar",
            "situation",
            "Gently.",
            "Shankar",
            "say",
            "in",
            "a",
            "hard",
            ",",
            "warn",
            "tone",
            ",",
            "before",
            "add",
            "in",
            "sympathy",
            ",",
            "and",
            "hope",
            "for",
            "the",
            "best.",
            "Logan",
            "sigh",
            ",",
            "rub",
            "he",
            "temple",
            "in",
            "sudden",
            "exhaustion",
            ",",
            "despite",
            "the",
            "fact",
            "it",
            "be",
            "only",
            "just",
            "now",
            "creep",
            "up",
            "on",
            "midnight",
            "."
        ],
        "preceding_context_tokens": [
            [
                "Could",
                "be",
                "hours",
                ",",
                "days",
                ",",
                "weeks",
                "Shankar",
                "sighed",
                "in",
                "frustration",
                ",",
                "knowing",
                "that",
                "the",
                "man",
                "in",
                "front",
                "of",
                "her",
                "just",
                "did",
                "not",
                "want",
                "to",
                "accept",
                "the",
                "only",
                "answer",
                "she",
                "could",
                "give",
                "him",
                "."
            ],
            [
                "In",
                "all",
                "honesty",
                ",",
                "Logan",
                "It",
                "could",
                "be",
                "never",
                "."
            ],
            [
                "Even",
                "to",
                "this",
                "day",
                ",",
                "not",
                "much",
                "is",
                "known",
                "about",
                "amnesia",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "could",
                "be",
                "hour",
                ",",
                "day",
                ",",
                "week",
                "Shankar",
                "sigh",
                "in",
                "frustration",
                ",",
                "know",
                "that",
                "the",
                "man",
                "in",
                "front",
                "of",
                "she",
                "just",
                "do",
                "not",
                "want",
                "to",
                "accept",
                "the",
                "only",
                "answer",
                "she",
                "could",
                "give",
                "he",
                "."
            ],
            [
                "in",
                "all",
                "honesty",
                ",",
                "Logan",
                "it",
                "could",
                "be",
                "never",
                "."
            ],
            [
                "even",
                "to",
                "this",
                "day",
                ",",
                "not",
                "much",
                "be",
                "know",
                "about",
                "amnesia",
                "."
            ]
        ],
        "label": "Sadness"
    },
    {
        "body_part_token_idx": 4,
        "sentence_id": "67137966-6efc-35cd-bf12-4665a9d7001d",
        "tokens": [
            "``",
            "Chris",
            "raises",
            "his",
            "eyebrows",
            "in",
            "shock",
            "towards",
            "Stark",
            ",",
            "``",
            "You",
            "sound",
            "very",
            "interested",
            "in",
            "Hentai",
            ",",
            "sir",
            "."
        ],
        "lemmatized_tokens": [
            "``",
            "Chris",
            "raise",
            "he",
            "eyebrow",
            "in",
            "shock",
            "towards",
            "Stark",
            ",",
            "``",
            "you",
            "sound",
            "very",
            "interested",
            "in",
            "Hentai",
            ",",
            "sir",
            "."
        ],
        "preceding_context_tokens": [
            [
                "And",
                "with",
                "half",
                "the",
                "places",
                "out",
                "in",
                "this",
                "city",
                "kicking",
                "mutants",
                "out",
                ",",
                "it",
                "'s",
                "real",
                "bad",
                ".",
                "''"
            ],
            [
                "He",
                "looks",
                "over",
                "his",
                "glasses",
                "to",
                "Christopher",
                "."
            ],
            [
                "``",
                "And",
                "tentacles",
                "are",
                "n't",
                "as",
                "dangerous",
                "as",
                "what",
                "you",
                "seem",
                "to",
                "be",
                "able",
                "to",
                "do",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "and",
                "with",
                "half",
                "the",
                "place",
                "out",
                "in",
                "this",
                "city",
                "kick",
                "mutant",
                "out",
                ",",
                "it",
                "be",
                "real",
                "bad",
                ".",
                "''"
            ],
            [
                "he",
                "look",
                "over",
                "he",
                "glass",
                "to",
                "Christopher",
                "."
            ],
            [
                "``",
                "and",
                "tentacle",
                "be",
                "not",
                "as",
                "dangerous",
                "as",
                "what",
                "you",
                "seem",
                "to",
                "be",
                "able",
                "to",
                "do",
                "."
            ]
        ],
        "label": "Surprise"
    },
    {
        "body_part_token_idx": 17,
        "sentence_id": "5881b8ee-7ca5-32b5-8593-bf68bec133f5",
        "tokens": [
            "Levi",
            "'s",
            ",",
            "Jaejoong",
            "whispered",
            "to",
            "himself",
            "quite",
            "audibly",
            "as",
            "he",
            "felt",
            "a",
            "blush",
            "creeping",
            "into",
            "his",
            "cheeks",
            "for",
            "the",
            "umpteenth",
            "time",
            "."
        ],
        "lemmatized_tokens": [
            "Levi",
            "'s",
            ",",
            "Jaejoong",
            "whisper",
            "to",
            "himself",
            "quite",
            "audibly",
            "as",
            "he",
            "feel",
            "a",
            "blush",
            "creep",
            "into",
            "he",
            "cheek",
            "for",
            "the",
            "umpteenth",
            "time",
            "."
        ],
        "preceding_context_tokens": [
            [
                "Yunho",
                ",",
                "I",
                "wonder",
                "if",
                "he",
                "really",
                "does",
                "dream",
                "about",
                "me",
                "often",
                ",",
                "he",
                "thought",
                "."
            ],
            [
                "Jaejoong",
                "watched",
                "silently",
                "while",
                "Yunho",
                "slipped",
                "a",
                "navy",
                "striped",
                "hoodie",
                "over",
                "the",
                "white",
                "tank",
                "top",
                "he",
                "had",
                "on",
                "."
            ],
            [
                "As",
                "Yunho",
                "raised",
                "his",
                "hands",
                "up",
                "to",
                "put",
                "the",
                "hoodie",
                "over",
                "his",
                "head",
                ",",
                "the",
                "white",
                "tank",
                "top",
                "lifted",
                "up",
                "slightly",
                "and",
                "visible",
                "underneath",
                "was",
                "a",
                "sliver",
                "of",
                "his",
                "boxers",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "Yunho",
                ",",
                "I",
                "wonder",
                "if",
                "he",
                "really",
                "do",
                "dream",
                "about",
                "I",
                "often",
                ",",
                "he",
                "think",
                "."
            ],
            [
                "Jaejoong",
                "watch",
                "silently",
                "while",
                "Yunho",
                "slip",
                "a",
                "navy",
                "strip",
                "hoodie",
                "over",
                "the",
                "white",
                "tank",
                "top",
                "he",
                "have",
                "on",
                "."
            ],
            [
                "as",
                "Yunho",
                "raise",
                "he",
                "hand",
                "up",
                "to",
                "put",
                "the",
                "hoodie",
                "over",
                "he",
                "head",
                ",",
                "the",
                "white",
                "tank",
                "top",
                "lift",
                "up",
                "slightly",
                "and",
                "visible",
                "underneath",
                "be",
                "a",
                "sliver",
                "of",
                "he",
                "boxer",
                "."
            ]
        ],
        "label": "Surprise"
    },
    {
        "body_part_token_idx": 6,
        "sentence_id": "e1907c24-82a9-375a-be58-e3fb65711f38",
        "tokens": [
            "Nino",
            "said",
            "as",
            "he",
            "bit",
            "his",
            "lip",
            "shyly",
            ",",
            "waiting",
            "for",
            "his",
            "gift",
            "from",
            "the",
            "other",
            "man",
            "."
        ],
        "lemmatized_tokens": [
            "Nino",
            "say",
            "as",
            "he",
            "bite",
            "he",
            "lip",
            "shyly",
            ",",
            "wait",
            "for",
            "he",
            "gift",
            "from",
            "the",
            "other",
            "man",
            "."
        ],
        "preceding_context_tokens": [
            [
                "he",
                "asked",
                "slowly",
                ",",
                "looking",
                "to",
                "Nino",
                "for",
                "confirmation",
                "."
            ],
            [
                "Nino",
                "laughed",
                "and",
                "nodded",
                "while",
                "Ohno",
                "'s",
                "smile",
                "grew",
                "larger",
                "."
            ],
            [
                "``",
                "My",
                "anniversary",
                "gift",
                "to",
                "you",
                ".",
                "''"
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "he",
                "ask",
                "slowly",
                ",",
                "look",
                "to",
                "Nino",
                "for",
                "confirmation",
                "."
            ],
            [
                "Nino",
                "laugh",
                "and",
                "nod",
                "while",
                "Ohno",
                "'s",
                "smile",
                "grow",
                "larger",
                "."
            ],
            [
                "``",
                "my",
                "anniversary",
                "gift",
                "to",
                "you",
                ".",
                "''"
            ]
        ],
        "label": "Joy"
    },
    {
        "body_part_token_idx": 6,
        "sentence_id": "90a2141b-de9d-38e2-8f79-57d765a96ab1",
        "tokens": [
            "Two",
            "words",
            "came",
            "out",
            "of",
            "my",
            "mouth",
            "``",
            "Piss",
            "off",
            "''",
            "I",
            "was",
            "staying",
            "at",
            "my",
            "friends",
            "on",
            "the",
            "week",
            "of",
            "my",
            "18th",
            ",",
            "just",
            "because",
            "his",
            "parents",
            "had",
            "gone",
            "on",
            "holiday",
            "and",
            "we",
            "were",
            "getting",
            "drunk",
            "everyday",
            "."
        ],
        "lemmatized_tokens": [
            "two",
            "word",
            "come",
            "out",
            "of",
            "my",
            "mouth",
            "``",
            "Piss",
            "off",
            "''",
            "I",
            "be",
            "stay",
            "at",
            "my",
            "friend",
            "on",
            "the",
            "week",
            "of",
            "my",
            "18th",
            ",",
            "just",
            "because",
            "he",
            "parent",
            "have",
            "go",
            "on",
            "holiday",
            "and",
            "we",
            "be",
            "get",
            "drunk",
            "everyday",
            "."
        ],
        "preceding_context_tokens": [
            [
                "I",
                "just",
                "blanked",
                "him",
                "altogether",
                "."
            ],
            [
                "One",
                "occasion",
                "he",
                "tried",
                "to",
                "start",
                "a",
                "conversation",
                "."
            ],
            [
                "So",
                ",",
                "what",
                "happened",
                "at",
                "college",
                "?",
                "''"
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "I",
                "just",
                "blank",
                "he",
                "altogether",
                "."
            ],
            [
                "one",
                "occasion",
                "he",
                "try",
                "to",
                "start",
                "a",
                "conversation",
                "."
            ],
            [
                "so",
                ",",
                "what",
                "happen",
                "at",
                "college",
                "?",
                "''"
            ]
        ],
        "label": "Anger"
    },
    {
        "body_part_token_idx": 1,
        "sentence_id": "f488cf8e-6e29-3561-9253-ab2ca00d1b60",
        "tokens": [
            "Her",
            "heart",
            "begins",
            "to",
            "race",
            ";",
            "she",
            "can",
            "hear",
            "it",
            "pounding",
            "frantically",
            "."
        ],
        "lemmatized_tokens": [
            "she",
            "heart",
            "begin",
            "to",
            "race",
            ";",
            "she",
            "can",
            "hear",
            "it",
            "pound",
            "frantically",
            "."
        ],
        "preceding_context_tokens": [
            [
                "Donna",
                "laughs",
                "with",
                "him",
                ",",
                "and",
                "buried",
                "in",
                "that",
                "weak",
                ",",
                "wheezy",
                "chuckle",
                "is",
                "the",
                "delighted",
                "laugh",
                "of",
                "a",
                "thirty",
                "-",
                "something",
                "temp",
                "who",
                "is",
                "seeing",
                "the",
                "world",
                "anew",
                "."
            ],
            [
                "``",
                "I",
                "rather",
                "thought",
                ",",
                "''",
                "the",
                "Doctor",
                "says",
                "once",
                "they",
                "'ve",
                "stopped",
                "laughing",
                ",",
                "``",
                "that",
                "...",
                "well",
                "...",
                "that",
                "you",
                "might",
                "fancy",
                "just",
                "one",
                "more",
                "trip",
                ".",
                "''"
            ],
            [
                "Donna",
                "'s",
                "breath",
                "catches",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "Donna",
                "laugh",
                "with",
                "he",
                ",",
                "and",
                "bury",
                "in",
                "that",
                "weak",
                ",",
                "wheezy",
                "chuckle",
                "be",
                "the",
                "delighted",
                "laugh",
                "of",
                "a",
                "thirty",
                "-",
                "something",
                "temp",
                "who",
                "be",
                "see",
                "the",
                "world",
                "anew",
                "."
            ],
            [
                "``",
                "I",
                "rather",
                "think",
                ",",
                "''",
                "the",
                "Doctor",
                "say",
                "once",
                "they",
                "have",
                "stop",
                "laugh",
                ",",
                "``",
                "that",
                "...",
                "well",
                "...",
                "that",
                "you",
                "might",
                "fancy",
                "just",
                "one",
                "more",
                "trip",
                ".",
                "''"
            ],
            [
                "Donna",
                "'s",
                "breath",
                "catch",
                "."
            ]
        ],
        "label": "Surprise"
    },
    {
        "body_part_token_idx": 6,
        "sentence_id": "e920b5d9-c4d4-3cb0-8e05-eda1486dd0f6",
        "tokens": [
            "Then",
            "a",
            "smile",
            "spread",
            "across",
            "his",
            "face",
            "again",
            "."
        ],
        "lemmatized_tokens": [
            "then",
            "a",
            "smile",
            "spread",
            "across",
            "he",
            "face",
            "again",
            "."
        ],
        "preceding_context_tokens": [
            [
                "Ryan",
                "rolled",
                "his",
                "eyes",
                "."
            ],
            [
                "``",
                "What",
                "is",
                "it",
                "?",
                "''"
            ],
            [
                "Brendon",
                "looked",
                "up",
                "and",
                "thought",
                "for",
                "a",
                "moment",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "Ryan",
                "roll",
                "he",
                "eye",
                "."
            ],
            [
                "``",
                "what",
                "be",
                "it",
                "?",
                "''"
            ],
            [
                "Brendon",
                "look",
                "up",
                "and",
                "think",
                "for",
                "a",
                "moment",
                "."
            ]
        ],
        "label": "Joy"
    },
    {
        "body_part_token_idx": 1,
        "sentence_id": "835b0e03-e36f-3555-a528-a7909b48f10a",
        "tokens": [
            "Her",
            "face",
            "was",
            "like",
            "zoomed",
            "in",
            "like",
            "in",
            "a",
            "movie",
            "."
        ],
        "lemmatized_tokens": [
            "she",
            "face",
            "be",
            "like",
            "zoom",
            "in",
            "like",
            "in",
            "a",
            "movie",
            "."
        ],
        "preceding_context_tokens": [
            [
                "My",
                "mom",
                "saw",
                "her",
                "and",
                "my",
                "grandma",
                "lost",
                "her",
                "stoic",
                "expression",
                "and",
                "was",
                "back",
                "to",
                "normal",
                ",",
                "laughing",
                "and",
                "such",
                "."
            ],
            [
                "When",
                "everyone",
                "was",
                "putting",
                "the",
                "groceries",
                "in",
                "the",
                "car",
                ",",
                "I",
                "got",
                "her",
                "attention",
                "and",
                "asked",
                "her",
                ",",
                "``",
                "What",
                "are",
                "you",
                "doing",
                "here",
                "?",
                "''"
            ],
            [
                "Everyone",
                "was",
                "just",
                "silent",
                ",",
                "and",
                "she",
                "looked",
                "at",
                "me",
                "with",
                "the",
                "same",
                "stoic",
                "/",
                "serious",
                "expression",
                "from",
                "before",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "my",
                "mom",
                "see",
                "she",
                "and",
                "my",
                "grandma",
                "lose",
                "she",
                "stoic",
                "expression",
                "and",
                "be",
                "back",
                "to",
                "normal",
                ",",
                "laugh",
                "and",
                "such",
                "."
            ],
            [
                "when",
                "everyone",
                "be",
                "put",
                "the",
                "grocery",
                "in",
                "the",
                "car",
                ",",
                "I",
                "get",
                "she",
                "attention",
                "and",
                "ask",
                "she",
                ",",
                "``",
                "what",
                "be",
                "you",
                "do",
                "here",
                "?",
                "''"
            ],
            [
                "everyone",
                "be",
                "just",
                "silent",
                ",",
                "and",
                "she",
                "look",
                "at",
                "I",
                "with",
                "the",
                "same",
                "stoic",
                "/",
                "serious",
                "expression",
                "from",
                "before",
                "."
            ]
        ],
        "label": "Anger"
    },
    {
        "body_part_token_idx": 12,
        "sentence_id": "370d77a5-5348-3cf1-9555-2bae8fd0a646",
        "tokens": [
            "Wissen",
            "had",
            "an",
            "urge",
            "to",
            "hit",
            "himself",
            "in",
            "the",
            "forehead",
            "with",
            "his",
            "palm",
            "."
        ],
        "lemmatized_tokens": [
            "Wissen",
            "have",
            "a",
            "urge",
            "to",
            "hit",
            "himself",
            "in",
            "the",
            "forehead",
            "with",
            "he",
            "palm",
            "."
        ],
        "preceding_context_tokens": [
            [
                "Just",
                "wait",
                "until",
                "he",
                "blows",
                "everything",
                "up",
                ".",
                "''"
            ],
            [
                "He",
                "was",
                "enjoying",
                "every",
                "minute",
                "of",
                "this",
                "."
            ],
            [
                "Oh",
                "great",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "just",
                "wait",
                "until",
                "he",
                "blow",
                "everything",
                "up",
                ".",
                "''"
            ],
            [
                "he",
                "be",
                "enjoy",
                "every",
                "minute",
                "of",
                "this",
                "."
            ],
            [
                "oh",
                "great",
                "."
            ]
        ],
        "label": "Disgust"
    },
    {
        "body_part_token_idx": 6,
        "sentence_id": "efcc5c9b-8c63-3918-a3cd-508dc67abb78",
        "tokens": [
            "The",
            "tears",
            "are",
            "prickling",
            "behind",
            "my",
            "eyes",
            "as",
            "I",
            "pull",
            "my",
            "jeans",
            "on",
            "and",
            "race",
            "downstairs.I",
            "find",
            "a",
            "pen",
            "and",
            "paper",
            "in",
            "the",
            "kitchen",
            "and",
            "in",
            "a",
            "hasty",
            "scrawl",
            ",",
            "I",
            "write",
            "out",
            ",",
            "``",
            "Like",
            "I",
            "said",
            ",",
            "I",
            "ca",
            "n't",
            "do",
            "this.Sorry.See",
            "you",
            "at",
            "work",
            "."
        ],
        "lemmatized_tokens": [
            "the",
            "tear",
            "be",
            "prickle",
            "behind",
            "my",
            "eye",
            "as",
            "I",
            "pull",
            "my",
            "jeans",
            "on",
            "and",
            "race",
            "downstairs.i",
            "find",
            "a",
            "pen",
            "and",
            "paper",
            "in",
            "the",
            "kitchen",
            "and",
            "in",
            "a",
            "hasty",
            "scrawl",
            ",",
            "I",
            "write",
            "out",
            ",",
            "``",
            "like",
            "I",
            "say",
            ",",
            "I",
            "can",
            "not",
            "do",
            "this.sorry.see",
            "you",
            "at",
            "work",
            "."
        ],
        "preceding_context_tokens": [
            [
                "The",
                "empty",
                "feeling",
                "is",
                "replaced",
                "by",
                "blind",
                "fear",
                "because",
                "I",
                "know",
                "that",
                "she",
                "'ll",
                "know",
                "."
            ],
            [
                "I",
                "never",
                "called",
                "."
            ],
            [
                "I",
                "was",
                "going",
                "to",
                "call",
                "when",
                "I",
                "left",
                "but",
                "I",
                "never",
                "called",
                "because",
                "I",
                "never",
                "left",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "the",
                "empty",
                "feeling",
                "be",
                "replace",
                "by",
                "blind",
                "fear",
                "because",
                "I",
                "know",
                "that",
                "she",
                "will",
                "know",
                "."
            ],
            [
                "I",
                "never",
                "call",
                "."
            ],
            [
                "I",
                "be",
                "go",
                "to",
                "call",
                "when",
                "I",
                "leave",
                "but",
                "I",
                "never",
                "call",
                "because",
                "I",
                "never",
                "leave",
                "."
            ]
        ],
        "label": "Sadness"
    },
    {
        "body_part_token_idx": 5,
        "sentence_id": "20a9c8a2-fbd6-3672-ad08-f1b4b06693f8",
        "tokens": [
            "Matt",
            ",",
            "Chris",
            "bit",
            "his",
            "lip",
            ",",
            "meaning",
            "clear",
            "now",
            "."
        ],
        "lemmatized_tokens": [
            "Matt",
            ",",
            "Chris",
            "bite",
            "he",
            "lip",
            ",",
            "mean",
            "clear",
            "now",
            "."
        ],
        "preceding_context_tokens": [
            [
                "I",
                "heard",
                "you.",
                "What?",
                "Dom",
                "turned",
                "around",
                ",",
                "taken",
                "by",
                "surprise",
                "."
            ],
            [
                "He",
                "realised",
                "Matt",
                "was",
                "talking",
                "to",
                "Chris",
                ",",
                "who",
                "also",
                "seemed",
                "taken",
                "aback",
                "."
            ],
            [
                "I",
                "heard",
                "you",
                "saying",
                "it",
                "was",
                "my",
                "fault.",
                "He",
                "repeated",
                "in",
                "a",
                "whisper",
                ",",
                "fidgeting",
                "with",
                "his",
                "fingers",
                "in",
                "his",
                "lap",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "I",
                "hear",
                "you.",
                "What?",
                "Dom",
                "turn",
                "around",
                ",",
                "take",
                "by",
                "surprise",
                "."
            ],
            [
                "he",
                "realise",
                "Matt",
                "be",
                "talk",
                "to",
                "Chris",
                ",",
                "who",
                "also",
                "seem",
                "take",
                "aback",
                "."
            ],
            [
                "I",
                "hear",
                "you",
                "say",
                "it",
                "be",
                "my",
                "fault.",
                "he",
                "repeat",
                "in",
                "a",
                "whisper",
                ",",
                "fidget",
                "with",
                "he",
                "finger",
                "in",
                "he",
                "lap",
                "."
            ]
        ],
        "label": "Sadness"
    },
    {
        "body_part_token_idx": 8,
        "sentence_id": "cccbd3ce-2408-35fc-9e40-cb7c77c1c8eb",
        "tokens": [
            "He",
            "no",
            "longer",
            "has",
            "the",
            "light",
            "in",
            "his",
            "eyes",
            "."
        ],
        "lemmatized_tokens": [
            "he",
            "no",
            "longer",
            "have",
            "the",
            "light",
            "in",
            "he",
            "eye",
            "."
        ],
        "preceding_context_tokens": [
            [
                "After",
                "fifty",
                "years",
                "stranded",
                "here",
                "he",
                "takes",
                "a",
                "job",
                "to",
                "assassinate",
                "a",
                "European",
                "figurehead",
                "and",
                "comes",
                "face",
                "to",
                "face",
                "with",
                "someone",
                "he",
                "thought",
                "he",
                "lost",
                "many",
                "years",
                "ago.Chapter",
                "4",
                ":",
                "Impossible?",
                "Do",
                "n't",
                "hurt",
                "him",
                ",",
                "please",
                "bring",
                "him",
                "back",
                "unscathed",
                ",",
                "he",
                "yelled",
                "after",
                "the",
                "security",
                "guards",
                "moving",
                "in",
                "the",
                "opposite",
                "direction",
                "as",
                "others",
                "hustled",
                "him",
                "into",
                "the",
                "back",
                "room",
                "and",
                "then",
                "out",
                "to",
                "his",
                "car.",
                "How",
                "can",
                "it",
                "be",
                ",",
                "I",
                "'ve",
                "finally",
                "found",
                "him",
                "and",
                "he",
                "has",
                "been",
                "utterly",
                "corrupted",
                "?"
            ],
            [
                "This",
                "is",
                "how",
                "he",
                "intended",
                "to",
                "change",
                "the",
                "world",
                "?"
            ],
            [
                "Through",
                "death",
                "and",
                "destruction",
                "?"
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "after",
                "fifty",
                "year",
                "strand",
                "here",
                "he",
                "take",
                "a",
                "job",
                "to",
                "assassinate",
                "a",
                "european",
                "figurehead",
                "and",
                "come",
                "face",
                "to",
                "face",
                "with",
                "someone",
                "he",
                "think",
                "he",
                "lose",
                "many",
                "year",
                "ago.chapter",
                "4",
                ":",
                "Impossible?",
                "do",
                "not",
                "hurt",
                "he",
                ",",
                "please",
                "bring",
                "he",
                "back",
                "unscathed",
                ",",
                "he",
                "yell",
                "after",
                "the",
                "security",
                "guard",
                "move",
                "in",
                "the",
                "opposite",
                "direction",
                "as",
                "other",
                "hustle",
                "he",
                "into",
                "the",
                "back",
                "room",
                "and",
                "then",
                "out",
                "to",
                "he",
                "car.",
                "how",
                "can",
                "it",
                "be",
                ",",
                "I",
                "have",
                "finally",
                "find",
                "he",
                "and",
                "he",
                "have",
                "be",
                "utterly",
                "corrupt",
                "?"
            ],
            [
                "this",
                "be",
                "how",
                "he",
                "intend",
                "to",
                "change",
                "the",
                "world",
                "?"
            ],
            [
                "through",
                "death",
                "and",
                "destruction",
                "?"
            ]
        ],
        "label": "Sadness"
    },
    {
        "body_part_token_idx": 5,
        "sentence_id": "121dcaa9-c8a2-351b-b519-3849d1b05e34",
        "tokens": [
            "Thinking",
            "about",
            "this",
            "made",
            "her",
            "eyes",
            "well",
            "with",
            "tears",
            "."
        ],
        "lemmatized_tokens": [
            "think",
            "about",
            "this",
            "make",
            "she",
            "eye",
            "well",
            "with",
            "tear",
            "."
        ],
        "preceding_context_tokens": [
            [
                "After",
                "what",
                "the",
                "Al",
                "Qaeda",
                "group",
                "had",
                "done",
                ",",
                "she",
                "had",
                "taken",
                "her",
                "own",
                "prejudiced",
                "stand",
                "against",
                "them",
                "."
            ],
            [
                "Sitting",
                "there",
                "stiffly",
                ",",
                "Emily",
                "looked",
                "at",
                "the",
                "woman",
                "."
            ],
            [
                "To",
                "her",
                ",",
                "she",
                "represented",
                "those",
                "who",
                "were",
                "suicide",
                "bombing",
                "and",
                "killing",
                "innocent",
                "people",
                "of",
                "their",
                "own",
                "country",
                "as",
                "well",
                "as",
                "those",
                "from",
                "the",
                "United",
                "States",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "after",
                "what",
                "the",
                "Al",
                "Qaeda",
                "group",
                "have",
                "do",
                ",",
                "she",
                "have",
                "take",
                "she",
                "own",
                "prejudiced",
                "stand",
                "against",
                "they",
                "."
            ],
            [
                "sit",
                "there",
                "stiffly",
                ",",
                "Emily",
                "look",
                "at",
                "the",
                "woman",
                "."
            ],
            [
                "to",
                "she",
                ",",
                "she",
                "represent",
                "those",
                "who",
                "be",
                "suicide",
                "bombing",
                "and",
                "kill",
                "innocent",
                "people",
                "of",
                "they",
                "own",
                "country",
                "as",
                "well",
                "as",
                "those",
                "from",
                "the",
                "United",
                "States",
                "."
            ]
        ],
        "label": "Sadness"
    },
    {
        "body_part_token_idx": 13,
        "sentence_id": "24100852-59f1-38d8-9799-5de6347911ff",
        "tokens": [
            "He",
            "was",
            "watching",
            "them",
            "vanish",
            "into",
            "the",
            "washer",
            "with",
            "the",
            "eagerness",
            "in",
            "his",
            "eyes",
            "of",
            "a",
            "long",
            "life",
            "spent",
            "at",
            "the",
            "bottom",
            "of",
            "the",
            "middle",
            "tier",
            ",",
            "scrimping",
            "and",
            "saving",
            "and",
            "worrying",
            "over",
            "every",
            "penny",
            "."
        ],
        "lemmatized_tokens": [
            "he",
            "be",
            "watch",
            "they",
            "vanish",
            "into",
            "the",
            "washer",
            "with",
            "the",
            "eagerness",
            "in",
            "he",
            "eye",
            "of",
            "a",
            "long",
            "life",
            "spend",
            "at",
            "the",
            "bottom",
            "of",
            "the",
            "middle",
            "tier",
            ",",
            "scrimp",
            "and",
            "save",
            "and",
            "worry",
            "over",
            "every",
            "penny",
            "."
        ],
        "preceding_context_tokens": [
            [
                "They",
                "slid",
                "freely",
                "into",
                "my",
                "palm",
                "."
            ],
            [
                "I",
                "seperated",
                "the",
                "darks",
                "and",
                "lights",
                "as",
                "best",
                "as",
                "I",
                "knew",
                "how",
                "."
            ],
            [
                "I",
                "glanced",
                "over",
                "as",
                "I",
                "pressed",
                "the",
                "coins",
                "into",
                "the",
                "slot",
                "and",
                "started",
                "the",
                "machine",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "they",
                "slide",
                "freely",
                "into",
                "my",
                "palm",
                "."
            ],
            [
                "I",
                "seperate",
                "the",
                "dark",
                "and",
                "light",
                "as",
                "best",
                "as",
                "I",
                "know",
                "how",
                "."
            ],
            [
                "I",
                "glance",
                "over",
                "as",
                "I",
                "press",
                "the",
                "coin",
                "into",
                "the",
                "slot",
                "and",
                "start",
                "the",
                "machine",
                "."
            ]
        ],
        "label": "Sadness"
    },
    {
        "body_part_token_idx": 36,
        "sentence_id": "ec4ec760-bf9f-3fc6-ab36-584910c152a6",
        "tokens": [
            "my",
            "grandma",
            ",",
            "my",
            "mom",
            ",",
            "my",
            "grandaunt",
            ",",
            "my",
            "aunt",
            ",",
            "my",
            "sister",
            "I",
            "CRIED",
            "and",
            "WEPT",
            "in",
            "my",
            "sleep",
            "...",
            "I",
            "just",
            "shook",
            "and",
            "sobbed",
            "and",
            "sniffled",
            "...",
            "then",
            "I",
            "woke",
            "up",
            "and",
            "my",
            "eyes",
            "were",
            "wet",
            "."
        ],
        "lemmatized_tokens": [
            "my",
            "grandma",
            ",",
            "my",
            "mom",
            ",",
            "my",
            "grandaunt",
            ",",
            "my",
            "aunt",
            ",",
            "my",
            "sister",
            "I",
            "cry",
            "and",
            "weep",
            "in",
            "my",
            "sleep",
            "...",
            "I",
            "just",
            "shake",
            "and",
            "sob",
            "and",
            "sniffle",
            "...",
            "then",
            "I",
            "wake",
            "up",
            "and",
            "my",
            "eye",
            "be",
            "wet",
            "."
        ],
        "preceding_context_tokens": [
            [
                "I",
                "was",
                "DREAMING",
                "...",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "I",
                "be",
                "dream",
                "...",
                "."
            ]
        ],
        "label": "Sadness"
    },
    {
        "body_part_token_idx": 1,
        "sentence_id": "ee920894-f451-3944-8425-ce21be91bbc2",
        "tokens": [
            "Her",
            "jaw",
            "dropped",
            "."
        ],
        "lemmatized_tokens": [
            "she",
            "jaw",
            "drop",
            "."
        ],
        "preceding_context_tokens": [
            [
                "``",
                "Not",
                "like",
                "you",
                "do",
                ",",
                "that",
                "'s",
                "for",
                "sure",
                ",",
                "''",
                "I",
                "answered",
                ",",
                "and",
                "she",
                "passed",
                "me",
                "her",
                "laptop",
                "so",
                "I",
                "could",
                "give",
                "her",
                "a",
                "demonstration",
                "."
            ],
            [
                "I",
                "hammered",
                "out",
                "a",
                "few",
                "lines",
                ",",
                "a",
                "paragraph",
                "."
            ],
            [
                "She",
                "could",
                "n't",
                "believe",
                "it",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "``",
                "not",
                "like",
                "you",
                "do",
                ",",
                "that",
                "be",
                "for",
                "sure",
                ",",
                "''",
                "I",
                "answer",
                ",",
                "and",
                "she",
                "pass",
                "I",
                "she",
                "laptop",
                "so",
                "I",
                "could",
                "give",
                "she",
                "a",
                "demonstration",
                "."
            ],
            [
                "I",
                "hammer",
                "out",
                "a",
                "few",
                "line",
                ",",
                "a",
                "paragraph",
                "."
            ],
            [
                "she",
                "could",
                "not",
                "believe",
                "it",
                "."
            ]
        ],
        "label": "Surprise"
    },
    {
        "body_part_token_idx": 16,
        "sentence_id": "3a8115f8-07ff-31b0-8de7-bc59afb4fd42",
        "tokens": [
            "Do",
            "you",
            "think",
            "that",
            "I",
            "'m",
            "lying",
            "when",
            "I",
            "say",
            "that",
            "it",
            "hurts?",
            "Gintoki",
            "scratched",
            "his",
            "cheek",
            ",",
            "not",
            "knowing",
            "what",
            "to",
            "say",
            "."
        ],
        "lemmatized_tokens": [
            "do",
            "you",
            "think",
            "that",
            "I",
            "be",
            "lie",
            "when",
            "I",
            "say",
            "that",
            "it",
            "hurts?",
            "Gintoki",
            "scratch",
            "he",
            "cheek",
            ",",
            "not",
            "know",
            "what",
            "to",
            "say",
            "."
        ],
        "preceding_context_tokens": [
            [
                "Are",
                "you",
                "really",
                "that",
                "much",
                "of",
                "an",
                "idiot?",
                "What",
                "do",
                "you",
                "mean?",
                "asked",
                "Gintoki",
                ",",
                "not",
                "really",
                "wanting",
                "to",
                "know",
                "."
            ],
            [
                "I",
                "'ve",
                "always",
                "ever",
                "since",
                "She",
                "rested",
                "her",
                "head",
                "between",
                "her",
                "knees",
                "once",
                "more",
                "."
            ],
            [
                "I",
                "just",
                "could",
                "n't",
                "take",
                "it",
                "anymore",
                ",",
                "Gin",
                "-",
                "chan",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "be",
                "you",
                "really",
                "that",
                "much",
                "of",
                "a",
                "idiot?",
                "what",
                "do",
                "you",
                "mean?",
                "ask",
                "Gintoki",
                ",",
                "not",
                "really",
                "want",
                "to",
                "know",
                "."
            ],
            [
                "I",
                "have",
                "always",
                "ever",
                "since",
                "she",
                "rest",
                "she",
                "head",
                "between",
                "she",
                "knee",
                "once",
                "more",
                "."
            ],
            [
                "I",
                "just",
                "could",
                "not",
                "take",
                "it",
                "anymore",
                ",",
                "Gin",
                "-",
                "chan",
                "."
            ]
        ],
        "label": "Surprise"
    },
    {
        "body_part_token_idx": 20,
        "sentence_id": "3c2ff07c-a922-3b20-bd7c-ce3df3990be0",
        "tokens": [
            "Episode",
            "7",
            "*",
            "once",
            "at",
            "the",
            "hospital",
            ",",
            "they",
            "took",
            "Takashi",
            "n",
            "the",
            "babies",
            "in",
            "*",
            "Orion",
            ";",
            "8bit",
            "his",
            "lip",
            "in",
            "worry8",
            "*",
            "abt",
            "an",
            "hour",
            "later",
            ",",
            "the",
            "doctor",
            "who",
            "treated",
            "Takashi",
            "the",
            "last",
            "time",
            "came",
            "out",
            "*",
            "Orion",
            ";",
            "8shot",
            "up8",
            "Doc",
            ":",
            "Hey",
            "there",
            "."
        ],
        "lemmatized_tokens": [
            "episode",
            "7",
            "*",
            "once",
            "at",
            "the",
            "hospital",
            ",",
            "they",
            "take",
            "Takashi",
            "n",
            "the",
            "baby",
            "in",
            "*",
            "Orion",
            ";",
            "8bit",
            "he",
            "lip",
            "in",
            "worry8",
            "*",
            "abt",
            "a",
            "hour",
            "later",
            ",",
            "the",
            "doctor",
            "who",
            "treat",
            "Takashi",
            "the",
            "last",
            "time",
            "come",
            "out",
            "*",
            "Orion",
            ";",
            "8shot",
            "up8",
            "doc",
            ":",
            "hey",
            "there",
            "."
        ],
        "preceding_context_tokens": [],
        "preceding_context_lemmatized_tokens": [],
        "label": "Fear"
    },
    {
        "body_part_token_idx": 1,
        "sentence_id": "c0a54b57-08d8-3acb-aca8-5b4c69b2b436",
        "tokens": [
            "My",
            "heart",
            "pounded",
            "as",
            "I",
            "held",
            "my",
            "breath",
            "when",
            "he",
            "pulled",
            "me",
            "into",
            "his",
            "arms",
            "and",
            "-",
            "-",
            "slammed",
            "his",
            "mouth",
            "into",
            "mine",
            "."
        ],
        "lemmatized_tokens": [
            "my",
            "heart",
            "pound",
            "as",
            "I",
            "hold",
            "my",
            "breath",
            "when",
            "he",
            "pull",
            "I",
            "into",
            "he",
            "arm",
            "and",
            "-",
            "-",
            "slam",
            "he",
            "mouth",
            "into",
            "mine",
            "."
        ],
        "preceding_context_tokens": [
            [
                "My",
                "teeth",
                "chattered",
                "."
            ],
            [
                "My",
                "mouthwash",
                "stopped",
                "working",
                "."
            ],
            [
                "It",
                "was",
                "so",
                "quiet",
                "in",
                "the",
                "high",
                "school",
                "gym",
                "you",
                "could",
                "hear",
                "the",
                "director",
                "chewing",
                "on",
                "the",
                "end",
                "of",
                "his",
                "pencil",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "my",
                "tooth",
                "chatter",
                "."
            ],
            [
                "my",
                "mouthwash",
                "stop",
                "work",
                "."
            ],
            [
                "it",
                "be",
                "so",
                "quiet",
                "in",
                "the",
                "high",
                "school",
                "gym",
                "you",
                "could",
                "hear",
                "the",
                "director",
                "chew",
                "on",
                "the",
                "end",
                "of",
                "he",
                "pencil",
                "."
            ]
        ],
        "label": "Fear"
    },
    {
        "body_part_token_idx": 27,
        "sentence_id": "fa7bf01d-b3e6-311a-9d14-307faaf95d7f",
        "tokens": [
            "They",
            "had",
            "a",
            "really",
            "cute",
            "connection",
            "going",
            "toward",
            "the",
            "end",
            "of",
            "the",
            "evening",
            ",",
            "Tai",
            "watching",
            "Blue",
            "with",
            "wide",
            "eyes",
            "and",
            "Blue",
            "shyly",
            "grinning",
            "and",
            "ducking",
            "his",
            "head",
            ",",
            "playing",
            "a",
            "coy",
            "sort",
            "of",
            "peek",
            "-",
            "a-boo",
            "."
        ],
        "lemmatized_tokens": [
            "they",
            "have",
            "a",
            "really",
            "cute",
            "connection",
            "go",
            "toward",
            "the",
            "end",
            "of",
            "the",
            "evening",
            ",",
            "Tai",
            "watch",
            "Blue",
            "with",
            "wide",
            "eye",
            "and",
            "blue",
            "shyly",
            "grin",
            "and",
            "duck",
            "he",
            "head",
            ",",
            "play",
            "a",
            "coy",
            "sort",
            "of",
            "peek",
            "-",
            "a-boo",
            "."
        ],
        "preceding_context_tokens": [
            [
                "It",
                "was",
                "a",
                "perfect",
                "way",
                "to",
                "enjoy",
                "the",
                "first",
                "day",
                "of",
                "summer",
                "!"
            ],
            [
                "Tai",
                "is",
                "nearly",
                "5",
                "months",
                "old",
                "now",
                "and",
                "cute",
                "as",
                "a",
                "button",
                "."
            ],
            [
                "He",
                "'s",
                "really",
                "friendly",
                "and",
                "social",
                ",",
                "smiles",
                "and",
                "laughs",
                "a",
                "lot",
                ",",
                "and",
                "he",
                "was",
                "very",
                "interested",
                "in",
                "watching",
                "Blue",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "it",
                "be",
                "a",
                "perfect",
                "way",
                "to",
                "enjoy",
                "the",
                "first",
                "day",
                "of",
                "summer",
                "!"
            ],
            [
                "Tai",
                "be",
                "nearly",
                "5",
                "month",
                "old",
                "now",
                "and",
                "cute",
                "as",
                "a",
                "button",
                "."
            ],
            [
                "he",
                "be",
                "really",
                "friendly",
                "and",
                "social",
                ",",
                "smile",
                "and",
                "laugh",
                "a",
                "lot",
                ",",
                "and",
                "he",
                "be",
                "very",
                "interested",
                "in",
                "watch",
                "Blue",
                "."
            ]
        ],
        "label": "Joy"
    },
    {
        "body_part_token_idx": 15,
        "sentence_id": "e9d0bd0d-fc85-31fa-a984-9a41b204cd8d",
        "tokens": [
            "He",
            "asked",
            "her",
            ",",
            "sounding",
            "concerned",
            ",",
            "he",
            "could",
            "see",
            "the",
            "worried",
            "look",
            "on",
            "her",
            "face",
            "."
        ],
        "lemmatized_tokens": [
            "he",
            "ask",
            "she",
            ",",
            "sound",
            "concerned",
            ",",
            "he",
            "could",
            "see",
            "the",
            "worried",
            "look",
            "on",
            "she",
            "face",
            "."
        ],
        "preceding_context_tokens": [
            [
                "``",
                "Oliver",
                ",",
                "''",
                "The",
                "quiet",
                "voice",
                "came",
                "from",
                "behind",
                "him",
                ",",
                "and",
                "he",
                "turned",
                "to",
                "see",
                "Ginny",
                "Weasley",
                "standing",
                "there",
                "."
            ],
            [
                "``",
                "Ginny",
                "."
            ],
            [
                "What",
                "happened",
                "?",
                "''"
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "``",
                "Oliver",
                ",",
                "''",
                "the",
                "quiet",
                "voice",
                "come",
                "from",
                "behind",
                "he",
                ",",
                "and",
                "he",
                "turn",
                "to",
                "see",
                "Ginny",
                "Weasley",
                "stand",
                "there",
                "."
            ],
            [
                "``",
                "Ginny",
                "."
            ],
            [
                "what",
                "happen",
                "?",
                "''"
            ]
        ],
        "label": "Fear"
    },
    {
        "body_part_token_idx": 18,
        "sentence_id": "236f2bd4-cf17-324e-a6f1-b17329673775",
        "tokens": [
            "In",
            "fact",
            ",",
            "a",
            "story",
            "I",
            "hear",
            "her",
            "tell",
            "all",
            "the",
            "time",
            "has",
            "just",
            "brought",
            "tears",
            "to",
            "my",
            "eyes",
            "."
        ],
        "lemmatized_tokens": [
            "in",
            "fact",
            ",",
            "a",
            "story",
            "I",
            "hear",
            "she",
            "tell",
            "all",
            "the",
            "time",
            "have",
            "just",
            "bring",
            "tear",
            "to",
            "my",
            "eye",
            "."
        ],
        "preceding_context_tokens": [
            [
                "I",
                "'m",
                "sitting",
                "in",
                "a",
                "room",
                "of",
                "100",
                "strangers",
                "in",
                "Casper",
                ",",
                "WY",
                ",",
                "most",
                "of",
                "whom",
                "are",
                "listening",
                "to",
                "my",
                "sister",
                "speak",
                "about",
                "the",
                "importance",
                "of",
                "early",
                "experiences",
                "for",
                "children",
                "."
            ],
            [
                "It",
                "is",
                "the",
                "first",
                "time",
                "in",
                "a",
                "while",
                "that",
                "I",
                "feel",
                "."
            ],
            [
                "Something",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "I",
                "be",
                "sit",
                "in",
                "a",
                "room",
                "of",
                "100",
                "stranger",
                "in",
                "Casper",
                ",",
                "WY",
                ",",
                "most",
                "of",
                "whom",
                "be",
                "listen",
                "to",
                "my",
                "sister",
                "speak",
                "about",
                "the",
                "importance",
                "of",
                "early",
                "experience",
                "for",
                "child",
                "."
            ],
            [
                "it",
                "be",
                "the",
                "first",
                "time",
                "in",
                "a",
                "while",
                "that",
                "I",
                "feel",
                "."
            ],
            [
                "something",
                "."
            ]
        ],
        "label": "Sadness"
    },
    {
        "body_part_token_idx": 10,
        "sentence_id": "02aeb3b7-8f8d-3f72-81d9-7721b464b77a",
        "tokens": [
            "She",
            "brushed",
            "a",
            "tear",
            "that",
            "had",
            "fallen",
            "on",
            "to",
            "her",
            "cheek",
            "away",
            "."
        ],
        "lemmatized_tokens": [
            "she",
            "brush",
            "a",
            "tear",
            "that",
            "have",
            "fall",
            "on",
            "to",
            "she",
            "cheek",
            "away",
            "."
        ],
        "preceding_context_tokens": [
            [
                "``",
                "I",
                "'m",
                "sorry",
                "...",
                "''",
                "``",
                "Coop",
                ",",
                "do",
                "n't",
                ".",
                "''"
            ],
            [
                "Ashlee",
                "paused",
                "for",
                "a",
                "moment",
                "and",
                "took",
                "a",
                "deep",
                "breath",
                "."
            ],
            [
                "``",
                "Do",
                "n't",
                "apologize",
                "...",
                "I",
                "know",
                "you",
                "thought",
                "I",
                "was",
                "never",
                "going",
                "to",
                "wake",
                "up",
                "...",
                "rationally",
                "I",
                "know",
                "that",
                ".",
                "''"
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "``",
                "I",
                "be",
                "sorry",
                "...",
                "''",
                "``",
                "Coop",
                ",",
                "do",
                "not",
                ".",
                "''"
            ],
            [
                "Ashlee",
                "pause",
                "for",
                "a",
                "moment",
                "and",
                "take",
                "a",
                "deep",
                "breath",
                "."
            ],
            [
                "``",
                "do",
                "not",
                "apologize",
                "...",
                "I",
                "know",
                "you",
                "think",
                "I",
                "be",
                "never",
                "go",
                "to",
                "wake",
                "up",
                "...",
                "rationally",
                "I",
                "know",
                "that",
                ".",
                "''"
            ]
        ],
        "label": "Sadness"
    },
    {
        "body_part_token_idx": 3,
        "sentence_id": "e87540b4-0793-38a7-8447-0c3a2f6ab8aa",
        "tokens": [
            "She",
            "withdraws",
            "her",
            "hand",
            ",",
            "steps",
            "back",
            "into",
            "the",
            "cell",
            "."
        ],
        "lemmatized_tokens": [
            "she",
            "withdraw",
            "she",
            "hand",
            ",",
            "step",
            "back",
            "into",
            "the",
            "cell",
            "."
        ],
        "preceding_context_tokens": [
            [
                "You",
                "can",
                "have",
                "a",
                "taste",
                ",",
                "if",
                "you",
                "want",
                "."
            ],
            [
                "Samuel",
                "gently",
                "takes",
                "her",
                "hand",
                "and",
                "LICKS",
                "it",
                "."
            ],
            [
                "Mira",
                "ca",
                "n't",
                "watch",
                ",",
                "but",
                "she",
                "resists",
                "her",
                "tears",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "you",
                "can",
                "have",
                "a",
                "taste",
                ",",
                "if",
                "you",
                "want",
                "."
            ],
            [
                "Samuel",
                "gently",
                "take",
                "she",
                "hand",
                "and",
                "lick",
                "it",
                "."
            ],
            [
                "Mira",
                "can",
                "not",
                "watch",
                ",",
                "but",
                "she",
                "resist",
                "she",
                "tear",
                "."
            ]
        ],
        "label": "Disgust"
    },
    {
        "body_part_token_idx": 7,
        "sentence_id": "b690473f-5d62-37f0-9b48-d33666b9101d",
        "tokens": [
            "She",
            "got",
            "the",
            "biggest",
            "smile",
            "on",
            "her",
            "face",
            "and",
            "clapped",
            "along",
            "."
        ],
        "lemmatized_tokens": [
            "she",
            "get",
            "the",
            "biggest",
            "smile",
            "on",
            "she",
            "face",
            "and",
            "clap",
            "along",
            "."
        ],
        "preceding_context_tokens": [
            [
                "Our",
                "sweet",
                "Hayley",
                "is",
                "TWO",
                "years",
                "old",
                "today",
                "."
            ],
            [
                "When",
                "she",
                "woke",
                "up",
                "this",
                "morning",
                ",",
                "I",
                "went",
                "into",
                "her",
                "room",
                "and",
                "sang",
                "Happy",
                "Birthday",
                "!"
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "we",
                "sweet",
                "Hayley",
                "be",
                "two",
                "year",
                "old",
                "today",
                "."
            ],
            [
                "when",
                "she",
                "wake",
                "up",
                "this",
                "morning",
                ",",
                "I",
                "go",
                "into",
                "she",
                "room",
                "and",
                "sing",
                "happy",
                "birthday",
                "!"
            ]
        ],
        "label": "Joy"
    },
    {
        "body_part_token_idx": 6,
        "sentence_id": "27b2e459-4b2f-3ff9-8d68-5faa7b74ca88",
        "tokens": [
            "All",
            "he",
            "did",
            "was",
            "furrow",
            "his",
            "eyebrows",
            "once",
            "more",
            ",",
            "grimacing",
            "again",
            "as",
            "he",
            "glares",
            "at",
            "Joshua",
            "."
        ],
        "lemmatized_tokens": [
            "all",
            "he",
            "do",
            "be",
            "furrow",
            "he",
            "eyebrow",
            "once",
            "more",
            ",",
            "grimace",
            "again",
            "as",
            "he",
            "glare",
            "at",
            "Joshua",
            "."
        ],
        "preceding_context_tokens": [
            [
                "What",
                "the",
                "hell",
                "was",
                "Joshua",
                "thinking",
                "?"
            ],
            [
                "He",
                "was",
                "completely",
                "over",
                "looking",
                "the",
                "fact",
                "that",
                "once",
                "again",
                "Joshua",
                "over",
                "looked",
                "him",
                "once",
                ",",
                "and",
                "then",
                "saw",
                "all",
                "his",
                "feelings",
                "the",
                "next",
                "."
            ],
            [
                "His",
                "eyes",
                "turned",
                "almost",
                "blank",
                ",",
                "nearly",
                "surprised",
                "as",
                "he",
                "realized",
                "that",
                "fact",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "what",
                "the",
                "hell",
                "be",
                "Joshua",
                "think",
                "?"
            ],
            [
                "he",
                "be",
                "completely",
                "over",
                "look",
                "the",
                "fact",
                "that",
                "once",
                "again",
                "Joshua",
                "over",
                "look",
                "he",
                "once",
                ",",
                "and",
                "then",
                "see",
                "all",
                "he",
                "feeling",
                "the",
                "next",
                "."
            ],
            [
                "he",
                "eye",
                "turn",
                "almost",
                "blank",
                ",",
                "nearly",
                "surprised",
                "as",
                "he",
                "realize",
                "that",
                "fact",
                "."
            ]
        ],
        "label": "Anger"
    },
    {
        "body_part_token_idx": 9,
        "sentence_id": "b689d901-6955-3207-8b0f-62f6eb651bdf",
        "tokens": [
            "Now",
            ",",
            "I",
            "just",
            "sit",
            "there",
            "and",
            "nod",
            "my",
            "head",
            ",",
            "as",
            "I",
            "listen",
            "to",
            "the",
            "excuses",
            "people",
            "use",
            "to",
            "not",
            "make",
            "positive",
            "changes",
            "in",
            "their",
            "life",
            "."
        ],
        "lemmatized_tokens": [
            "now",
            ",",
            "I",
            "just",
            "sit",
            "there",
            "and",
            "nod",
            "my",
            "head",
            ",",
            "as",
            "I",
            "listen",
            "to",
            "the",
            "excuse",
            "people",
            "use",
            "to",
            "not",
            "make",
            "positive",
            "change",
            "in",
            "they",
            "life",
            "."
        ],
        "preceding_context_tokens": [
            [
                "I",
                "just",
                "would",
                "not",
                "believe",
                "it",
                "."
            ],
            [
                "That",
                "is",
                ",",
                "until",
                "I",
                "was",
                "ready",
                "for",
                "a",
                "real",
                "change",
                "in",
                "my",
                "life",
                "."
            ],
            [
                "What",
                "I",
                "was",
                "really",
                "not",
                "ready",
                "to",
                "believe",
                "in",
                "was",
                "myself",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "I",
                "just",
                "would",
                "not",
                "believe",
                "it",
                "."
            ],
            [
                "that",
                "be",
                ",",
                "until",
                "I",
                "be",
                "ready",
                "for",
                "a",
                "real",
                "change",
                "in",
                "my",
                "life",
                "."
            ],
            [
                "what",
                "I",
                "be",
                "really",
                "not",
                "ready",
                "to",
                "believe",
                "in",
                "be",
                "myself",
                "."
            ]
        ],
        "label": "Sadness"
    },
    {
        "body_part_token_idx": 10,
        "sentence_id": "6835bae6-17c0-3786-b85b-e110713a8749",
        "tokens": [
            "A",
            "good",
            "bonk",
            "to",
            "something",
            "...",
            "''",
            "She",
            "shakes",
            "her",
            "head",
            "."
        ],
        "lemmatized_tokens": [
            "a",
            "good",
            "bonk",
            "to",
            "something",
            "...",
            "''",
            "she",
            "shake",
            "she",
            "head",
            "."
        ],
        "preceding_context_tokens": [
            [
                "``",
                "I.",
                "."
            ],
            [
                "She",
                "considers",
                "her",
                "words",
                "carefully",
                "."
            ],
            [
                "``",
                "Your",
                "brother",
                "is",
                "a",
                "good",
                "friend",
                "of",
                "mine",
                ",",
                "Rik",
                ",",
                "but",
                "yeah",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "``",
                "I.",
                "."
            ],
            [
                "she",
                "consider",
                "she",
                "word",
                "carefully",
                "."
            ],
            [
                "``",
                "you",
                "brother",
                "be",
                "a",
                "good",
                "friend",
                "of",
                "mine",
                ",",
                "Rik",
                ",",
                "but",
                "yeah",
                "."
            ]
        ],
        "label": "Disgust"
    },
    {
        "body_part_token_idx": 1,
        "sentence_id": "3de13d5b-cd4a-36a7-ab99-97f8ea4e1415",
        "tokens": [
            "Her",
            "heart",
            "went",
            "pitter",
            "-",
            "patter",
            "at",
            "the",
            "name",
            ",",
            "for",
            "she",
            "now",
            "knew",
            "that",
            "this",
            "was",
            "her",
            "truelove",
            ",",
            "because",
            "she",
            "now",
            "had",
            "knowledge",
            "of",
            "her",
            "past",
            "lives",
            "."
        ],
        "lemmatized_tokens": [
            "she",
            "heart",
            "go",
            "pitter",
            "-",
            "patter",
            "at",
            "the",
            "name",
            ",",
            "for",
            "she",
            "now",
            "know",
            "that",
            "this",
            "be",
            "she",
            "truelove",
            ",",
            "because",
            "she",
            "now",
            "have",
            "knowledge",
            "of",
            "she",
            "past",
            "life",
            "."
        ],
        "preceding_context_tokens": [
            [
                "Last",
                "night",
                ",",
                "was",
                "nothing",
                "however",
                ",",
                "compared",
                "to",
                "the",
                "ball",
                "they",
                "would",
                "host",
                "this",
                "night",
                "for",
                "tonight",
                "was",
                "the",
                "prince",
                "'s",
                "arrival",
                "home",
                "from",
                "school",
                "in",
                "a",
                "far",
                "off",
                "country",
                "."
            ],
            [
                "He",
                "was",
                "a",
                "good",
                "deal",
                "older",
                "than",
                "Jaclyn",
                ",",
                "by",
                "a",
                "few",
                "years",
                ",",
                "she",
                "just",
                "over",
                "eighteen",
                ",",
                "and",
                "he",
                "already",
                "a",
                "full",
                "grown",
                "man",
                ",",
                "out",
                "of",
                "college",
                "."
            ],
            [
                "She",
                "had",
                "never",
                "once",
                "met",
                "the",
                "prince",
                ",",
                "but",
                "knew",
                "that",
                "his",
                "name",
                "was",
                "Ryan",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "last",
                "night",
                ",",
                "be",
                "nothing",
                "however",
                ",",
                "compare",
                "to",
                "the",
                "ball",
                "they",
                "would",
                "host",
                "this",
                "night",
                "for",
                "tonight",
                "be",
                "the",
                "prince",
                "'s",
                "arrival",
                "home",
                "from",
                "school",
                "in",
                "a",
                "far",
                "off",
                "country",
                "."
            ],
            [
                "he",
                "be",
                "a",
                "good",
                "deal",
                "older",
                "than",
                "Jaclyn",
                ",",
                "by",
                "a",
                "few",
                "year",
                ",",
                "she",
                "just",
                "over",
                "eighteen",
                ",",
                "and",
                "he",
                "already",
                "a",
                "full",
                "grown",
                "man",
                ",",
                "out",
                "of",
                "college",
                "."
            ],
            [
                "she",
                "have",
                "never",
                "once",
                "meet",
                "the",
                "prince",
                ",",
                "but",
                "know",
                "that",
                "he",
                "name",
                "be",
                "Ryan",
                "."
            ]
        ],
        "label": "Surprise"
    },
    {
        "body_part_token_idx": 20,
        "sentence_id": "a2ac1575-6859-32a0-8f93-09babbc61bf7",
        "tokens": [
            "I",
            "was",
            "fully",
            "aware",
            "of",
            "the",
            "fact",
            "that",
            "once",
            "I",
            "began",
            "to",
            "freak",
            "out",
            "about",
            "the",
            "situation",
            "was",
            "when",
            "my",
            "spine",
            "began",
            "flaring",
            "up",
            ",",
            "so",
            "I",
            "tried",
            "my",
            "hardest",
            "to",
            "get",
            "back",
            "into",
            "the",
            "zone",
            "I",
            "was",
            "in",
            "while",
            "I",
            "was",
            "at",
            "home",
            "."
        ],
        "lemmatized_tokens": [
            "I",
            "be",
            "fully",
            "aware",
            "of",
            "the",
            "fact",
            "that",
            "once",
            "I",
            "begin",
            "to",
            "freak",
            "out",
            "about",
            "the",
            "situation",
            "be",
            "when",
            "my",
            "spine",
            "begin",
            "flare",
            "up",
            ",",
            "so",
            "I",
            "try",
            "my",
            "hardest",
            "to",
            "get",
            "back",
            "into",
            "the",
            "zone",
            "I",
            "be",
            "in",
            "while",
            "I",
            "be",
            "at",
            "home",
            "."
        ],
        "preceding_context_tokens": [
            [
                "We",
                "got",
                "to",
                "Sharp",
                "Mary",
                "Birch",
                "hospital",
                "and",
                "I",
                "had",
                "to",
                "get",
                "checked",
                "in",
                "and",
                "monitored",
                "."
            ],
            [
                "I",
                "was",
                "n't",
                "allowed",
                "to",
                "move",
                "from",
                "the",
                "hospital",
                "bed",
                "for",
                "about",
                "15",
                "minutes",
                "-",
                "time",
                "distortion",
                "worked",
                "just",
                "the",
                "opposite",
                "for",
                "me",
                "at",
                "this",
                "point",
                ",",
                "it",
                "felt",
                "like",
                "an",
                "eternity",
                "before",
                "they",
                "transferred",
                "me",
                "to",
                "L&D",
                "."
            ],
            [
                "The",
                "intake",
                "nurse",
                "checked",
                "me",
                "and",
                "stated",
                "that",
                "I",
                "was",
                "7.5",
                "cm",
                "at",
                "this",
                "point",
                "-",
                "I",
                "told",
                "the",
                "staff",
                "and",
                "Trevor",
                "I",
                "felt",
                "like",
                "I",
                "had",
                "un-dilated",
                "between",
                "our",
                "house",
                "and",
                "the",
                "hospital",
                "-",
                "and",
                "I",
                "would",
                "n't",
                "be",
                "surprised",
                "if",
                "I",
                "did",
                ",",
                "it",
                "was",
                "a",
                "psychologically",
                "and",
                "physically",
                "draining",
                "drive",
                "for",
                "me",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "we",
                "get",
                "to",
                "Sharp",
                "Mary",
                "Birch",
                "hospital",
                "and",
                "I",
                "have",
                "to",
                "get",
                "check",
                "in",
                "and",
                "monitor",
                "."
            ],
            [
                "I",
                "be",
                "not",
                "allow",
                "to",
                "move",
                "from",
                "the",
                "hospital",
                "bed",
                "for",
                "about",
                "15",
                "minute",
                "-",
                "time",
                "distortion",
                "work",
                "just",
                "the",
                "opposite",
                "for",
                "I",
                "at",
                "this",
                "point",
                ",",
                "it",
                "feel",
                "like",
                "a",
                "eternity",
                "before",
                "they",
                "transfer",
                "I",
                "to",
                "L&D",
                "."
            ],
            [
                "the",
                "intake",
                "nurse",
                "check",
                "I",
                "and",
                "state",
                "that",
                "I",
                "be",
                "7.5",
                "cm",
                "at",
                "this",
                "point",
                "-",
                "I",
                "tell",
                "the",
                "staff",
                "and",
                "Trevor",
                "I",
                "feel",
                "like",
                "I",
                "have",
                "un-dilate",
                "between",
                "we",
                "house",
                "and",
                "the",
                "hospital",
                "-",
                "and",
                "I",
                "would",
                "not",
                "be",
                "surprised",
                "if",
                "I",
                "do",
                ",",
                "it",
                "be",
                "a",
                "psychologically",
                "and",
                "physically",
                "drain",
                "drive",
                "for",
                "I",
                "."
            ]
        ],
        "label": "Fear"
    },
    {
        "body_part_token_idx": 20,
        "sentence_id": "4571d0cc-c451-3598-aa11-052ef958ac6d",
        "tokens": [
            "`",
            "this",
            "should",
            "be",
            "funny",
            "'",
            "he",
            "thought",
            "to",
            "himself",
            "with",
            "a",
            "very",
            "smug",
            "smirk",
            "on",
            "the",
            "edge",
            "of",
            "his",
            "lip",
            "."
        ],
        "lemmatized_tokens": [
            "`",
            "this",
            "should",
            "be",
            "funny",
            "'",
            "he",
            "think",
            "to",
            "himself",
            "with",
            "a",
            "very",
            "smug",
            "smirk",
            "on",
            "the",
            "edge",
            "of",
            "he",
            "lip",
            "."
        ],
        "preceding_context_tokens": [
            [
                "``",
                "Taking",
                "another",
                "chance",
                "in",
                "the",
                "park",
                "?",
                "''"
            ],
            [
                "he",
                "wonders",
                "aloud",
                ",",
                "trying",
                "to",
                "keep",
                "his",
                "voice",
                "to",
                "himself",
                "as",
                "he",
                "chuckles",
                "at",
                "his",
                "little",
                "joke.Chris",
                "on",
                "the",
                "other",
                "hand",
                "had",
                "taken",
                "the",
                "initiative",
                "to",
                "move",
                "and",
                "lean",
                "against",
                "a",
                "nearby",
                "tree",
                "."
            ],
            [
                "His",
                "lips",
                "stayed",
                "shut",
                "and",
                "only",
                "watched",
                "with",
                "squinted",
                "eyes",
                "as",
                "every",
                "Penny",
                "that",
                "-",
                "might",
                "-",
                "come",
                "within",
                "grasp",
                "was",
                "about",
                "to",
                "mysteriously",
                "fly",
                "away",
                "from",
                "Mr.",
                "Starks",
                "reach",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "``",
                "take",
                "another",
                "chance",
                "in",
                "the",
                "park",
                "?",
                "''"
            ],
            [
                "he",
                "wonder",
                "aloud",
                ",",
                "try",
                "to",
                "keep",
                "he",
                "voice",
                "to",
                "himself",
                "as",
                "he",
                "chuckle",
                "at",
                "he",
                "little",
                "joke.chris",
                "on",
                "the",
                "other",
                "hand",
                "have",
                "take",
                "the",
                "initiative",
                "to",
                "move",
                "and",
                "lean",
                "against",
                "a",
                "nearby",
                "tree",
                "."
            ],
            [
                "he",
                "lip",
                "stay",
                "shut",
                "and",
                "only",
                "watch",
                "with",
                "squint",
                "eye",
                "as",
                "every",
                "penny",
                "that",
                "-",
                "might",
                "-",
                "come",
                "within",
                "grasp",
                "be",
                "about",
                "to",
                "mysteriously",
                "fly",
                "away",
                "from",
                "Mr.",
                "Starks",
                "reach",
                "."
            ]
        ],
        "label": "Joy"
    },
    {
        "body_part_token_idx": 1,
        "sentence_id": "e4b8a1db-36cc-3b01-a6ff-16faadda28ac",
        "tokens": [
            "Her",
            "knees",
            "went",
            "weak",
            "and",
            "it",
            "was",
            "Mr.",
            "McGravey",
            "who",
            "rushed",
            "to",
            "her",
            "side",
            "to",
            "hold",
            "her",
            "up",
            "."
        ],
        "lemmatized_tokens": [
            "she",
            "knee",
            "go",
            "weak",
            "and",
            "it",
            "be",
            "Mr.",
            "McGravey",
            "who",
            "rush",
            "to",
            "she",
            "side",
            "to",
            "hold",
            "she",
            "up",
            "."
        ],
        "preceding_context_tokens": [
            [
                "His",
                "burden",
                "was",
                "her",
                "burden",
                "a",
                "thousand",
                "times",
                "over",
                "."
            ],
            [
                "No",
                "more",
                "hollow",
                "words",
                "had",
                "to",
                "be",
                "said",
                "."
            ],
            [
                "He",
                "let",
                "his",
                "eyes",
                "speak",
                "for",
                "him.From",
                "the",
                "silent",
                "conversation",
                "that",
                "occurred",
                "between",
                "them",
                "she",
                "finally",
                "cracked",
                "and",
                "then",
                "buckled",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "he",
                "burden",
                "be",
                "she",
                "burden",
                "a",
                "thousand",
                "time",
                "over",
                "."
            ],
            [
                "no",
                "more",
                "hollow",
                "word",
                "have",
                "to",
                "be",
                "say",
                "."
            ],
            [
                "he",
                "let",
                "he",
                "eye",
                "speak",
                "for",
                "him.From",
                "the",
                "silent",
                "conversation",
                "that",
                "occur",
                "between",
                "they",
                "she",
                "finally",
                "crack",
                "and",
                "then",
                "buckle",
                "."
            ]
        ],
        "label": "Sadness"
    },
    {
        "body_part_token_idx": 3,
        "sentence_id": "97fae8f9-a4d6-3a6c-a00b-1c3386a15a89",
        "tokens": [
            "She",
            "cuts",
            "her",
            "eyes",
            "at",
            "Lily",
            ",",
            "who",
            "must",
            "have",
            "asked",
            "the",
            "question",
            "and",
            "says",
            ",",
            "``",
            "Dare",
            ".",
            "''"
        ],
        "lemmatized_tokens": [
            "she",
            "cut",
            "she",
            "eye",
            "at",
            "Lily",
            ",",
            "who",
            "must",
            "have",
            "ask",
            "the",
            "question",
            "and",
            "say",
            ",",
            "``",
            "dare",
            ".",
            "''"
        ],
        "preceding_context_tokens": [
            [
                "Perhaps",
                "it",
                "is",
                "that",
                "they",
                "will",
                "be",
                "leaving",
                "for",
                "their",
                "last",
                "proper",
                "summer",
                "holiday",
                "soon",
                "that",
                "makes",
                "them",
                "seem",
                "all",
                "the",
                "more",
                "precious",
                "to",
                "Alice",
                "."
            ],
            [
                "They",
                "have",
                "n't",
                "played",
                "this",
                "game",
                "since",
                "fourth",
                "year",
                ",",
                "back",
                "when",
                "they",
                "all",
                "had",
                "very",
                "few",
                "secrets",
                "to",
                "tell",
                "."
            ],
            [
                "She",
                "'s",
                "completely",
                "lost",
                "track",
                "of",
                "the",
                "questions",
                "and",
                "Dorcas",
                "is",
                "smiling",
                "coyly",
                "and",
                "biting",
                "her",
                "lip",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "perhaps",
                "it",
                "be",
                "that",
                "they",
                "will",
                "be",
                "leave",
                "for",
                "they",
                "last",
                "proper",
                "summer",
                "holiday",
                "soon",
                "that",
                "make",
                "they",
                "seem",
                "all",
                "the",
                "more",
                "precious",
                "to",
                "Alice",
                "."
            ],
            [
                "they",
                "have",
                "not",
                "play",
                "this",
                "game",
                "since",
                "fourth",
                "year",
                ",",
                "back",
                "when",
                "they",
                "all",
                "have",
                "very",
                "few",
                "secret",
                "to",
                "tell",
                "."
            ],
            [
                "she",
                "be",
                "completely",
                "lost",
                "track",
                "of",
                "the",
                "question",
                "and",
                "Dorcas",
                "be",
                "smile",
                "coyly",
                "and",
                "bite",
                "she",
                "lip",
                "."
            ]
        ],
        "label": "Joy"
    },
    {
        "body_part_token_idx": 3,
        "sentence_id": "a7f01f3b-f0f3-39ea-b431-5ec74c41fdb7",
        "tokens": [
            "Ryan",
            "ducks",
            "his",
            "head",
            "down",
            "to",
            "his",
            "notebook",
            "."
        ],
        "lemmatized_tokens": [
            "Ryan",
            "duck",
            "he",
            "head",
            "down",
            "to",
            "he",
            "notebook",
            "."
        ],
        "preceding_context_tokens": [
            [
                "Mr.",
                "Iero",
                "grins",
                "and",
                "claps",
                "Brendon",
                "on",
                "the",
                "back",
                "."
            ],
            [
                "``",
                "See",
                "you",
                "next",
                "week",
                ",",
                "kid",
                ".",
                "''"
            ],
            [
                "Brendon",
                "waves",
                "and",
                "then",
                "turns",
                "back",
                "to",
                "Ryan",
                ",",
                "smiling",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "Mr.",
                "Iero",
                "grin",
                "and",
                "clap",
                "Brendon",
                "on",
                "the",
                "back",
                "."
            ],
            [
                "``",
                "see",
                "you",
                "next",
                "week",
                ",",
                "kid",
                ".",
                "''"
            ],
            [
                "Brendon",
                "wave",
                "and",
                "then",
                "turn",
                "back",
                "to",
                "Ryan",
                ",",
                "smile",
                "."
            ]
        ],
        "label": "Fear"
    },
    {
        "body_part_token_idx": 16,
        "sentence_id": "31f71d66-b8b8-3f57-952b-bd898eed5433",
        "tokens": [
            "At",
            "that",
            "moment",
            ",",
            "something",
            "broke",
            "within",
            "her",
            "and",
            "a",
            "liquid",
            "salt",
            "burst",
            "out",
            "of",
            "her",
            "eyes",
            "."
        ],
        "lemmatized_tokens": [
            "at",
            "that",
            "moment",
            ",",
            "something",
            "break",
            "within",
            "she",
            "and",
            "a",
            "liquid",
            "salt",
            "burst",
            "out",
            "of",
            "she",
            "eye",
            "."
        ],
        "preceding_context_tokens": [
            [
                "-",
                "Do",
                "n't",
                "say",
                "that",
                ",",
                "please",
                ",",
                "-",
                "she",
                "begged",
                "him",
                ",",
                "whispering",
                ";",
                "her",
                "gaze",
                "rushing",
                "in",
                "disarray",
                "along",
                "the",
                "edges",
                "of",
                "the",
                "dim",
                "room",
                "."
            ],
            [
                "-",
                "No",
                "."
            ],
            [
                "He",
                "turned",
                "to",
                "her",
                "and",
                "guiltily",
                "dropped",
                "his",
                "head",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "-",
                "do",
                "not",
                "say",
                "that",
                ",",
                "please",
                ",",
                "-",
                "she",
                "beg",
                "he",
                ",",
                "whisper",
                ";",
                "she",
                "gaze",
                "rush",
                "in",
                "disarray",
                "along",
                "the",
                "edge",
                "of",
                "the",
                "dim",
                "room",
                "."
            ],
            [
                "-",
                "no",
                "."
            ],
            [
                "he",
                "turn",
                "to",
                "she",
                "and",
                "guiltily",
                "drop",
                "he",
                "head",
                "."
            ]
        ],
        "label": "Sadness"
    },
    {
        "body_part_token_idx": 1,
        "sentence_id": "ad985ab3-310f-3279-80d7-0e24269d21c5",
        "tokens": [
            "My",
            "chest",
            "was",
            "lighter",
            ",",
            "my",
            "entire",
            "body",
            "was",
            "lighter",
            "."
        ],
        "lemmatized_tokens": [
            "my",
            "chest",
            "be",
            "lighter",
            ",",
            "my",
            "entire",
            "body",
            "be",
            "lighter",
            "."
        ],
        "preceding_context_tokens": [
            [
                "They",
                "were",
                "her",
                "favorite",
                "flower.At",
                "first",
                "I",
                "was",
                "glad",
                "that",
                "the",
                "color",
                "had",
                "finally",
                "stopped",
                "tormenting",
                "me",
                "."
            ],
            [
                "The",
                "source",
                "of",
                "my",
                "deepest",
                "regrets",
                "had",
                "left",
                "."
            ],
            [
                "I",
                "sat",
                "on",
                "the",
                "floor",
                "of",
                "my",
                "living",
                "room",
                "and",
                "sighed",
                "with",
                "relief",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "they",
                "be",
                "she",
                "favorite",
                "flower.at",
                "first",
                "I",
                "be",
                "glad",
                "that",
                "the",
                "color",
                "have",
                "finally",
                "stop",
                "torment",
                "I",
                "."
            ],
            [
                "the",
                "source",
                "of",
                "my",
                "deepest",
                "regret",
                "have",
                "leave",
                "."
            ],
            [
                "I",
                "sit",
                "on",
                "the",
                "floor",
                "of",
                "my",
                "living",
                "room",
                "and",
                "sigh",
                "with",
                "relief",
                "."
            ]
        ],
        "label": "Joy"
    },
    {
        "body_part_token_idx": 23,
        "sentence_id": "581c5bbe-eb04-3377-8fd0-12e7d79fdaf2",
        "tokens": [
            "The",
            "contact",
            "lenses",
            "replaced",
            "with",
            "glasses",
            "and",
            "his",
            "hair",
            "cut",
            "shorter",
            "than",
            "I",
            "remembered",
            ",",
            "close",
            "around",
            "his",
            "ears",
            "and",
            "kinky",
            "atop",
            "his",
            "head",
            "from",
            "nervously",
            "tugging",
            "and",
            "raking",
            "through",
            "it",
            "."
        ],
        "lemmatized_tokens": [
            "the",
            "contact",
            "lens",
            "replace",
            "with",
            "glass",
            "and",
            "he",
            "hair",
            "cut",
            "shorter",
            "than",
            "I",
            "remember",
            ",",
            "close",
            "around",
            "he",
            "ear",
            "and",
            "kinky",
            "atop",
            "he",
            "head",
            "from",
            "nervously",
            "tug",
            "and",
            "rake",
            "through",
            "it",
            "."
        ],
        "preceding_context_tokens": [
            [
                "Where",
                "are",
                "you",
                "working",
                "now",
                "?"
            ],
            [
                "When",
                "the",
                "conversation",
                "lulled",
                "I",
                "made",
                "second",
                "and",
                "third",
                "cups",
                "of",
                "tea",
                ",",
                "lingering",
                "in",
                "the",
                "kitchen",
                "stirring",
                "in",
                "splashes",
                "of",
                "milk",
                "."
            ],
            [
                "When",
                "the",
                "caffeine",
                "fortified",
                "me",
                "enough",
                "to",
                "look",
                "at",
                "him",
                "longer",
                ",",
                "I",
                "noticed",
                "what",
                "a",
                "beautiful",
                "job",
                "he",
                "'d",
                "done",
                "of",
                "growing",
                "up",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "where",
                "be",
                "you",
                "work",
                "now",
                "?"
            ],
            [
                "when",
                "the",
                "conversation",
                "lull",
                "I",
                "make",
                "second",
                "and",
                "third",
                "cup",
                "of",
                "tea",
                ",",
                "linger",
                "in",
                "the",
                "kitchen",
                "stirring",
                "in",
                "splash",
                "of",
                "milk",
                "."
            ],
            [
                "when",
                "the",
                "caffeine",
                "fortify",
                "I",
                "enough",
                "to",
                "look",
                "at",
                "he",
                "longer",
                ",",
                "I",
                "notice",
                "what",
                "a",
                "beautiful",
                "job",
                "he",
                "have",
                "do",
                "of",
                "grow",
                "up",
                "."
            ]
        ],
        "label": "Fear"
    },
    {
        "body_part_token_idx": 1,
        "sentence_id": "1272411c-90c6-3262-91fa-32db4a55eb82",
        "tokens": [
            "My",
            "mouth",
            "quickly",
            "strected",
            "out",
            "into",
            "a",
            "howl",
            "of",
            "horror",
            "at",
            "the",
            "numbers",
            "on",
            "the",
            "display",
            ".8",
            ":",
            "07",
            "!"
        ],
        "lemmatized_tokens": [
            "my",
            "mouth",
            "quickly",
            "strect",
            "out",
            "into",
            "a",
            "howl",
            "of",
            "horror",
            "at",
            "the",
            "number",
            "on",
            "the",
            "display",
            ".8",
            ":",
            "07",
            "!"
        ],
        "preceding_context_tokens": [
            [
                "I",
                "woke",
                "up",
                "before",
                "my",
                "alarm",
                "today",
                ",",
                "snuggled",
                "lazily",
                "for",
                "a",
                "bit",
                ",",
                "then",
                "as",
                "is",
                "my",
                "wont",
                "picked",
                "up",
                "my",
                "mobile",
                "phone",
                "whch",
                "does",
                "double",
                "duty",
                "as",
                "an",
                "alarm",
                "clock",
                "to",
                "see",
                "how",
                "much",
                "longer",
                "I",
                "could",
                "laze",
                "in",
                "bed",
                "and",
                "if",
                "it",
                "was",
                "worth",
                "going",
                "back",
                "to",
                "sleep",
                "-LRB-",
                "to",
                "which",
                "the",
                "answer",
                "is",
                "almost",
                "always",
                "yes",
                ".",
                ")"
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "I",
                "wake",
                "up",
                "before",
                "my",
                "alarm",
                "today",
                ",",
                "snuggle",
                "lazily",
                "for",
                "a",
                "bit",
                ",",
                "then",
                "as",
                "be",
                "my",
                "wont",
                "pick",
                "up",
                "my",
                "mobile",
                "phone",
                "whch",
                "do",
                "double",
                "duty",
                "as",
                "a",
                "alarm",
                "clock",
                "to",
                "see",
                "how",
                "much",
                "longer",
                "I",
                "could",
                "laze",
                "in",
                "bed",
                "and",
                "if",
                "it",
                "be",
                "worth",
                "go",
                "back",
                "to",
                "sleep",
                "-lrb-",
                "to",
                "which",
                "the",
                "answer",
                "be",
                "almost",
                "always",
                "yes",
                ".",
                ")"
            ]
        ],
        "label": "Fear"
    },
    {
        "body_part_token_idx": 16,
        "sentence_id": "1e74db5c-789c-367f-a4e6-0d8f227d43f6",
        "tokens": [
            "Francis",
            "laughed",
            "and",
            "gave",
            "his",
            "most",
            "charming",
            "smile",
            "to",
            "the",
            "boy",
            ",",
            "who",
            "only",
            "rolled",
            "his",
            "eyes",
            "absently",
            "before",
            "turning",
            "his",
            "attention",
            "to",
            "Arthur",
            "."
        ],
        "lemmatized_tokens": [
            "Francis",
            "laugh",
            "and",
            "give",
            "he",
            "most",
            "charming",
            "smile",
            "to",
            "the",
            "boy",
            ",",
            "who",
            "only",
            "roll",
            "he",
            "eye",
            "absently",
            "before",
            "turn",
            "he",
            "attention",
            "to",
            "Arthur",
            "."
        ],
        "preceding_context_tokens": [
            [
                "``",
                "Arthur",
                "$",
                "''",
                "Matthew",
                "said",
                ",",
                "holding",
                "out",
                "his",
                "hands",
                "in",
                "a",
                "pacifying",
                "manner",
                "."
            ],
            [
                "``",
                "You",
                "know",
                "that",
                "Francis",
                "does",
                "n't",
                "mean",
                "it",
                "$",
                "''",
                "``",
                "Oh",
                ",",
                "but",
                "I",
                "do",
                ",",
                "''",
                "Francis",
                "said",
                "primly",
                "."
            ],
            [
                "Matthew",
                "looked",
                "over",
                "his",
                "shoulder",
                "at",
                "Francis",
                "and",
                "the",
                "look",
                "he",
                "gave",
                "him",
                "could",
                "have",
                "withered",
                "fresh",
                "-",
                "cut",
                "flowers",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "``",
                "Arthur",
                "$",
                "''",
                "Matthew",
                "say",
                ",",
                "hold",
                "out",
                "he",
                "hand",
                "in",
                "a",
                "pacify",
                "manner",
                "."
            ],
            [
                "``",
                "you",
                "know",
                "that",
                "Francis",
                "do",
                "not",
                "mean",
                "it",
                "$",
                "''",
                "``",
                "oh",
                ",",
                "but",
                "I",
                "do",
                ",",
                "''",
                "Francis",
                "say",
                "primly",
                "."
            ],
            [
                "Matthew",
                "look",
                "over",
                "he",
                "shoulder",
                "at",
                "Francis",
                "and",
                "the",
                "look",
                "he",
                "give",
                "he",
                "could",
                "have",
                "wither",
                "fresh",
                "-",
                "cut",
                "flower",
                "."
            ]
        ],
        "label": "Disgust"
    },
    {
        "body_part_token_idx": 9,
        "sentence_id": "67f64e1a-e3be-31f8-a861-b4dd79c3c32a",
        "tokens": [
            "But",
            "I",
            "was",
            "feeling",
            "really",
            "nervous",
            ",",
            "and",
            "my",
            "hands",
            "were",
            "sweaty",
            "."
        ],
        "lemmatized_tokens": [
            "but",
            "I",
            "be",
            "feel",
            "really",
            "nervous",
            ",",
            "and",
            "my",
            "hand",
            "be",
            "sweaty",
            "."
        ],
        "preceding_context_tokens": [
            [
                "The",
                "phone",
                "call",
                "between",
                "Seohyun",
                "and",
                "me",
                "had",
                "be",
                "very",
                "brief",
                "."
            ],
            [
                "I",
                "asked",
                "her",
                "to",
                "meet",
                "me",
                "at",
                "this",
                "cute",
                "caf",
                ",",
                "in",
                "front",
                "of",
                "her",
                "dorm",
                "."
            ],
            [
                "I",
                "said",
                "I",
                "wanted",
                "to",
                "apologize",
                "in",
                "person",
                ",",
                "and",
                "not",
                "just",
                "over",
                "the",
                "phone",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "the",
                "phone",
                "call",
                "between",
                "Seohyun",
                "and",
                "I",
                "have",
                "be",
                "very",
                "brief",
                "."
            ],
            [
                "I",
                "ask",
                "she",
                "to",
                "meet",
                "I",
                "at",
                "this",
                "cute",
                "caf",
                ",",
                "in",
                "front",
                "of",
                "she",
                "dorm",
                "."
            ],
            [
                "I",
                "say",
                "I",
                "want",
                "to",
                "apologize",
                "in",
                "person",
                ",",
                "and",
                "not",
                "just",
                "over",
                "the",
                "phone",
                "."
            ]
        ],
        "label": "Fear"
    },
    {
        "body_part_token_idx": 8,
        "sentence_id": "ac0863eb-c27e-3e6e-8aca-f8809a88a56c",
        "tokens": [
            "The",
            "blush",
            "was",
            "beginning",
            "to",
            "fade",
            "from",
            "her",
            "cheeks",
            "."
        ],
        "lemmatized_tokens": [
            "the",
            "blush",
            "be",
            "begin",
            "to",
            "fade",
            "from",
            "she",
            "cheek",
            "."
        ],
        "preceding_context_tokens": [
            [
                "Taemin",
                "stared",
                "after",
                "him",
                "."
            ],
            [
                "After",
                "hearing",
                "the",
                "front",
                "door",
                "open",
                "then",
                "close",
                "again",
                ",",
                "Eunsook",
                "cleared",
                "her",
                "throat",
                "."
            ],
            [
                "``",
                "Well",
                ",",
                "he",
                "seems",
                "$",
                "nice",
                ",",
                "''",
                "she",
                "offered",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "Taemin",
                "stare",
                "after",
                "he",
                "."
            ],
            [
                "after",
                "hear",
                "the",
                "front",
                "door",
                "open",
                "then",
                "close",
                "again",
                ",",
                "Eunsook",
                "clear",
                "she",
                "throat",
                "."
            ],
            [
                "``",
                "well",
                ",",
                "he",
                "seem",
                "$",
                "nice",
                ",",
                "''",
                "she",
                "offer",
                "."
            ]
        ],
        "label": "Joy"
    },
    {
        "body_part_token_idx": 47,
        "sentence_id": "15cfce17-39cc-38c5-9be6-d8cb8ec93871",
        "tokens": [
            "Yes",
            "yesh",
            "folkies",
            ",",
            "im",
            "here",
            "on",
            "this",
            "frightful",
            "abomination",
            "of",
            "a",
            "night",
            "once",
            "more",
            "hopin",
            "its",
            "all",
            "gravy",
            "with",
            "urselves",
            "because",
            "as",
            "for",
            "me",
            "not",
            "a",
            "lot",
            "is",
            "too",
            "different",
            ",",
            "its",
            "al",
            "good",
            "an",
            "im",
            "chilled",
            ",",
            "high",
            ",",
            "with",
            "a",
            "big",
            "grin",
            "on",
            "my",
            "face",
            "i",
            "do",
            "nt",
            "know",
            "why",
            "cause",
            "the",
            "only",
            "thing",
            "i",
            "got",
            "right",
            "now",
            "apart",
            "from",
            "some",
            "good",
            "smoke",
            "is",
            "a",
            "big",
            "fat",
            "fucken",
            "wad",
            "of",
            "cash",
            "muahaha",
            "."
        ],
        "lemmatized_tokens": [
            "yes",
            "yesh",
            "folky",
            ",",
            "im",
            "here",
            "on",
            "this",
            "frightful",
            "abomination",
            "of",
            "a",
            "night",
            "once",
            "more",
            "hopin",
            "its",
            "all",
            "gravy",
            "with",
            "urselve",
            "because",
            "as",
            "for",
            "I",
            "not",
            "a",
            "lot",
            "be",
            "too",
            "different",
            ",",
            "its",
            "al",
            "good",
            "a",
            "im",
            "chilled",
            ",",
            "high",
            ",",
            "with",
            "a",
            "big",
            "grin",
            "on",
            "my",
            "face",
            "i",
            "do",
            "nt",
            "know",
            "why",
            "cause",
            "the",
            "only",
            "thing",
            "i",
            "get",
            "right",
            "now",
            "apart",
            "from",
            "some",
            "good",
            "smoke",
            "be",
            "a",
            "big",
            "fat",
            "fucken",
            "wad",
            "of",
            "cash",
            "muahaha",
            "."
        ],
        "preceding_context_tokens": [],
        "preceding_context_lemmatized_tokens": [],
        "label": "Joy"
    },
    {
        "body_part_token_idx": 1,
        "sentence_id": "308220c5-63c3-3aee-a116-afc4dbc03e9e",
        "tokens": [
            "Her",
            "eyes",
            "softened",
            "and",
            "her",
            "frown",
            "disappeared",
            "."
        ],
        "lemmatized_tokens": [
            "she",
            "eye",
            "soften",
            "and",
            "she",
            "frown",
            "disappear",
            "."
        ],
        "preceding_context_tokens": [
            [
                "The",
                "other",
                "day",
                ",",
                "i",
                "pretended",
                "to",
                "play",
                "mommy",
                "and",
                "i",
                "said",
                "''",
                "Enough",
                "...",
                "enough",
                "...",
                "thank",
                "you",
                "''",
                "."
            ],
            [
                "And",
                "for",
                "a",
                "split",
                "second",
                ",",
                "out",
                "of",
                "the",
                "corner",
                "of",
                "her",
                "eye",
                ",",
                "mommy",
                "heard",
                "me",
                "."
            ],
            [
                "She",
                "heard",
                "herself",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "the",
                "other",
                "day",
                ",",
                "i",
                "pretend",
                "to",
                "play",
                "mommy",
                "and",
                "i",
                "say",
                "''",
                "enough",
                "...",
                "enough",
                "...",
                "thank",
                "you",
                "''",
                "."
            ],
            [
                "and",
                "for",
                "a",
                "split",
                "second",
                ",",
                "out",
                "of",
                "the",
                "corner",
                "of",
                "she",
                "eye",
                ",",
                "mommy",
                "hear",
                "I",
                "."
            ],
            [
                "she",
                "hear",
                "herself",
                "."
            ]
        ],
        "label": "Joy"
    },
    {
        "body_part_token_idx": 5,
        "sentence_id": "848dd212-684c-318a-a50f-b087ff9696b8",
        "tokens": [
            "A",
            "smile",
            "spread",
            "across",
            "my",
            "face",
            "."
        ],
        "lemmatized_tokens": [
            "a",
            "smile",
            "spread",
            "across",
            "my",
            "face",
            "."
        ],
        "preceding_context_tokens": [
            [
                "I",
                "was",
                "a",
                "junior",
                "in",
                "high",
                "school",
                ",",
                "almost",
                "at",
                "the",
                "top",
                "of",
                "the",
                "``",
                "social",
                "food",
                "chain",
                ",",
                "''",
                "and",
                "yet",
                "I",
                "was",
                "taken",
                "in",
                "by",
                "this",
                "freshman",
                "girl",
                "."
            ],
            [
                "She",
                "was",
                "so",
                "shy",
                "and",
                "quiet",
                "when",
                "she",
                "was",
                "around",
                "people",
                ",",
                "but",
                "something",
                "stood",
                "out",
                "about",
                "her",
                "."
            ],
            [
                "Maybe",
                "it",
                "was",
                "the",
                "way",
                "she",
                "caught",
                "me",
                "every",
                "time",
                "I",
                "glanced",
                "admiringly",
                "at",
                "her",
                ";",
                "or",
                "maybe",
                "it",
                "was",
                "because",
                "I",
                "caught",
                "her",
                "too",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "I",
                "be",
                "a",
                "junior",
                "in",
                "high",
                "school",
                ",",
                "almost",
                "at",
                "the",
                "top",
                "of",
                "the",
                "``",
                "social",
                "food",
                "chain",
                ",",
                "''",
                "and",
                "yet",
                "I",
                "be",
                "take",
                "in",
                "by",
                "this",
                "freshman",
                "girl",
                "."
            ],
            [
                "she",
                "be",
                "so",
                "shy",
                "and",
                "quiet",
                "when",
                "she",
                "be",
                "around",
                "people",
                ",",
                "but",
                "something",
                "stand",
                "out",
                "about",
                "she",
                "."
            ],
            [
                "maybe",
                "it",
                "be",
                "the",
                "way",
                "she",
                "catch",
                "I",
                "every",
                "time",
                "I",
                "glance",
                "admiringly",
                "at",
                "she",
                ";",
                "or",
                "maybe",
                "it",
                "be",
                "because",
                "I",
                "catch",
                "she",
                "too",
                "."
            ]
        ],
        "label": "Joy"
    },
    {
        "body_part_token_idx": 3,
        "sentence_id": "a21dd96d-c976-32a9-b975-affb150e561f",
        "tokens": [
            "He",
            "lifted",
            "his",
            "head",
            ",",
            "eyes",
            "narrowed",
            "and",
            "dry",
            "."
        ],
        "lemmatized_tokens": [
            "he",
            "lift",
            "he",
            "head",
            ",",
            "eye",
            "narrow",
            "and",
            "dry",
            "."
        ],
        "preceding_context_tokens": [
            [
                "He",
                "lowered",
                "his",
                "head",
                "against",
                "the",
                "rough",
                "ground",
                ",",
                "tears",
                "wetting",
                "his",
                "fur",
                "as",
                "he",
                "pounded",
                "a",
                "fist",
                "."
            ],
            [
                "``",
                "I",
                "'m",
                "supposed",
                "to",
                "protect",
                "him",
                "...",
                "''",
                "He",
                "whispered",
                "to",
                "no",
                "one.A",
                "crystal",
                "brilliance",
                "flashed",
                "through",
                "his",
                "mind",
                "."
            ],
            [
                "A",
                "sharp",
                "second",
                "of",
                "guiding",
                "clarity",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "he",
                "lower",
                "he",
                "head",
                "against",
                "the",
                "rough",
                "ground",
                ",",
                "tear",
                "wet",
                "he",
                "fur",
                "as",
                "he",
                "pound",
                "a",
                "fist",
                "."
            ],
            [
                "``",
                "I",
                "be",
                "suppose",
                "to",
                "protect",
                "he",
                "...",
                "''",
                "he",
                "whisper",
                "to",
                "no",
                "one.a",
                "crystal",
                "brilliance",
                "flash",
                "through",
                "he",
                "mind",
                "."
            ],
            [
                "a",
                "sharp",
                "second",
                "of",
                "guide",
                "clarity",
                "."
            ]
        ],
        "label": "Joy"
    },
    {
        "body_part_token_idx": 10,
        "sentence_id": "344ca721-f99a-3ae3-bce6-f0363abd48d2",
        "tokens": [
            "Damien",
            "watched",
            "the",
            "fireflies",
            "with",
            "a",
            "loving",
            "look",
            "on",
            "his",
            "face",
            "."
        ],
        "lemmatized_tokens": [
            "Damien",
            "watch",
            "the",
            "firefly",
            "with",
            "a",
            "loving",
            "look",
            "on",
            "he",
            "face",
            "."
        ],
        "preceding_context_tokens": [
            [
                "Fireflies",
                "."
            ],
            [
                "Or",
                "maybe",
                "lightning",
                "bugs",
                "or",
                "glow",
                "worms",
                "."
            ],
            [
                "They",
                "are",
                "able",
                "to",
                "produce",
                "light",
                "due",
                "to",
                "a",
                "chemical",
                "reaction",
                "in",
                "their",
                "organs",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "firefly",
                "."
            ],
            [
                "or",
                "maybe",
                "lightning",
                "bug",
                "or",
                "glow",
                "worm",
                "."
            ],
            [
                "they",
                "be",
                "able",
                "to",
                "produce",
                "light",
                "due",
                "to",
                "a",
                "chemical",
                "reaction",
                "in",
                "they",
                "organ",
                "."
            ]
        ],
        "label": "Joy"
    },
    {
        "body_part_token_idx": 24,
        "sentence_id": "e290c9fc-4de4-3508-aa42-1d7b543dcb60",
        "tokens": [
            "People",
            "just",
            "are",
            "n't",
            "buying",
            "CD",
            "'s",
            "any",
            "more.",
            "When",
            "J.",
            "Warren",
            ",",
            "former",
            "owner",
            "of",
            "Vibes",
            "music",
            ",",
            "spoke",
            "these",
            "words",
            ",",
            "my",
            "heart",
            "sunk",
            "a",
            "little",
            "in",
            "my",
            "chest",
            "."
        ],
        "lemmatized_tokens": [
            "people",
            "just",
            "be",
            "not",
            "buy",
            "CD",
            "'s",
            "any",
            "more.",
            "when",
            "J.",
            "Warren",
            ",",
            "former",
            "owner",
            "of",
            "vibes",
            "music",
            ",",
            "speak",
            "these",
            "word",
            ",",
            "my",
            "heart",
            "sink",
            "a",
            "little",
            "in",
            "my",
            "chest",
            "."
        ],
        "preceding_context_tokens": [
            [
                "The",
                "days",
                "of",
                "the",
                "brick",
                "and",
                "mortar",
                "record",
                "shop",
                "are",
                "over",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "the",
                "day",
                "of",
                "the",
                "brick",
                "and",
                "mortar",
                "record",
                "shop",
                "be",
                "over",
                "."
            ]
        ],
        "label": "Sadness"
    },
    {
        "body_part_token_idx": 30,
        "sentence_id": "e290c9fc-4de4-3508-aa42-1d7b543dcb60",
        "tokens": [
            "People",
            "just",
            "are",
            "n't",
            "buying",
            "CD",
            "'s",
            "any",
            "more.",
            "When",
            "J.",
            "Warren",
            ",",
            "former",
            "owner",
            "of",
            "Vibes",
            "music",
            ",",
            "spoke",
            "these",
            "words",
            ",",
            "my",
            "heart",
            "sunk",
            "a",
            "little",
            "in",
            "my",
            "chest",
            "."
        ],
        "lemmatized_tokens": [
            "people",
            "just",
            "be",
            "not",
            "buy",
            "CD",
            "'s",
            "any",
            "more.",
            "when",
            "J.",
            "Warren",
            ",",
            "former",
            "owner",
            "of",
            "vibes",
            "music",
            ",",
            "speak",
            "these",
            "word",
            ",",
            "my",
            "heart",
            "sink",
            "a",
            "little",
            "in",
            "my",
            "chest",
            "."
        ],
        "preceding_context_tokens": [
            [
                "The",
                "days",
                "of",
                "the",
                "brick",
                "and",
                "mortar",
                "record",
                "shop",
                "are",
                "over",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "the",
                "day",
                "of",
                "the",
                "brick",
                "and",
                "mortar",
                "record",
                "shop",
                "be",
                "over",
                "."
            ]
        ],
        "label": "Sadness"
    },
    {
        "body_part_token_idx": 3,
        "sentence_id": "55d050dc-3086-32ef-a0ce-abd526074f6c",
        "tokens": [
            "He",
            "felt",
            "his",
            "eyebrows",
            "fly",
            "up",
            "in",
            "astonishment",
            "."
        ],
        "lemmatized_tokens": [
            "he",
            "feel",
            "he",
            "eyebrow",
            "fly",
            "up",
            "in",
            "astonishment",
            "."
        ],
        "preceding_context_tokens": [
            [
                "``",
                "And",
                "?",
                "''"
            ],
            [
                "he",
                "prompted",
                ",",
                "the",
                "last",
                "of",
                "his",
                "patience",
                "vanishing",
                "sharply",
                "away",
                "."
            ],
            [
                "``",
                "Well",
                ",",
                "we",
                "ate",
                "together",
                ",",
                "an",
                "'",
                "then",
                "he",
                "took",
                "the",
                "check",
                "before",
                "I",
                "could",
                "get",
                "to",
                "it",
                ",",
                "an",
                "''",
                "''",
                "``",
                "You",
                "let",
                "him",
                "pay",
                "for",
                "your",
                "meal",
                "?",
                "''"
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "``",
                "and",
                "?",
                "''"
            ],
            [
                "he",
                "prompt",
                ",",
                "the",
                "last",
                "of",
                "he",
                "patience",
                "vanish",
                "sharply",
                "away",
                "."
            ],
            [
                "``",
                "well",
                ",",
                "we",
                "eat",
                "together",
                ",",
                "a",
                "'",
                "then",
                "he",
                "take",
                "the",
                "check",
                "before",
                "I",
                "could",
                "get",
                "to",
                "it",
                ",",
                "a",
                "''",
                "''",
                "``",
                "you",
                "let",
                "he",
                "pay",
                "for",
                "you",
                "meal",
                "?",
                "''"
            ]
        ],
        "label": "Surprise"
    },
    {
        "body_part_token_idx": 6,
        "sentence_id": "ddd2aefd-061f-34f8-bbe3-4fa045a5f957",
        "tokens": [
            "Cookbooks",
            ",",
            "Noboru",
            "hoped",
            ",",
            "his",
            "heart",
            "beating",
            "a",
            "little",
            "faster",
            "for",
            "some",
            "unknown",
            "reason",
            "."
        ],
        "lemmatized_tokens": [
            "cookbook",
            ",",
            "Noboru",
            "hope",
            ",",
            "he",
            "heart",
            "beat",
            "a",
            "little",
            "faster",
            "for",
            "some",
            "unknown",
            "reason",
            "."
        ],
        "preceding_context_tokens": [
            [
                "Nowaki",
                "let",
                "Noboru",
                "into",
                "a",
                "decent",
                "-",
                "sized",
                "apartment",
                "that",
                "was",
                "full",
                "of",
                "light",
                "and",
                "sparsely",
                "furnished",
                "."
            ],
            [
                "Books",
                "seemed",
                "to",
                "line",
                "every",
                "wall",
                "of",
                "every",
                "room",
                "."
            ],
            [
                "There",
                "were",
                "even",
                "books",
                "in",
                "the",
                "kitchen",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "Nowaki",
                "let",
                "Noboru",
                "into",
                "a",
                "decent",
                "-",
                "sized",
                "apartment",
                "that",
                "be",
                "full",
                "of",
                "light",
                "and",
                "sparsely",
                "furnished",
                "."
            ],
            [
                "book",
                "seem",
                "to",
                "line",
                "every",
                "wall",
                "of",
                "every",
                "room",
                "."
            ],
            [
                "there",
                "be",
                "even",
                "book",
                "in",
                "the",
                "kitchen",
                "."
            ]
        ],
        "label": "Surprise"
    },
    {
        "body_part_token_idx": 6,
        "sentence_id": "e77d2f2e-838f-39f6-8f5b-0d30ec98f4ab",
        "tokens": [
            "Confusion",
            "was",
            "spread",
            "all",
            "over",
            "her",
            "face",
            "and",
            "she",
            "pressed",
            "the",
            "paper",
            "in",
            "front",
            "of",
            "her",
            "boyfriends",
            "noose",
            "."
        ],
        "lemmatized_tokens": [
            "confusion",
            "be",
            "spread",
            "all",
            "over",
            "she",
            "face",
            "and",
            "she",
            "press",
            "the",
            "paper",
            "in",
            "front",
            "of",
            "she",
            "boyfriend",
            "noose",
            "."
        ],
        "preceding_context_tokens": [
            [
                "After",
                "I",
                "showered",
                "and",
                "dressed",
                ",",
                "I",
                "found",
                "the",
                "couple",
                "with",
                "Shika",
                "in",
                "the",
                "kitchen",
                "."
            ],
            [
                "Come",
                "on",
                ",",
                "let",
                "me",
                "read!",
                "Surprised",
                "I",
                "looked",
                "how",
                "Ino",
                "yanked",
                "a",
                "paper",
                "out",
                "of",
                "Shikamaru",
                "'s",
                "hands",
                "."
            ],
            [
                "What",
                "is",
                "this",
                "?!"
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "after",
                "I",
                "shower",
                "and",
                "dress",
                ",",
                "I",
                "find",
                "the",
                "couple",
                "with",
                "Shika",
                "in",
                "the",
                "kitchen",
                "."
            ],
            [
                "come",
                "on",
                ",",
                "let",
                "I",
                "read!",
                "surprised",
                "I",
                "look",
                "how",
                "Ino",
                "yank",
                "a",
                "paper",
                "out",
                "of",
                "Shikamaru",
                "'s",
                "hand",
                "."
            ],
            [
                "what",
                "be",
                "this",
                "?!"
            ]
        ],
        "label": "Surprise"
    },
    {
        "body_part_token_idx": 15,
        "sentence_id": "418268d4-6a01-30d9-86b4-00d5def4282a",
        "tokens": [
            "There",
            "was",
            "Jongwoon",
            "and",
            "he",
            "was",
            "standing",
            "next",
            "to",
            "the",
            "police",
            "chief",
            ",",
            "shaking",
            "his",
            "hand",
            "and",
            "smiling",
            "victoriously",
            "."
        ],
        "lemmatized_tokens": [
            "there",
            "be",
            "Jongwoon",
            "and",
            "he",
            "be",
            "stand",
            "next",
            "to",
            "the",
            "police",
            "chief",
            ",",
            "shake",
            "he",
            "hand",
            "and",
            "smile",
            "victoriously",
            "."
        ],
        "preceding_context_tokens": [
            [
                "It",
                "was",
                "probably",
                "just",
                "the",
                "drugs",
                "wearing",
                "off",
                "or",
                "something",
                "but",
                "to",
                "me",
                ",",
                "it",
                "was",
                "something",
                "inside",
                "of",
                "her",
                "that",
                "made",
                "her",
                "look",
                "so",
                "distrusting",
                "."
            ],
            [
                "I",
                "heard",
                "a",
                "noise",
                "and",
                "looked",
                "up",
                "at",
                "the",
                "television",
                "."
            ],
            [
                "I",
                "walked",
                "over",
                "and",
                "turned",
                "up",
                "the",
                "volume",
                ",",
                "staring",
                ",",
                "open",
                "-",
                "mouthed",
                "at",
                "what",
                "I",
                "saw",
                "in",
                "front",
                "of",
                "me",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "it",
                "be",
                "probably",
                "just",
                "the",
                "drug",
                "wear",
                "off",
                "or",
                "something",
                "but",
                "to",
                "I",
                ",",
                "it",
                "be",
                "something",
                "inside",
                "of",
                "she",
                "that",
                "make",
                "she",
                "look",
                "so",
                "distrust",
                "."
            ],
            [
                "I",
                "hear",
                "a",
                "noise",
                "and",
                "look",
                "up",
                "at",
                "the",
                "television",
                "."
            ],
            [
                "I",
                "walk",
                "over",
                "and",
                "turn",
                "up",
                "the",
                "volume",
                ",",
                "stare",
                ",",
                "open",
                "-",
                "mouthed",
                "at",
                "what",
                "I",
                "see",
                "in",
                "front",
                "of",
                "I",
                "."
            ]
        ],
        "label": "Joy"
    },
    {
        "body_part_token_idx": 53,
        "sentence_id": "136df848-ad63-3781-9d13-cedfd50035b7",
        "tokens": [
            "Regret",
            "for",
            "driving",
            "his",
            "parents",
            "away",
            ",",
            "regret",
            "for",
            "never",
            "fighting",
            "for",
            "Julie",
            "when",
            "the",
            "Swede",
            "came",
            "along",
            ",",
            "regret",
            "for",
            "becoming",
            "attached",
            "to",
            "Carlotta",
            ",",
            "regret",
            "for",
            "giving",
            "Coach",
            "a",
            "reason",
            "to",
            "take",
            "the",
            "job",
            "at",
            "TMU",
            ",",
            "and",
            "regret",
            "for",
            "just",
            "never",
            "being",
            "good",
            "enough.He",
            "feels",
            "the",
            "tears",
            "coming",
            "down",
            "his",
            "face",
            "again",
            "."
        ],
        "lemmatized_tokens": [
            "regret",
            "for",
            "drive",
            "he",
            "parent",
            "away",
            ",",
            "regret",
            "for",
            "never",
            "fight",
            "for",
            "Julie",
            "when",
            "the",
            "swede",
            "come",
            "along",
            ",",
            "regret",
            "for",
            "become",
            "attach",
            "to",
            "Carlotta",
            ",",
            "regret",
            "for",
            "give",
            "Coach",
            "a",
            "reason",
            "to",
            "take",
            "the",
            "job",
            "at",
            "TMU",
            ",",
            "and",
            "regret",
            "for",
            "just",
            "never",
            "be",
            "good",
            "enough.he",
            "feel",
            "the",
            "tear",
            "come",
            "down",
            "he",
            "face",
            "again",
            "."
        ],
        "preceding_context_tokens": [
            [
                "Every",
                "bad",
                "thing",
                "that",
                "'s",
                "ever",
                "happened",
                "in",
                "his",
                "life",
                "was",
                "his",
                "own",
                "fault.His",
                "body",
                "is",
                "numb",
                "now",
                "."
            ],
            [
                "He",
                "ca",
                "n't",
                "feel",
                "the",
                "water",
                "anymore",
                "."
            ],
            [
                "All",
                "he",
                "feels",
                "is",
                "regret",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "every",
                "bad",
                "thing",
                "that",
                "be",
                "ever",
                "happen",
                "in",
                "he",
                "life",
                "be",
                "he",
                "own",
                "fault.His",
                "body",
                "be",
                "numb",
                "now",
                "."
            ],
            [
                "he",
                "can",
                "not",
                "feel",
                "the",
                "water",
                "anymore",
                "."
            ],
            [
                "all",
                "he",
                "feel",
                "be",
                "regret",
                "."
            ]
        ],
        "label": "Sadness"
    },
    {
        "body_part_token_idx": 8,
        "sentence_id": "3e3dfe05-e7be-3d98-8895-7815db9b312e",
        "tokens": [
            "Fear",
            "spread",
            "like",
            "ice",
            "-",
            "water",
            "down",
            "her",
            "spine",
            "."
        ],
        "lemmatized_tokens": [
            "fear",
            "spread",
            "like",
            "ice",
            "-",
            "water",
            "down",
            "she",
            "spine",
            "."
        ],
        "preceding_context_tokens": [
            [
                "'",
                "She",
                "shouted",
                ",",
                "and",
                "the",
                "pale",
                "blue",
                "shield",
                "that",
                "sprung",
                "from",
                "her",
                "wand",
                "deflected",
                "the",
                "first",
                "few",
                "shadowy",
                "wraiths",
                "away",
                "from",
                "her",
                ",",
                "throwing",
                "them",
                "back",
                "into",
                "the",
                "darkness",
                "above",
                "."
            ],
            [
                "She",
                "tried",
                "to",
                "hold",
                "steady",
                "on",
                "the",
                "shaking",
                "ground",
                ",",
                "tried",
                "to",
                "keep",
                "her",
                "concentration",
                "despite",
                "the",
                "painful",
                "wailing",
                "noise",
                ",",
                "but",
                "more",
                "and",
                "more",
                "of",
                "them",
                "dive",
                "-",
                "bombed",
                "her",
                ",",
                "determined",
                "to",
                "get",
                "through",
                "."
            ],
            [
                "The",
                "small",
                "ball",
                "of",
                "light",
                "was",
                "fading",
                "fast",
                ",",
                "and",
                "tears",
                "seeped",
                "from",
                "the",
                "corners",
                "of",
                "her",
                "eyes",
                "in",
                "concentration",
                ",",
                "in",
                "desperation",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "'",
                "she",
                "shout",
                ",",
                "and",
                "the",
                "pale",
                "blue",
                "shield",
                "that",
                "spring",
                "from",
                "she",
                "wand",
                "deflect",
                "the",
                "first",
                "few",
                "shadowy",
                "wraith",
                "away",
                "from",
                "she",
                ",",
                "throw",
                "they",
                "back",
                "into",
                "the",
                "darkness",
                "above",
                "."
            ],
            [
                "she",
                "try",
                "to",
                "hold",
                "steady",
                "on",
                "the",
                "shake",
                "ground",
                ",",
                "try",
                "to",
                "keep",
                "she",
                "concentration",
                "despite",
                "the",
                "painful",
                "wail",
                "noise",
                ",",
                "but",
                "more",
                "and",
                "more",
                "of",
                "they",
                "dive",
                "-",
                "bomb",
                "she",
                ",",
                "determine",
                "to",
                "get",
                "through",
                "."
            ],
            [
                "the",
                "small",
                "ball",
                "of",
                "light",
                "be",
                "fade",
                "fast",
                ",",
                "and",
                "tear",
                "seep",
                "from",
                "the",
                "corner",
                "of",
                "she",
                "eye",
                "in",
                "concentration",
                ",",
                "in",
                "desperation",
                "."
            ]
        ],
        "label": "Fear"
    },
    {
        "body_part_token_idx": 13,
        "sentence_id": "553e62da-351b-3d4a-b7a6-2668fc26d0da",
        "tokens": [
            "Several",
            "times",
            "in",
            "the",
            "last",
            "couple",
            "weeks",
            "I",
            "'ve",
            "had",
            "to",
            "scratch",
            "my",
            "head",
            "cleverly",
            "for",
            "a",
            "few",
            "minutes",
            "trying",
            "to",
            "figure",
            "out",
            "how",
            "to",
            "get",
            "into",
            "my",
            "office",
            "."
        ],
        "lemmatized_tokens": [
            "several",
            "time",
            "in",
            "the",
            "last",
            "couple",
            "week",
            "I",
            "have",
            "have",
            "to",
            "scratch",
            "my",
            "head",
            "cleverly",
            "for",
            "a",
            "few",
            "minute",
            "try",
            "to",
            "figure",
            "out",
            "how",
            "to",
            "get",
            "into",
            "my",
            "office",
            "."
        ],
        "preceding_context_tokens": [
            [
                "Its",
                "been",
                "snowing",
                "almost",
                "non-stop",
                "since",
                "we",
                "got",
                "back",
                "."
            ],
            [
                "Sometimes",
                "heavy",
                ",",
                "sometimes",
                "blizzardy",
                "."
            ],
            [
                "Sometimes",
                "this",
                "light",
                "drizzly",
                "stuff",
                "that",
                "'s",
                "misleading",
                "because",
                "it",
                "never",
                "actually",
                "stops",
                ",",
                "and",
                "you",
                "think",
                "it",
                "'s",
                "nothing",
                "till",
                "you",
                "open",
                "the",
                "front",
                "door",
                "the",
                "next",
                "morning",
                "and",
                "your",
                "front",
                "entrance",
                "caves",
                "in",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "its",
                "be",
                "snow",
                "almost",
                "non-stop",
                "since",
                "we",
                "get",
                "back",
                "."
            ],
            [
                "sometimes",
                "heavy",
                ",",
                "sometimes",
                "blizzardy",
                "."
            ],
            [
                "sometimes",
                "this",
                "light",
                "drizzly",
                "stuff",
                "that",
                "be",
                "misleading",
                "because",
                "it",
                "never",
                "actually",
                "stop",
                ",",
                "and",
                "you",
                "think",
                "it",
                "be",
                "nothing",
                "till",
                "you",
                "open",
                "the",
                "front",
                "door",
                "the",
                "next",
                "morning",
                "and",
                "you",
                "front",
                "entrance",
                "cave",
                "in",
                "."
            ]
        ],
        "label": "Surprise"
    },
    {
        "body_part_token_idx": 3,
        "sentence_id": "9badfe61-ca7b-3a43-8b3c-23d0daf854aa",
        "tokens": [
            "After",
            "scratching",
            "my",
            "head",
            ",",
            "I",
            "headed",
            "to",
            "the",
            "front",
            "yard",
            ",",
            "where",
            "there",
            "are",
            "no",
            "trees",
            ",",
            "on",
            "the",
            "off",
            "chance",
            "that",
            "something",
            "truly",
            "weird",
            "had",
            "caused",
            "a",
            "limb",
            "to",
            "plop",
            "down",
            "on",
            "my",
            "house",
            "."
        ],
        "lemmatized_tokens": [
            "after",
            "scratch",
            "my",
            "head",
            ",",
            "I",
            "head",
            "to",
            "the",
            "front",
            "yard",
            ",",
            "where",
            "there",
            "be",
            "no",
            "tree",
            ",",
            "on",
            "the",
            "off",
            "chance",
            "that",
            "something",
            "truly",
            "weird",
            "have",
            "cause",
            "a",
            "limb",
            "to",
            "plop",
            "down",
            "on",
            "my",
            "house",
            "."
        ],
        "preceding_context_tokens": [
            [
                "Something",
                "must",
                "have",
                "hit",
                "the",
                "roof",
                "."
            ],
            [
                "I",
                "rushed",
                "outside",
                "and",
                "carefully",
                "studied",
                "the",
                "back",
                "of",
                "the",
                "house",
                ",",
                "where",
                "my",
                "trees",
                "are",
                "."
            ],
            [
                "All",
                "three",
                "of",
                "them",
                "were",
                "right",
                "where",
                "they",
                "belonged",
                ",",
                "no",
                "limbs",
                "missing",
                ",",
                "enjoying",
                "the",
                "sunshine",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "something",
                "must",
                "have",
                "hit",
                "the",
                "roof",
                "."
            ],
            [
                "I",
                "rush",
                "outside",
                "and",
                "carefully",
                "study",
                "the",
                "back",
                "of",
                "the",
                "house",
                ",",
                "where",
                "my",
                "tree",
                "be",
                "."
            ],
            [
                "all",
                "three",
                "of",
                "they",
                "be",
                "right",
                "where",
                "they",
                "belong",
                ",",
                "no",
                "limb",
                "miss",
                ",",
                "enjoy",
                "the",
                "sunshine",
                "."
            ]
        ],
        "label": "Surprise"
    },
    {
        "body_part_token_idx": 28,
        "sentence_id": "cf61e76b-e63b-3bbc-a63b-678daee91bd0",
        "tokens": [
            "But",
            "she",
            "does",
            "n't",
            "know",
            "how",
            "much",
            "I",
            "ache",
            "whenever",
            "she",
            "touches",
            "me",
            "with",
            "those",
            "hands",
            ",",
            "those",
            "eyes",
            ",",
            "those",
            "lips",
            ",",
            "that",
            "ache",
            "that",
            "connects",
            "my",
            "heart",
            ",",
            "my",
            "gut",
            ",",
            "and",
            "my",
            "cunt",
            "in",
            "one",
            "fell",
            "swoop",
            "."
        ],
        "lemmatized_tokens": [
            "but",
            "she",
            "do",
            "not",
            "know",
            "how",
            "much",
            "I",
            "ache",
            "whenever",
            "she",
            "touch",
            "I",
            "with",
            "those",
            "hand",
            ",",
            "those",
            "eye",
            ",",
            "those",
            "lip",
            ",",
            "that",
            "ache",
            "that",
            "connect",
            "my",
            "heart",
            ",",
            "my",
            "gut",
            ",",
            "and",
            "my",
            "cunt",
            "in",
            "one",
            "fall",
            "swoop",
            "."
        ],
        "preceding_context_tokens": [
            [
                "I",
                "think",
                "she",
                "'s",
                "almost",
                "amused",
                "by",
                "how",
                "*",
                "seriously",
                "*",
                "I",
                "take",
                "her",
                "questions",
                "."
            ],
            [
                "Was",
                "I",
                "good",
                "?"
            ],
            [
                "Did",
                "I",
                "do",
                "what",
                "she",
                "wanted",
                "me",
                "to",
                "do",
                "?"
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "I",
                "think",
                "she",
                "be",
                "almost",
                "amuse",
                "by",
                "how",
                "*",
                "seriously",
                "*",
                "I",
                "take",
                "she",
                "question",
                "."
            ],
            [
                "be",
                "I",
                "good",
                "?"
            ],
            [
                "do",
                "I",
                "do",
                "what",
                "she",
                "want",
                "I",
                "to",
                "do",
                "?"
            ]
        ],
        "label": "Joy"
    },
    {
        "body_part_token_idx": 6,
        "sentence_id": "0ff74aa5-2d73-3e80-9b37-027c2bca3e16",
        "tokens": [
            "Dean",
            "snorted",
            "incredulously",
            ",",
            "shaking",
            "his",
            "head",
            "in",
            "disbelief",
            "."
        ],
        "lemmatized_tokens": [
            "Dean",
            "snort",
            "incredulously",
            ",",
            "shake",
            "he",
            "head",
            "in",
            "disbelief",
            "."
        ],
        "preceding_context_tokens": [
            [
                "``",
                "They",
                "'re",
                "really",
                "not",
                "that",
                "bad",
                "!",
                "''"
            ],
            [
                "Sam",
                "insisted",
                "."
            ],
            [
                "``",
                "Oh",
                "yeah",
                "?",
                "''"
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "``",
                "they",
                "be",
                "really",
                "not",
                "that",
                "bad",
                "!",
                "''"
            ],
            [
                "Sam",
                "insist",
                "."
            ],
            [
                "``",
                "oh",
                "yeah",
                "?",
                "''"
            ]
        ],
        "label": "Disgust"
    },
    {
        "body_part_token_idx": 3,
        "sentence_id": "0929bf69-9e2d-3136-aefa-9df484c25fef",
        "tokens": [
            "Reita",
            "shrugged",
            "his",
            "shoulders",
            "``",
            "What",
            "?"
        ],
        "lemmatized_tokens": [
            "Reita",
            "shrug",
            "he",
            "shoulder",
            "``",
            "what",
            "?"
        ],
        "preceding_context_tokens": [
            [
                "He",
                "thought",
                "for",
                "a",
                "second",
                "before",
                "continuing",
                "."
            ],
            [
                "``",
                "This",
                "silly",
                "spell",
                "I",
                "must",
                "undo",
                "...",
                "but",
                "only",
                "because",
                "Kai",
                "told",
                "me",
                "too",
                ".",
                "''"
            ],
            [
                "They",
                "all",
                "stared",
                "at",
                "Ruki",
                "but",
                "nothing",
                "happened",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "he",
                "think",
                "for",
                "a",
                "second",
                "before",
                "continue",
                "."
            ],
            [
                "``",
                "this",
                "silly",
                "spell",
                "I",
                "must",
                "undo",
                "...",
                "but",
                "only",
                "because",
                "Kai",
                "tell",
                "I",
                "too",
                ".",
                "''"
            ],
            [
                "they",
                "all",
                "stare",
                "at",
                "Ruki",
                "but",
                "nothing",
                "happen",
                "."
            ]
        ],
        "label": "Surprise"
    },
    {
        "body_part_token_idx": 5,
        "sentence_id": "1fd54f0a-1728-3181-8e5c-c16aaf7dceca",
        "tokens": [
            "Ignoring",
            "the",
            "ache",
            "in",
            "his",
            "heart",
            ",",
            "he",
            "tried",
            "his",
            "best",
            "not",
            "to",
            "move",
            "when",
            "he",
            "felt",
            "something",
            "wetting",
            "his",
            "thin",
            "white",
            "singlet",
            "that",
            "he",
            "was",
            "wearing",
            "."
        ],
        "lemmatized_tokens": [
            "ignore",
            "the",
            "ache",
            "in",
            "he",
            "heart",
            ",",
            "he",
            "try",
            "he",
            "best",
            "not",
            "to",
            "move",
            "when",
            "he",
            "feel",
            "something",
            "wet",
            "he",
            "thin",
            "white",
            "singlet",
            "that",
            "he",
            "be",
            "wear",
            "."
        ],
        "preceding_context_tokens": [
            [
                "He",
                "ran",
                "a",
                "soothing",
                "hand",
                "down",
                "the",
                "other",
                "man",
                "'s",
                "arm",
                ",",
                "trying",
                "to",
                "re-assure",
                "Yunho",
                "that",
                "he",
                "was",
                "n't",
                "going",
                "anywhere",
                "."
            ],
            [
                "It",
                "was",
                "late",
                "outside",
                ",",
                "one",
                "maybe",
                "two",
                "in",
                "the",
                "morning",
                ",",
                "quite",
                "late",
                "for",
                "a",
                "member",
                "idol",
                "who",
                "needs",
                "to",
                "wake",
                "up",
                "at",
                "six",
                "in",
                "the",
                "morning",
                "."
            ],
            [
                "He",
                "tried",
                "to",
                "count",
                "the",
                "blinking",
                "stars",
                ",",
                "absently",
                "concluding",
                "that",
                "those",
                "small",
                "bulbs",
                "of",
                "light",
                "were",
                "a",
                "bit",
                "withdrawn",
                "tonight",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "he",
                "run",
                "a",
                "soothing",
                "hand",
                "down",
                "the",
                "other",
                "man",
                "'s",
                "arm",
                ",",
                "try",
                "to",
                "re-assure",
                "Yunho",
                "that",
                "he",
                "be",
                "not",
                "go",
                "anywhere",
                "."
            ],
            [
                "it",
                "be",
                "late",
                "outside",
                ",",
                "one",
                "maybe",
                "two",
                "in",
                "the",
                "morning",
                ",",
                "quite",
                "late",
                "for",
                "a",
                "member",
                "idol",
                "who",
                "need",
                "to",
                "wake",
                "up",
                "at",
                "six",
                "in",
                "the",
                "morning",
                "."
            ],
            [
                "he",
                "try",
                "to",
                "count",
                "the",
                "blink",
                "star",
                ",",
                "absently",
                "conclude",
                "that",
                "those",
                "small",
                "bulb",
                "of",
                "light",
                "be",
                "a",
                "bit",
                "withdraw",
                "tonight",
                "."
            ]
        ],
        "label": "Sadness"
    },
    {
        "body_part_token_idx": 7,
        "sentence_id": "2d98c178-d498-310e-8238-2bfe1a72507c",
        "tokens": [
            "``",
            "She",
            "sniffles",
            "and",
            "pushes",
            "at",
            "her",
            "eyes",
            "with",
            "the",
            "side",
            "of",
            "her",
            "finger",
            ",",
            "trying",
            "not",
            "to",
            "cry",
            "as",
            "she",
            "turns",
            "to",
            "point",
            "out",
            "where",
            "she",
            "hit",
            "her",
            "head",
            ".",
            "''"
        ],
        "lemmatized_tokens": [
            "``",
            "she",
            "sniffle",
            "and",
            "push",
            "at",
            "she",
            "eye",
            "with",
            "the",
            "side",
            "of",
            "she",
            "finger",
            ",",
            "try",
            "not",
            "to",
            "cry",
            "as",
            "she",
            "turn",
            "to",
            "point",
            "out",
            "where",
            "she",
            "hit",
            "she",
            "head",
            ".",
            "''"
        ],
        "preceding_context_tokens": [
            [
                "She",
                "starts",
                "to",
                "cry",
                "and",
                "the",
                "red",
                "headed",
                "man",
                "tells",
                "the",
                "butler",
                "to",
                "shut",
                "her",
                "up",
                ",",
                "saying",
                "he",
                "has",
                "no",
                "time",
                "for",
                "this.The",
                "butler",
                "walks",
                "over",
                "as",
                "the",
                "man",
                "leaves",
                "for",
                "a",
                "room",
                ",",
                "the",
                "door",
                "clicking",
                "locked",
                "."
            ],
            [
                "``",
                "Shhh",
                ",",
                "it",
                "'s",
                "alright",
                "Waverly",
                "."
            ],
            [
                "Let",
                "'s",
                "have",
                "a",
                "look",
                "at",
                "your",
                "head",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "she",
                "start",
                "to",
                "cry",
                "and",
                "the",
                "red",
                "headed",
                "man",
                "tell",
                "the",
                "butler",
                "to",
                "shut",
                "she",
                "up",
                ",",
                "say",
                "he",
                "have",
                "no",
                "time",
                "for",
                "this.the",
                "butler",
                "walk",
                "over",
                "as",
                "the",
                "man",
                "leave",
                "for",
                "a",
                "room",
                ",",
                "the",
                "door",
                "click",
                "lock",
                "."
            ],
            [
                "``",
                "Shhh",
                ",",
                "it",
                "be",
                "alright",
                "Waverly",
                "."
            ],
            [
                "let",
                "'s",
                "have",
                "a",
                "look",
                "at",
                "you",
                "head",
                "."
            ]
        ],
        "label": "Sadness"
    },
    {
        "body_part_token_idx": 13,
        "sentence_id": "2d98c178-d498-310e-8238-2bfe1a72507c",
        "tokens": [
            "``",
            "She",
            "sniffles",
            "and",
            "pushes",
            "at",
            "her",
            "eyes",
            "with",
            "the",
            "side",
            "of",
            "her",
            "finger",
            ",",
            "trying",
            "not",
            "to",
            "cry",
            "as",
            "she",
            "turns",
            "to",
            "point",
            "out",
            "where",
            "she",
            "hit",
            "her",
            "head",
            ".",
            "''"
        ],
        "lemmatized_tokens": [
            "``",
            "she",
            "sniffle",
            "and",
            "push",
            "at",
            "she",
            "eye",
            "with",
            "the",
            "side",
            "of",
            "she",
            "finger",
            ",",
            "try",
            "not",
            "to",
            "cry",
            "as",
            "she",
            "turn",
            "to",
            "point",
            "out",
            "where",
            "she",
            "hit",
            "she",
            "head",
            ".",
            "''"
        ],
        "preceding_context_tokens": [
            [
                "She",
                "starts",
                "to",
                "cry",
                "and",
                "the",
                "red",
                "headed",
                "man",
                "tells",
                "the",
                "butler",
                "to",
                "shut",
                "her",
                "up",
                ",",
                "saying",
                "he",
                "has",
                "no",
                "time",
                "for",
                "this.The",
                "butler",
                "walks",
                "over",
                "as",
                "the",
                "man",
                "leaves",
                "for",
                "a",
                "room",
                ",",
                "the",
                "door",
                "clicking",
                "locked",
                "."
            ],
            [
                "``",
                "Shhh",
                ",",
                "it",
                "'s",
                "alright",
                "Waverly",
                "."
            ],
            [
                "Let",
                "'s",
                "have",
                "a",
                "look",
                "at",
                "your",
                "head",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "she",
                "start",
                "to",
                "cry",
                "and",
                "the",
                "red",
                "headed",
                "man",
                "tell",
                "the",
                "butler",
                "to",
                "shut",
                "she",
                "up",
                ",",
                "say",
                "he",
                "have",
                "no",
                "time",
                "for",
                "this.the",
                "butler",
                "walk",
                "over",
                "as",
                "the",
                "man",
                "leave",
                "for",
                "a",
                "room",
                ",",
                "the",
                "door",
                "click",
                "lock",
                "."
            ],
            [
                "``",
                "Shhh",
                ",",
                "it",
                "be",
                "alright",
                "Waverly",
                "."
            ],
            [
                "let",
                "'s",
                "have",
                "a",
                "look",
                "at",
                "you",
                "head",
                "."
            ]
        ],
        "label": "Sadness"
    },
    {
        "body_part_token_idx": 41,
        "sentence_id": "d50277aa-d9f5-3270-b10c-08a601b671ae",
        "tokens": [
            "``",
            "I",
            "\"",
            "m",
            "sorry",
            ",",
            "\"",
            "were",
            "his",
            "last",
            "words",
            ",",
            "before",
            "he",
            "placed",
            "the",
            "gun",
            "against",
            "his",
            "temple.A",
            "gunshot",
            "rang",
            "through",
            "the",
            "hallways",
            "of",
            "Tree",
            "Hill",
            "High",
            "School",
            "for",
            "the",
            "third",
            "time",
            "that",
            "day",
            "and",
            "Lucas",
            "fell",
            "to",
            "his",
            "knees",
            ",",
            "vaguely",
            "aware",
            "of",
            "his",
            "Uncle",
            "Keith",
            "\"",
            "s",
            "hurried",
            "voice",
            "at",
            "his",
            "side",
            "."
        ],
        "lemmatized_tokens": [
            "``",
            "I",
            "\"",
            "m",
            "sorry",
            ",",
            "\"",
            "be",
            "he",
            "last",
            "word",
            ",",
            "before",
            "he",
            "place",
            "the",
            "gun",
            "against",
            "he",
            "temple.a",
            "gunshot",
            "ring",
            "through",
            "the",
            "hallway",
            "of",
            "Tree",
            "Hill",
            "High",
            "School",
            "for",
            "the",
            "third",
            "time",
            "that",
            "day",
            "and",
            "Lucas",
            "fall",
            "to",
            "he",
            "knee",
            ",",
            "vaguely",
            "aware",
            "of",
            "he",
            "Uncle",
            "Keith",
            "\"",
            "s",
            "hurried",
            "voice",
            "at",
            "he",
            "side",
            "."
        ],
        "preceding_context_tokens": [
            [
                "Glass",
                "shattered",
                "behind",
                "them",
                ",",
                "the",
                "far",
                "-",
                "doors",
                "making",
                "the",
                "brunt",
                "impact",
                "of",
                "the",
                "bullet",
                "that",
                "had",
                "grazed",
                "against",
                "Lucas",
                "\"",
                "s",
                "ribcage.He",
                "stumbled",
                "to",
                "the",
                "other",
                "side",
                "of",
                "the",
                "hallway",
                ",",
                "catching",
                "his",
                "weight",
                "against",
                "the",
                "wall",
                "."
            ],
            [
                "He",
                "shifted",
                "Peyton",
                "\"",
                "s",
                "fragile",
                "form",
                "to",
                "one",
                "side",
                ",",
                "setting",
                "his",
                "hand",
                "against",
                "the",
                "other",
                ",",
                "feeling",
                "something",
                "wet",
                "and",
                "sticky",
                "pooled",
                "around",
                "his",
                "hip",
                "."
            ],
            [
                "He",
                "dazedly",
                "looked",
                "up",
                "at",
                "the",
                "shooter",
                ",",
                "taking",
                "in",
                "Jimmy",
                "\"",
                "s",
                "pallid",
                "shaking",
                ",",
                "a",
                "choked",
                "sob",
                "rising",
                "in",
                "the",
                "throat",
                ",",
                "unable",
                "to",
                "tear",
                "his",
                "eyes",
                "away",
                "from",
                "the",
                "blood",
                "drenching",
                "Lucas",
                "\"",
                "s",
                "t",
                "-",
                "shirt",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "Glass",
                "shatter",
                "behind",
                "they",
                ",",
                "the",
                "far",
                "-",
                "door",
                "make",
                "the",
                "brunt",
                "impact",
                "of",
                "the",
                "bullet",
                "that",
                "have",
                "graze",
                "against",
                "Lucas",
                "\"",
                "s",
                "ribcage.He",
                "stumble",
                "to",
                "the",
                "other",
                "side",
                "of",
                "the",
                "hallway",
                ",",
                "catch",
                "he",
                "weight",
                "against",
                "the",
                "wall",
                "."
            ],
            [
                "he",
                "shift",
                "Peyton",
                "\"",
                "s",
                "fragile",
                "form",
                "to",
                "one",
                "side",
                ",",
                "set",
                "he",
                "hand",
                "against",
                "the",
                "other",
                ",",
                "feel",
                "something",
                "wet",
                "and",
                "sticky",
                "pool",
                "around",
                "he",
                "hip",
                "."
            ],
            [
                "he",
                "dazedly",
                "look",
                "up",
                "at",
                "the",
                "shooter",
                ",",
                "take",
                "in",
                "Jimmy",
                "\"",
                "s",
                "pallid",
                "shaking",
                ",",
                "a",
                "choke",
                "sob",
                "rise",
                "in",
                "the",
                "throat",
                ",",
                "unable",
                "to",
                "tear",
                "he",
                "eye",
                "away",
                "from",
                "the",
                "blood",
                "drenching",
                "Lucas",
                "\"",
                "s",
                "t",
                "-",
                "shirt",
                "."
            ]
        ],
        "label": "Sadness"
    },
    {
        "body_part_token_idx": 3,
        "sentence_id": "898758b6-1fc8-3e49-8562-42998c49aa68",
        "tokens": [
            "Sheldon",
            "cleared",
            "his",
            "throat",
            ",",
            "``",
            "There",
            "is",
            "a",
            "time",
            "and",
            "a",
            "place",
            "for",
            "everything",
            ",",
            "Penny",
            "."
        ],
        "lemmatized_tokens": [
            "Sheldon",
            "clear",
            "he",
            "throat",
            ",",
            "``",
            "there",
            "be",
            "a",
            "time",
            "and",
            "a",
            "place",
            "for",
            "everything",
            ",",
            "penny",
            "."
        ],
        "preceding_context_tokens": [
            [
                "``",
                "The",
                "shoes",
                "?",
                "''"
            ],
            [
                "Penny",
                "was",
                "confused",
                "."
            ],
            [
                "``",
                "I",
                "thought",
                "you",
                "liked",
                "shoes",
                ".",
                "''"
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "``",
                "the",
                "shoe",
                "?",
                "''"
            ],
            [
                "penny",
                "be",
                "confuse",
                "."
            ],
            [
                "``",
                "I",
                "think",
                "you",
                "like",
                "shoe",
                ".",
                "''"
            ]
        ],
        "label": "Disgust"
    },
    {
        "body_part_token_idx": 12,
        "sentence_id": "652a8ee5-949b-3545-b7fd-87abfd55bbc4",
        "tokens": [
            "Every",
            "time",
            "her",
            "dog",
            "lifted",
            "its",
            "leg",
            "or",
            "squatted",
            "she",
            "pursed",
            "her",
            "lips",
            "and",
            "looked",
            "the",
            "other",
            "way",
            "."
        ],
        "lemmatized_tokens": [
            "every",
            "time",
            "she",
            "dog",
            "lift",
            "its",
            "leg",
            "or",
            "squat",
            "she",
            "purse",
            "she",
            "lip",
            "and",
            "look",
            "the",
            "other",
            "way",
            "."
        ],
        "preceding_context_tokens": [
            [
                "James",
                "walked",
                "with",
                "his",
                "bowl",
                "and",
                "sat",
                "again",
                "on",
                "the",
                "window",
                "seat",
                "looking",
                "out",
                "."
            ],
            [
                "He",
                "watched",
                "a",
                "woman",
                "`",
                "walk",
                "'",
                "her",
                "dog",
                "round",
                "the",
                "small",
                "front",
                "garden",
                "."
            ],
            [
                "It",
                "was",
                "a",
                "poodle",
                ",",
                "prancing",
                "and",
                "pooing",
                "-",
                "its",
                "dance",
                "was",
                "quite",
                "amusing",
                "but",
                "the",
                "owner",
                "was",
                "better",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "James",
                "walk",
                "with",
                "he",
                "bowl",
                "and",
                "sit",
                "again",
                "on",
                "the",
                "window",
                "seat",
                "look",
                "out",
                "."
            ],
            [
                "he",
                "watch",
                "a",
                "woman",
                "`",
                "walk",
                "'",
                "she",
                "dog",
                "round",
                "the",
                "small",
                "front",
                "garden",
                "."
            ],
            [
                "it",
                "be",
                "a",
                "poodle",
                ",",
                "prance",
                "and",
                "poo",
                "-",
                "its",
                "dance",
                "be",
                "quite",
                "amusing",
                "but",
                "the",
                "owner",
                "be",
                "better",
                "."
            ]
        ],
        "label": "Disgust"
    },
    {
        "body_part_token_idx": 11,
        "sentence_id": "0e2e3487-9d76-30e9-a0d2-b7e4cdc5f443",
        "tokens": [
            "She",
            "slowly",
            "stood",
            "up",
            "and",
            "walked",
            "to",
            "a",
            "corner",
            "with",
            "her",
            "arms",
            "around",
            "her",
            "in",
            "comfort.",
            "My",
            "mother.",
            "Was",
            "all",
            "she",
            "said.",
            "Well",
            ",",
            "Erik",
            "stood",
            "up",
            "and",
            "walked",
            "to",
            "her",
            "."
        ],
        "lemmatized_tokens": [
            "she",
            "slowly",
            "stand",
            "up",
            "and",
            "walk",
            "to",
            "a",
            "corner",
            "with",
            "she",
            "arm",
            "around",
            "she",
            "in",
            "comfort.",
            "my",
            "mother.",
            "be",
            "all",
            "she",
            "said.",
            "well",
            ",",
            "Erik",
            "stand",
            "up",
            "and",
            "walk",
            "to",
            "she",
            "."
        ],
        "preceding_context_tokens": [
            [
                "This",
                "song",
                "should",
                "be",
                "sung",
                "to",
                "someone",
                "it",
                "will",
                "have",
                "a",
                "great",
                "impact",
                "on",
                "."
            ],
            [
                "Is",
                "there",
                "anyone",
                "in",
                "your",
                "life",
                "who",
                "could",
                "be",
                "touched",
                "by",
                "this",
                "song?",
                "Erik",
                "looked",
                "into",
                "her",
                "eyes",
                "as",
                "her",
                "realization",
                "began",
                "to",
                "take",
                "place",
                "in",
                "her",
                "mind",
                "."
            ],
            [
                "Adele",
                "'s",
                "eyes",
                "grew",
                "teary",
                "and",
                "she",
                "looked",
                "away",
                "from",
                "Erik",
                "'s",
                "gaze",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "this",
                "song",
                "should",
                "be",
                "sing",
                "to",
                "someone",
                "it",
                "will",
                "have",
                "a",
                "great",
                "impact",
                "on",
                "."
            ],
            [
                "be",
                "there",
                "anyone",
                "in",
                "you",
                "life",
                "who",
                "could",
                "be",
                "touch",
                "by",
                "this",
                "song?",
                "Erik",
                "look",
                "into",
                "she",
                "eye",
                "as",
                "she",
                "realization",
                "begin",
                "to",
                "take",
                "place",
                "in",
                "she",
                "mind",
                "."
            ],
            [
                "Adele",
                "'s",
                "eye",
                "grow",
                "teary",
                "and",
                "she",
                "look",
                "away",
                "from",
                "Erik",
                "'s",
                "gaze",
                "."
            ]
        ],
        "label": "Sadness"
    },
    {
        "body_part_token_idx": 1,
        "sentence_id": "ee52f6cf-2feb-3e44-9cf0-a78e92f9741e",
        "tokens": [
            "His",
            "face",
            "was",
            "as",
            "colorless",
            "as",
            "Olga",
            "knew",
            "her",
            "own",
            "to",
            "be",
            "and",
            "his",
            "hands",
            "were",
            "clenched",
            "into",
            "fists",
            "at",
            "his",
            "said",
            "."
        ],
        "lemmatized_tokens": [
            "he",
            "face",
            "be",
            "as",
            "colorless",
            "as",
            "Olga",
            "know",
            "she",
            "own",
            "to",
            "be",
            "and",
            "he",
            "hand",
            "be",
            "clench",
            "into",
            "fist",
            "at",
            "he",
            "say",
            "."
        ],
        "preceding_context_tokens": [
            [
                "Teddy",
                "was",
                "loudly",
                "proclaiming",
                "Dan",
                "to",
                "be",
                "a",
                "fiend",
                "and",
                "Jem",
                "was",
                "coughing",
                ",",
                "having",
                "had",
                "the",
                "misfortune",
                "to",
                "have",
                "taken",
                "a",
                "bite",
                "of",
                "fig",
                "pudding",
                "a",
                "moment",
                "before",
                "Dan",
                "'s",
                "announcement",
                "and",
                "promptly",
                "choking",
                "on",
                "it",
                "."
            ],
            [
                "But",
                "it",
                "was",
                "Jordan",
                "'s",
                "reaction",
                "that",
                "bothered",
                "her",
                "the",
                "most",
                "."
            ],
            [
                "He",
                "had",
                "stood",
                "upright",
                "at",
                "Dan",
                "'s",
                "pronouncement",
                ",",
                "his",
                "book",
                "falling",
                "aside",
                "unnoticed",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "Teddy",
                "be",
                "loudly",
                "proclaim",
                "Dan",
                "to",
                "be",
                "a",
                "fiend",
                "and",
                "Jem",
                "be",
                "cough",
                ",",
                "have",
                "have",
                "the",
                "misfortune",
                "to",
                "have",
                "take",
                "a",
                "bite",
                "of",
                "fig",
                "pudding",
                "a",
                "moment",
                "before",
                "Dan",
                "'s",
                "announcement",
                "and",
                "promptly",
                "choke",
                "on",
                "it",
                "."
            ],
            [
                "but",
                "it",
                "be",
                "Jordan",
                "'s",
                "reaction",
                "that",
                "bother",
                "she",
                "the",
                "most",
                "."
            ],
            [
                "he",
                "have",
                "stand",
                "upright",
                "at",
                "Dan",
                "'s",
                "pronouncement",
                ",",
                "he",
                "book",
                "fall",
                "aside",
                "unnoticed",
                "."
            ]
        ],
        "label": "Anger"
    },
    {
        "body_part_token_idx": 1,
        "sentence_id": "53f051f0-3d24-30bc-b2db-604a7a627ebb",
        "tokens": [
            "My",
            "knuckles",
            "turn",
            "white",
            "though",
            "."
        ],
        "lemmatized_tokens": [
            "my",
            "knuckle",
            "turn",
            "white",
            "though",
            "."
        ],
        "preceding_context_tokens": [
            [
                "My",
                "knuckles",
                "turn",
                "white",
                "when",
                "I",
                "'m",
                "nervous",
                "."
            ],
            [
                "When",
                "I",
                "hear",
                "bad",
                "news",
                "I",
                "do",
                "n't",
                "cry",
                "right",
                "away",
                "."
            ],
            [
                "I",
                "do",
                "n't",
                "panic",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "my",
                "knuckle",
                "turn",
                "white",
                "when",
                "I",
                "be",
                "nervous",
                "."
            ],
            [
                "when",
                "I",
                "hear",
                "bad",
                "news",
                "I",
                "do",
                "not",
                "cry",
                "right",
                "away",
                "."
            ],
            [
                "I",
                "do",
                "not",
                "panic",
                "."
            ]
        ],
        "label": "Fear"
    },
    {
        "body_part_token_idx": 2,
        "sentence_id": "afef1720-7689-3ab0-894a-dfcb68390022",
        "tokens": [
            "Then",
            "her",
            "face",
            "changed",
            "."
        ],
        "lemmatized_tokens": [
            "then",
            "she",
            "face",
            "change",
            "."
        ],
        "preceding_context_tokens": [
            [
                "I",
                "almost",
                "broke",
                "my",
                "ankle",
                "on",
                "that",
                "cup",
                "thing",
                "rolling",
                "on",
                "the",
                "floor",
                ",",
                "you",
                "know",
                ",",
                "he",
                "protested",
                "at",
                "Alice",
                "'s",
                "knowing",
                "look",
                "."
            ],
            [
                "So",
                ",",
                "you",
                "'re",
                "tired",
                "because",
                "you",
                "fell",
                "over",
                "?"
            ],
            [
                "And",
                "the",
                "Oath",
                "Grail",
                "is",
                "a",
                "very",
                "powerful",
                "object",
                "``",
                "we",
                "only",
                "have",
                "to",
                "find",
                "out",
                "how",
                "it",
                "works",
                ",",
                "she",
                "said",
                ",",
                "lightly",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "I",
                "almost",
                "break",
                "my",
                "ankle",
                "on",
                "that",
                "cup",
                "thing",
                "roll",
                "on",
                "the",
                "floor",
                ",",
                "you",
                "know",
                ",",
                "he",
                "protest",
                "at",
                "Alice",
                "'s",
                "know",
                "look",
                "."
            ],
            [
                "so",
                ",",
                "you",
                "be",
                "tired",
                "because",
                "you",
                "fall",
                "over",
                "?"
            ],
            [
                "and",
                "the",
                "oath",
                "Grail",
                "be",
                "a",
                "very",
                "powerful",
                "object",
                "``",
                "we",
                "only",
                "have",
                "to",
                "find",
                "out",
                "how",
                "it",
                "work",
                ",",
                "she",
                "say",
                ",",
                "lightly",
                "."
            ]
        ],
        "label": "Surprise"
    },
    {
        "body_part_token_idx": 10,
        "sentence_id": "bf7aa02e-3528-3bc3-9876-b235eb3e603a",
        "tokens": [
            "Then",
            "why",
            "is",
            "he",
            "looking",
            "for",
            "it?",
            "Rikku",
            "wrinkled",
            "her",
            "nose",
            "."
        ],
        "lemmatized_tokens": [
            "then",
            "why",
            "be",
            "he",
            "look",
            "for",
            "it?",
            "Rikku",
            "wrinkle",
            "she",
            "nose",
            "."
        ],
        "preceding_context_tokens": [
            [
                "What",
                "did",
                "you",
                "do",
                "to",
                "him?",
                "I",
                "just",
                "asked",
                "him",
                "to",
                "find",
                "a",
                "certain",
                "gear",
                "for",
                "me.",
                "Rikku",
                "blinked",
                "innocently",
                "up",
                "at",
                "Paine",
                "."
            ],
            [
                "There",
                "'s",
                "only",
                "one",
                "gear",
                "in",
                "stock",
                "right",
                "now",
                ",",
                "and",
                "it",
                "'s",
                "small",
                ",",
                "which",
                "will",
                "make",
                "it",
                "very",
                "difficult",
                "to",
                "find.",
                "Where",
                "is",
                "it?",
                "Paine",
                "asked",
                "."
            ],
            [
                "Right",
                "here.",
                "Rikku",
                "opened",
                "her",
                "palm",
                ",",
                "revealing",
                "a",
                "small",
                "silver",
                "gear",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "what",
                "do",
                "you",
                "do",
                "to",
                "him?",
                "I",
                "just",
                "ask",
                "he",
                "to",
                "find",
                "a",
                "certain",
                "gear",
                "for",
                "me.",
                "Rikku",
                "blink",
                "innocently",
                "up",
                "at",
                "Paine",
                "."
            ],
            [
                "there",
                "be",
                "only",
                "one",
                "gear",
                "in",
                "stock",
                "right",
                "now",
                ",",
                "and",
                "it",
                "be",
                "small",
                ",",
                "which",
                "will",
                "make",
                "it",
                "very",
                "difficult",
                "to",
                "find.",
                "where",
                "be",
                "it?",
                "Paine",
                "ask",
                "."
            ],
            [
                "right",
                "here.",
                "Rikku",
                "open",
                "she",
                "palm",
                ",",
                "reveal",
                "a",
                "small",
                "silver",
                "gear",
                "."
            ]
        ],
        "label": "Surprise"
    },
    {
        "body_part_token_idx": 12,
        "sentence_id": "2e10a863-39e6-3a1c-a6df-d1456ed186c4",
        "tokens": [
            "``",
            "It",
            "means",
            "$",
            "''",
            "he",
            "blew",
            "his",
            "bangs",
            "out",
            "of",
            "his",
            "eyes",
            "and",
            "plopped",
            "down",
            "on",
            "the",
            "floor",
            "."
        ],
        "lemmatized_tokens": [
            "``",
            "it",
            "mean",
            "$",
            "''",
            "he",
            "blow",
            "he",
            "bang",
            "out",
            "of",
            "he",
            "eye",
            "and",
            "plop",
            "down",
            "on",
            "the",
            "floor",
            "."
        ],
        "preceding_context_tokens": [
            [
                "``",
                "You",
                "do",
                "n't",
                "get",
                "it",
                "."
            ],
            [
                "I",
                "know",
                "what",
                "it",
                "is",
                "."
            ],
            [
                "But",
                "what",
                "does",
                "it",
                "mean",
                "?",
                "''"
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "``",
                "you",
                "do",
                "not",
                "get",
                "it",
                "."
            ],
            [
                "I",
                "know",
                "what",
                "it",
                "be",
                "."
            ],
            [
                "but",
                "what",
                "do",
                "it",
                "mean",
                "?",
                "''"
            ]
        ],
        "label": "Joy"
    },
    {
        "body_part_token_idx": 14,
        "sentence_id": "ffc289d9-4d9f-30da-87a1-b5f1db27c971",
        "tokens": [
            "When",
            "they",
            "stood",
            "there",
            ",",
            "he",
            "looked",
            "at",
            "Jungmin",
            "who",
            "had",
            "tears",
            "in",
            "his",
            "eyes",
            "."
        ],
        "lemmatized_tokens": [
            "when",
            "they",
            "stand",
            "there",
            ",",
            "he",
            "look",
            "at",
            "Jungmin",
            "who",
            "have",
            "tear",
            "in",
            "he",
            "eye",
            "."
        ],
        "preceding_context_tokens": [
            [
                "It",
                "was",
                "n't",
                "far",
                "towards",
                "the",
                "playground",
                "from",
                "the",
                "hospital",
                "and",
                "arrived",
                "there",
                "after",
                "a",
                "short",
                "walk",
                "."
            ],
            [
                "``",
                "Let",
                "'s",
                "go",
                "up",
                "the",
                "hill",
                "where",
                "the",
                "swings",
                "are",
                ",",
                "you",
                "can",
                "see",
                "the",
                "sundown",
                "there",
                ".",
                "''"
            ],
            [
                "Minho",
                "whispered",
                ",",
                "before",
                "pushing",
                "the",
                "wheelchair",
                "up",
                "the",
                "hill",
                "with",
                "a",
                "lot",
                "of",
                "effort",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "it",
                "be",
                "not",
                "far",
                "towards",
                "the",
                "playground",
                "from",
                "the",
                "hospital",
                "and",
                "arrive",
                "there",
                "after",
                "a",
                "short",
                "walk",
                "."
            ],
            [
                "``",
                "let",
                "'s",
                "go",
                "up",
                "the",
                "hill",
                "where",
                "the",
                "swing",
                "be",
                ",",
                "you",
                "can",
                "see",
                "the",
                "sundown",
                "there",
                ".",
                "''"
            ],
            [
                "Minho",
                "whisper",
                ",",
                "before",
                "push",
                "the",
                "wheelchair",
                "up",
                "the",
                "hill",
                "with",
                "a",
                "lot",
                "of",
                "effort",
                "."
            ]
        ],
        "label": "Sadness"
    },
    {
        "body_part_token_idx": 6,
        "sentence_id": "603f790a-fac7-3a46-b6d1-f448cc9234b1",
        "tokens": [
            "``",
            "He",
            "seemed",
            "puzzled",
            ",",
            "his",
            "eyes",
            "not",
            "showing",
            "understanding",
            "at",
            "first",
            ",",
            "then",
            "he",
            "reached",
            "for",
            "his",
            "wallet",
            "and",
            "flipped",
            "it",
            "open",
            "in",
            "front",
            "of",
            "her",
            "face",
            "."
        ],
        "lemmatized_tokens": [
            "``",
            "he",
            "seem",
            "puzzled",
            ",",
            "he",
            "eye",
            "not",
            "show",
            "understanding",
            "at",
            "first",
            ",",
            "then",
            "he",
            "reach",
            "for",
            "he",
            "wallet",
            "and",
            "flip",
            "it",
            "open",
            "in",
            "front",
            "of",
            "she",
            "face",
            "."
        ],
        "preceding_context_tokens": [
            [
                "Are",
                "you",
                "going",
                "to",
                "murder",
                "me",
                "?"
            ],
            [
                "Are",
                "you",
                "some",
                "psycho",
                "...",
                "well",
                ",",
                "just",
                "do",
                "it",
                "."
            ],
            [
                "Spare",
                "me",
                "the",
                "fairytales",
                "and",
                "folklore",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "be",
                "you",
                "go",
                "to",
                "murder",
                "I",
                "?"
            ],
            [
                "be",
                "you",
                "some",
                "psycho",
                "...",
                "well",
                ",",
                "just",
                "do",
                "it",
                "."
            ],
            [
                "spare",
                "I",
                "the",
                "fairytales",
                "and",
                "folklore",
                "."
            ]
        ],
        "label": "Surprise"
    },
    {
        "body_part_token_idx": 17,
        "sentence_id": "b25e3f9f-8971-3ed5-960e-d80040688ebd",
        "tokens": [
            "Promise?Soiree",
            "'s",
            "head",
            "bumped",
            "gently",
            "against",
            "his",
            "own",
            ",",
            "and",
            "that",
            "was",
            "what",
            "made",
            "Alba",
            "open",
            "his",
            "eyes",
            "."
        ],
        "lemmatized_tokens": [
            "Promise?Soiree",
            "'s",
            "head",
            "bump",
            "gently",
            "against",
            "he",
            "own",
            ",",
            "and",
            "that",
            "be",
            "what",
            "make",
            "Alba",
            "open",
            "he",
            "eye",
            "."
        ],
        "preceding_context_tokens": [
            [
                "But",
                "he",
                "held",
                "up",
                "the",
                "blankets",
                "and",
                "wrapped",
                "his",
                "arms",
                "around",
                "Yasashiku",
                "'s",
                "waist",
                ",",
                "holding",
                "him",
                "close",
                ",",
                "and",
                "Yasashiku",
                "could",
                "n't",
                "stop",
                "the",
                "smile.Fandom",
                ":",
                "King",
                "of",
                "FightersPairing",
                ":",
                "Alba",
                "+",
                "Soiree",
                "-LRB-",
                "platonic",
                ")",
                "."
            ],
            [
                "Belated",
                "birthday",
                "fic",
                "."
            ],
            [
                ":",
                ")",
                "Prompt",
                ":",
                "30_friends",
                "6",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "but",
                "he",
                "hold",
                "up",
                "the",
                "blanket",
                "and",
                "wrap",
                "he",
                "arm",
                "around",
                "Yasashiku",
                "'s",
                "waist",
                ",",
                "hold",
                "he",
                "close",
                ",",
                "and",
                "Yasashiku",
                "could",
                "not",
                "stop",
                "the",
                "smile.fandom",
                ":",
                "King",
                "of",
                "FightersPairing",
                ":",
                "Alba",
                "+",
                "Soiree",
                "-LRB-",
                "platonic",
                ")",
                "."
            ],
            [
                "belated",
                "birthday",
                "fic",
                "."
            ],
            [
                ":",
                ")",
                "prompt",
                ":",
                "30_friends",
                "6",
                "."
            ]
        ],
        "label": "Surprise"
    },
    {
        "body_part_token_idx": 15,
        "sentence_id": "a6b62485-13be-3d34-aee2-d5165ce0b5b4",
        "tokens": [
            "Willie",
            "'s",
            "stomach",
            "took",
            "a",
            "mad",
            ",",
            "lurching",
            "dive",
            "as",
            "he",
            "sank",
            "back",
            "on",
            "his",
            "heels",
            ",",
            "feeling",
            "his",
            "shoulders",
            "sag",
            "."
        ],
        "lemmatized_tokens": [
            "Willie",
            "'s",
            "stomach",
            "take",
            "a",
            "mad",
            ",",
            "lurch",
            "dive",
            "as",
            "he",
            "sink",
            "back",
            "on",
            "he",
            "heel",
            ",",
            "feel",
            "he",
            "shoulder",
            "sag",
            "."
        ],
        "preceding_context_tokens": [
            [
                "Then",
                "he",
                "looked",
                "at",
                "Willie",
                "with",
                "dark",
                "eyes",
                "."
            ],
            [
                "``",
                "That",
                "is",
                "a",
                "falsehood",
                ",",
                "''",
                "he",
                "said",
                "with",
                "even",
                ",",
                "measured",
                "tones",
                "."
            ],
            [
                "``",
                "You",
                "'ve",
                "purchased",
                "the",
                "supplies",
                ",",
                "obviously",
                "you",
                "'ve",
                "already",
                "decided",
                "the",
                "course",
                "of",
                "action",
                "you",
                "would",
                "take",
                ".",
                "''"
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "then",
                "he",
                "look",
                "at",
                "Willie",
                "with",
                "dark",
                "eye",
                "."
            ],
            [
                "``",
                "that",
                "be",
                "a",
                "falsehood",
                ",",
                "''",
                "he",
                "say",
                "with",
                "even",
                ",",
                "measure",
                "tone",
                "."
            ],
            [
                "``",
                "you",
                "have",
                "purchase",
                "the",
                "supplies",
                ",",
                "obviously",
                "you",
                "have",
                "already",
                "decide",
                "the",
                "course",
                "of",
                "action",
                "you",
                "would",
                "take",
                ".",
                "''"
            ]
        ],
        "label": "Fear"
    },
    {
        "body_part_token_idx": 5,
        "sentence_id": "91458da1-58ba-3e1e-84f7-6b8f93dfb44f",
        "tokens": [
            "Drusilla",
            ",",
            "sadness",
            "in",
            "her",
            "eyes",
            ",",
            "snaked",
            "her",
            "hand",
            "up",
            "to",
            "the",
            "slayer",
            "'s",
            "lips",
            "and",
            "nodded",
            "."
        ],
        "lemmatized_tokens": [
            "Drusilla",
            ",",
            "sadness",
            "in",
            "she",
            "eye",
            ",",
            "snake",
            "she",
            "hand",
            "up",
            "to",
            "the",
            "slayer",
            "'s",
            "lip",
            "and",
            "nod",
            "."
        ],
        "preceding_context_tokens": [
            [
                "Let",
                "her",
                "go",
                "."
            ],
            [
                "He",
                "stood",
                "behind",
                "her",
                "girl",
                "with",
                "Faith",
                "'s",
                "own",
                "sword",
                "at",
                "her",
                "back",
                "."
            ],
            [
                "I",
                "see",
                "how",
                "this",
                "unfolds",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "let",
                "she",
                "go",
                "."
            ],
            [
                "he",
                "stand",
                "behind",
                "she",
                "girl",
                "with",
                "faith",
                "'s",
                "own",
                "sword",
                "at",
                "she",
                "back",
                "."
            ],
            [
                "I",
                "see",
                "how",
                "this",
                "unfold",
                "."
            ]
        ],
        "label": "Sadness"
    },
    {
        "body_part_token_idx": 9,
        "sentence_id": "2b956d18-9edc-37ca-8e7c-6a46cb1b8487",
        "tokens": [
            "Yeah",
            ",",
            "she",
            "managed",
            "to",
            "sigh",
            "blissfully",
            ",",
            "her",
            "eyes",
            "striving",
            "to",
            "focus",
            "."
        ],
        "lemmatized_tokens": [
            "yeah",
            ",",
            "she",
            "manage",
            "to",
            "sigh",
            "blissfully",
            ",",
            "she",
            "eye",
            "strive",
            "to",
            "focus",
            "."
        ],
        "preceding_context_tokens": [
            [
                "When",
                "she",
                "had",
                "stopped",
                ",",
                "he",
                "wiped",
                "his",
                "mouth",
                "with",
                "the",
                "back",
                "of",
                "his",
                "hand",
                "and",
                "smiled",
                "to",
                "himself",
                "."
            ],
            [
                "Bet",
                "they",
                "heard",
                "that",
                "all",
                "the",
                "way",
                "downstairs",
                ",",
                "he",
                "thought",
                "smugly",
                "."
            ],
            [
                "Big",
                "boom",
                ",",
                "huh?",
                "he",
                "asked",
                "as",
                "he",
                "rose",
                "on",
                "shaky",
                "knees",
                "to",
                "slip",
                "an",
                "arm",
                "around",
                "her",
                "back",
                "and",
                "draw",
                "her",
                "close",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "when",
                "she",
                "have",
                "stop",
                ",",
                "he",
                "wipe",
                "he",
                "mouth",
                "with",
                "the",
                "back",
                "of",
                "he",
                "hand",
                "and",
                "smile",
                "to",
                "himself",
                "."
            ],
            [
                "bet",
                "they",
                "hear",
                "that",
                "all",
                "the",
                "way",
                "downstairs",
                ",",
                "he",
                "think",
                "smugly",
                "."
            ],
            [
                "big",
                "boom",
                ",",
                "huh?",
                "he",
                "ask",
                "as",
                "he",
                "rise",
                "on",
                "shaky",
                "knee",
                "to",
                "slip",
                "a",
                "arm",
                "around",
                "she",
                "back",
                "and",
                "draw",
                "she",
                "close",
                "."
            ]
        ],
        "label": "Joy"
    },
    {
        "body_part_token_idx": 12,
        "sentence_id": "b1fa5aeb-dd7e-3131-9eb4-fd776a789d09",
        "tokens": [
            "I",
            "smiled",
            "and",
            "embraced",
            "myself",
            "as",
            "a",
            "single",
            "tear",
            "dripped",
            "down",
            "my",
            "cheek",
            "."
        ],
        "lemmatized_tokens": [
            "I",
            "smile",
            "and",
            "embrace",
            "myself",
            "as",
            "a",
            "single",
            "tear",
            "drip",
            "down",
            "my",
            "cheek",
            "."
        ],
        "preceding_context_tokens": [
            [
                "I",
                "allowed",
                "my",
                "mind",
                "to",
                "wander",
                "as",
                "I",
                "stared",
                "upon",
                "the",
                "blankness",
                "of",
                "it",
                "and",
                "giggled",
                "at",
                "the",
                "very",
                "notion",
                "that",
                "I",
                "no",
                "longer",
                "connected",
                "with",
                "the",
                "emptiness",
                "."
            ],
            [
                "My",
                "mind",
                "was",
                "full",
                "of",
                "exciting",
                "possibilities",
                "."
            ],
            [
                "I",
                "was",
                "happy",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "I",
                "allow",
                "my",
                "mind",
                "to",
                "wander",
                "as",
                "I",
                "stare",
                "upon",
                "the",
                "blankness",
                "of",
                "it",
                "and",
                "giggle",
                "at",
                "the",
                "very",
                "notion",
                "that",
                "I",
                "no",
                "longer",
                "connect",
                "with",
                "the",
                "emptiness",
                "."
            ],
            [
                "my",
                "mind",
                "be",
                "full",
                "of",
                "exciting",
                "possibility",
                "."
            ],
            [
                "I",
                "be",
                "happy",
                "."
            ]
        ],
        "label": "Joy"
    },
    {
        "body_part_token_idx": 5,
        "sentence_id": "b9c51c45-f864-3457-997f-24d3c59c85da",
        "tokens": [
            "And",
            "then",
            "she",
            "bit",
            "her",
            "tongue",
            "and",
            "raised",
            "her",
            "eyebrows",
            "expectantly",
            "at",
            "him",
            "."
        ],
        "lemmatized_tokens": [
            "and",
            "then",
            "she",
            "bite",
            "she",
            "tongue",
            "and",
            "raise",
            "she",
            "eyebrow",
            "expectantly",
            "at",
            "he",
            "."
        ],
        "preceding_context_tokens": [
            [
                "Can",
                "you",
                "bring",
                "it",
                "in",
                "?",
                "''"
            ],
            [
                "He",
                "arched",
                "an",
                "eyebrow",
                "at",
                "her",
                ",",
                "almost",
                "as",
                "if",
                "he",
                "could",
                "n't",
                "believe",
                "her",
                "words",
                "."
            ],
            [
                "She",
                "started",
                "to",
                "tell",
                "him",
                "to",
                "forget",
                "it",
                ",",
                "never",
                "mind",
                ",",
                "as",
                "her",
                "lovely",
                "afternoon",
                "of",
                "setting",
                "up",
                "Christmas",
                "decorations",
                "with",
                "Stefan",
                "faded",
                "in",
                "her",
                "mind",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "can",
                "you",
                "bring",
                "it",
                "in",
                "?",
                "''"
            ],
            [
                "he",
                "arch",
                "a",
                "eyebrow",
                "at",
                "she",
                ",",
                "almost",
                "as",
                "if",
                "he",
                "could",
                "not",
                "believe",
                "she",
                "word",
                "."
            ],
            [
                "she",
                "start",
                "to",
                "tell",
                "he",
                "to",
                "forget",
                "it",
                ",",
                "never",
                "mind",
                ",",
                "as",
                "she",
                "lovely",
                "afternoon",
                "of",
                "set",
                "up",
                "Christmas",
                "decoration",
                "with",
                "Stefan",
                "fade",
                "in",
                "she",
                "mind",
                "."
            ]
        ],
        "label": "Anger"
    },
    {
        "body_part_token_idx": 8,
        "sentence_id": "ea9a34a4-c0d8-3a23-a455-572d56bbc698",
        "tokens": [
            "I",
            "swing",
            "and",
            "bounce",
            "while",
            "picking",
            "at",
            "my",
            "nails",
            ",",
            "another",
            "little",
            "habit",
            "of",
            "mine",
            "."
        ],
        "lemmatized_tokens": [
            "I",
            "swing",
            "and",
            "bounce",
            "while",
            "pick",
            "at",
            "my",
            "nail",
            ",",
            "another",
            "little",
            "habit",
            "of",
            "mine",
            "."
        ],
        "preceding_context_tokens": [
            [
                "Airplanes",
                "are",
                "torturous",
                "for",
                "me",
                "."
            ],
            [
                "Ca",
                "n't",
                "bounce",
                "or",
                "I",
                "'d",
                "have",
                "very",
                "upset",
                "seatmates",
                "."
            ],
            [
                "At",
                "the",
                "movies",
                ",",
                "Josh",
                "is",
                "always",
                "squeezing",
                "my",
                "knee",
                "softly",
                "to",
                "remind",
                "me",
                "I",
                "'m",
                "shaking",
                "the",
                "entire",
                "row",
                "of",
                "theater",
                "seats",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "Airplanes",
                "be",
                "torturous",
                "for",
                "I",
                "."
            ],
            [
                "can",
                "not",
                "bounce",
                "or",
                "I",
                "would",
                "have",
                "very",
                "upset",
                "seatmate",
                "."
            ],
            [
                "at",
                "the",
                "movie",
                ",",
                "Josh",
                "be",
                "always",
                "squeeze",
                "my",
                "knee",
                "softly",
                "to",
                "remind",
                "I",
                "I",
                "be",
                "shake",
                "the",
                "entire",
                "row",
                "of",
                "theater",
                "seat",
                "."
            ]
        ],
        "label": "Sadness"
    },
    {
        "body_part_token_idx": 10,
        "sentence_id": "568eeffb-b6e1-37d5-a6ef-261faef78d7a",
        "tokens": [
            "I",
            "'ve",
            "been",
            "alone",
            "&",
            "really",
            "focused",
            "on",
            "prayer",
            "my",
            "heart",
            "starts",
            "to",
            "pound",
            "so",
            "hard",
            "it",
            "aches",
            ",",
            "my",
            "eyes",
            "closed",
            "so",
            "tight",
            "with",
            "tears",
            "welling",
            "up",
            "ready",
            "to",
            "pour",
            "out",
            "the",
            "minute",
            "I",
            "open",
            "them",
            ",",
            "feeling",
            "like",
            "I",
            "am",
            "inside",
            "my",
            "body",
            "looking",
            "out",
            "almost",
            "like",
            "some",
            "weird",
            "reverse",
            "out",
            "of",
            "body",
            "experience",
            "."
        ],
        "lemmatized_tokens": [
            "I",
            "have",
            "be",
            "alone",
            "&",
            "really",
            "focus",
            "on",
            "prayer",
            "my",
            "heart",
            "start",
            "to",
            "pound",
            "so",
            "hard",
            "it",
            "ache",
            ",",
            "my",
            "eye",
            "close",
            "so",
            "tight",
            "with",
            "tear",
            "well",
            "up",
            "ready",
            "to",
            "pour",
            "out",
            "the",
            "minute",
            "I",
            "open",
            "they",
            ",",
            "feel",
            "like",
            "I",
            "be",
            "inside",
            "my",
            "body",
            "look",
            "out",
            "almost",
            "like",
            "some",
            "weird",
            "reverse",
            "out",
            "of",
            "body",
            "experience",
            "."
        ],
        "preceding_context_tokens": [
            [
                "I",
                "'ve",
                "had",
                "many",
                "conversations",
                "with",
                "Him",
                "where",
                "I",
                "'ve",
                "asked",
                "for",
                "forgiveness",
                "and",
                "mercy",
                "and",
                "guidance",
                "."
            ],
            [
                "In",
                "the",
                "car",
                "driving",
                "to",
                "work",
                ",",
                "walking",
                "the",
                "dog",
                ",",
                "sitting",
                "in",
                "my",
                "bedroom",
                "and",
                "sitting",
                "in",
                "church",
                "."
            ],
            [
                "I",
                "have",
                "felt",
                "his",
                "presence",
                "a",
                "few",
                "times",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "I",
                "have",
                "have",
                "many",
                "conversation",
                "with",
                "he",
                "where",
                "I",
                "have",
                "ask",
                "for",
                "forgiveness",
                "and",
                "mercy",
                "and",
                "guidance",
                "."
            ],
            [
                "in",
                "the",
                "car",
                "drive",
                "to",
                "work",
                ",",
                "walk",
                "the",
                "dog",
                ",",
                "sit",
                "in",
                "my",
                "bedroom",
                "and",
                "sit",
                "in",
                "church",
                "."
            ],
            [
                "I",
                "have",
                "feel",
                "he",
                "presence",
                "a",
                "few",
                "time",
                "."
            ]
        ],
        "label": "Fear"
    },
    {
        "body_part_token_idx": 20,
        "sentence_id": "568eeffb-b6e1-37d5-a6ef-261faef78d7a",
        "tokens": [
            "I",
            "'ve",
            "been",
            "alone",
            "&",
            "really",
            "focused",
            "on",
            "prayer",
            "my",
            "heart",
            "starts",
            "to",
            "pound",
            "so",
            "hard",
            "it",
            "aches",
            ",",
            "my",
            "eyes",
            "closed",
            "so",
            "tight",
            "with",
            "tears",
            "welling",
            "up",
            "ready",
            "to",
            "pour",
            "out",
            "the",
            "minute",
            "I",
            "open",
            "them",
            ",",
            "feeling",
            "like",
            "I",
            "am",
            "inside",
            "my",
            "body",
            "looking",
            "out",
            "almost",
            "like",
            "some",
            "weird",
            "reverse",
            "out",
            "of",
            "body",
            "experience",
            "."
        ],
        "lemmatized_tokens": [
            "I",
            "have",
            "be",
            "alone",
            "&",
            "really",
            "focus",
            "on",
            "prayer",
            "my",
            "heart",
            "start",
            "to",
            "pound",
            "so",
            "hard",
            "it",
            "ache",
            ",",
            "my",
            "eye",
            "close",
            "so",
            "tight",
            "with",
            "tear",
            "well",
            "up",
            "ready",
            "to",
            "pour",
            "out",
            "the",
            "minute",
            "I",
            "open",
            "they",
            ",",
            "feel",
            "like",
            "I",
            "be",
            "inside",
            "my",
            "body",
            "look",
            "out",
            "almost",
            "like",
            "some",
            "weird",
            "reverse",
            "out",
            "of",
            "body",
            "experience",
            "."
        ],
        "preceding_context_tokens": [
            [
                "I",
                "'ve",
                "had",
                "many",
                "conversations",
                "with",
                "Him",
                "where",
                "I",
                "'ve",
                "asked",
                "for",
                "forgiveness",
                "and",
                "mercy",
                "and",
                "guidance",
                "."
            ],
            [
                "In",
                "the",
                "car",
                "driving",
                "to",
                "work",
                ",",
                "walking",
                "the",
                "dog",
                ",",
                "sitting",
                "in",
                "my",
                "bedroom",
                "and",
                "sitting",
                "in",
                "church",
                "."
            ],
            [
                "I",
                "have",
                "felt",
                "his",
                "presence",
                "a",
                "few",
                "times",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "I",
                "have",
                "have",
                "many",
                "conversation",
                "with",
                "he",
                "where",
                "I",
                "have",
                "ask",
                "for",
                "forgiveness",
                "and",
                "mercy",
                "and",
                "guidance",
                "."
            ],
            [
                "in",
                "the",
                "car",
                "drive",
                "to",
                "work",
                ",",
                "walk",
                "the",
                "dog",
                ",",
                "sit",
                "in",
                "my",
                "bedroom",
                "and",
                "sit",
                "in",
                "church",
                "."
            ],
            [
                "I",
                "have",
                "feel",
                "he",
                "presence",
                "a",
                "few",
                "time",
                "."
            ]
        ],
        "label": "Fear"
    },
    {
        "body_part_token_idx": 10,
        "sentence_id": "fc3c9f0e-cd4d-3da7-962d-e71f8fc9f7cb",
        "tokens": [
            "So",
            "onto",
            "the",
            "laptop",
            "and",
            "one",
            "Google",
            "search",
            "later",
            "my",
            "face",
            "lit",
            "up",
            "like",
            "Sydney",
            "Harbour",
            "on",
            "New",
            "Year",
            "'s",
            "Eve",
            "."
        ],
        "lemmatized_tokens": [
            "so",
            "onto",
            "the",
            "laptop",
            "and",
            "one",
            "Google",
            "search",
            "later",
            "my",
            "face",
            "light",
            "up",
            "like",
            "Sydney",
            "Harbour",
            "on",
            "New",
            "Year",
            "'s",
            "Eve",
            "."
        ],
        "preceding_context_tokens": [
            [
                "The",
                "police",
                "were",
                "alerted",
                "by",
                "the",
                "alarms",
                "going",
                "off",
                "but",
                "after",
                "the",
                "3",
                "rd",
                "time",
                "decided",
                "there",
                "was",
                "a",
                "fault",
                "with",
                "the",
                "alarm",
                "system",
                "as",
                "there",
                "was",
                "no",
                "sign",
                "of",
                "a",
                "break",
                "in",
                "and",
                "they",
                "could",
                "n't",
                "get",
                "hold",
                "of",
                "anyone",
                "from",
                "the",
                "bank",
                "to",
                "open",
                "up",
                "as",
                "they",
                "were",
                "all",
                "on",
                "holiday",
                ",",
                "it",
                "was",
                "new",
                "years",
                "after",
                "all",
                "."
            ],
            [
                "I",
                "wonder",
                "where",
                "the",
                "gang",
                "got",
                "the",
                "idea",
                "for",
                "such",
                "a",
                "daring",
                "heist",
                "?"
            ],
            [
                "It",
                "was",
                "whilst",
                "watching",
                "the",
                "news",
                "an",
                "item",
                "came",
                "on",
                "about",
                "the",
                "Dakar",
                "rally",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "the",
                "police",
                "be",
                "alert",
                "by",
                "the",
                "alarm",
                "go",
                "off",
                "but",
                "after",
                "the",
                "3",
                "rd",
                "time",
                "decide",
                "there",
                "be",
                "a",
                "fault",
                "with",
                "the",
                "alarm",
                "system",
                "as",
                "there",
                "be",
                "no",
                "sign",
                "of",
                "a",
                "break",
                "in",
                "and",
                "they",
                "could",
                "not",
                "get",
                "hold",
                "of",
                "anyone",
                "from",
                "the",
                "bank",
                "to",
                "open",
                "up",
                "as",
                "they",
                "be",
                "all",
                "on",
                "holiday",
                ",",
                "it",
                "be",
                "new",
                "year",
                "after",
                "all",
                "."
            ],
            [
                "I",
                "wonder",
                "where",
                "the",
                "gang",
                "get",
                "the",
                "idea",
                "for",
                "such",
                "a",
                "daring",
                "heist",
                "?"
            ],
            [
                "it",
                "be",
                "whilst",
                "watch",
                "the",
                "news",
                "a",
                "item",
                "come",
                "on",
                "about",
                "the",
                "Dakar",
                "rally",
                "."
            ]
        ],
        "label": "Joy"
    },
    {
        "body_part_token_idx": 28,
        "sentence_id": "78a2a870-a9e4-328f-a7b5-62ace78398cf",
        "tokens": [
            "The",
            "celebration",
            "was",
            "from",
            "7",
            "pm",
            "to",
            "1",
            "am",
            ",",
            "and",
            "all",
            "the",
            "rides",
            "and",
            "attractions",
            "were",
            "open",
            ",",
            "including",
            "the",
            "huge",
            "scary",
            "rollercoaster",
            "that",
            "I",
            "closed",
            "my",
            "eyes",
            "on",
            "the",
            "whole",
            "time",
            "I",
            "was",
            "on",
            "it",
            "."
        ],
        "lemmatized_tokens": [
            "the",
            "celebration",
            "be",
            "from",
            "7",
            "pm",
            "to",
            "1",
            "am",
            ",",
            "and",
            "all",
            "the",
            "ride",
            "and",
            "attraction",
            "be",
            "open",
            ",",
            "include",
            "the",
            "huge",
            "scary",
            "rollercoaster",
            "that",
            "I",
            "close",
            "my",
            "eye",
            "on",
            "the",
            "whole",
            "time",
            "I",
            "be",
            "on",
            "it",
            "."
        ],
        "preceding_context_tokens": [
            [
                "My",
                "family",
                ",",
                "Franco",
                ",",
                "his",
                "brother",
                "Mosi",
                "and",
                "I",
                "spent",
                "new",
                "year",
                "'s",
                "at",
                "Knott",
                "'s",
                "Berry",
                "Farm",
                "."
            ],
            [
                "I",
                "had",
                "n't",
                "been",
                "since",
                "junior",
                "high",
                "and",
                "Franco",
                "and",
                "Mosi",
                "had",
                "never",
                "been",
                "."
            ],
            [
                "They",
                "were",
                "having",
                "a",
                "rockin",
                "'",
                "new",
                "year",
                "'s",
                "eve",
                "bash",
                "so",
                "we",
                "decided",
                "to",
                "crash",
                "it",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "my",
                "family",
                ",",
                "Franco",
                ",",
                "he",
                "brother",
                "Mosi",
                "and",
                "I",
                "spend",
                "new",
                "year",
                "'s",
                "at",
                "Knott",
                "'s",
                "Berry",
                "Farm",
                "."
            ],
            [
                "I",
                "have",
                "not",
                "be",
                "since",
                "junior",
                "high",
                "and",
                "Franco",
                "and",
                "Mosi",
                "have",
                "never",
                "be",
                "."
            ],
            [
                "they",
                "be",
                "have",
                "a",
                "rockin",
                "'",
                "new",
                "year",
                "'s",
                "eve",
                "bash",
                "so",
                "we",
                "decide",
                "to",
                "crash",
                "it",
                "."
            ]
        ],
        "label": "Fear"
    },
    {
        "body_part_token_idx": 4,
        "sentence_id": "277e0f82-8308-3aa3-b00a-f29d8152945d",
        "tokens": [
            "Violence!",
            "I",
            "widened",
            "my",
            "eyes",
            "and",
            "this",
            "time",
            "I",
            "really",
            "did",
            "push",
            "him",
            "."
        ],
        "lemmatized_tokens": [
            "Violence!",
            "I",
            "widen",
            "my",
            "eye",
            "and",
            "this",
            "time",
            "I",
            "really",
            "do",
            "push",
            "he",
            "."
        ],
        "preceding_context_tokens": [
            [
                "I",
                "'m",
                "glad",
                "to",
                "hear",
                "that",
                "He",
                "ran",
                "his",
                "fingers",
                "through",
                "my",
                "hair",
                "and",
                "tucked",
                "it",
                "behind",
                "my",
                "ear",
                "."
            ],
            [
                "Aww",
                ",",
                "how",
                "cute",
                "Gerroff",
                "I",
                "mumbled",
                ",",
                "shaking",
                "my",
                "head",
                "so",
                "my",
                "hair",
                "fell",
                "back",
                "into",
                "its",
                "original",
                "place",
                "."
            ],
            [
                "I",
                "pushed",
                "him",
                "playfully",
                "and",
                "he",
                "acted",
                "insulted",
                "Violence",
                "Franklin",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "I",
                "be",
                "glad",
                "to",
                "hear",
                "that",
                "he",
                "run",
                "he",
                "finger",
                "through",
                "my",
                "hair",
                "and",
                "tuck",
                "it",
                "behind",
                "my",
                "ear",
                "."
            ],
            [
                "Aww",
                ",",
                "how",
                "cute",
                "Gerroff",
                "I",
                "mumble",
                ",",
                "shake",
                "my",
                "head",
                "so",
                "my",
                "hair",
                "fall",
                "back",
                "into",
                "its",
                "original",
                "place",
                "."
            ],
            [
                "I",
                "push",
                "he",
                "playfully",
                "and",
                "he",
                "act",
                "insult",
                "violence",
                "Franklin",
                "."
            ]
        ],
        "label": "Surprise"
    },
    {
        "body_part_token_idx": 9,
        "sentence_id": "5cfb725f-f7fa-33c7-ae66-88039dbd379f",
        "tokens": [
            "She",
            "watches",
            "him",
            "for",
            "a",
            "moment",
            ",",
            "before",
            "her",
            "eyes",
            "widen",
            "."
        ],
        "lemmatized_tokens": [
            "she",
            "watch",
            "he",
            "for",
            "a",
            "moment",
            ",",
            "before",
            "she",
            "eye",
            "widen",
            "."
        ],
        "preceding_context_tokens": [
            [
                "But",
                "that",
                "does",
                "n't",
                "mean",
                "she",
                "is",
                "n't",
                "prone",
                "to",
                "the",
                "attitude",
                "every",
                "now",
                "and",
                "then",
                "."
            ],
            [
                "``",
                "Are",
                "you",
                "serious",
                "?",
                "''"
            ],
            [
                "she",
                "raises",
                "an",
                "eyebrow",
                "at",
                "him",
                ",",
                "and",
                "he",
                "just",
                "looks",
                "back",
                "up",
                "at",
                "her",
                ",",
                "his",
                "face",
                "not",
                "giving",
                "away",
                "anything",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "but",
                "that",
                "do",
                "not",
                "mean",
                "she",
                "be",
                "not",
                "prone",
                "to",
                "the",
                "attitude",
                "every",
                "now",
                "and",
                "then",
                "."
            ],
            [
                "``",
                "be",
                "you",
                "serious",
                "?",
                "''"
            ],
            [
                "she",
                "raise",
                "a",
                "eyebrow",
                "at",
                "he",
                ",",
                "and",
                "he",
                "just",
                "look",
                "back",
                "up",
                "at",
                "she",
                ",",
                "he",
                "face",
                "not",
                "give",
                "away",
                "anything",
                "."
            ]
        ],
        "label": "Surprise"
    },
    {
        "body_part_token_idx": 8,
        "sentence_id": "b8fc3396-3059-377c-a3c1-fa315d14fe19",
        "tokens": [
            "Warm",
            ",",
            "salty",
            "tears",
            "slowly",
            "rolled",
            "down",
            "my",
            "face",
            "and",
            "made",
            "my",
            "goggles",
            "wet",
            "."
        ],
        "lemmatized_tokens": [
            "warm",
            ",",
            "salty",
            "tear",
            "slowly",
            "roll",
            "down",
            "my",
            "face",
            "and",
            "make",
            "my",
            "goggles",
            "wet",
            "."
        ],
        "preceding_context_tokens": [
            [
                "On",
                "the",
                "day",
                "of",
                "competition",
                ",",
                "when",
                "I",
                "stepped",
                "on",
                "the",
                "diving",
                "deck",
                ",",
                "I",
                "was",
                "so",
                "proud",
                "of",
                "myself",
                "."
            ],
            [
                "I",
                "was",
                "proud",
                "that",
                "I",
                "overcame",
                "all",
                "the",
                "barriers",
                "that",
                "I",
                "had",
                "."
            ],
            [
                "I",
                "overcame",
                "all",
                "the",
                "trainings",
                "that",
                "I",
                "had",
                "to",
                "do",
                ",",
                "I",
                "overcame",
                "all",
                "the",
                "competition",
                "from",
                "the",
                "locals",
                ",",
                "and",
                "now",
                ",",
                "I",
                "was",
                "proud",
                "that",
                "I",
                "was",
                "standing",
                "on",
                "the",
                "diving",
                "board",
                "of",
                "the",
                "national",
                "competition",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "on",
                "the",
                "day",
                "of",
                "competition",
                ",",
                "when",
                "I",
                "step",
                "on",
                "the",
                "diving",
                "deck",
                ",",
                "I",
                "be",
                "so",
                "proud",
                "of",
                "myself",
                "."
            ],
            [
                "I",
                "be",
                "proud",
                "that",
                "I",
                "overcome",
                "all",
                "the",
                "barrier",
                "that",
                "I",
                "have",
                "."
            ],
            [
                "I",
                "overcome",
                "all",
                "the",
                "training",
                "that",
                "I",
                "have",
                "to",
                "do",
                ",",
                "I",
                "overcome",
                "all",
                "the",
                "competition",
                "from",
                "the",
                "local",
                ",",
                "and",
                "now",
                ",",
                "I",
                "be",
                "proud",
                "that",
                "I",
                "be",
                "stand",
                "on",
                "the",
                "diving",
                "board",
                "of",
                "the",
                "national",
                "competition",
                "."
            ]
        ],
        "label": "Joy"
    },
    {
        "body_part_token_idx": 3,
        "sentence_id": "42a93fbd-3051-3c43-adc4-091449d81d37",
        "tokens": [
            "He",
            "shrugged",
            "his",
            "shoulders",
            "and",
            "started",
            "heading",
            "into",
            "the",
            "lobby",
            ",",
            "waving",
            "to",
            "those",
            "who",
            "greeted",
            "him",
            "."
        ],
        "lemmatized_tokens": [
            "he",
            "shrug",
            "he",
            "shoulder",
            "and",
            "start",
            "head",
            "into",
            "the",
            "lobby",
            ",",
            "wave",
            "to",
            "those",
            "who",
            "greet",
            "he",
            "."
        ],
        "preceding_context_tokens": [
            [
                "He",
                "guessed",
                "that",
                "he",
                "would",
                "be",
                "coming",
                "in",
                "a",
                "bit",
                "later",
                "."
            ],
            [
                "Or",
                "maybe",
                "he",
                "would",
                "n't",
                "come",
                "at",
                "all",
                "."
            ],
            [
                "Wissen",
                "would",
                "n't",
                "be",
                "surprised",
                "if",
                "that",
                "happened",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "he",
                "guess",
                "that",
                "he",
                "would",
                "be",
                "come",
                "in",
                "a",
                "bit",
                "later",
                "."
            ],
            [
                "or",
                "maybe",
                "he",
                "would",
                "not",
                "come",
                "at",
                "all",
                "."
            ],
            [
                "Wissen",
                "would",
                "not",
                "be",
                "surprised",
                "if",
                "that",
                "happen",
                "."
            ]
        ],
        "label": "Sadness"
    },
    {
        "body_part_token_idx": 19,
        "sentence_id": "84eb414a-9851-3922-bdf0-efa3f4ac4166",
        "tokens": [
            "~",
            "*",
            "~",
            "The",
            "presence",
            "at",
            "her",
            "side",
            "was",
            "comforting",
            "and",
            "Jo",
            "turned",
            "her",
            "head",
            ",",
            "glancing",
            "over",
            "her",
            "shoulder",
            "to",
            "offer",
            "Lily",
            "a",
            "sheepish",
            "smile",
            "."
        ],
        "lemmatized_tokens": [
            "~",
            "*",
            "~",
            "the",
            "presence",
            "at",
            "she",
            "side",
            "be",
            "comforting",
            "and",
            "Jo",
            "turn",
            "she",
            "head",
            ",",
            "glance",
            "over",
            "she",
            "shoulder",
            "to",
            "offer",
            "Lily",
            "a",
            "sheepish",
            "smile",
            "."
        ],
        "preceding_context_tokens": [
            [
                "He",
                "'s",
                "right",
                "."
            ],
            [
                "We",
                "should",
                "ju",
                "''",
                "A",
                "feminine",
                "scream",
                "cut",
                "Jake",
                "off",
                "mid-word",
                "and",
                "the",
                "group",
                "spun",
                "toward",
                "the",
                "sound",
                "."
            ],
            [
                "Sam",
                "'s",
                "stomach",
                "knotted",
                "and",
                "he",
                "stated",
                "softly",
                ",",
                "Lily",
                "and",
                "Jo",
                ",",
                "before",
                "taking",
                "off",
                "the",
                "way",
                "they",
                "'d",
                "come",
                "with",
                "Ava",
                ",",
                "Andy",
                "and",
                "Jake",
                "not",
                "far",
                "behind",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "he",
                "be",
                "right",
                "."
            ],
            [
                "we",
                "should",
                "ju",
                "''",
                "a",
                "feminine",
                "scream",
                "cut",
                "Jake",
                "off",
                "mid-word",
                "and",
                "the",
                "group",
                "spin",
                "toward",
                "the",
                "sound",
                "."
            ],
            [
                "Sam",
                "'s",
                "stomach",
                "knot",
                "and",
                "he",
                "state",
                "softly",
                ",",
                "Lily",
                "and",
                "Jo",
                ",",
                "before",
                "take",
                "off",
                "the",
                "way",
                "they",
                "have",
                "come",
                "with",
                "Ava",
                ",",
                "Andy",
                "and",
                "Jake",
                "not",
                "far",
                "behind",
                "."
            ]
        ],
        "label": "Joy"
    },
    {
        "body_part_token_idx": 8,
        "sentence_id": "2c1c88c6-c2f7-3d11-8cf4-f7f4e32487c1",
        "tokens": [
            "She",
            "gets",
            "this",
            "quirky",
            "little",
            "smile",
            "on",
            "her",
            "face",
            "and",
            "very",
            "quietly",
            "says",
            ",",
            "``",
            "I",
            "own",
            "him",
            "."
        ],
        "lemmatized_tokens": [
            "she",
            "get",
            "this",
            "quirky",
            "little",
            "smile",
            "on",
            "she",
            "face",
            "and",
            "very",
            "quietly",
            "say",
            ",",
            "``",
            "I",
            "own",
            "he",
            "."
        ],
        "preceding_context_tokens": [
            [
                "I",
                "worry",
                "about",
                "her",
                "drive",
                "to",
                "be",
                "``",
                "bad",
                "''",
                "``",
                "edgy",
                "''",
                "``",
                "wild",
                "''",
                "."
            ],
            [
                "OY",
                "VEYShe",
                "'s",
                "my",
                "girl",
                "."
            ],
            [
                "What",
                "can",
                "I",
                "say.About",
                "a",
                "month",
                "ago",
                "she",
                "was",
                "standing",
                "by",
                "the",
                "kitchen",
                "and",
                "was",
                "talking",
                "about",
                "her",
                "boyfriend",
                "-LRB-",
                "the",
                "one",
                "who",
                "is",
                "currently",
                "in",
                "only",
                "maybe",
                "status",
                ".",
                ")"
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "I",
                "worry",
                "about",
                "she",
                "drive",
                "to",
                "be",
                "``",
                "bad",
                "''",
                "``",
                "edgy",
                "''",
                "``",
                "wild",
                "''",
                "."
            ],
            [
                "OY",
                "VEYShe",
                "'s",
                "my",
                "girl",
                "."
            ],
            [
                "what",
                "can",
                "I",
                "say.about",
                "a",
                "month",
                "ago",
                "she",
                "be",
                "stand",
                "by",
                "the",
                "kitchen",
                "and",
                "be",
                "talk",
                "about",
                "she",
                "boyfriend",
                "-lrb-_VBZ",
                "the",
                "one",
                "who",
                "be",
                "currently",
                "in",
                "only",
                "maybe",
                "status",
                ".",
                ")"
            ]
        ],
        "label": "Joy"
    },
    {
        "body_part_token_idx": 8,
        "sentence_id": "d7af28f8-e928-3c00-9145-2ed968bc0fca",
        "tokens": [
            "i",
            "'ve",
            "got",
            "the",
            "tug",
            "happening",
            "in",
            "my",
            "chest",
            "."
        ],
        "lemmatized_tokens": [
            "i",
            "have",
            "get",
            "the",
            "tug",
            "happen",
            "in",
            "my",
            "chest",
            "."
        ],
        "preceding_context_tokens": [
            [
                "they",
                "seem",
                "to",
                "rarely",
                "get",
                "younger",
                "dogs",
                "."
            ],
            [
                "i",
                "'d",
                "happily",
                "take",
                "an",
                "older",
                "dog",
                "home",
                ",",
                "too",
                ",",
                "but",
                "nothing",
                "has",
                "``",
                "clicked",
                "''",
                "."
            ],
            [
                "it",
                "'s",
                "easier",
                "to",
                "visit",
                "since",
                "we",
                "'ve",
                "gotten",
                "billy",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "they",
                "seem",
                "to",
                "rarely",
                "get",
                "younger",
                "dog",
                "."
            ],
            [
                "i",
                "would",
                "happily",
                "take",
                "a",
                "older",
                "dog",
                "home",
                ",",
                "too",
                ",",
                "but",
                "nothing",
                "have",
                "``",
                "click",
                "''",
                "."
            ],
            [
                "it",
                "be",
                "easier",
                "to",
                "visit",
                "since",
                "we",
                "have",
                "get",
                "billy",
                "."
            ]
        ],
        "label": "Sadness"
    },
    {
        "body_part_token_idx": 8,
        "sentence_id": "8ca3fbdd-68d6-3a27-b954-90eb990d9e3d",
        "tokens": [
            "But",
            "then",
            "Spencer",
            "notices",
            "the",
            "look",
            "on",
            "his",
            "face",
            ":",
            "it",
            "'s",
            "pity",
            ";",
            "and",
            "now",
            "all",
            "he",
            "can",
            "think",
            "of",
            "is",
            "Brendon",
            "again",
            "."
        ],
        "lemmatized_tokens": [
            "but",
            "then",
            "Spencer",
            "notice",
            "the",
            "look",
            "on",
            "he",
            "face",
            ":",
            "it",
            "be",
            "pity",
            ";",
            "and",
            "now",
            "all",
            "he",
            "can",
            "think",
            "of",
            "be",
            "Brendon",
            "again",
            "."
        ],
        "preceding_context_tokens": [
            [
                "He",
                "appreciates",
                "the",
                "offer",
                ",",
                "but",
                "all",
                "the",
                "same",
                ",",
                "he",
                "declines",
                "."
            ],
            [
                "He",
                "does",
                "not",
                "like",
                "appearing",
                "vulnerable",
                "or",
                "scared",
                ",",
                "even",
                "if",
                ",",
                "right",
                "now",
                ",",
                "that",
                "is",
                "mostly",
                "what",
                "he",
                "is",
                "feeling",
                "."
            ],
            [
                "Why",
                "would",
                "Morris",
                "care",
                "anyway",
                "?"
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "he",
                "appreciate",
                "the",
                "offer",
                ",",
                "but",
                "all",
                "the",
                "same",
                ",",
                "he",
                "decline",
                "."
            ],
            [
                "he",
                "do",
                "not",
                "like",
                "appear",
                "vulnerable",
                "or",
                "scared",
                ",",
                "even",
                "if",
                ",",
                "right",
                "now",
                ",",
                "that",
                "be",
                "mostly",
                "what",
                "he",
                "be",
                "feel",
                "."
            ],
            [
                "why",
                "would",
                "Morris",
                "care",
                "anyway",
                "?"
            ]
        ],
        "label": "Disgust"
    },
    {
        "body_part_token_idx": 28,
        "sentence_id": "5b51cdf2-b449-3609-88e4-54cb3e13e121",
        "tokens": [
            "Then",
            "he",
            "slid",
            "down",
            ",",
            "knees",
            "bending",
            ",",
            "arms",
            "encircling",
            "them",
            ",",
            "till",
            "he",
            "was",
            "on",
            "the",
            "floor",
            ",",
            "heels",
            "tucking",
            "in",
            "close",
            ",",
            "head",
            "buried",
            "in",
            "his",
            "arms",
            "."
        ],
        "lemmatized_tokens": [
            "then",
            "he",
            "slide",
            "down",
            ",",
            "knee",
            "bend",
            ",",
            "arm",
            "encircle",
            "they",
            ",",
            "till",
            "he",
            "be",
            "on",
            "the",
            "floor",
            ",",
            "heel",
            "tuck",
            "in",
            "close",
            ",",
            "head",
            "bury",
            "in",
            "he",
            "arm",
            "."
        ],
        "preceding_context_tokens": [
            [
                "No",
                "."
            ],
            [
                "He",
                "backed",
                "away",
                "."
            ],
            [
                "Kept",
                "backing",
                "up",
                "until",
                "his",
                "shoulder",
                "hit",
                "the",
                "mantelpiece",
                "and",
                "he",
                "slid",
                "along",
                "it",
                "till",
                "he",
                "hit",
                "the",
                "edge",
                "and",
                "pushed",
                "back",
                "until",
                "he",
                "felt",
                "the",
                "wall",
                "with",
                "his",
                "shoulder",
                "blades",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "no",
                "."
            ],
            [
                "he",
                "back",
                "away",
                "."
            ],
            [
                "keep",
                "back",
                "up",
                "until",
                "he",
                "shoulder",
                "hit",
                "the",
                "mantelpiece",
                "and",
                "he",
                "slide",
                "along",
                "it",
                "till",
                "he",
                "hit",
                "the",
                "edge",
                "and",
                "push",
                "back",
                "until",
                "he",
                "feel",
                "the",
                "wall",
                "with",
                "he",
                "shoulder",
                "blade",
                "."
            ]
        ],
        "label": "Sadness"
    },
    {
        "body_part_token_idx": 13,
        "sentence_id": "5155882d-fa4e-39fc-bbd4-179dd70c3105",
        "tokens": [
            "I",
            "woke",
            "up",
            "with",
            "sweat",
            "dripping",
            "from",
            "my",
            "body",
            "and",
            "cascading",
            "down",
            "my",
            "face",
            "."
        ],
        "lemmatized_tokens": [
            "I",
            "wake",
            "up",
            "with",
            "sweat",
            "drip",
            "from",
            "my",
            "body",
            "and",
            "cascade",
            "down",
            "my",
            "face",
            "."
        ],
        "preceding_context_tokens": [
            [
                "If",
                "something",
                "that",
                "you",
                "were",
                "assigned",
                "by",
                "her",
                "did",
                "not",
                "satisfy",
                "her",
                "taste",
                ",",
                "then",
                "you",
                "were",
                "beat",
                "until",
                "they",
                "were",
                "pleased",
                "."
            ],
            [
                "That",
                "was",
                "my",
                "first",
                "time",
                "getting",
                "whipped",
                "and",
                "I",
                "cried",
                "."
            ],
            [
                "She",
                "held",
                "a",
                "haunting",
                "glint",
                "in",
                "her",
                "light",
                "brown",
                "eyes",
                "that",
                "made",
                "me",
                "weep",
                "in",
                "sleep",
                "and",
                "scream",
                "at",
                "night",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "if",
                "something",
                "that",
                "you",
                "be",
                "assign",
                "by",
                "she",
                "do",
                "not",
                "satisfy",
                "she",
                "taste",
                ",",
                "then",
                "you",
                "be",
                "beat",
                "until",
                "they",
                "be",
                "pleased",
                "."
            ],
            [
                "that",
                "be",
                "my",
                "first",
                "time",
                "get",
                "whip",
                "and",
                "I",
                "cry",
                "."
            ],
            [
                "she",
                "hold",
                "a",
                "haunting",
                "glint",
                "in",
                "she",
                "light",
                "brown",
                "eye",
                "that",
                "make",
                "I",
                "weep",
                "in",
                "sleep",
                "and",
                "scream",
                "at",
                "night",
                "."
            ]
        ],
        "label": "Fear"
    },
    {
        "body_part_token_idx": 8,
        "sentence_id": "325e4124-af5f-39b1-a679-b8f88ba630c8",
        "tokens": [
            "Trevor",
            "raised",
            "a",
            "daring",
            "brow",
            "and",
            "shook",
            "his",
            "head",
            "."
        ],
        "lemmatized_tokens": [
            "Trevor",
            "raise",
            "a",
            "daring",
            "brow",
            "and",
            "shake",
            "he",
            "head",
            "."
        ],
        "preceding_context_tokens": [
            [
                "How",
                "long",
                "had",
                "he",
                "even",
                "been",
                "there",
                "?"
            ],
            [
                "He",
                "smirked",
                "and",
                "shrugged",
                ",",
                "icy",
                "blue",
                "eyes",
                "instead",
                "settled",
                "on",
                "the",
                "boy",
                "'s",
                "body",
                ",",
                "raking",
                "him",
                "up",
                "and",
                "down",
                "."
            ],
            [
                "Shoulda",
                "gone",
                "with",
                "the",
                "skirt",
                ",",
                "he",
                "noted",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "how",
                "long",
                "have",
                "he",
                "even",
                "be",
                "there",
                "?"
            ],
            [
                "he",
                "smirk",
                "and",
                "shrug",
                ",",
                "icy",
                "blue",
                "eye",
                "instead",
                "settle",
                "on",
                "the",
                "boy",
                "'s",
                "body",
                ",",
                "rake",
                "he",
                "up",
                "and",
                "down",
                "."
            ],
            [
                "Shoulda",
                "go",
                "with",
                "the",
                "skirt",
                ",",
                "he",
                "note",
                "."
            ]
        ],
        "label": "Disgust"
    },
    {
        "body_part_token_idx": 9,
        "sentence_id": "b8423cfa-ec88-31eb-b787-fa7c547cd7e3",
        "tokens": [
            "OMG",
            "*",
            "deep",
            "breath",
            "*",
            "not",
            "good",
            "for",
            "my",
            "heart",
            "."
        ],
        "lemmatized_tokens": [
            "omg",
            "*",
            "deep",
            "breath",
            "*",
            "not",
            "good",
            "for",
            "my",
            "heart",
            "."
        ],
        "preceding_context_tokens": [
            [
                "What",
                "has",
                "my",
                "being",
                "on",
                "the",
                "phone",
                "got",
                "to",
                "do",
                "with",
                "anything",
                "?"
            ],
            [
                "It",
                "'s",
                "not",
                "like",
                "I",
                "am",
                "the",
                "one",
                "packing",
                "the",
                "bloody",
                "nasi",
                "lemak",
                "."
            ],
            [
                "I",
                "have",
                "to",
                "stand",
                "there",
                "and",
                "do",
                "bloody",
                "nothing",
                "only",
                "you",
                "will",
                "consider",
                "serving",
                "me",
                "is",
                "it",
                "?"
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "what",
                "have",
                "my",
                "be",
                "on",
                "the",
                "phone",
                "get",
                "to",
                "do",
                "with",
                "anything",
                "?"
            ],
            [
                "it",
                "be",
                "not",
                "like",
                "I",
                "be",
                "the",
                "one",
                "pack",
                "the",
                "bloody",
                "nasi",
                "lemak",
                "."
            ],
            [
                "I",
                "have",
                "to",
                "stand",
                "there",
                "and",
                "do",
                "bloody",
                "nothing",
                "only",
                "you",
                "will",
                "consider",
                "serve",
                "I",
                "be",
                "it",
                "?"
            ]
        ],
        "label": "Anger"
    },
    {
        "body_part_token_idx": 12,
        "sentence_id": "bb0f8674-8052-3e30-afe4-bbaacf63fead",
        "tokens": [
            "Amanda",
            "kneeled",
            "beside",
            "me",
            ",",
            "and",
            "there",
            "were",
            "tears",
            "rolling",
            "down",
            "her",
            "cheeks",
            "."
        ],
        "lemmatized_tokens": [
            "Amanda",
            "kneel",
            "beside",
            "I",
            ",",
            "and",
            "there",
            "be",
            "tear",
            "roll",
            "down",
            "she",
            "cheek",
            "."
        ],
        "preceding_context_tokens": [
            [
                "That",
                "sound",
                "made",
                "me",
                "all",
                "the",
                "more",
                "sad",
                "."
            ],
            [
                "I",
                "collapsed",
                "to",
                "the",
                "ground",
                "and",
                "saw",
                "the",
                "blood",
                "pour",
                "out",
                "of",
                "the",
                "wound",
                "on",
                "my",
                "shoulder",
                "."
            ],
            [
                "In",
                "the",
                "distance",
                "I",
                "could",
                "see",
                "Rickey",
                ",",
                "running",
                "as",
                "fast",
                "as",
                "he",
                "could",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "that",
                "sound",
                "make",
                "I",
                "all",
                "the",
                "more",
                "sad",
                "."
            ],
            [
                "I",
                "collapse",
                "to",
                "the",
                "ground",
                "and",
                "see",
                "the",
                "blood",
                "pour",
                "out",
                "of",
                "the",
                "wound",
                "on",
                "my",
                "shoulder",
                "."
            ],
            [
                "in",
                "the",
                "distance",
                "I",
                "could",
                "see",
                "Rickey",
                ",",
                "run",
                "as",
                "fast",
                "as",
                "he",
                "could",
                "."
            ]
        ],
        "label": "Sadness"
    },
    {
        "body_part_token_idx": 3,
        "sentence_id": "8fba54ad-1d3e-3001-827d-401febe89c43",
        "tokens": [
            "I",
            "rolled",
            "my",
            "eyes",
            "."
        ],
        "lemmatized_tokens": [
            "I",
            "roll",
            "my",
            "eye",
            "."
        ],
        "preceding_context_tokens": [
            [
                "Even",
                "from",
                "my",
                "peripheral",
                "vision",
                ",",
                "I",
                "could",
                "see",
                "the",
                "smirk",
                "dancing",
                "around",
                "the",
                "corners",
                "of",
                "his",
                "eyes",
                "."
            ],
            [
                "He",
                "turned",
                "to",
                "Jasper",
                "who",
                "was",
                "standing",
                "behind",
                "me",
                ",",
                "Do",
                "you",
                "think",
                "that",
                "'s",
                "her",
                "brave",
                "look?",
                "he",
                "asked.Jasper",
                "snorted",
                ",",
                "I",
                "think",
                "I",
                "'d",
                "call",
                "that",
                "the",
                "martyr",
                "'",
                "."
            ],
            [
                "And",
                "they",
                "both",
                "began",
                "laughing",
                "again",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "even",
                "from",
                "my",
                "peripheral",
                "vision",
                ",",
                "I",
                "could",
                "see",
                "the",
                "smirk",
                "dance",
                "around",
                "the",
                "corner",
                "of",
                "he",
                "eye",
                "."
            ],
            [
                "he",
                "turn",
                "to",
                "Jasper",
                "who",
                "be",
                "stand",
                "behind",
                "I",
                ",",
                "do",
                "you",
                "think",
                "that",
                "be",
                "she",
                "brave",
                "look?",
                "he",
                "asked.jasper",
                "snort",
                ",",
                "I",
                "think",
                "I",
                "would",
                "call",
                "that",
                "the",
                "martyr",
                "'",
                "."
            ],
            [
                "and",
                "they",
                "both",
                "begin",
                "laugh",
                "again",
                "."
            ]
        ],
        "label": "Disgust"
    },
    {
        "body_part_token_idx": 19,
        "sentence_id": "a7449bd7-0252-338b-ae32-f4642e691c04",
        "tokens": [
            "He",
            "should",
            "be",
            "out",
            "for",
            "at",
            "least",
            "the",
            "rest",
            "of",
            "the",
            "day",
            ",",
            "''",
            "Randy",
            "instructed",
            ",",
            "keeping",
            "his",
            "back",
            "to",
            "the",
            "cabin",
            "and",
            "looking",
            "at",
            "the",
            "surrounding",
            "trees",
            "."
        ],
        "lemmatized_tokens": [
            "he",
            "should",
            "be",
            "out",
            "for",
            "at",
            "least",
            "the",
            "rest",
            "of",
            "the",
            "day",
            ",",
            "''",
            "Randy",
            "instruct",
            ",",
            "keep",
            "he",
            "back",
            "to",
            "the",
            "cabin",
            "and",
            "look",
            "at",
            "the",
            "surround",
            "tree",
            "."
        ],
        "preceding_context_tokens": [
            [
                "Josh",
                "and",
                "Dan",
                "were",
                "still",
                "fairly",
                "young",
                ";",
                "Josh",
                "was",
                "nineteen",
                "and",
                "Dan",
                "twenty",
                "and",
                "they",
                "were",
                "still",
                "feeling",
                "their",
                "way",
                "into",
                "the",
                "pack",
                "hierarchy",
                "."
            ],
            [
                "They",
                "both",
                "saw",
                "this",
                "as",
                "an",
                "opportunity",
                "to",
                "help",
                "prove",
                "themselves",
                "to",
                "their",
                "Alpha",
                "."
            ],
            [
                "``",
                "Josh",
                ",",
                "Dan",
                ",",
                "stay",
                "here",
                "and",
                "guard",
                "Griffin",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "Josh",
                "and",
                "Dan",
                "be",
                "still",
                "fairly",
                "young",
                ";",
                "Josh",
                "be",
                "nineteen",
                "and",
                "Dan",
                "twenty",
                "and",
                "they",
                "be",
                "still",
                "feel",
                "they",
                "way",
                "into",
                "the",
                "pack",
                "hierarchy",
                "."
            ],
            [
                "they",
                "both",
                "see",
                "this",
                "as",
                "a",
                "opportunity",
                "to",
                "help",
                "prove",
                "themselves",
                "to",
                "they",
                "alpha",
                "."
            ],
            [
                "``",
                "Josh",
                ",",
                "Dan",
                ",",
                "stay",
                "here",
                "and",
                "guard",
                "Griffin",
                "."
            ]
        ],
        "label": "Fear"
    },
    {
        "body_part_token_idx": 14,
        "sentence_id": "da8040d0-20c6-3509-8978-b6e95702bd83",
        "tokens": [
            "They",
            "looked",
            "at",
            "one",
            "another",
            "for",
            "a",
            "long",
            "moment",
            ",",
            "before",
            "Alfred",
            "slanted",
            "his",
            "eyes",
            "away",
            ",",
            "stabbing",
            "his",
            "fork",
            "into",
            "his",
            "food",
            "."
        ],
        "lemmatized_tokens": [
            "they",
            "look",
            "at",
            "one",
            "another",
            "for",
            "a",
            "long",
            "moment",
            ",",
            "before",
            "Alfred",
            "slant",
            "he",
            "eye",
            "away",
            ",",
            "stab",
            "he",
            "fork",
            "into",
            "he",
            "food",
            "."
        ],
        "preceding_context_tokens": [
            [
                "``",
                "Take",
                "a",
                "step",
                "back",
                ",",
                "take",
                "things",
                "slowly",
                "."
            ],
            [
                "Relax",
                ",",
                "and",
                "it",
                "'ll",
                "be",
                "much",
                "easier",
                "for",
                "you",
                ".",
                "''"
            ],
            [
                "Alfred",
                "'s",
                "brow",
                "furrowed",
                "further",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "``",
                "take",
                "a",
                "step",
                "back",
                ",",
                "take",
                "thing",
                "slowly",
                "."
            ],
            [
                "relax",
                ",",
                "and",
                "it",
                "will",
                "be",
                "much",
                "easier",
                "for",
                "you",
                ".",
                "''"
            ],
            [
                "Alfred",
                "'s",
                "brow",
                "furrow",
                "further",
                "."
            ]
        ],
        "label": "Anger"
    },
    {
        "body_part_token_idx": 1,
        "sentence_id": "26c51e4b-fd13-30f9-a609-1899f763ffa1",
        "tokens": [
            "His",
            "hand",
            "hesitated",
            "on",
            "the",
            "third",
            "card",
            ",",
            "drawn",
            "from",
            "the",
            "last",
            "pile",
            "--",
            "the",
            "`",
            "supporting",
            "'",
            "card",
            ",",
            "the",
            "reason",
            "for",
            "the",
            "conflict",
            "and",
            "misery",
            "."
        ],
        "lemmatized_tokens": [
            "he",
            "hand",
            "hesitate",
            "on",
            "the",
            "third",
            "card",
            ",",
            "draw",
            "from",
            "the",
            "last",
            "pile",
            "--",
            "the",
            "`",
            "support",
            "'",
            "card",
            ",",
            "the",
            "reason",
            "for",
            "the",
            "conflict",
            "and",
            "misery",
            "."
        ],
        "preceding_context_tokens": [
            [
                "A",
                "sign",
                "of",
                "intense",
                ",",
                "often",
                "maligned",
                "conflict",
                ";",
                "no",
                "surprise",
                "there",
                "."
            ],
            [
                "The",
                "second",
                "card",
                "he",
                "drew",
                "from",
                "the",
                "next",
                "pile",
                "and",
                "laid",
                "cross-ways",
                "over",
                "the",
                "first",
                "."
            ],
            [
                "The",
                "Nine",
                "of",
                "Swords",
                ",",
                "indicating",
                "confusion",
                "and",
                "misery",
                ",",
                "distrust",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "a",
                "sign",
                "of",
                "intense",
                ",",
                "often",
                "malign",
                "conflict",
                ";",
                "no",
                "surprise",
                "there",
                "."
            ],
            [
                "the",
                "second",
                "card",
                "he",
                "draw",
                "from",
                "the",
                "next",
                "pile",
                "and",
                "lay",
                "cross-way",
                "over",
                "the",
                "first",
                "."
            ],
            [
                "the",
                "nine",
                "of",
                "sword",
                ",",
                "indicate",
                "confusion",
                "and",
                "misery",
                ",",
                "distrust",
                "."
            ]
        ],
        "label": "Fear"
    },
    {
        "body_part_token_idx": 4,
        "sentence_id": "0cf64203-dc27-38e0-b022-6e8af747c626",
        "tokens": [
            "then",
            "I",
            "shook",
            "my",
            "head",
            "."
        ],
        "lemmatized_tokens": [
            "then",
            "I",
            "shake",
            "my",
            "head",
            "."
        ],
        "preceding_context_tokens": [
            [
                "but",
                "I",
                "will",
                "not",
                "let",
                "it",
                "dstroy",
                "me",
                "!"
            ],
            [
                "my",
                "amaths",
                "tutor",
                "told",
                "me",
                "to",
                "give",
                "up",
                "amaths",
                "tuition",
                ",",
                "and",
                "that",
                "I",
                "shld",
                "take",
                "up",
                "either",
                "physics",
                "or",
                "eng",
                "tuition",
                "."
            ],
            [
                "haha",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "but",
                "I",
                "will",
                "not",
                "let",
                "it",
                "dstroy",
                "I",
                "!"
            ],
            [
                "my",
                "amaths",
                "tutor",
                "tell",
                "I",
                "to",
                "give",
                "up",
                "amath",
                "tuition",
                ",",
                "and",
                "that",
                "I",
                "shld",
                "take",
                "up",
                "either",
                "physics",
                "or",
                "eng",
                "tuition",
                "."
            ],
            [
                "haha",
                "."
            ]
        ],
        "label": "Disgust"
    },
    {
        "body_part_token_idx": 9,
        "sentence_id": "ca444fa2-1c23-39b2-94f1-d17b2af8729c",
        "tokens": [
            "The",
            "aisles",
            "were",
            "foggy",
            "to",
            "me",
            ",",
            "because",
            "my",
            "eyes",
            "were",
            "filled",
            "with",
            "tears",
            "that",
            "I",
            "was",
            "fighting",
            "to",
            "keep",
            "in",
            "my",
            "eyes",
            "and",
            "off",
            "my",
            "cheeks",
            "."
        ],
        "lemmatized_tokens": [
            "the",
            "aisle",
            "be",
            "foggy",
            "to",
            "I",
            ",",
            "because",
            "my",
            "eye",
            "be",
            "fill",
            "with",
            "tear",
            "that",
            "I",
            "be",
            "fight",
            "to",
            "keep",
            "in",
            "my",
            "eye",
            "and",
            "off",
            "my",
            "cheek",
            "."
        ],
        "preceding_context_tokens": [
            [
                "Ah",
                ",",
                "my",
                "first",
                "experience",
                "grocery",
                "shopping",
                "without",
                "money",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "ah",
                ",",
                "my",
                "first",
                "experience",
                "grocery",
                "shopping",
                "without",
                "money",
                "."
            ]
        ],
        "label": "Sadness"
    },
    {
        "body_part_token_idx": 22,
        "sentence_id": "ca444fa2-1c23-39b2-94f1-d17b2af8729c",
        "tokens": [
            "The",
            "aisles",
            "were",
            "foggy",
            "to",
            "me",
            ",",
            "because",
            "my",
            "eyes",
            "were",
            "filled",
            "with",
            "tears",
            "that",
            "I",
            "was",
            "fighting",
            "to",
            "keep",
            "in",
            "my",
            "eyes",
            "and",
            "off",
            "my",
            "cheeks",
            "."
        ],
        "lemmatized_tokens": [
            "the",
            "aisle",
            "be",
            "foggy",
            "to",
            "I",
            ",",
            "because",
            "my",
            "eye",
            "be",
            "fill",
            "with",
            "tear",
            "that",
            "I",
            "be",
            "fight",
            "to",
            "keep",
            "in",
            "my",
            "eye",
            "and",
            "off",
            "my",
            "cheek",
            "."
        ],
        "preceding_context_tokens": [
            [
                "Ah",
                ",",
                "my",
                "first",
                "experience",
                "grocery",
                "shopping",
                "without",
                "money",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "ah",
                ",",
                "my",
                "first",
                "experience",
                "grocery",
                "shopping",
                "without",
                "money",
                "."
            ]
        ],
        "label": "Sadness"
    },
    {
        "body_part_token_idx": 26,
        "sentence_id": "ca444fa2-1c23-39b2-94f1-d17b2af8729c",
        "tokens": [
            "The",
            "aisles",
            "were",
            "foggy",
            "to",
            "me",
            ",",
            "because",
            "my",
            "eyes",
            "were",
            "filled",
            "with",
            "tears",
            "that",
            "I",
            "was",
            "fighting",
            "to",
            "keep",
            "in",
            "my",
            "eyes",
            "and",
            "off",
            "my",
            "cheeks",
            "."
        ],
        "lemmatized_tokens": [
            "the",
            "aisle",
            "be",
            "foggy",
            "to",
            "I",
            ",",
            "because",
            "my",
            "eye",
            "be",
            "fill",
            "with",
            "tear",
            "that",
            "I",
            "be",
            "fight",
            "to",
            "keep",
            "in",
            "my",
            "eye",
            "and",
            "off",
            "my",
            "cheek",
            "."
        ],
        "preceding_context_tokens": [
            [
                "Ah",
                ",",
                "my",
                "first",
                "experience",
                "grocery",
                "shopping",
                "without",
                "money",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "ah",
                ",",
                "my",
                "first",
                "experience",
                "grocery",
                "shopping",
                "without",
                "money",
                "."
            ]
        ],
        "label": "Sadness"
    },
    {
        "body_part_token_idx": 10,
        "sentence_id": "ef0eae7c-4ba3-3203-a37c-59eea7b171a2",
        "tokens": [
            "``",
            "Hey",
            ",",
            "''",
            "he",
            "said",
            ",",
            "then",
            "cleared",
            "his",
            "throat",
            "and",
            "tried",
            "not",
            "to",
            "blush",
            "."
        ],
        "lemmatized_tokens": [
            "``",
            "hey",
            ",",
            "''",
            "he",
            "say",
            ",",
            "then",
            "clear",
            "he",
            "throat",
            "and",
            "try",
            "not",
            "to",
            "blush",
            "."
        ],
        "preceding_context_tokens": [
            [
                "``",
                "Hello",
                "."
            ],
            [
                "``",
                "He",
                "turned",
                ",",
                "and",
                "his",
                "gut",
                "clenched",
                "."
            ],
            [
                "The",
                "woman",
                "standing",
                "in",
                "front",
                "of",
                "him",
                "was",
                "n't",
                "beautiful",
                ",",
                "exactly",
                ",",
                "but",
                "...",
                "it",
                "was",
                "her",
                "eyes",
                ",",
                "he",
                "thought",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "``",
                "hello",
                "."
            ],
            [
                "``",
                "he",
                "turn",
                ",",
                "and",
                "he",
                "gut",
                "clench",
                "."
            ],
            [
                "the",
                "woman",
                "stand",
                "in",
                "front",
                "of",
                "he",
                "be",
                "not",
                "beautiful",
                ",",
                "exactly",
                ",",
                "but",
                "...",
                "it",
                "be",
                "she",
                "eye",
                ",",
                "he",
                "think",
                "."
            ]
        ],
        "label": "Fear"
    },
    {
        "body_part_token_idx": 2,
        "sentence_id": "016dcd0d-3188-3547-993d-33539526fee3",
        "tokens": [
            "Were",
            "her",
            "cheeks",
            "turning",
            "pink",
            "?"
        ],
        "lemmatized_tokens": [
            "be",
            "she",
            "cheek",
            "turn",
            "pink",
            "?"
        ],
        "preceding_context_tokens": [
            [
                "``",
                "Can",
                "you",
                "hook",
                "me",
                "up",
                "with",
                "a",
                "pencil",
                "?",
                "''"
            ],
            [
                "She",
                "did",
                "n't",
                "look",
                "up",
                "."
            ],
            [
                "``",
                "Hey",
                ",",
                "''",
                "he",
                "said",
                "again",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "``",
                "can",
                "you",
                "hook",
                "I",
                "up",
                "with",
                "a",
                "pencil",
                "?",
                "''"
            ],
            [
                "she",
                "do",
                "not",
                "look",
                "up",
                "."
            ],
            [
                "``",
                "hey",
                ",",
                "''",
                "he",
                "say",
                "again",
                "."
            ]
        ],
        "label": "Fear"
    },
    {
        "body_part_token_idx": 3,
        "sentence_id": "b3c95a1d-718e-3ddf-b555-759a0a26f718",
        "tokens": [
            "I",
            "stomped",
            "my",
            "foot",
            "in",
            "anger",
            "."
        ],
        "lemmatized_tokens": [
            "I",
            "stomp",
            "my",
            "foot",
            "in",
            "anger",
            "."
        ],
        "preceding_context_tokens": [
            [
                "He",
                "did",
                "n't",
                "want",
                "to",
                "rock",
                "in",
                "the",
                "rocking",
                "chair",
                "or",
                "bounce",
                "on",
                "the",
                "yoga",
                "ball",
                "."
            ],
            [
                "I",
                "had",
                "even",
                "tried",
                "taking",
                "him",
                "outside",
                ",",
                "but",
                "it",
                "did",
                "n't",
                "seem",
                "to",
                "help",
                "and",
                "I",
                "did",
                "n't",
                "want",
                "calls",
                "from",
                "the",
                "neighbors",
                "."
            ],
            [
                "He",
                "was",
                "supposed",
                "to",
                "be",
                "asleep",
                "but",
                "every",
                "time",
                "I",
                "laid",
                "him",
                "back",
                "down",
                "in",
                "his",
                "crib",
                ",",
                "he",
                "howled",
                "even",
                "louder",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "he",
                "do",
                "not",
                "want",
                "to",
                "rock",
                "in",
                "the",
                "rock",
                "chair",
                "or",
                "bounce",
                "on",
                "the",
                "yoga",
                "ball",
                "."
            ],
            [
                "I",
                "have",
                "even",
                "try",
                "take",
                "he",
                "outside",
                ",",
                "but",
                "it",
                "do",
                "not",
                "seem",
                "to",
                "help",
                "and",
                "I",
                "do",
                "not",
                "want",
                "call",
                "from",
                "the",
                "neighbor",
                "."
            ],
            [
                "he",
                "be",
                "suppose",
                "to",
                "be",
                "asleep",
                "but",
                "every",
                "time",
                "I",
                "lay",
                "he",
                "back",
                "down",
                "in",
                "he",
                "crib",
                ",",
                "he",
                "howl",
                "even",
                "louder",
                "."
            ]
        ],
        "label": "Anger"
    },
    {
        "body_part_token_idx": 3,
        "sentence_id": "e15461ef-dedd-30a2-82e1-d1200dfa209e",
        "tokens": [
            "He",
            "shook",
            "his",
            "head",
            "and",
            "said",
            "out",
            "loud",
            ",",
            "`",
            "Allah",
            "is",
            "that",
            "you",
            "?"
        ],
        "lemmatized_tokens": [
            "he",
            "shake",
            "he",
            "head",
            "and",
            "say",
            "out",
            "loud",
            ",",
            "`",
            "Allah",
            "be",
            "that",
            "you",
            "?"
        ],
        "preceding_context_tokens": [
            [
                "I",
                "will",
                "listen",
                "."
            ],
            [
                "I",
                "will",
                "do",
                "my",
                "best",
                "to",
                "obey",
                "."
            ],
            [
                "'",
                "As",
                "he",
                "drove",
                "down",
                "the",
                "main",
                "street",
                "of",
                "his",
                "town",
                ",",
                "he",
                "had",
                "the",
                "strangest",
                "thought",
                "to",
                "stop",
                "and",
                "buy",
                "a",
                "gallon",
                "of",
                "milk",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "I",
                "will",
                "listen",
                "."
            ],
            [
                "I",
                "will",
                "do",
                "my",
                "best",
                "to",
                "obey",
                "."
            ],
            [
                "'",
                "as",
                "he",
                "drive",
                "down",
                "the",
                "main",
                "street",
                "of",
                "he",
                "town",
                ",",
                "he",
                "have",
                "the",
                "strangest",
                "thought",
                "to",
                "stop",
                "and",
                "buy",
                "a",
                "gallon",
                "of",
                "milk",
                "."
            ]
        ],
        "label": "Surprise"
    },
    {
        "body_part_token_idx": 3,
        "sentence_id": "ea480790-e426-3152-9f5f-2a0d6edac56e",
        "tokens": [
            "Sam",
            "shook",
            "his",
            "head",
            "and",
            "leaned",
            "the",
            "shovel",
            "against",
            "the",
            "headstone",
            "before",
            "jogging",
            "over",
            "to",
            "the",
            "car",
            "."
        ],
        "lemmatized_tokens": [
            "Sam",
            "shake",
            "he",
            "head",
            "and",
            "lean",
            "the",
            "shovel",
            "against",
            "the",
            "headstone",
            "before",
            "jog",
            "over",
            "to",
            "the",
            "car",
            "."
        ],
        "preceding_context_tokens": [
            [
                "``",
                "Must",
                "'ve",
                "rolled",
                "out",
                "of",
                "my",
                "bag",
                "."
            ],
            [
                "Door",
                "'s",
                "unlocked",
                ":",
                "it",
                "should",
                "still",
                "be",
                "in",
                "the",
                "backseat",
                "."
            ],
            [
                "Go",
                "fetch",
                ",",
                "man",
                ",",
                "walk",
                "it",
                "off",
                ",",
                "''",
                "said",
                "Dean",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "``",
                "must",
                "have",
                "roll",
                "out",
                "of",
                "my",
                "bag",
                "."
            ],
            [
                "door",
                "'s",
                "unlock",
                ":",
                "it",
                "should",
                "still",
                "be",
                "in",
                "the",
                "backseat",
                "."
            ],
            [
                "go",
                "fetch",
                ",",
                "man",
                ",",
                "walk",
                "it",
                "off",
                ",",
                "''",
                "say",
                "Dean",
                "."
            ]
        ],
        "label": "Disgust"
    },
    {
        "body_part_token_idx": 7,
        "sentence_id": "c6d70623-61a6-3056-97b1-b8ff962d2129",
        "tokens": [
            "I",
            "get",
            "a",
            "huge",
            "grin",
            "on",
            "my",
            "face",
            "and",
            "say",
            ",",
            "``",
            "Why",
            "yes",
            ",",
            "he",
            "'s",
            "been",
            "sleeping",
            "all",
            "night",
            "for",
            "two",
            "weeks",
            "now",
            "."
        ],
        "lemmatized_tokens": [
            "I",
            "get",
            "a",
            "huge",
            "grin",
            "on",
            "my",
            "face",
            "and",
            "say",
            ",",
            "``",
            "why",
            "yes",
            ",",
            "he",
            "be",
            "be",
            "sleep",
            "all",
            "night",
            "for",
            "two",
            "week",
            "now",
            "."
        ],
        "preceding_context_tokens": [
            [
                "Throughout",
                "the",
                "day",
                ",",
                "we",
                "might",
                "make",
                "errands",
                "that",
                "most",
                "definitely",
                "is",
                "filled",
                "with",
                "questions",
                "such",
                "as",
                ",",
                "``",
                "How",
                "old",
                "is",
                "he",
                "?",
                "''"
            ],
            [
                "or",
                "something",
                "asanine",
                "like",
                ",",
                "``",
                "Is",
                "he",
                "sleeping",
                "through",
                "the",
                "night",
                "yet",
                "?",
                "''"
            ],
            [
                "You",
                "come",
                "to",
                "realize",
                "that",
                "the",
                "latter",
                "of",
                "the",
                "two",
                "questions",
                "is",
                "n't",
                "so",
                "much",
                "a",
                "question",
                ",",
                "as",
                "a",
                "judgement",
                ",",
                "that",
                "some",
                "people",
                "like",
                "to",
                "make",
                "when",
                "they",
                "think",
                "that",
                "their",
                "children",
                "or",
                "that",
                "they",
                "themselves",
                "are",
                "better",
                "than",
                "you",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "throughout",
                "the",
                "day",
                ",",
                "we",
                "might",
                "make",
                "errand",
                "that",
                "most",
                "definitely",
                "be",
                "fill",
                "with",
                "question",
                "such",
                "as",
                ",",
                "``",
                "how",
                "old",
                "be",
                "he",
                "?",
                "''"
            ],
            [
                "or",
                "something",
                "asanine",
                "like",
                ",",
                "``",
                "be",
                "he",
                "sleep",
                "through",
                "the",
                "night",
                "yet",
                "?",
                "''"
            ],
            [
                "you",
                "come",
                "to",
                "realize",
                "that",
                "the",
                "latter",
                "of",
                "the",
                "two",
                "question",
                "be",
                "not",
                "so",
                "much",
                "a",
                "question",
                ",",
                "as",
                "a",
                "judgement",
                ",",
                "that",
                "some",
                "people",
                "like",
                "to",
                "make",
                "when",
                "they",
                "think",
                "that",
                "they",
                "child",
                "or",
                "that",
                "they",
                "themselves",
                "be",
                "better",
                "than",
                "you",
                "."
            ]
        ],
        "label": "Joy"
    },
    {
        "body_part_token_idx": 12,
        "sentence_id": "68d506c9-3fe0-3ab5-bd34-be0f5fcc3f49",
        "tokens": [
            "Out",
            "of",
            "sudden",
            ",",
            "chest",
            "pains",
            "like",
            "something",
            "it",
            "bumping",
            "into",
            "my",
            "heart",
            "and",
            "I",
            "can",
            "not",
            "breathe",
            "."
        ],
        "lemmatized_tokens": [
            "out",
            "of",
            "sudden",
            ",",
            "chest",
            "pain",
            "like",
            "something",
            "it",
            "bump",
            "into",
            "my",
            "heart",
            "and",
            "I",
            "can",
            "not",
            "breathe",
            "."
        ],
        "preceding_context_tokens": [
            [
                "However",
                ",",
                "no",
                "tears",
                "come",
                "out",
                "and",
                "it",
                "hurts",
                "me",
                "more",
                "."
            ],
            [
                "When",
                "I",
                "reached",
                "my",
                "house",
                ",",
                "I",
                "scrambled",
                "to",
                "get",
                "the",
                "keys",
                "and",
                "go",
                "inside",
                "."
            ],
            [
                "The",
                "keys",
                "slipped",
                "down",
                "to",
                "the",
                "floor",
                "and",
                "I",
                "tried",
                "to",
                "pick",
                "it",
                "up",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "however",
                ",",
                "no",
                "tear",
                "come",
                "out",
                "and",
                "it",
                "hurt",
                "I",
                "more",
                "."
            ],
            [
                "when",
                "I",
                "reach",
                "my",
                "house",
                ",",
                "I",
                "scramble",
                "to",
                "get",
                "the",
                "key",
                "and",
                "go",
                "inside",
                "."
            ],
            [
                "the",
                "key",
                "slip",
                "down",
                "to",
                "the",
                "floor",
                "and",
                "I",
                "try",
                "to",
                "pick",
                "it",
                "up",
                "."
            ]
        ],
        "label": "Fear"
    },
    {
        "body_part_token_idx": 14,
        "sentence_id": "78b04109-9ab3-35f8-8f7a-c8b8c8cd9757",
        "tokens": [
            "When",
            "we",
            "got",
            "home",
            ",",
            "she",
            "'d",
            "been",
            "brooding",
            "and",
            "pouting",
            "and",
            "stomping",
            "her",
            "feet",
            "as",
            "she",
            "sulked",
            "around",
            "the",
            "house",
            "with",
            "nothing",
            "to",
            "do",
            "."
        ],
        "lemmatized_tokens": [
            "when",
            "we",
            "get",
            "home",
            ",",
            "she",
            "have",
            "be",
            "brooding",
            "and",
            "pouting",
            "and",
            "stomp",
            "she",
            "foot",
            "as",
            "she",
            "sulk",
            "around",
            "the",
            "house",
            "with",
            "nothing",
            "to",
            "do",
            "."
        ],
        "preceding_context_tokens": [
            [
                "So",
                ",",
                "anyway",
                "...",
                "bad",
                "mood",
                "yesterday",
                "morning",
                "."
            ],
            [
                "My",
                "mom",
                "asked",
                "if",
                "grandma",
                "was",
                "upset",
                "that",
                "Mom",
                "and",
                "I",
                "were",
                "spending",
                "the",
                "day",
                "together",
                "."
            ],
            [
                "She",
                "said",
                "no",
                "and",
                "stormed",
                "off",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "so",
                ",",
                "anyway",
                "...",
                "bad",
                "mood",
                "yesterday",
                "morning",
                "."
            ],
            [
                "my",
                "mom",
                "ask",
                "if",
                "grandma",
                "be",
                "upset",
                "that",
                "mom",
                "and",
                "I",
                "be",
                "spend",
                "the",
                "day",
                "together",
                "."
            ],
            [
                "she",
                "say",
                "no",
                "and",
                "storm",
                "off",
                "."
            ]
        ],
        "label": "Anger"
    },
    {
        "body_part_token_idx": 12,
        "sentence_id": "23a29577-c705-3134-ba74-32407cfeacf8",
        "tokens": [
            "My",
            "mother",
            "announced",
            "our",
            "names",
            "into",
            "the",
            "intercom",
            ";",
            "I",
            "folded",
            "my",
            "hands",
            "prayer",
            "-",
            "like",
            ":",
            "calm",
            "down",
            ",",
            "calm",
            "down",
            ",",
            "calm",
            "down",
            "."
        ],
        "lemmatized_tokens": [
            "my",
            "mother",
            "announce",
            "we",
            "name",
            "into",
            "the",
            "intercom",
            ";",
            "I",
            "fold",
            "my",
            "hand",
            "prayer",
            "-",
            "like",
            ":",
            "calm",
            "down",
            ",",
            "calm",
            "down",
            ",",
            "calm",
            "down",
            "."
        ],
        "preceding_context_tokens": [
            [
                "She",
                "tapped",
                "her",
                "foot",
                "from",
                "gas",
                "pedal",
                "to",
                "brake",
                ",",
                "gas",
                "pedal",
                ",",
                "brake",
                "."
            ],
            [
                "``",
                "Look",
                ",",
                "dolly",
                "."
            ],
            [
                "The",
                "wooden",
                "security",
                "gate",
                "!",
                "''"
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "she",
                "tap",
                "she",
                "foot",
                "from",
                "gas",
                "pedal",
                "to",
                "brake",
                ",",
                "gas",
                "pedal",
                ",",
                "brake",
                "."
            ],
            [
                "``",
                "look",
                ",",
                "dolly",
                "."
            ],
            [
                "the",
                "wooden",
                "security",
                "gate",
                "!",
                "''"
            ]
        ],
        "label": "Fear"
    },
    {
        "body_part_token_idx": 28,
        "sentence_id": "0cdceb8a-5429-3e6e-976d-ab979393f892",
        "tokens": [
            "What",
            "is",
            "that",
            ",",
            "cerulean?",
            "Teal",
            ",",
            "O'Hara",
            "instantly",
            "gushed",
            "back",
            ",",
            "making",
            "Henry",
            "study",
            "her",
            "again",
            ",",
            "from",
            "her",
            "flat",
            "shoes",
            "to",
            "the",
            "blush",
            "stealing",
            "over",
            "her",
            "cheeks",
            "as",
            "she",
            "darted",
            "looks",
            "at",
            "her",
            "partner",
            "."
        ],
        "lemmatized_tokens": [
            "what",
            "be",
            "that",
            ",",
            "cerulean?",
            "Teal",
            ",",
            "O'Hara",
            "instantly",
            "gush",
            "back",
            ",",
            "make",
            "Henry",
            "study",
            "she",
            "again",
            ",",
            "from",
            "she",
            "flat",
            "shoe",
            "to",
            "the",
            "blush",
            "steal",
            "over",
            "she",
            "cheek",
            "as",
            "she",
            "dart",
            "look",
            "at",
            "she",
            "partner",
            "."
        ],
        "preceding_context_tokens": [
            [
                "All",
                "shall",
                "be",
                "revealed",
                "in",
                "he",
                "glanced",
                "at",
                "his",
                "wrist",
                "though",
                "he",
                "was",
                "n't",
                "wearing",
                "a",
                "watch",
                "."
            ],
            [
                "Oh",
                ",",
                "about",
                "one",
                "and",
                "a",
                "half",
                "minutes",
                "."
            ],
            [
                "That",
                "is",
                "a",
                "lovely",
                "top",
                "by",
                "the",
                "way",
                ",",
                "Jules.",
                "Having",
                "drawn",
                "every",
                "eye",
                "back",
                "to",
                "him",
                ",",
                "Shawn",
                "dropped",
                "to",
                "lean",
                "against",
                "the",
                "Crown",
                "Vic",
                "and",
                "flashed",
                "another",
                "smile",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "all",
                "shall",
                "be",
                "reveal",
                "in",
                "he",
                "glance",
                "at",
                "he",
                "wrist",
                "though",
                "he",
                "be",
                "not",
                "wear",
                "a",
                "watch",
                "."
            ],
            [
                "oh",
                ",",
                "about",
                "one",
                "and",
                "a",
                "half",
                "minute",
                "."
            ],
            [
                "that",
                "be",
                "a",
                "lovely",
                "top",
                "by",
                "the",
                "way",
                ",",
                "Jules.",
                "have",
                "draw",
                "every",
                "eye",
                "back",
                "to",
                "he",
                ",",
                "Shawn",
                "drop",
                "to",
                "lean",
                "against",
                "the",
                "Crown",
                "Vic",
                "and",
                "flash",
                "another",
                "smile",
                "."
            ]
        ],
        "label": "Joy"
    },
    {
        "body_part_token_idx": 39,
        "sentence_id": "2c6b21b9-ba7f-3f04-9e2c-cfc83ba6e98c",
        "tokens": [
            "She",
            "sighed.",
            "Allan",
            ",",
            "I",
            "'m",
            "not",
            "being",
            "funny",
            ",",
            "but",
            "Robin",
            "is",
            "n't",
            "going",
            "to",
            "welcome",
            "you",
            "back",
            "into",
            "the",
            "fold",
            "anytime",
            "soon.",
            "She",
            "ignored",
            "the",
            "hint",
            "of",
            "a",
            "glare",
            "that",
            "he",
            "threw",
            "at",
            "her",
            ",",
            "putting",
            "her",
            "hands",
            "on",
            "her",
            "hips",
            "."
        ],
        "lemmatized_tokens": [
            "she",
            "sighed.",
            "Allan",
            ",",
            "I",
            "be",
            "not",
            "be",
            "funny",
            ",",
            "but",
            "Robin",
            "be",
            "not",
            "go",
            "to",
            "welcome",
            "you",
            "back",
            "into",
            "the",
            "fold",
            "anytime",
            "soon.",
            "she",
            "ignore",
            "the",
            "hint",
            "of",
            "a",
            "glare",
            "that",
            "he",
            "throw",
            "at",
            "she",
            ",",
            "put",
            "she",
            "hand",
            "on",
            "she",
            "hip",
            "."
        ],
        "preceding_context_tokens": [
            [
                "Gisborne",
                "will",
                "have",
                "you",
                "hunted",
                "and",
                "killed",
                "if",
                "it",
                "looks",
                "like",
                "you",
                "'ve",
                "simply",
                "turned",
                "on",
                "him",
                "."
            ],
            [
                "But",
                "if",
                "you",
                "go",
                "to",
                "him",
                ",",
                "explain",
                "that",
                "Robin",
                "gave",
                "you",
                "the",
                "boot",
                ",",
                "he",
                "'s",
                "more",
                "likely",
                "to",
                "understand",
                "and",
                "give",
                "you",
                "a",
                "job.",
                "I",
                "do",
                "n't",
                "want",
                "to",
                "work",
                "for",
                "Gisborne",
                "anymore",
                "."
            ],
            [
                "I",
                "do",
                "n't",
                "want",
                "to",
                "sell",
                "my",
                "soul",
                ",",
                "he",
                "replied",
                "softly",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "Gisborne",
                "will",
                "have",
                "you",
                "hunt",
                "and",
                "kill",
                "if",
                "it",
                "look",
                "like",
                "you",
                "have",
                "simply",
                "turn",
                "on",
                "he",
                "."
            ],
            [
                "but",
                "if",
                "you",
                "go",
                "to",
                "he",
                ",",
                "explain",
                "that",
                "Robin",
                "give",
                "you",
                "the",
                "boot",
                ",",
                "he",
                "be",
                "more",
                "likely",
                "to",
                "understand",
                "and",
                "give",
                "you",
                "a",
                "job.",
                "I",
                "do",
                "not",
                "want",
                "to",
                "work",
                "for",
                "Gisborne",
                "anymore",
                "."
            ],
            [
                "I",
                "do",
                "not",
                "want",
                "to",
                "sell",
                "my",
                "soul",
                ",",
                "he",
                "reply",
                "softly",
                "."
            ]
        ],
        "label": "Anger"
    },
    {
        "body_part_token_idx": 42,
        "sentence_id": "2c6b21b9-ba7f-3f04-9e2c-cfc83ba6e98c",
        "tokens": [
            "She",
            "sighed.",
            "Allan",
            ",",
            "I",
            "'m",
            "not",
            "being",
            "funny",
            ",",
            "but",
            "Robin",
            "is",
            "n't",
            "going",
            "to",
            "welcome",
            "you",
            "back",
            "into",
            "the",
            "fold",
            "anytime",
            "soon.",
            "She",
            "ignored",
            "the",
            "hint",
            "of",
            "a",
            "glare",
            "that",
            "he",
            "threw",
            "at",
            "her",
            ",",
            "putting",
            "her",
            "hands",
            "on",
            "her",
            "hips",
            "."
        ],
        "lemmatized_tokens": [
            "she",
            "sighed.",
            "Allan",
            ",",
            "I",
            "be",
            "not",
            "be",
            "funny",
            ",",
            "but",
            "Robin",
            "be",
            "not",
            "go",
            "to",
            "welcome",
            "you",
            "back",
            "into",
            "the",
            "fold",
            "anytime",
            "soon.",
            "she",
            "ignore",
            "the",
            "hint",
            "of",
            "a",
            "glare",
            "that",
            "he",
            "throw",
            "at",
            "she",
            ",",
            "put",
            "she",
            "hand",
            "on",
            "she",
            "hip",
            "."
        ],
        "preceding_context_tokens": [
            [
                "Gisborne",
                "will",
                "have",
                "you",
                "hunted",
                "and",
                "killed",
                "if",
                "it",
                "looks",
                "like",
                "you",
                "'ve",
                "simply",
                "turned",
                "on",
                "him",
                "."
            ],
            [
                "But",
                "if",
                "you",
                "go",
                "to",
                "him",
                ",",
                "explain",
                "that",
                "Robin",
                "gave",
                "you",
                "the",
                "boot",
                ",",
                "he",
                "'s",
                "more",
                "likely",
                "to",
                "understand",
                "and",
                "give",
                "you",
                "a",
                "job.",
                "I",
                "do",
                "n't",
                "want",
                "to",
                "work",
                "for",
                "Gisborne",
                "anymore",
                "."
            ],
            [
                "I",
                "do",
                "n't",
                "want",
                "to",
                "sell",
                "my",
                "soul",
                ",",
                "he",
                "replied",
                "softly",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "Gisborne",
                "will",
                "have",
                "you",
                "hunt",
                "and",
                "kill",
                "if",
                "it",
                "look",
                "like",
                "you",
                "have",
                "simply",
                "turn",
                "on",
                "he",
                "."
            ],
            [
                "but",
                "if",
                "you",
                "go",
                "to",
                "he",
                ",",
                "explain",
                "that",
                "Robin",
                "give",
                "you",
                "the",
                "boot",
                ",",
                "he",
                "be",
                "more",
                "likely",
                "to",
                "understand",
                "and",
                "give",
                "you",
                "a",
                "job.",
                "I",
                "do",
                "not",
                "want",
                "to",
                "work",
                "for",
                "Gisborne",
                "anymore",
                "."
            ],
            [
                "I",
                "do",
                "not",
                "want",
                "to",
                "sell",
                "my",
                "soul",
                ",",
                "he",
                "reply",
                "softly",
                "."
            ]
        ],
        "label": "Anger"
    },
    {
        "body_part_token_idx": 1,
        "sentence_id": "ac137cb9-3a23-3166-86b0-52aa72e88bff",
        "tokens": [
            "His",
            "lips",
            "were",
            "quivering",
            "but",
            "he",
            "had",
            "a",
            "small",
            "smile",
            "on",
            "it",
            "."
        ],
        "lemmatized_tokens": [
            "he",
            "lip",
            "be",
            "quiver",
            "but",
            "he",
            "have",
            "a",
            "small",
            "smile",
            "on",
            "it",
            "."
        ],
        "preceding_context_tokens": [
            [
                "Let",
                "'s",
                "get",
                "you",
                "to",
                "the",
                "Hospital",
                "!",
                "''"
            ],
            [
                "He",
                "swatted",
                "my",
                "hands",
                "away",
                "as",
                "his",
                "knees",
                "buckled",
                "and",
                "he",
                "slumped",
                "on",
                "the",
                "floor",
                ",",
                "now",
                "gripping",
                "on",
                "his",
                "chest",
                "."
            ],
            [
                "He",
                "looked",
                "at",
                "me",
                ",",
                "his",
                "left",
                "eye",
                "half",
                "-",
                "closed",
                "as",
                "the",
                "other",
                "battled",
                "to",
                "keep",
                "open",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "let",
                "'s",
                "get",
                "you",
                "to",
                "the",
                "hospital",
                "!",
                "''"
            ],
            [
                "he",
                "swat",
                "my",
                "hand",
                "away",
                "as",
                "he",
                "knee",
                "buckle",
                "and",
                "he",
                "slump",
                "on",
                "the",
                "floor",
                ",",
                "now",
                "grip",
                "on",
                "he",
                "chest",
                "."
            ],
            [
                "he",
                "look",
                "at",
                "I",
                ",",
                "he",
                "left",
                "eye",
                "half",
                "-",
                "close",
                "as",
                "the",
                "other",
                "battle",
                "to",
                "keep",
                "open",
                "."
            ]
        ],
        "label": "Fear"
    },
    {
        "body_part_token_idx": 17,
        "sentence_id": "a9972b52-0350-3ccb-a0c6-db297cfc6c32",
        "tokens": [
            "Finn",
            "bumped",
            "shoulders",
            "with",
            "him",
            ",",
            "motioning",
            "towards",
            "their",
            "parents",
            "with",
            "a",
            "juvenile",
            "gagging",
            "expression",
            "on",
            "his",
            "face",
            ",",
            "and",
            "Kurt",
            "turned",
            "to",
            "look",
            "at",
            "them",
            ",",
            "laughing",
            "happily",
            "at",
            "what",
            "he",
            "saw",
            "."
        ],
        "lemmatized_tokens": [
            "Finn",
            "bump",
            "shoulder",
            "with",
            "he",
            ",",
            "motion",
            "towards",
            "they",
            "parent",
            "with",
            "a",
            "juvenile",
            "gagging",
            "expression",
            "on",
            "he",
            "face",
            ",",
            "and",
            "Kurt",
            "turn",
            "to",
            "look",
            "at",
            "they",
            ",",
            "laugh",
            "happily",
            "at",
            "what",
            "he",
            "see",
            "."
        ],
        "preceding_context_tokens": [
            [
                "Even",
                "though",
                "Burt",
                "always",
                "made",
                "a",
                "point",
                "of",
                "getting",
                "amazing",
                "fireworks",
                "for",
                "New",
                "Years",
                ",",
                "this",
                "year",
                "he",
                "had",
                "gone",
                "all",
                "out",
                ",",
                "probably",
                "with",
                "the",
                "intent",
                "of",
                "impressing",
                "his",
                "wife",
                "and",
                "step",
                "-",
                "son",
                "."
            ],
            [
                "And",
                "he",
                "was",
                "pretty",
                "sure",
                "it",
                "was",
                "working",
                "."
            ],
            [
                "Finn",
                "had",
                "been",
                "jittery",
                "with",
                "excitement",
                "all",
                "night",
                ",",
                "and",
                "was",
                "staring",
                "up",
                "at",
                "the",
                "sky",
                "with",
                "that",
                "huge",
                "grin",
                "on",
                "his",
                "face",
                "as",
                "the",
                "explosives",
                "went",
                "off",
                "all",
                "around",
                "them",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "even",
                "though",
                "Burt",
                "always",
                "make",
                "a",
                "point",
                "of",
                "get",
                "amazing",
                "firework",
                "for",
                "New",
                "Years",
                ",",
                "this",
                "year",
                "he",
                "have",
                "go",
                "all",
                "out",
                ",",
                "probably",
                "with",
                "the",
                "intent",
                "of",
                "impress",
                "he",
                "wife",
                "and",
                "step",
                "-",
                "son",
                "."
            ],
            [
                "and",
                "he",
                "be",
                "pretty",
                "sure",
                "it",
                "be",
                "work",
                "."
            ],
            [
                "Finn",
                "have",
                "be",
                "jittery",
                "with",
                "excitement",
                "all",
                "night",
                ",",
                "and",
                "be",
                "stare",
                "up",
                "at",
                "the",
                "sky",
                "with",
                "that",
                "huge",
                "grin",
                "on",
                "he",
                "face",
                "as",
                "the",
                "explosive",
                "go",
                "off",
                "all",
                "around",
                "they",
                "."
            ]
        ],
        "label": "Joy"
    },
    {
        "body_part_token_idx": 21,
        "sentence_id": "6945367e-058a-3946-8d08-12043f588197",
        "tokens": [
            "``",
            "He",
            "'s",
            "lost",
            "a",
            "lot",
            "of",
            "blood",
            ",",
            "''",
            "Scott",
            "'s",
            "doctor",
            "finally",
            "announced",
            "and",
            "Mrs.",
            "Warren",
            "squeaked",
            "into",
            "her",
            "palms",
            "."
        ],
        "lemmatized_tokens": [
            "``",
            "he",
            "be",
            "lose",
            "a",
            "lot",
            "of",
            "blood",
            ",",
            "''",
            "Scott",
            "'s",
            "doctor",
            "finally",
            "announce",
            "and",
            "Mrs.",
            "Warren",
            "squeak",
            "into",
            "she",
            "palm",
            "."
        ],
        "preceding_context_tokens": [
            [
                "I",
                "finished",
                "a",
                "word",
                "search",
                "in",
                "the",
                "mean",
                "time",
                "and",
                "picked",
                "up",
                "on",
                "the",
                "pattern",
                "on",
                "which",
                "members",
                "of",
                "the",
                "hospital",
                "staff",
                "actually",
                "did",
                "anything",
                "and",
                "which",
                "seemed",
                "to",
                "be",
                "the",
                "spares",
                "."
            ],
            [
                "The",
                "sun",
                "had",
                "come",
                "up",
                "and",
                "shone",
                "in",
                "through",
                "the",
                "individual",
                "rooms",
                "and",
                "into",
                "the",
                "hall",
                "."
            ],
            [
                "The",
                "white",
                "floors",
                "looked",
                "yellow",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "I",
                "finish",
                "a",
                "word",
                "search",
                "in",
                "the",
                "mean",
                "time",
                "and",
                "pick",
                "up",
                "on",
                "the",
                "pattern",
                "on",
                "which",
                "member",
                "of",
                "the",
                "hospital",
                "staff",
                "actually",
                "do",
                "anything",
                "and",
                "which",
                "seem",
                "to",
                "be",
                "the",
                "spare",
                "."
            ],
            [
                "the",
                "sun",
                "have",
                "come",
                "up",
                "and",
                "shine",
                "in",
                "through",
                "the",
                "individual",
                "room",
                "and",
                "into",
                "the",
                "hall",
                "."
            ],
            [
                "the",
                "white",
                "floor",
                "look",
                "yellow",
                "."
            ]
        ],
        "label": "Fear"
    },
    {
        "body_part_token_idx": 3,
        "sentence_id": "e9a8afcb-9477-3cf4-b2b2-138a8d17ecfe",
        "tokens": [
            "I",
            "rolled",
            "my",
            "eyes",
            "laughing",
            "."
        ],
        "lemmatized_tokens": [
            "I",
            "roll",
            "my",
            "eye",
            "laugh",
            "."
        ],
        "preceding_context_tokens": [
            [
                "He",
                "led",
                "me",
                "inside",
                "and",
                "to",
                "the",
                "head",
                "table",
                "."
            ],
            [
                "We",
                "sat",
                "down",
                "in",
                "our",
                "places",
                "and",
                "the",
                "speeches",
                "were",
                "made",
                "."
            ],
            [
                "He",
                "then",
                "ran",
                "to",
                "our",
                "buffet",
                "determined",
                "to",
                "be",
                "first",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "he",
                "lead",
                "I",
                "inside",
                "and",
                "to",
                "the",
                "head",
                "table",
                "."
            ],
            [
                "we",
                "sit",
                "down",
                "in",
                "we",
                "place",
                "and",
                "the",
                "speech",
                "be",
                "make",
                "."
            ],
            [
                "he",
                "then",
                "run",
                "to",
                "we",
                "buffet",
                "determine",
                "to",
                "be",
                "first",
                "."
            ]
        ],
        "label": "Joy"
    },
    {
        "body_part_token_idx": 3,
        "sentence_id": "0cfac99a-7c2c-351b-b22e-386877d79398",
        "tokens": [
            "He",
            "straightened",
            "his",
            "back",
            ",",
            "ready",
            "to",
            "wish",
            "Jack",
            "luck",
            "and",
            "go",
            "home",
            "and",
            "let",
            "his",
            "heart",
            "break",
            "completely",
            "in",
            "private",
            "."
        ],
        "lemmatized_tokens": [
            "he",
            "straighten",
            "he",
            "back",
            ",",
            "ready",
            "to",
            "wish",
            "Jack",
            "luck",
            "and",
            "go",
            "home",
            "and",
            "let",
            "he",
            "heart",
            "break",
            "completely",
            "in",
            "private",
            "."
        ],
        "preceding_context_tokens": [
            [
                "I",
                "meant",
                "I",
                "need",
                "you",
                "to",
                "wait",
                "and",
                "listen.",
                "Oh",
                ",",
                "Ianto",
                "said",
                ",",
                "his",
                "heart",
                "breaking",
                "a",
                "little",
                "."
            ],
            [
                "This",
                "was",
                "it",
                ",",
                "then",
                "."
            ],
            [
                "Jack",
                "could",
                "n't",
                "be",
                "who",
                "Ianto",
                "wanted",
                "him",
                "to",
                "be",
                ";",
                "who",
                "Ianto",
                "knew",
                "he",
                "really",
                "was",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "I",
                "mean",
                "I",
                "need",
                "you",
                "to",
                "wait",
                "and",
                "listen.",
                "oh",
                ",",
                "Ianto",
                "say",
                ",",
                "he",
                "heart",
                "break",
                "a",
                "little",
                "."
            ],
            [
                "this",
                "be",
                "it",
                ",",
                "then",
                "."
            ],
            [
                "Jack",
                "could",
                "not",
                "be",
                "who",
                "Ianto",
                "want",
                "he",
                "to",
                "be",
                ";",
                "who",
                "Ianto",
                "know",
                "he",
                "really",
                "be",
                "."
            ]
        ],
        "label": "Sadness"
    },
    {
        "body_part_token_idx": 8,
        "sentence_id": "425d8904-fcdc-33b2-812f-9b40310f770b",
        "tokens": [
            "She",
            "jumped",
            "up",
            "and",
            "down",
            "and",
            "clapped",
            "her",
            "hands",
            "and",
            "covered",
            "her",
            "mouth",
            "and",
            "giggled",
            "."
        ],
        "lemmatized_tokens": [
            "she",
            "jump",
            "up",
            "and",
            "down",
            "and",
            "clap",
            "she",
            "hand",
            "and",
            "cover",
            "she",
            "mouth",
            "and",
            "giggle",
            "."
        ],
        "preceding_context_tokens": [
            [
                "Evie",
                "is",
                "home",
                "!"
            ],
            [
                "We",
                "picked",
                "her",
                "up",
                "last",
                "night",
                "."
            ],
            [
                "Big",
                "sister",
                "was",
                "so",
                "excited",
                "she",
                "could",
                "not",
                "contain",
                "herself",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "Evie",
                "be",
                "home",
                "!"
            ],
            [
                "we",
                "pick",
                "she",
                "up",
                "last",
                "night",
                "."
            ],
            [
                "big",
                "sister",
                "be",
                "so",
                "excited",
                "she",
                "could",
                "not",
                "contain",
                "herself",
                "."
            ]
        ],
        "label": "Joy"
    },
    {
        "body_part_token_idx": 12,
        "sentence_id": "425d8904-fcdc-33b2-812f-9b40310f770b",
        "tokens": [
            "She",
            "jumped",
            "up",
            "and",
            "down",
            "and",
            "clapped",
            "her",
            "hands",
            "and",
            "covered",
            "her",
            "mouth",
            "and",
            "giggled",
            "."
        ],
        "lemmatized_tokens": [
            "she",
            "jump",
            "up",
            "and",
            "down",
            "and",
            "clap",
            "she",
            "hand",
            "and",
            "cover",
            "she",
            "mouth",
            "and",
            "giggle",
            "."
        ],
        "preceding_context_tokens": [
            [
                "Evie",
                "is",
                "home",
                "!"
            ],
            [
                "We",
                "picked",
                "her",
                "up",
                "last",
                "night",
                "."
            ],
            [
                "Big",
                "sister",
                "was",
                "so",
                "excited",
                "she",
                "could",
                "not",
                "contain",
                "herself",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "Evie",
                "be",
                "home",
                "!"
            ],
            [
                "we",
                "pick",
                "she",
                "up",
                "last",
                "night",
                "."
            ],
            [
                "big",
                "sister",
                "be",
                "so",
                "excited",
                "she",
                "could",
                "not",
                "contain",
                "herself",
                "."
            ]
        ],
        "label": "Joy"
    },
    {
        "body_part_token_idx": 14,
        "sentence_id": "175ad5f9-28a8-3481-9aa4-4b310983d94f",
        "tokens": [
            "Ke",
            "$",
            "ha",
            "(",
            "The",
            "Animal",
            "Kingdom",
            ")",
            "-",
            "Dancing",
            "With",
            "Tears",
            "In",
            "My",
            "Eyes",
            "(",
            "02:56",
            ")",
            "13/73",
            "."
        ],
        "lemmatized_tokens": [
            "Ke",
            "$",
            "ha",
            "(",
            "the",
            "animal",
            "Kingdom",
            ")",
            "-",
            "dance",
            "with",
            "tear",
            "in",
            "my",
            "eye",
            "(",
            "02:56",
            ")",
            "13/73",
            "."
        ],
        "preceding_context_tokens": [
            [
                "Ke",
                "$",
                "ha",
                "(",
                "The",
                "Animal",
                "Kingdom",
                ")",
                "-",
                "Backstabber",
                "(",
                "03:17",
                ")",
                "10/73",
                "."
            ],
            [
                "Ke",
                "$",
                "ha",
                "(",
                "The",
                "Animal",
                "Kingdom",
                ")",
                "-",
                "Blind",
                "(",
                "02:55",
                ")",
                "11/73",
                "."
            ],
            [
                "Ke",
                "$",
                "ha",
                "(",
                "The",
                "Animal",
                "Kingdom",
                ")",
                "-",
                "Dinosaur",
                "(",
                "03:29",
                ")",
                "12/73",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "Ke",
                "$",
                "ha",
                "(",
                "the",
                "animal",
                "Kingdom",
                ")",
                "-",
                "backstabber",
                "(",
                "03:17",
                ")",
                "10/73",
                "."
            ],
            [
                "Ke",
                "$",
                "ha",
                "(",
                "the",
                "animal",
                "Kingdom",
                ")",
                "-",
                "blind",
                "(",
                "02:55",
                ")",
                "11/73",
                "."
            ],
            [
                "Ke",
                "$",
                "ha",
                "(",
                "the",
                "animal",
                "Kingdom",
                ")",
                "-",
                "dinosaur",
                "(",
                "03:29",
                ")",
                "12/73",
                "."
            ]
        ],
        "label": "Sadness"
    },
    {
        "body_part_token_idx": 4,
        "sentence_id": "355ffee7-3534-3c2f-aed7-ce82cc8859f0",
        "tokens": [
            "But",
            "she",
            "bit",
            "her",
            "tongue",
            ",",
            "and",
            "thanked",
            "her",
            "for",
            "the",
            "suggestion",
            "instead",
            "."
        ],
        "lemmatized_tokens": [
            "but",
            "she",
            "bite",
            "she",
            "tongue",
            ",",
            "and",
            "thank",
            "she",
            "for",
            "the",
            "suggestion",
            "instead",
            "."
        ],
        "preceding_context_tokens": [
            [
                "Let",
                "'s",
                "not",
                "sit",
                "here",
                "and",
                "mope",
                "all",
                "day.",
                "I",
                "do",
                "n't",
                "know",
                "if",
                "I",
                "feel",
                "up",
                "to",
                "going",
                "anywhere",
                ",",
                "she",
                "admitted",
                "with",
                "a",
                "small",
                "shrug",
                "."
            ],
            [
                "That",
                "'s",
                "alright",
                ",",
                "Ginny",
                "assured",
                "her",
                "."
            ],
            [
                "We",
                "can",
                "order",
                "take",
                "out",
                "and",
                "rent",
                "a",
                "bunch",
                "of",
                "films.",
                "She",
                "smiled",
                "at",
                "the",
                "suggestion",
                ",",
                "wondering",
                "when",
                "Ginny",
                "had",
                "turned",
                "so",
                "very",
                "Muggle",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "let",
                "'s",
                "not",
                "sit",
                "here",
                "and",
                "mope",
                "all",
                "day.",
                "I",
                "do",
                "not",
                "know",
                "if",
                "I",
                "feel",
                "up",
                "to",
                "go",
                "anywhere",
                ",",
                "she",
                "admit",
                "with",
                "a",
                "small",
                "shrug",
                "."
            ],
            [
                "that",
                "be",
                "alright",
                ",",
                "Ginny",
                "assure",
                "she",
                "."
            ],
            [
                "we",
                "can",
                "order",
                "take",
                "out",
                "and",
                "rent",
                "a",
                "bunch",
                "of",
                "films.",
                "she",
                "smile",
                "at",
                "the",
                "suggestion",
                ",",
                "wonder",
                "when",
                "Ginny",
                "have",
                "turn",
                "so",
                "very",
                "Muggle",
                "."
            ]
        ],
        "label": "Fear"
    },
    {
        "body_part_token_idx": 8,
        "sentence_id": "cb1f3f17-3d4a-3308-908c-21408d8506db",
        "tokens": [
            "I",
            "was",
            "crying",
            ",",
            "mascara",
            "running",
            "down",
            "my",
            "face",
            ",",
            "my",
            "eyes",
            "burning",
            "because",
            "of",
            "it",
            "."
        ],
        "lemmatized_tokens": [
            "I",
            "be",
            "cry",
            ",",
            "mascara",
            "run",
            "down",
            "my",
            "face",
            ",",
            "my",
            "eye",
            "burn",
            "because",
            "of",
            "it",
            "."
        ],
        "preceding_context_tokens": [
            [
                "The",
                "thought",
                "of",
                "losing",
                "him",
                ",",
                "was",
                "heart",
                "wrenching",
                "."
            ],
            [
                "I",
                "would",
                "rather",
                "take",
                "a",
                "thousand",
                "beatings",
                "than",
                "to",
                "never",
                "be",
                "with",
                "Quinn",
                "again",
                "."
            ],
            [
                "Quinn",
                "pulled",
                "me",
                "off",
                "the",
                "bed",
                "and",
                "pushed",
                "me",
                "against",
                "the",
                "wall",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "the",
                "thought",
                "of",
                "lose",
                "he",
                ",",
                "be",
                "heart",
                "wrench",
                "."
            ],
            [
                "I",
                "would",
                "rather",
                "take",
                "a",
                "thousand",
                "beating",
                "than",
                "to",
                "never",
                "be",
                "with",
                "Quinn",
                "again",
                "."
            ],
            [
                "Quinn",
                "pull",
                "I",
                "off",
                "the",
                "bed",
                "and",
                "push",
                "I",
                "against",
                "the",
                "wall",
                "."
            ]
        ],
        "label": "Sadness"
    },
    {
        "body_part_token_idx": 3,
        "sentence_id": "9ff8ac5c-e4b9-380c-ab92-d791265175bd",
        "tokens": [
            "I",
            "bawled",
            "my",
            "eyes",
            "out",
            "when",
            "Wait",
            "."
        ],
        "lemmatized_tokens": [
            "I",
            "bawl",
            "my",
            "eye",
            "out",
            "when",
            "wait",
            "."
        ],
        "preceding_context_tokens": [
            [
                "So",
                "there",
                ",",
                "I",
                "finished",
                "it",
                "in",
                "a",
                "day",
                "."
            ],
            [
                "MY",
                "EYES",
                "ACHE",
                "FROM",
                "THE",
                "READING",
                "AND",
                "THE",
                "CRYING",
                "."
            ],
            [
                "Gosh",
                ",",
                "what",
                "was",
                "there",
                "not",
                "to",
                "cry",
                "about",
                "???"
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "so",
                "there",
                ",",
                "I",
                "finish",
                "it",
                "in",
                "a",
                "day",
                "."
            ],
            [
                "my",
                "eyes",
                "ACHE",
                "from",
                "the",
                "reading",
                "and",
                "the",
                "crying",
                "."
            ],
            [
                "gosh",
                ",",
                "what",
                "be",
                "there",
                "not",
                "to",
                "cry",
                "about",
                "???"
            ]
        ],
        "label": "Sadness"
    },
    {
        "body_part_token_idx": 8,
        "sentence_id": "8a033c11-9d1a-38a0-9cb7-c1d1dce70e77",
        "tokens": [
            "A",
            "tear",
            "bubbled",
            "at",
            "the",
            "corner",
            "of",
            "my",
            "eye",
            ",",
            "and",
            "then",
            "slowly",
            "caressed",
            "my",
            "cheek",
            "."
        ],
        "lemmatized_tokens": [
            "a",
            "tear",
            "bubble",
            "at",
            "the",
            "corner",
            "of",
            "my",
            "eye",
            ",",
            "and",
            "then",
            "slowly",
            "caress",
            "my",
            "cheek",
            "."
        ],
        "preceding_context_tokens": [
            [
                "An",
                "immediate",
                "sense",
                "of",
                "serenity",
                "permeated",
                "my",
                "skin",
                "."
            ],
            [
                "Serenity",
                "and",
                "safety",
                "."
            ],
            [
                "I",
                "exhaled",
                "slowly",
                ",",
                "knowing",
                "I",
                "'d",
                "made",
                "the",
                "right",
                "decision",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "a",
                "immediate",
                "sense",
                "of",
                "serenity",
                "permeate",
                "my",
                "skin",
                "."
            ],
            [
                "serenity",
                "and",
                "safety",
                "."
            ],
            [
                "I",
                "exhale",
                "slowly",
                ",",
                "know",
                "I",
                "would",
                "make",
                "the",
                "right",
                "decision",
                "."
            ]
        ],
        "label": "Joy"
    },
    {
        "body_part_token_idx": 15,
        "sentence_id": "8a033c11-9d1a-38a0-9cb7-c1d1dce70e77",
        "tokens": [
            "A",
            "tear",
            "bubbled",
            "at",
            "the",
            "corner",
            "of",
            "my",
            "eye",
            ",",
            "and",
            "then",
            "slowly",
            "caressed",
            "my",
            "cheek",
            "."
        ],
        "lemmatized_tokens": [
            "a",
            "tear",
            "bubble",
            "at",
            "the",
            "corner",
            "of",
            "my",
            "eye",
            ",",
            "and",
            "then",
            "slowly",
            "caress",
            "my",
            "cheek",
            "."
        ],
        "preceding_context_tokens": [
            [
                "An",
                "immediate",
                "sense",
                "of",
                "serenity",
                "permeated",
                "my",
                "skin",
                "."
            ],
            [
                "Serenity",
                "and",
                "safety",
                "."
            ],
            [
                "I",
                "exhaled",
                "slowly",
                ",",
                "knowing",
                "I",
                "'d",
                "made",
                "the",
                "right",
                "decision",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "a",
                "immediate",
                "sense",
                "of",
                "serenity",
                "permeate",
                "my",
                "skin",
                "."
            ],
            [
                "serenity",
                "and",
                "safety",
                "."
            ],
            [
                "I",
                "exhale",
                "slowly",
                ",",
                "know",
                "I",
                "would",
                "make",
                "the",
                "right",
                "decision",
                "."
            ]
        ],
        "label": "Joy"
    },
    {
        "body_part_token_idx": 1,
        "sentence_id": "335dcee4-1be4-345a-a055-beeb97d7f9f8",
        "tokens": [
            "My",
            "hands",
            "were",
            "shaking",
            "and",
            "I",
            "could",
            "feel",
            "her",
            "hatred",
            "for",
            "me",
            ",",
            "almost",
            "radiating",
            "out",
            "of",
            "my",
            "computer",
            "screen",
            "."
        ],
        "lemmatized_tokens": [
            "my",
            "hand",
            "be",
            "shake",
            "and",
            "I",
            "could",
            "feel",
            "she",
            "hatred",
            "for",
            "I",
            ",",
            "almost",
            "radiate",
            "out",
            "of",
            "my",
            "computer",
            "screen",
            "."
        ],
        "preceding_context_tokens": [
            [
                "I",
                "cared",
                "."
            ],
            [
                "I",
                "hurt",
                "."
            ],
            [
                "I",
                "was",
                "crying",
                "when",
                "I",
                "read",
                "it",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "I",
                "care",
                "."
            ],
            [
                "I",
                "hurt",
                "."
            ],
            [
                "I",
                "be",
                "cry",
                "when",
                "I",
                "read",
                "it",
                "."
            ]
        ],
        "label": "Sadness"
    },
    {
        "body_part_token_idx": 31,
        "sentence_id": "6f14b735-3ee4-39dc-b3c7-1f022fa304fc",
        "tokens": [
            "3",
            "years",
            "ago",
            "today",
            ",",
            "some",
            "random",
            "guy",
            "walked",
            "up",
            "to",
            "me",
            "at",
            "the",
            "Hoey",
            "Crowie",
            "-LRB-",
            "aka",
            "the",
            "Crows",
            "Nest",
            "Hotel",
            ")",
            "and",
            "with",
            "a",
            "big",
            "goofy",
            "smile",
            "on",
            "his",
            "face",
            ",",
            "struck",
            "up",
            "a",
            "conversation",
            "with",
            "me",
            "."
        ],
        "lemmatized_tokens": [
            "3",
            "year",
            "ago",
            "today",
            ",",
            "some",
            "random",
            "guy",
            "walk",
            "up",
            "to",
            "I",
            "at",
            "the",
            "Hoey",
            "Crowie",
            "-LRB-",
            "aka",
            "the",
            "crow",
            "Nest",
            "Hotel",
            ")",
            "and",
            "with",
            "a",
            "big",
            "goofy",
            "smile",
            "on",
            "he",
            "face",
            ",",
            "strike",
            "up",
            "a",
            "conversation",
            "with",
            "I",
            "."
        ],
        "preceding_context_tokens": [],
        "preceding_context_lemmatized_tokens": [],
        "label": "Joy"
    },
    {
        "body_part_token_idx": 6,
        "sentence_id": "36d84bb7-127d-3066-a744-8130abe6bebf",
        "tokens": [
            "A",
            "groan",
            "of",
            "pain",
            "drew",
            "his",
            "eyes",
            "downward",
            ",",
            "where",
            "his",
            "son",
            "lay",
            "sprawled",
            "on",
            "the",
            "ground",
            "."
        ],
        "lemmatized_tokens": [
            "a",
            "groan",
            "of",
            "pain",
            "draw",
            "he",
            "eye",
            "downward",
            ",",
            "where",
            "he",
            "son",
            "lay",
            "sprawl",
            "on",
            "the",
            "ground",
            "."
        ],
        "preceding_context_tokens": [
            [
                "I",
                "would",
                "n't",
                "recommend",
                "doing",
                "that",
                "."
            ],
            [
                "Ron",
                "growled",
                "and",
                "rounded",
                "on",
                "the",
                "other",
                "man",
                ",",
                "then",
                "blinked",
                "."
            ],
            [
                "Where",
                "there",
                "had",
                "been",
                "two",
                "men",
                "``",
                "his",
                "son",
                "and",
                "the",
                "plain",
                "-",
                "faced",
                "boy",
                "``",
                "there",
                "was",
                "now",
                "only",
                "the",
                "younger",
                "one",
                ",",
                "standing",
                "free",
                "as",
                "a",
                "bird",
                "and",
                "smug",
                "as",
                "a",
                "kitten",
                "with",
                "a",
                "duckling",
                "in",
                "its",
                "jaws",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "I",
                "would",
                "not",
                "recommend",
                "do",
                "that",
                "."
            ],
            [
                "Ron",
                "growl",
                "and",
                "round",
                "on",
                "the",
                "other",
                "man",
                ",",
                "then",
                "blink",
                "."
            ],
            [
                "where",
                "there",
                "have",
                "be",
                "two",
                "man",
                "``",
                "he",
                "son",
                "and",
                "the",
                "plain",
                "-",
                "faced",
                "boy",
                "``",
                "there",
                "be",
                "now",
                "only",
                "the",
                "younger",
                "one",
                ",",
                "stand",
                "free",
                "as",
                "a",
                "bird",
                "and",
                "smug",
                "as",
                "a",
                "kitten",
                "with",
                "a",
                "duckling",
                "in",
                "its",
                "jaw",
                "."
            ]
        ],
        "label": "Sadness"
    },
    {
        "body_part_token_idx": 16,
        "sentence_id": "742eeb5f-b9fd-3386-86c6-c4f304a886b7",
        "tokens": [
            "At",
            "these",
            "words",
            "Yoseob",
            "turned",
            "to",
            "look",
            "at",
            "him",
            "and",
            "saw",
            "a",
            "strange",
            "expression",
            "on",
            "his",
            "face",
            "."
        ],
        "lemmatized_tokens": [
            "at",
            "these",
            "word",
            "Yoseob",
            "turn",
            "to",
            "look",
            "at",
            "he",
            "and",
            "see",
            "a",
            "strange",
            "expression",
            "on",
            "he",
            "face",
            "."
        ],
        "preceding_context_tokens": [
            [
                "I",
                "mean",
                "what",
                "was",
                "she",
                "doing",
                "here",
                ",",
                "you",
                "'ve",
                "never",
                "talked",
                "about",
                "her",
                "before",
                "...",
                "'",
                "Yoseob",
                "added",
                "shyly",
                "."
            ],
            [
                "`",
                "Ah",
                "!"
            ],
            [
                "Well",
                "...",
                "My",
                "parents",
                "are",
                "kind",
                "of",
                "...",
                "worried",
                "'",
                "Doojoon",
                "began",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "I",
                "mean",
                "what",
                "be",
                "she",
                "do",
                "here",
                ",",
                "you",
                "have",
                "never",
                "talk",
                "about",
                "she",
                "before",
                "...",
                "'",
                "Yoseob",
                "add",
                "shyly",
                "."
            ],
            [
                "`",
                "ah",
                "!"
            ],
            [
                "well",
                "...",
                "my",
                "parent",
                "be",
                "kind",
                "of",
                "...",
                "worry",
                "'",
                "Doojoon",
                "begin",
                "."
            ]
        ],
        "label": "Fear"
    },
    {
        "body_part_token_idx": 34,
        "sentence_id": "f5768d42-c848-3dce-8907-101dd9b048be",
        "tokens": [
            "So",
            "instead",
            ",",
            "I",
            "locked",
            "myself",
            "up",
            "in",
            "my",
            "room",
            ",",
            "put",
            "on",
            "Lisa",
            "Loeb",
            ",",
            "and",
            "as",
            "she",
            "sang",
            "the",
            "words",
            "Bring",
            "me",
            "wild",
            "plums",
            ",",
            "wild",
            "plums",
            "and",
            "agrimony",
            "I",
            "close",
            "my",
            "eyes",
            "and",
            "took",
            "a",
            "huge",
            "bite",
            "of",
            "the",
            "smooth",
            "plum",
            "in",
            "my",
            "hand",
            "."
        ],
        "lemmatized_tokens": [
            "so",
            "instead",
            ",",
            "I",
            "lock",
            "myself",
            "up",
            "in",
            "my",
            "room",
            ",",
            "put",
            "on",
            "Lisa",
            "Loeb",
            ",",
            "and",
            "as",
            "she",
            "sing",
            "the",
            "word",
            "bring",
            "I",
            "wild",
            "plum",
            ",",
            "wild",
            "plum",
            "and",
            "agrimony",
            "I",
            "close",
            "my",
            "eye",
            "and",
            "take",
            "a",
            "huge",
            "bite",
            "of",
            "the",
            "smooth",
            "plum",
            "in",
            "my",
            "hand",
            "."
        ],
        "preceding_context_tokens": [
            [
                "They",
                "were",
                "passing",
                "out",
                "sample",
                "slices",
                "too",
                ",",
                "but",
                "I",
                "just",
                "went",
                "straight",
                "for",
                "the",
                "lovely",
                "purplish",
                "fruits",
                "and",
                "bought",
                "eight",
                "of",
                "them",
                "using",
                "what",
                "'s",
                "left",
                "of",
                "my",
                "allowance",
                "."
            ],
            [
                "I",
                "was",
                "very",
                "much",
                "aware",
                ",",
                "of",
                "course",
                ",",
                "that",
                "these",
                "plums",
                "will",
                "never",
                "be",
                "able",
                "to",
                "measure",
                "up",
                "to",
                "plums",
                "eaten",
                "straight",
                "from",
                "being",
                "picked",
                "."
            ],
            [
                "But",
                "I",
                "understand",
                "that",
                "I",
                "would",
                "probably",
                "have",
                "to",
                "move",
                "to",
                "another",
                "country",
                "if",
                "I",
                "want",
                "to",
                "be",
                "able",
                "to",
                "do",
                "that",
                ",",
                "so",
                "I",
                "refuse",
                "to",
                "complain",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "they",
                "be",
                "pass",
                "out",
                "sample",
                "slice",
                "too",
                ",",
                "but",
                "I",
                "just",
                "go",
                "straight",
                "for",
                "the",
                "lovely",
                "purplish",
                "fruit",
                "and",
                "buy",
                "eight",
                "of",
                "they",
                "use",
                "what",
                "be",
                "leave",
                "of",
                "my",
                "allowance",
                "."
            ],
            [
                "I",
                "be",
                "very",
                "much",
                "aware",
                ",",
                "of",
                "course",
                ",",
                "that",
                "these",
                "plum",
                "will",
                "never",
                "be",
                "able",
                "to",
                "measure",
                "up",
                "to",
                "plum",
                "eat",
                "straight",
                "from",
                "be",
                "pick",
                "."
            ],
            [
                "but",
                "I",
                "understand",
                "that",
                "I",
                "would",
                "probably",
                "have",
                "to",
                "move",
                "to",
                "another",
                "country",
                "if",
                "I",
                "want",
                "to",
                "be",
                "able",
                "to",
                "do",
                "that",
                ",",
                "so",
                "I",
                "refuse",
                "to",
                "complain",
                "."
            ]
        ],
        "label": "Joy"
    },
    {
        "body_part_token_idx": 14,
        "sentence_id": "65ee4908-5031-3cd1-b89f-ce8273b7bca7",
        "tokens": [
            "The",
            "branch",
            "soon",
            "breaks",
            "and",
            "he",
            "falls",
            "from",
            "the",
            "tree",
            ",",
            "Ohno",
            "squeezing",
            "his",
            "eyes",
            "tightly",
            "shut",
            ",",
            "anticipating",
            "the",
            "not",
            "-",
            "so",
            "-",
            "smooth",
            "landing",
            "."
        ],
        "lemmatized_tokens": [
            "the",
            "branch",
            "soon",
            "break",
            "and",
            "he",
            "fall",
            "from",
            "the",
            "tree",
            ",",
            "Ohno",
            "squeeze",
            "he",
            "eye",
            "tightly",
            "shut",
            ",",
            "anticipate",
            "the",
            "not",
            "-",
            "so",
            "-",
            "smooth",
            "landing",
            "."
        ],
        "preceding_context_tokens": [
            [
                "-LRB-",
                "Ohno",
                "figures",
                "there",
                "are",
                "some",
                "feelings",
                "that",
                "just",
                "never",
                "change",
                ",",
                "despite",
                "gender",
                ")",
                "."
            ],
            [
                "A",
                "branch",
                "cracks",
                "above",
                "them",
                "and",
                "Ohno",
                "glances",
                "up",
                "."
            ],
            [
                "Jun",
                "'s",
                "face",
                "turns",
                "bright",
                "red",
                "as",
                "he",
                "flaps",
                "his",
                "butterfly",
                "wings",
                "madly",
                ",",
                "trying",
                "to",
                "fly",
                "away",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "-LRB-",
                "Ohno",
                "figure",
                "there",
                "be",
                "some",
                "feeling",
                "that",
                "just",
                "never",
                "change",
                ",",
                "despite",
                "gender",
                ")",
                "."
            ],
            [
                "a",
                "branch",
                "crack",
                "above",
                "they",
                "and",
                "ohno",
                "glance",
                "up",
                "."
            ],
            [
                "Jun",
                "'s",
                "face",
                "turn",
                "bright",
                "red",
                "as",
                "he",
                "flap",
                "he",
                "butterfly",
                "wing",
                "madly",
                ",",
                "try",
                "to",
                "fly",
                "away",
                "."
            ]
        ],
        "label": "Fear"
    },
    {
        "body_part_token_idx": 20,
        "sentence_id": "4f6149b4-d4e2-3490-9429-c85db7ece9a3",
        "tokens": [
            "She",
            "said",
            "she",
            "agree",
            "with",
            "me",
            "but",
            "did",
            "n't",
            "know",
            "how",
            "to",
            "leave",
            "...",
            "To",
            "that",
            ",",
            "I",
            "shrugged",
            "my",
            "shoulders",
            ",",
            "shit",
            "I",
            "know",
            "how",
            ",",
            "pack",
            "your",
            "shit",
            "and",
            "leave",
            "...",
            "I",
            "mean",
            ",",
            "you",
            "know",
            "?"
        ],
        "lemmatized_tokens": [
            "she",
            "say",
            "she",
            "agree",
            "with",
            "I",
            "but",
            "do",
            "not",
            "know",
            "how",
            "to",
            "leave",
            "...",
            "to",
            "that",
            ",",
            "I",
            "shrug",
            "my",
            "shoulder",
            ",",
            "shit",
            "I",
            "know",
            "how",
            ",",
            "pack",
            "you",
            "shit",
            "and",
            "leave",
            "...",
            "I",
            "mean",
            ",",
            "you",
            "know",
            "?"
        ],
        "preceding_context_tokens": [
            [
                "So",
                "what",
                "she",
                "is",
                "older",
                "?"
            ],
            [
                "Does",
                "n't",
                "make",
                "it",
                "easier",
                "...",
                "but",
                "then",
                "I",
                "was",
                "like",
                "``",
                "ok",
                "mina",
                ",",
                "stop",
                "being",
                "a",
                "bitch",
                "...",
                "''",
                "So",
                "I",
                "said",
                "something",
                "like",
                ",",
                "``",
                "listen",
                ",",
                "you",
                "are",
                "in",
                "a",
                "tough",
                "situation",
                "."
            ],
            [
                "I",
                "do",
                "n't",
                "think",
                "that",
                "relationship",
                "is",
                "working",
                "for",
                "you",
                "...",
                "and",
                "I",
                "would",
                "n't",
                "be",
                "with",
                "someone",
                "like",
                "her",
                "...",
                "I",
                "am",
                "just",
                "saying",
                "maybe",
                "it",
                "'s",
                "not",
                "the",
                "right",
                "thing",
                "for",
                "you",
                "right",
                "now",
                "...",
                "or",
                "ever",
                "''",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "so",
                "what",
                "she",
                "be",
                "older",
                "?"
            ],
            [
                "do",
                "not",
                "make",
                "it",
                "easier",
                "...",
                "but",
                "then",
                "I",
                "be",
                "like",
                "``",
                "ok",
                "mina",
                ",",
                "stop",
                "be",
                "a",
                "bitch",
                "...",
                "''",
                "so",
                "I",
                "say",
                "something",
                "like",
                ",",
                "``",
                "listen",
                ",",
                "you",
                "be",
                "in",
                "a",
                "tough",
                "situation",
                "."
            ],
            [
                "I",
                "do",
                "not",
                "think",
                "that",
                "relationship",
                "be",
                "work",
                "for",
                "you",
                "...",
                "and",
                "I",
                "would",
                "not",
                "be",
                "with",
                "someone",
                "like",
                "she",
                "...",
                "I",
                "be",
                "just",
                "say",
                "maybe",
                "it",
                "be",
                "not",
                "the",
                "right",
                "thing",
                "for",
                "you",
                "right",
                "now",
                "...",
                "or",
                "ever",
                "''",
                "."
            ]
        ],
        "label": "Disgust"
    },
    {
        "body_part_token_idx": 1,
        "sentence_id": "941b512e-d12c-3824-8123-735b71ff7032",
        "tokens": [
            "His",
            "face",
            "kinda",
            "changed",
            ",",
            "from",
            "sad",
            "to",
            "confused",
            "."
        ],
        "lemmatized_tokens": [
            "he",
            "face",
            "kinda",
            "change",
            ",",
            "from",
            "sad",
            "to",
            "confused",
            "."
        ],
        "preceding_context_tokens": [
            [
                "``",
                "Pero",
                "I",
                "should",
                "'ve",
                "known",
                ",",
                "friends",
                "tayo",
                ",",
                "but",
                "hindi",
                "ko",
                "alam",
                "when",
                "is",
                "your",
                "birthday",
                "."
            ],
            [
                "``",
                "Nah",
                ",",
                "kaya",
                "nga",
                "I",
                "invited",
                "you",
                "here",
                "eh",
                ",",
                "para",
                "I",
                "'m",
                "not",
                "alone",
                "naman",
                "on",
                "this",
                "special",
                "day",
                "diba",
                "?!"
            ],
            [
                "At",
                "least",
                "now",
                ",",
                "I",
                "'m",
                "with",
                "a",
                "special",
                "person",
                "''",
                "Mejo",
                "nagulat",
                "ako",
                "to",
                "what",
                "he",
                "said",
                ",",
                "but",
                "I",
                "have",
                "to",
                "react",
                ",",
                "so",
                "I",
                "said",
                "``",
                "Oo",
                "naman",
                ",",
                "bestfriend",
                "tayo",
                "eh",
                ",",
                "edi",
                "special",
                "!",
                "''"
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "``",
                "Pero",
                "I",
                "should",
                "have",
                "know",
                ",",
                "friend",
                "tayo",
                ",",
                "but",
                "hindi",
                "ko",
                "alam",
                "when",
                "be",
                "you",
                "birthday",
                "."
            ],
            [
                "``",
                "Nah",
                ",",
                "kaya",
                "nga",
                "I",
                "invite",
                "you",
                "here",
                "eh",
                ",",
                "para",
                "I",
                "be",
                "not",
                "alone",
                "naman",
                "on",
                "this",
                "special",
                "day",
                "diba",
                "?!"
            ],
            [
                "at",
                "least",
                "now",
                ",",
                "I",
                "be",
                "with",
                "a",
                "special",
                "person",
                "''",
                "Mejo",
                "nagulat",
                "ako",
                "to",
                "what",
                "he",
                "say",
                ",",
                "but",
                "I",
                "have",
                "to",
                "react",
                ",",
                "so",
                "I",
                "say",
                "``",
                "Oo",
                "naman",
                ",",
                "bestfriend",
                "tayo",
                "eh",
                ",",
                "edi",
                "special",
                "!",
                "''"
            ]
        ],
        "label": "Surprise"
    },
    {
        "body_part_token_idx": 13,
        "sentence_id": "c4d1a426-a38a-36db-a02b-ede51b175a1a",
        "tokens": [
            "He",
            "raises",
            "an",
            "eyebrow",
            "at",
            "Yesung",
            ",",
            "but",
            "the",
            "younger",
            "simply",
            "shrugs",
            "his",
            "shoulders",
            "before",
            "moving",
            "away",
            "to",
            "the",
            "kitchen",
            "."
        ],
        "lemmatized_tokens": [
            "he",
            "raise",
            "a",
            "eyebrow",
            "at",
            "Yesung",
            ",",
            "but",
            "the",
            "younger",
            "simply",
            "shrug",
            "he",
            "shoulder",
            "before",
            "move",
            "away",
            "to",
            "the",
            "kitchen",
            "."
        ],
        "preceding_context_tokens": [
            [
                "Yesung",
                "got",
                "out",
                "of",
                "his",
                "room",
                ",",
                "the",
                "noise",
                "level",
                "serving",
                "as",
                "his",
                "wake",
                "-",
                "up",
                "call",
                ",",
                "and",
                "he",
                "asks",
                "what",
                "food",
                "they",
                "brought",
                "."
            ],
            [
                "Just",
                "then",
                "Heechul",
                "was",
                "in",
                "front",
                "of",
                "him",
                ",",
                "and",
                "my",
                "entire",
                "body",
                "became",
                "frigid",
                "with",
                "dread",
                "."
            ],
            [
                "He",
                "knows",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "Yesung",
                "get",
                "out",
                "of",
                "he",
                "room",
                ",",
                "the",
                "noise",
                "level",
                "serve",
                "as",
                "he",
                "wake",
                "-",
                "up",
                "call",
                ",",
                "and",
                "he",
                "ask",
                "what",
                "food",
                "they",
                "bring",
                "."
            ],
            [
                "just",
                "then",
                "Heechul",
                "be",
                "in",
                "front",
                "of",
                "he",
                ",",
                "and",
                "my",
                "entire",
                "body",
                "become",
                "frigid",
                "with",
                "dread",
                "."
            ],
            [
                "he",
                "know",
                "."
            ]
        ],
        "label": "Disgust"
    },
    {
        "body_part_token_idx": 13,
        "sentence_id": "fa06e72f-549b-3504-8dac-d6090fc99bb1",
        "tokens": [
            "She",
            "knows",
            "what",
            "that",
            "means",
            "and",
            "it",
            "makes",
            "her",
            "pulse",
            "race",
            "and",
            "her",
            "cheeks",
            "warm",
            "up",
            "."
        ],
        "lemmatized_tokens": [
            "she",
            "know",
            "what",
            "that",
            "mean",
            "and",
            "it",
            "make",
            "she",
            "pulse",
            "race",
            "and",
            "she",
            "cheek",
            "warm",
            "up",
            "."
        ],
        "preceding_context_tokens": [
            [
                "She",
                "rolls",
                "her",
                "eyes",
                "."
            ],
            [
                "``",
                "I",
                "was",
                "just",
                "thinking",
                "about",
                "you",
                ".",
                "''"
            ],
            [
                "Oh",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "she",
                "roll",
                "she",
                "eye",
                "."
            ],
            [
                "``",
                "I",
                "be",
                "just",
                "think",
                "about",
                "you",
                ".",
                "''"
            ],
            [
                "oh",
                "."
            ]
        ],
        "label": "Surprise"
    },
    {
        "body_part_token_idx": 38,
        "sentence_id": "f7de0f23-e57e-3bcf-b62a-a31052d018ad",
        "tokens": [
            "After",
            "telling",
            "here",
            "I",
            "'m",
            "trying",
            "to",
            "withdrawal",
            "money",
            "from",
            "a",
            "Canadian",
            "account",
            "three",
            "times",
            "and",
            "then",
            "showing",
            "her",
            "my",
            "card",
            "she",
            "simply",
            "said",
            "``",
            "This",
            "card",
            "is",
            "not",
            "for",
            "this",
            "bank",
            "''",
            "and",
            "I",
            "just",
            "shook",
            "my",
            "head",
            "and",
            "laughed",
            "and",
            "walked",
            "away",
            "."
        ],
        "lemmatized_tokens": [
            "after",
            "tell",
            "here",
            "I",
            "be",
            "try",
            "to",
            "withdrawal",
            "money",
            "from",
            "a",
            "canadian",
            "account",
            "three",
            "time",
            "and",
            "then",
            "show",
            "she",
            "my",
            "card",
            "she",
            "simply",
            "say",
            "``",
            "this",
            "card",
            "be",
            "not",
            "for",
            "this",
            "bank",
            "''",
            "and",
            "I",
            "just",
            "shake",
            "my",
            "head",
            "and",
            "laugh",
            "and",
            "walk",
            "away",
            "."
        ],
        "preceding_context_tokens": [
            [
                "I",
                "get",
                "my",
                "card",
                "back",
                "and",
                "go",
                "try",
                "another",
                "machine",
                ",",
                "this",
                "time",
                "it",
                "gives",
                "me",
                "a",
                "message",
                "saying",
                "can",
                "not",
                "process",
                "transaction",
                "."
            ],
            [
                "I",
                "thought",
                "about",
                "it",
                "some",
                "more",
                "and",
                "knew",
                "I",
                "had",
                "money",
                "in",
                "there",
                "so",
                "I",
                "went",
                "up",
                "to",
                "the",
                "teller",
                "and",
                "talked",
                "to",
                "them",
                "."
            ],
            [
                "She",
                "was",
                "a",
                "moron",
                "and",
                "did",
                "n't",
                "understand",
                "what",
                "I",
                "was",
                "saying",
                "at",
                "all",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "I",
                "get",
                "my",
                "card",
                "back",
                "and",
                "go",
                "try",
                "another",
                "machine",
                ",",
                "this",
                "time",
                "it",
                "give",
                "I",
                "a",
                "message",
                "say",
                "can",
                "not",
                "process",
                "transaction",
                "."
            ],
            [
                "I",
                "think",
                "about",
                "it",
                "some",
                "more",
                "and",
                "know",
                "I",
                "have",
                "money",
                "in",
                "there",
                "so",
                "I",
                "go",
                "up",
                "to",
                "the",
                "teller",
                "and",
                "talk",
                "to",
                "they",
                "."
            ],
            [
                "she",
                "be",
                "a",
                "moron",
                "and",
                "do",
                "not",
                "understand",
                "what",
                "I",
                "be",
                "say",
                "at",
                "all",
                "."
            ]
        ],
        "label": "Disgust"
    },
    {
        "body_part_token_idx": 18,
        "sentence_id": "e2b169c1-d401-360d-9a30-ac0cb3e8cbc3",
        "tokens": [
            "Peering",
            "out",
            "her",
            "window",
            "onto",
            "the",
            "foggy",
            "street",
            "below",
            ",",
            "she",
            "felt",
            "a",
            "subtle",
            "chill",
            "shoot",
            "down",
            "her",
            "spine",
            ",",
            "through",
            "her",
            "fingers",
            "and",
            "toes",
            "."
        ],
        "lemmatized_tokens": [
            "peer",
            "out",
            "she",
            "window",
            "onto",
            "the",
            "foggy",
            "street",
            "below",
            ",",
            "she",
            "feel",
            "a",
            "subtle",
            "chill",
            "shoot",
            "down",
            "she",
            "spine",
            ",",
            "through",
            "she",
            "finger",
            "and",
            "toe",
            "."
        ],
        "preceding_context_tokens": [
            [
                "Title",
                ":",
                "UntitledShe",
                "awoke",
                "from",
                "her",
                "blissful",
                "slumber",
                "on",
                "a",
                "cold",
                "October",
                "night",
                ",",
                "a",
                "night",
                "that",
                "would",
                "turn",
                "out",
                "to",
                "be",
                "one",
                "she",
                "would",
                "not",
                "soon",
                "forget",
                "."
            ],
            [
                "In",
                "a",
                "trancelike",
                "state",
                ",",
                "she",
                "crept",
                "to",
                "the",
                "window",
                "without",
                "even",
                "knowing",
                "why",
                "."
            ],
            [
                "She",
                "felt",
                "herself",
                "strangely",
                "compelled",
                "to",
                "do",
                "so",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "title",
                ":",
                "UntitledShe",
                "awake",
                "from",
                "she",
                "blissful",
                "slumber",
                "on",
                "a",
                "cold",
                "October",
                "night",
                ",",
                "a",
                "night",
                "that",
                "would",
                "turn",
                "out",
                "to",
                "be",
                "one",
                "she",
                "would",
                "not",
                "soon",
                "forget",
                "."
            ],
            [
                "in",
                "a",
                "trancelike",
                "state",
                ",",
                "she",
                "creep",
                "to",
                "the",
                "window",
                "without",
                "even",
                "know",
                "why",
                "."
            ],
            [
                "she",
                "feel",
                "herself",
                "strangely",
                "compel",
                "to",
                "do",
                "so",
                "."
            ]
        ],
        "label": "Fear"
    },
    {
        "body_part_token_idx": 22,
        "sentence_id": "e2b169c1-d401-360d-9a30-ac0cb3e8cbc3",
        "tokens": [
            "Peering",
            "out",
            "her",
            "window",
            "onto",
            "the",
            "foggy",
            "street",
            "below",
            ",",
            "she",
            "felt",
            "a",
            "subtle",
            "chill",
            "shoot",
            "down",
            "her",
            "spine",
            ",",
            "through",
            "her",
            "fingers",
            "and",
            "toes",
            "."
        ],
        "lemmatized_tokens": [
            "peer",
            "out",
            "she",
            "window",
            "onto",
            "the",
            "foggy",
            "street",
            "below",
            ",",
            "she",
            "feel",
            "a",
            "subtle",
            "chill",
            "shoot",
            "down",
            "she",
            "spine",
            ",",
            "through",
            "she",
            "finger",
            "and",
            "toe",
            "."
        ],
        "preceding_context_tokens": [
            [
                "Title",
                ":",
                "UntitledShe",
                "awoke",
                "from",
                "her",
                "blissful",
                "slumber",
                "on",
                "a",
                "cold",
                "October",
                "night",
                ",",
                "a",
                "night",
                "that",
                "would",
                "turn",
                "out",
                "to",
                "be",
                "one",
                "she",
                "would",
                "not",
                "soon",
                "forget",
                "."
            ],
            [
                "In",
                "a",
                "trancelike",
                "state",
                ",",
                "she",
                "crept",
                "to",
                "the",
                "window",
                "without",
                "even",
                "knowing",
                "why",
                "."
            ],
            [
                "She",
                "felt",
                "herself",
                "strangely",
                "compelled",
                "to",
                "do",
                "so",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "title",
                ":",
                "UntitledShe",
                "awake",
                "from",
                "she",
                "blissful",
                "slumber",
                "on",
                "a",
                "cold",
                "October",
                "night",
                ",",
                "a",
                "night",
                "that",
                "would",
                "turn",
                "out",
                "to",
                "be",
                "one",
                "she",
                "would",
                "not",
                "soon",
                "forget",
                "."
            ],
            [
                "in",
                "a",
                "trancelike",
                "state",
                ",",
                "she",
                "creep",
                "to",
                "the",
                "window",
                "without",
                "even",
                "know",
                "why",
                "."
            ],
            [
                "she",
                "feel",
                "herself",
                "strangely",
                "compel",
                "to",
                "do",
                "so",
                "."
            ]
        ],
        "label": "Fear"
    },
    {
        "body_part_token_idx": 6,
        "sentence_id": "bcd35a71-e073-3e45-96f8-62f913a2a4cf",
        "tokens": [
            "It",
            "was",
            "just",
            "so",
            "$",
            "his",
            "heart",
            "pounded",
            "wildly",
            "in",
            "his",
            "chest",
            "and",
            "retrained",
            "his",
            "wish",
            "to",
            "flee",
            ",",
            "because",
            "he",
            "was",
            "just",
            "so",
            "confused",
            "it",
            "was",
            "n't",
            "fair",
            "and",
            "Arthur",
            "knew",
            "nothing",
            "."
        ],
        "lemmatized_tokens": [
            "it",
            "be",
            "just",
            "so",
            "$",
            "he",
            "heart",
            "pound",
            "wildly",
            "in",
            "he",
            "chest",
            "and",
            "retrain",
            "he",
            "wish",
            "to",
            "flee",
            ",",
            "because",
            "he",
            "be",
            "just",
            "so",
            "confused",
            "it",
            "be",
            "not",
            "fair",
            "and",
            "Arthur",
            "know",
            "nothing",
            "."
        ],
        "preceding_context_tokens": [
            [
                "He",
                "lifted",
                "his",
                "other",
                "hand",
                "and",
                "came",
                "in",
                "contact",
                "with",
                "Merlin",
                "'s",
                "cheekbone",
                "."
            ],
            [
                "He",
                "felt",
                "his",
                "cheekbones",
                ",",
                "then",
                "carefully",
                "traced",
                "the",
                "lines",
                "of",
                "his",
                "brows",
                "and",
                "then",
                "down",
                "his",
                "nose",
                "to",
                "its",
                "tip",
                "and",
                "down",
                "its",
                "sides",
                "to",
                "the",
                "corners",
                "of",
                "his",
                "lips",
                "."
            ],
            [
                "With",
                "careful",
                "and",
                "gentle",
                "fingers",
                "he",
                "traced",
                "the",
                "outline",
                "of",
                "his",
                "lips",
                "and",
                "Merlin",
                "barely",
                "suppressed",
                "the",
                "delicious",
                "shudder",
                "that",
                "went",
                "through",
                "him",
                ",",
                "the",
                "sparks",
                "flying",
                "off",
                "everywhere",
                ",",
                "by",
                "Arthur",
                "'s",
                "touch",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "he",
                "lift",
                "he",
                "other",
                "hand",
                "and",
                "come",
                "in",
                "contact",
                "with",
                "Merlin",
                "'s",
                "cheekbone",
                "."
            ],
            [
                "he",
                "feel",
                "he",
                "cheekbone",
                ",",
                "then",
                "carefully",
                "trace",
                "the",
                "line",
                "of",
                "he",
                "brow",
                "and",
                "then",
                "down",
                "he",
                "nose",
                "to",
                "its",
                "tip",
                "and",
                "down",
                "its",
                "side",
                "to",
                "the",
                "corner",
                "of",
                "he",
                "lip",
                "."
            ],
            [
                "with",
                "careful",
                "and",
                "gentle",
                "finger",
                "he",
                "trace",
                "the",
                "outline",
                "of",
                "he",
                "lip",
                "and",
                "Merlin",
                "barely",
                "suppress",
                "the",
                "delicious",
                "shudder",
                "that",
                "go",
                "through",
                "he",
                ",",
                "the",
                "spark",
                "fly",
                "off",
                "everywhere",
                ",",
                "by",
                "Arthur",
                "'s",
                "touch",
                "."
            ]
        ],
        "label": "Fear"
    },
    {
        "body_part_token_idx": 11,
        "sentence_id": "bcd35a71-e073-3e45-96f8-62f913a2a4cf",
        "tokens": [
            "It",
            "was",
            "just",
            "so",
            "$",
            "his",
            "heart",
            "pounded",
            "wildly",
            "in",
            "his",
            "chest",
            "and",
            "retrained",
            "his",
            "wish",
            "to",
            "flee",
            ",",
            "because",
            "he",
            "was",
            "just",
            "so",
            "confused",
            "it",
            "was",
            "n't",
            "fair",
            "and",
            "Arthur",
            "knew",
            "nothing",
            "."
        ],
        "lemmatized_tokens": [
            "it",
            "be",
            "just",
            "so",
            "$",
            "he",
            "heart",
            "pound",
            "wildly",
            "in",
            "he",
            "chest",
            "and",
            "retrain",
            "he",
            "wish",
            "to",
            "flee",
            ",",
            "because",
            "he",
            "be",
            "just",
            "so",
            "confused",
            "it",
            "be",
            "not",
            "fair",
            "and",
            "Arthur",
            "know",
            "nothing",
            "."
        ],
        "preceding_context_tokens": [
            [
                "He",
                "lifted",
                "his",
                "other",
                "hand",
                "and",
                "came",
                "in",
                "contact",
                "with",
                "Merlin",
                "'s",
                "cheekbone",
                "."
            ],
            [
                "He",
                "felt",
                "his",
                "cheekbones",
                ",",
                "then",
                "carefully",
                "traced",
                "the",
                "lines",
                "of",
                "his",
                "brows",
                "and",
                "then",
                "down",
                "his",
                "nose",
                "to",
                "its",
                "tip",
                "and",
                "down",
                "its",
                "sides",
                "to",
                "the",
                "corners",
                "of",
                "his",
                "lips",
                "."
            ],
            [
                "With",
                "careful",
                "and",
                "gentle",
                "fingers",
                "he",
                "traced",
                "the",
                "outline",
                "of",
                "his",
                "lips",
                "and",
                "Merlin",
                "barely",
                "suppressed",
                "the",
                "delicious",
                "shudder",
                "that",
                "went",
                "through",
                "him",
                ",",
                "the",
                "sparks",
                "flying",
                "off",
                "everywhere",
                ",",
                "by",
                "Arthur",
                "'s",
                "touch",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "he",
                "lift",
                "he",
                "other",
                "hand",
                "and",
                "come",
                "in",
                "contact",
                "with",
                "Merlin",
                "'s",
                "cheekbone",
                "."
            ],
            [
                "he",
                "feel",
                "he",
                "cheekbone",
                ",",
                "then",
                "carefully",
                "trace",
                "the",
                "line",
                "of",
                "he",
                "brow",
                "and",
                "then",
                "down",
                "he",
                "nose",
                "to",
                "its",
                "tip",
                "and",
                "down",
                "its",
                "side",
                "to",
                "the",
                "corner",
                "of",
                "he",
                "lip",
                "."
            ],
            [
                "with",
                "careful",
                "and",
                "gentle",
                "finger",
                "he",
                "trace",
                "the",
                "outline",
                "of",
                "he",
                "lip",
                "and",
                "Merlin",
                "barely",
                "suppress",
                "the",
                "delicious",
                "shudder",
                "that",
                "go",
                "through",
                "he",
                ",",
                "the",
                "spark",
                "fly",
                "off",
                "everywhere",
                ",",
                "by",
                "Arthur",
                "'s",
                "touch",
                "."
            ]
        ],
        "label": "Fear"
    },
    {
        "body_part_token_idx": 7,
        "sentence_id": "33e7de9f-97f7-3abb-8352-46aed59be720",
        "tokens": [
            "I",
            "became",
            "terrified",
            "and",
            "fell",
            "to",
            "my",
            "knees",
            ",",
            "realizing",
            "that",
            "I",
            "was",
            "in",
            "the",
            "presence",
            "of",
            "angels",
            "."
        ],
        "lemmatized_tokens": [
            "I",
            "become",
            "terrified",
            "and",
            "fall",
            "to",
            "my",
            "knee",
            ",",
            "realize",
            "that",
            "I",
            "be",
            "in",
            "the",
            "presence",
            "of",
            "angel",
            "."
        ],
        "preceding_context_tokens": [
            [
                "I",
                "whirled",
                "around",
                ",",
                "thinking",
                "I",
                "was",
                "hearing",
                "things",
                "in",
                "my",
                "shock",
                "."
            ],
            [
                "Wiping",
                "the",
                "sweat",
                "and",
                "smoke",
                "from",
                "my",
                "eyes",
                ",",
                "I",
                "saw",
                "two",
                "beings",
                "-",
                "men",
                ",",
                "I",
                "think",
                ",",
                "but",
                "these",
                "two",
                "had",
                "some",
                "sort",
                "of",
                "aura",
                "around",
                "them",
                "-LRB-",
                "for",
                "want",
                "of",
                "a",
                "better",
                "word",
                ")",
                ",",
                "like",
                "they",
                "were",
                "glowing",
                "."
            ],
            [
                "It",
                "was",
                "then",
                "that",
                "I",
                "realized",
                "that",
                "I",
                "had",
                "not",
                "spoken",
                "out",
                "loud",
                ",",
                "yet",
                "they",
                "answered",
                "me",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "I",
                "whirl",
                "around",
                ",",
                "think",
                "I",
                "be",
                "hear",
                "thing",
                "in",
                "my",
                "shock",
                "."
            ],
            [
                "wipe",
                "the",
                "sweat",
                "and",
                "smoke",
                "from",
                "my",
                "eye",
                ",",
                "I",
                "see",
                "two",
                "being",
                "-",
                "man",
                ",",
                "I",
                "think",
                ",",
                "but",
                "these",
                "two",
                "have",
                "some",
                "sort",
                "of",
                "aura",
                "around",
                "they",
                "-lrb-_VBP",
                "for",
                "want",
                "of",
                "a",
                "better",
                "word",
                ")",
                ",",
                "like",
                "they",
                "be",
                "glow",
                "."
            ],
            [
                "it",
                "be",
                "then",
                "that",
                "I",
                "realize",
                "that",
                "I",
                "have",
                "not",
                "speak",
                "out",
                "loud",
                ",",
                "yet",
                "they",
                "answer",
                "I",
                "."
            ]
        ],
        "label": "Fear"
    },
    {
        "body_part_token_idx": 9,
        "sentence_id": "cd00a0e1-e19d-389f-ba29-6f3b290680be",
        "tokens": [
            "Maybe",
            "they",
            "saw",
            "the",
            "look",
            "of",
            "ecstasy",
            "on",
            "my",
            "face",
            "as",
            "I",
            "sped",
            "up",
            "and",
            "slowed",
            "down",
            "with",
            "twiddling",
            "precision",
            "."
        ],
        "lemmatized_tokens": [
            "maybe",
            "they",
            "see",
            "the",
            "look",
            "of",
            "ecstasy",
            "on",
            "my",
            "face",
            "as",
            "I",
            "speed",
            "up",
            "and",
            "slow",
            "down",
            "with",
            "twiddle",
            "precision",
            "."
        ],
        "preceding_context_tokens": [
            [
                "Over",
                "the",
                "years",
                ",",
                "the",
                "twiddler",
                "evolved",
                "from",
                "grass",
                "to",
                "Iris",
                "leaves",
                ",",
                "Iris",
                "leaves",
                "to",
                "strips",
                "of",
                "plastic",
                ",",
                "strips",
                "of",
                "plastic",
                "to",
                "Christmas",
                "tinsel",
                "and",
                "finally",
                "to",
                "rubber",
                "bands",
                "."
            ],
            [
                "Rubber",
                "bands",
                ",",
                "of",
                "a",
                "certain",
                "thickness",
                ",",
                "were",
                "my",
                "preference",
                "for",
                "many",
                "years",
                "until",
                "I",
                "finally",
                "forced",
                "myself",
                "to",
                "kick",
                "the",
                "habit",
                "well",
                "into",
                "my",
                "twenties",
                "."
            ],
            [
                "Of",
                "course",
                ",",
                "my",
                "twiddling",
                "habit",
                "did",
                "not",
                "go",
                "unnoticed",
                "and",
                "believe",
                "it",
                "or",
                "not",
                "other",
                "kids",
                "at",
                "my",
                "school",
                "wanted",
                "in",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "over",
                "the",
                "year",
                ",",
                "the",
                "twiddler",
                "evolve",
                "from",
                "grass",
                "to",
                "Iris",
                "leave",
                ",",
                "Iris",
                "leave",
                "to",
                "strip",
                "of",
                "plastic",
                ",",
                "strip",
                "of",
                "plastic",
                "to",
                "Christmas",
                "tinsel",
                "and",
                "finally",
                "to",
                "rubber",
                "band",
                "."
            ],
            [
                "Rubber",
                "band",
                ",",
                "of",
                "a",
                "certain",
                "thickness",
                ",",
                "be",
                "my",
                "preference",
                "for",
                "many",
                "year",
                "until",
                "I",
                "finally",
                "force",
                "myself",
                "to",
                "kick",
                "the",
                "habit",
                "well",
                "into",
                "my",
                "twenty",
                "."
            ],
            [
                "of",
                "course",
                ",",
                "my",
                "twiddle",
                "habit",
                "do",
                "not",
                "go",
                "unnoticed",
                "and",
                "believe",
                "it",
                "or",
                "not",
                "other",
                "kid",
                "at",
                "my",
                "school",
                "want",
                "in",
                "."
            ]
        ],
        "label": "Joy"
    },
    {
        "body_part_token_idx": 15,
        "sentence_id": "a98a2d37-0438-34d4-84b6-a530b01c710f",
        "tokens": [
            "D",
            "held",
            "the",
            "phone",
            "out",
            "to",
            "me",
            "with",
            "a",
            "quizzical",
            "/",
            "worried",
            "look",
            "on",
            "her",
            "face",
            ",",
            "and",
            "said",
            "``",
            "She",
            "wants",
            "to",
            "talk",
            "to",
            "you",
            ".",
            "''"
        ],
        "lemmatized_tokens": [
            "d",
            "hold",
            "the",
            "phone",
            "out",
            "to",
            "I",
            "with",
            "a",
            "quizzical",
            "/",
            "worried",
            "look",
            "on",
            "she",
            "face",
            ",",
            "and",
            "say",
            "``",
            "she",
            "want",
            "to",
            "talk",
            "to",
            "you",
            ".",
            "''"
        ],
        "preceding_context_tokens": [
            [
                "It",
                "was",
                "``",
                "Granny",
                ".",
                "''"
            ],
            [
                "D",
                "rolled",
                "her",
                "eyes",
                "a",
                "lot",
                "while",
                "talking",
                "to",
                "her",
                "and",
                "J",
                "and",
                "AB",
                "seemed",
                "very",
                "surprised",
                "she",
                "had",
                "called",
                "."
            ],
            [
                "Then",
                "there",
                "was",
                "a",
                "tap",
                "on",
                "my",
                "shoulder",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "it",
                "be",
                "``",
                "Granny",
                ".",
                "''"
            ],
            [
                "d",
                "roll",
                "she",
                "eye",
                "a",
                "lot",
                "while",
                "talk",
                "to",
                "she",
                "and",
                "J",
                "and",
                "AB",
                "seem",
                "very",
                "surprised",
                "she",
                "have",
                "call",
                "."
            ],
            [
                "then",
                "there",
                "be",
                "a",
                "tap",
                "on",
                "my",
                "shoulder",
                "."
            ]
        ],
        "label": "Fear"
    },
    {
        "body_part_token_idx": 10,
        "sentence_id": "245bc7c8-e414-3456-b315-2e49b1c93275",
        "tokens": [
            "She",
            "went",
            "into",
            "the",
            "OR",
            "with",
            "a",
            "smile",
            "on",
            "her",
            "face",
            "."
        ],
        "lemmatized_tokens": [
            "she",
            "go",
            "into",
            "the",
            "OR",
            "with",
            "a",
            "smile",
            "on",
            "she",
            "face",
            "."
        ],
        "preceding_context_tokens": [
            [
                "We",
                "would",
                "n't",
                "want",
                "a",
                "doctor",
                "who",
                "might",
                "take",
                "out",
                "a",
                "kidney",
                "or",
                "lung",
                "instead",
                "of",
                "the",
                "right",
                "organ",
                "."
            ],
            [
                "It",
                "'s",
                "been",
                "a",
                "long",
                "day",
                "and",
                "right",
                "now",
                "I",
                "'m",
                "feeling",
                "a",
                "little",
                "nervous",
                ",",
                "tired",
                ",",
                "and",
                "lonely",
                "."
            ],
            [
                "I",
                "'ve",
                "admired",
                "The",
                "Wife",
                "'s",
                "ability",
                "to",
                "maintain",
                "her",
                "calm",
                "and",
                "positive",
                "attitude",
                "today",
                ",",
                "despite",
                "her",
                "hunger",
                ",",
                "thirst",
                ",",
                "and",
                "the",
                "delay",
                "in",
                "the",
                "time",
                "of",
                "her",
                "surgery",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "we",
                "would",
                "not",
                "want",
                "a",
                "doctor",
                "who",
                "might",
                "take",
                "out",
                "a",
                "kidney",
                "or",
                "lung",
                "instead",
                "of",
                "the",
                "right",
                "organ",
                "."
            ],
            [
                "it",
                "be",
                "be",
                "a",
                "long",
                "day",
                "and",
                "right",
                "now",
                "I",
                "be",
                "feel",
                "a",
                "little",
                "nervous",
                ",",
                "tired",
                ",",
                "and",
                "lonely",
                "."
            ],
            [
                "I",
                "have",
                "admire",
                "the",
                "Wife",
                "'s",
                "ability",
                "to",
                "maintain",
                "she",
                "calm",
                "and",
                "positive",
                "attitude",
                "today",
                ",",
                "despite",
                "she",
                "hunger",
                ",",
                "thirst",
                ",",
                "and",
                "the",
                "delay",
                "in",
                "the",
                "time",
                "of",
                "she",
                "surgery",
                "."
            ]
        ],
        "label": "Joy"
    },
    {
        "body_part_token_idx": 12,
        "sentence_id": "63b77b90-09cf-3b6a-a7ed-46871ca7a899",
        "tokens": [
            "Harry",
            "finished",
            "his",
            "drink",
            "in",
            "two",
            "fairly",
            "heroic",
            "goes",
            ",",
            "though",
            "his",
            "eyes",
            "did",
            "water",
            "a",
            "bit",
            "."
        ],
        "lemmatized_tokens": [
            "Harry",
            "finish",
            "he",
            "drink",
            "in",
            "two",
            "fairly",
            "heroic",
            "go",
            ",",
            "though",
            "he",
            "eye",
            "do",
            "water",
            "a",
            "bit",
            "."
        ],
        "preceding_context_tokens": [
            [
                "``",
                "I",
                "fought",
                "the",
                "evilest",
                "wizard",
                "of",
                "all",
                "time",
                "before",
                "I",
                "hit",
                "puberty",
                "."
            ],
            [
                "Pour",
                "me",
                "a",
                "drink",
                ".",
                "''"
            ],
            [
                "That",
                "was",
                "a",
                "fair",
                "point",
                ",",
                "so",
                "he",
                "did",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "``",
                "I",
                "fight",
                "the",
                "evilest",
                "wizard",
                "of",
                "all",
                "time",
                "before",
                "I",
                "hit",
                "puberty",
                "."
            ],
            [
                "pour",
                "I",
                "a",
                "drink",
                ".",
                "''"
            ],
            [
                "that",
                "be",
                "a",
                "fair",
                "point",
                ",",
                "so",
                "he",
                "do",
                "."
            ]
        ],
        "label": "Disgust"
    },
    {
        "body_part_token_idx": 3,
        "sentence_id": "9e08c34e-e5ac-3d83-be45-05551260d633",
        "tokens": [
            "He",
            "shook",
            "his",
            "head",
            ",",
            "turning",
            "his",
            "gaze",
            "to",
            "the",
            "fire",
            "."
        ],
        "lemmatized_tokens": [
            "he",
            "shake",
            "he",
            "head",
            ",",
            "turn",
            "he",
            "gaze",
            "to",
            "the",
            "fire",
            "."
        ],
        "preceding_context_tokens": [
            [
                "he",
                "inquired",
                ",",
                "his",
                "voice",
                "jovial",
                "and",
                "healthy.Samhuinn",
                "sat",
                "down",
                "beside",
                "the",
                "other",
                "bull",
                ",",
                "frowning",
                "at",
                "him",
                "thoughtfully",
                "."
            ],
            [
                "He",
                "did",
                "not",
                "like",
                "this",
                "feeling",
                ",",
                "he",
                "concluded",
                "."
            ],
            [
                "He",
                "did",
                "not",
                "wish",
                "to",
                "cause",
                "harm",
                "to",
                "Ambershanks",
                "at",
                "all",
                ",",
                "and",
                "so",
                "hating",
                "him",
                "felt",
                "unusual",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "he",
                "inquire",
                ",",
                "he",
                "voice",
                "jovial",
                "and",
                "healthy.Samhuinn",
                "sit",
                "down",
                "beside",
                "the",
                "other",
                "bull",
                ",",
                "frown",
                "at",
                "he",
                "thoughtfully",
                "."
            ],
            [
                "he",
                "do",
                "not",
                "like",
                "this",
                "feeling",
                ",",
                "he",
                "conclude",
                "."
            ],
            [
                "he",
                "do",
                "not",
                "wish",
                "to",
                "cause",
                "harm",
                "to",
                "Ambershanks",
                "at",
                "all",
                ",",
                "and",
                "so",
                "hate",
                "he",
                "feel",
                "unusual",
                "."
            ]
        ],
        "label": "Disgust"
    },
    {
        "body_part_token_idx": 4,
        "sentence_id": "3c29c8c2-8a13-3793-b7b7-f7a2a0550989",
        "tokens": [
            "Sherlock",
            "tilted",
            "up",
            "his",
            "head",
            "slightly",
            "in",
            "the",
            "tiniest",
            "nod",
            "."
        ],
        "lemmatized_tokens": [
            "Sherlock",
            "tilt",
            "up",
            "he",
            "head",
            "slightly",
            "in",
            "the",
            "tiniest",
            "nod",
            "."
        ],
        "preceding_context_tokens": [
            [
                "Sherlock",
                "leant",
                "forwards",
                ",",
                "bending",
                "his",
                "knees",
                "to",
                "sit",
                "up",
                "properly",
                "and",
                "John",
                "reached",
                "out",
                ",",
                "giving",
                "him",
                "a",
                "gentle",
                "but",
                "firm",
                "push",
                "on",
                "his",
                "chest",
                "to",
                "pin",
                "him",
                "back",
                "down",
                "to",
                "the",
                "mattress",
                "and",
                "against",
                "the",
                "pillows",
                "."
            ],
            [
                "he",
                "shifted",
                "a",
                "little",
                "closers",
                "so",
                "that",
                "he",
                "was",
                "kneeling",
                "between",
                "his",
                "legs",
                "and",
                "smiled",
                "at",
                "him",
                "."
            ],
            [
                "``",
                "No",
                ",",
                "you",
                "stay",
                "where",
                "you",
                "are",
                "and",
                "relax",
                ",",
                "alright",
                "?",
                "''"
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "Sherlock",
                "lean",
                "forward",
                ",",
                "bend",
                "he",
                "knee",
                "to",
                "sit",
                "up",
                "properly",
                "and",
                "John",
                "reach",
                "out",
                ",",
                "give",
                "he",
                "a",
                "gentle",
                "but",
                "firm",
                "push",
                "on",
                "he",
                "chest",
                "to",
                "pin",
                "he",
                "back",
                "down",
                "to",
                "the",
                "mattress",
                "and",
                "against",
                "the",
                "pillow",
                "."
            ],
            [
                "he",
                "shift",
                "a",
                "little",
                "closer",
                "so",
                "that",
                "he",
                "be",
                "kneel",
                "between",
                "he",
                "leg",
                "and",
                "smile",
                "at",
                "he",
                "."
            ],
            [
                "``",
                "no",
                ",",
                "you",
                "stay",
                "where",
                "you",
                "be",
                "and",
                "relax",
                ",",
                "alright",
                "?",
                "''"
            ]
        ],
        "label": "Joy"
    },
    {
        "body_part_token_idx": 4,
        "sentence_id": "b1392b06-d945-39f0-ba15-fc9f4a42ac29",
        "tokens": [
            "A",
            "smile",
            "on",
            "his",
            "face",
            ",",
            "he",
            "reached",
            "out",
            "and",
            "wiped",
            "the",
            "smallest",
            "speck",
            "of",
            "a",
            "cookie",
            "crumb",
            "from",
            "Hunny",
            "'s",
            "collar",
            "."
        ],
        "lemmatized_tokens": [
            "a",
            "smile",
            "on",
            "he",
            "face",
            ",",
            "he",
            "reach",
            "out",
            "and",
            "wipe",
            "the",
            "smallest",
            "speck",
            "of",
            "a",
            "cookie",
            "crumb",
            "from",
            "Hunny",
            "'s",
            "collar",
            "."
        ],
        "preceding_context_tokens": [
            [
                "For",
                "a",
                "moment",
                "Mori",
                "tried",
                "to",
                "speak",
                "."
            ],
            [
                "He",
                "felt",
                "the",
                "words",
                "rise",
                "in",
                "his",
                "throat",
                ",",
                "and",
                "then",
                "die",
                "."
            ],
            [
                "He",
                "had",
                "nothing",
                "to",
                "say",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "for",
                "a",
                "moment",
                "Mori",
                "try",
                "to",
                "speak",
                "."
            ],
            [
                "he",
                "feel",
                "the",
                "word",
                "rise",
                "in",
                "he",
                "throat",
                ",",
                "and",
                "then",
                "die",
                "."
            ],
            [
                "he",
                "have",
                "nothing",
                "to",
                "say",
                "."
            ]
        ],
        "label": "Joy"
    },
    {
        "body_part_token_idx": 17,
        "sentence_id": "4f8e0934-c2f7-34f6-8cd1-d093e89794f8",
        "tokens": [
            "Spike",
            ",",
            "let",
            "'s",
            "just",
            "talk",
            "this",
            "through",
            ",",
            "okay?",
            "She",
            "could",
            "see",
            "the",
            "anguish",
            "on",
            "his",
            "face",
            "."
        ],
        "lemmatized_tokens": [
            "spike",
            ",",
            "let",
            "'s",
            "just",
            "talk",
            "this",
            "through",
            ",",
            "okay?",
            "she",
            "could",
            "see",
            "the",
            "anguish",
            "on",
            "he",
            "face",
            "."
        ],
        "preceding_context_tokens": [
            [
                "You",
                "can",
                "stay",
                ",",
                "insisted",
                "Buffy",
                "."
            ],
            [
                "I",
                "'m",
                "okay",
                "."
            ],
            [
                "I",
                "'m",
                "all",
                "right",
                ",",
                "Spike.",
                "She",
                "got",
                "between",
                "him",
                "and",
                "the",
                "door",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "you",
                "can",
                "stay",
                ",",
                "insist",
                "Buffy",
                "."
            ],
            [
                "I",
                "be",
                "okay",
                "."
            ],
            [
                "I",
                "be",
                "all",
                "right",
                ",",
                "Spike.",
                "she",
                "get",
                "between",
                "he",
                "and",
                "the",
                "door",
                "."
            ]
        ],
        "label": "Sadness"
    },
    {
        "body_part_token_idx": 19,
        "sentence_id": "390bd5dc-a973-3d33-8137-ca155a53040c",
        "tokens": [
            "Only",
            "Augusten",
            "never",
            "got",
            "down",
            "on",
            "one",
            "knee.Instead",
            "he",
            "fidgeted",
            "with",
            "the",
            "ends",
            "of",
            "his",
            "scarf",
            ",",
            "shuffling",
            "his",
            "feet",
            "a",
            "little",
            "and",
            "sighing",
            "."
        ],
        "lemmatized_tokens": [
            "only",
            "Augusten",
            "never",
            "get",
            "down",
            "on",
            "one",
            "knee.instead",
            "he",
            "fidget",
            "with",
            "the",
            "end",
            "of",
            "he",
            "scarf",
            ",",
            "shuffling",
            "he",
            "foot",
            "a",
            "little",
            "and",
            "sighing",
            "."
        ],
        "preceding_context_tokens": [
            [
                "That",
                "Augusten",
                "would",
                "be",
                "putting",
                "a",
                "ring",
                "on",
                "her",
                "finger",
                "to",
                "the",
                "most",
                "gorgeous",
                "backdrop",
                "."
            ],
            [
                "The",
                "snow",
                "was",
                "falling",
                ",",
                "the",
                "lawn",
                "already",
                "coated",
                "in",
                "three",
                "inches",
                "of",
                "white",
                "fluff",
                ",",
                "the",
                "Christmas",
                "lights",
                "illuminating",
                "everything",
                ",",
                "it",
                "was",
                "an",
                "absolute",
                "winter",
                "wonderland",
                "."
            ],
            [
                "Her",
                "mother",
                "was",
                "waiting",
                "on",
                "the",
                "other",
                "side",
                "of",
                "the",
                "door",
                "with",
                "the",
                "camera",
                "to",
                "capture",
                "everything",
                "on",
                "film",
                ",",
                "so",
                "they",
                "could",
                "put",
                "it",
                "in",
                "their",
                "scrapbook",
                "later",
                "on",
                "down",
                "the",
                "road",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "that",
                "Augusten",
                "would",
                "be",
                "put",
                "a",
                "ring",
                "on",
                "she",
                "finger",
                "to",
                "the",
                "most",
                "gorgeous",
                "backdrop",
                "."
            ],
            [
                "the",
                "snow",
                "be",
                "fall",
                ",",
                "the",
                "lawn",
                "already",
                "coat",
                "in",
                "three",
                "inch",
                "of",
                "white",
                "fluff",
                ",",
                "the",
                "Christmas",
                "light",
                "illuminate",
                "everything",
                ",",
                "it",
                "be",
                "a",
                "absolute",
                "winter",
                "wonderland",
                "."
            ],
            [
                "she",
                "mother",
                "be",
                "wait",
                "on",
                "the",
                "other",
                "side",
                "of",
                "the",
                "door",
                "with",
                "the",
                "camera",
                "to",
                "capture",
                "everything",
                "on",
                "film",
                ",",
                "so",
                "they",
                "could",
                "put",
                "it",
                "in",
                "they",
                "scrapbook",
                "later",
                "on",
                "down",
                "the",
                "road",
                "."
            ]
        ],
        "label": "Fear"
    },
    {
        "body_part_token_idx": 11,
        "sentence_id": "c7e7083a-5995-30a8-8710-721844b70d1a",
        "tokens": [
            "I",
            "looked",
            "up",
            "at",
            "him",
            ",",
            "and",
            "then",
            "quickly",
            "shifted",
            "my",
            "eyes",
            "to",
            "the",
            "side",
            ",",
            "biting",
            "my",
            "lower",
            "lip",
            "."
        ],
        "lemmatized_tokens": [
            "I",
            "look",
            "up",
            "at",
            "he",
            ",",
            "and",
            "then",
            "quickly",
            "shift",
            "my",
            "eye",
            "to",
            "the",
            "side",
            ",",
            "bite",
            "my",
            "lower",
            "lip",
            "."
        ],
        "preceding_context_tokens": [
            [
                "That",
                "was",
                "$",
                "''",
                "His",
                "voice",
                "trailed",
                "off",
                "."
            ],
            [
                "I",
                "took",
                "a",
                "deep",
                "breath",
                ",",
                "and",
                "pulled",
                "my",
                "arms",
                "back",
                "down",
                "to",
                "my",
                "sides",
                "."
            ],
            [
                "``",
                "Yeah",
                "$",
                "it",
                "was",
                ".",
                "''"
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "that",
                "be",
                "$",
                "''",
                "he",
                "voice",
                "trail",
                "off",
                "."
            ],
            [
                "I",
                "take",
                "a",
                "deep",
                "breath",
                ",",
                "and",
                "pull",
                "my",
                "arm",
                "back",
                "down",
                "to",
                "my",
                "side",
                "."
            ],
            [
                "``",
                "yeah",
                "$",
                "it",
                "be",
                ".",
                "''"
            ]
        ],
        "label": "Fear"
    },
    {
        "body_part_token_idx": 8,
        "sentence_id": "9fbf0194-aa0d-33d8-bd1d-01c793b31d1a",
        "tokens": [
            "Finally",
            ",",
            "he",
            "nodded",
            "slowly",
            ",",
            "keeping",
            "his",
            "eyes",
            "lowered",
            "so",
            "that",
            "he",
            "did",
            "n't",
            "have",
            "to",
            "meet",
            "Angel",
            "'s",
            "gaze",
            "."
        ],
        "lemmatized_tokens": [
            "finally",
            ",",
            "he",
            "nod",
            "slowly",
            ",",
            "keep",
            "he",
            "eye",
            "lower",
            "so",
            "that",
            "he",
            "do",
            "not",
            "have",
            "to",
            "meet",
            "Angel",
            "'s",
            "gaze",
            "."
        ],
        "preceding_context_tokens": [
            [
                "Been",
                "watching",
                "Oprah",
                "?"
            ],
            [
                "Heh",
                "Does",
                "it",
                "show",
                "?"
            ],
            [
                "The",
                "Texan",
                "snorted",
                ",",
                "but",
                "then",
                "his",
                "brow",
                "puckered",
                "as",
                "if",
                "he",
                "was",
                "trying",
                "to",
                "decide",
                "something",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "be",
                "watch",
                "Oprah",
                "?"
            ],
            [
                "heh",
                "do",
                "it",
                "show",
                "?"
            ],
            [
                "the",
                "Texan",
                "snort",
                ",",
                "but",
                "then",
                "he",
                "brow",
                "pucker",
                "as",
                "if",
                "he",
                "be",
                "try",
                "to",
                "decide",
                "something",
                "."
            ]
        ],
        "label": "Fear"
    },
    {
        "body_part_token_idx": 4,
        "sentence_id": "53b19d26-dd25-3b6e-9af9-cc878259922d",
        "tokens": [
            "I",
            "finally",
            "bowed",
            "my",
            "knee",
            "and",
            "asked",
            "for",
            "forgiveness",
            "in",
            "September",
            ",",
            "1982",
            ",",
            "at",
            "RAF",
            "Mildenhall",
            "in",
            "England",
            "and",
            "I",
            "never",
            "let",
            "go",
            "."
        ],
        "lemmatized_tokens": [
            "I",
            "finally",
            "bow",
            "my",
            "knee",
            "and",
            "ask",
            "for",
            "forgiveness",
            "in",
            "September",
            ",",
            "1982",
            ",",
            "at",
            "RAF",
            "Mildenhall",
            "in",
            "England",
            "and",
            "I",
            "never",
            "let",
            "go",
            "."
        ],
        "preceding_context_tokens": [
            [
                "When",
                "I",
                "first",
                "went",
                "into",
                "the",
                "US",
                "Air",
                "Force",
                ",",
                "I",
                "slept",
                "in",
                "on",
                "Sundays",
                ",",
                "but",
                "something",
                "always",
                "gnawed",
                "at",
                "me",
                "telling",
                "me",
                "that",
                "there",
                "was",
                "someplace",
                "I",
                "was",
                "supposed",
                "to",
                "be",
                "."
            ],
            [
                "When",
                "I",
                "started",
                "my",
                "journey",
                "to",
                "become",
                "a",
                "devoted",
                "follower",
                "of",
                "Christ",
                ",",
                "I",
                "was",
                "in",
                "Austin",
                ",",
                "Texas.I",
                "remember",
                "finding",
                "an",
                "announcement",
                "for",
                "a",
                "Baptist",
                "Church",
                "and",
                "thought",
                ",",
                "``",
                "It",
                "'s",
                "time",
                "to",
                "go",
                "back",
                "to",
                "church",
                "''",
                "."
            ],
            [
                "The",
                "only",
                "thing",
                "that",
                "was",
                "certain",
                "was",
                "that",
                "it",
                "would",
                "no",
                "longer",
                "be",
                "a",
                "Catholic",
                "Church",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "when",
                "I",
                "first",
                "go",
                "into",
                "the",
                "US",
                "Air",
                "Force",
                ",",
                "I",
                "sleep",
                "in",
                "on",
                "Sundays",
                ",",
                "but",
                "something",
                "always",
                "gnaw",
                "at",
                "I",
                "tell",
                "I",
                "that",
                "there",
                "be",
                "someplace",
                "I",
                "be",
                "suppose",
                "to",
                "be",
                "."
            ],
            [
                "when",
                "I",
                "start",
                "my",
                "journey",
                "to",
                "become",
                "a",
                "devoted",
                "follower",
                "of",
                "Christ",
                ",",
                "I",
                "be",
                "in",
                "Austin",
                ",",
                "Texas.I",
                "remember",
                "find",
                "a",
                "announcement",
                "for",
                "a",
                "Baptist",
                "Church",
                "and",
                "think",
                ",",
                "``",
                "it",
                "be",
                "time",
                "to",
                "go",
                "back",
                "to",
                "church",
                "''",
                "."
            ],
            [
                "the",
                "only",
                "thing",
                "that",
                "be",
                "certain",
                "be",
                "that",
                "it",
                "would",
                "no",
                "longer",
                "be",
                "a",
                "Catholic",
                "Church",
                "."
            ]
        ],
        "label": "Sadness"
    },
    {
        "body_part_token_idx": 8,
        "sentence_id": "10acf6ac-1b79-3216-981f-603eb9296218",
        "tokens": [
            "I",
            "snapped",
            "my",
            "phone",
            "shut",
            ",",
            "clenching",
            "my",
            "fist",
            "around",
            "it",
            "tightly",
            "."
        ],
        "lemmatized_tokens": [
            "I",
            "snap",
            "my",
            "phone",
            "shut",
            ",",
            "clench",
            "my",
            "fist",
            "around",
            "it",
            "tightly",
            "."
        ],
        "preceding_context_tokens": [
            [
                "Amen",
                "."
            ],
            [
                "Warning",
                ":",
                "This",
                "is",
                "an",
                "mpreg",
                "."
            ],
            [
                "So",
                "if",
                "you",
                "'re",
                "no",
                "into",
                "that",
                "sort",
                "of",
                "thing",
                ",",
                "I",
                "would",
                "suggest",
                "you",
                "do",
                "n't",
                "read",
                "it",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "amen",
                "."
            ],
            [
                "warning",
                ":",
                "this",
                "be",
                "a",
                "mpreg",
                "."
            ],
            [
                "so",
                "if",
                "you",
                "be",
                "no",
                "into",
                "that",
                "sort",
                "of",
                "thing",
                ",",
                "I",
                "would",
                "suggest",
                "you",
                "do",
                "not",
                "read",
                "it",
                "."
            ]
        ],
        "label": "Anger"
    },
    {
        "body_part_token_idx": 5,
        "sentence_id": "ed523fe7-c8f2-39bd-8568-8c4f25317a8a",
        "tokens": [
            "Jenny",
            ",",
            "I",
            ",",
            "my",
            "throat",
            "choked",
            "when",
            "I",
            "hear",
            "my",
            "daughter",
            "'s",
            "voice",
            "."
        ],
        "lemmatized_tokens": [
            "Jenny",
            ",",
            "I",
            ",",
            "my",
            "throat",
            "choke",
            "when",
            "I",
            "hear",
            "my",
            "daughter",
            "'s",
            "voice",
            "."
        ],
        "preceding_context_tokens": [
            [
                "Yes",
                ",",
                "what",
                "'s",
                "wrong",
                "?"
            ],
            [
                "Your",
                "daughter",
                "wants",
                "to",
                "talk",
                "to",
                "you",
                ",",
                "Mrs.",
                "Johnson",
                "."
            ],
            [
                "Mom",
                ",",
                "please",
                "come",
                "bail",
                "me",
                "out",
                ",",
                "Jenny",
                "sobbed",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "yes",
                ",",
                "what",
                "be",
                "wrong",
                "?"
            ],
            [
                "you",
                "daughter",
                "want",
                "to",
                "talk",
                "to",
                "you",
                ",",
                "Mrs.",
                "Johnson",
                "."
            ],
            [
                "mom",
                ",",
                "please",
                "come",
                "bail",
                "I",
                "out",
                ",",
                "Jenny",
                "sob",
                "."
            ]
        ],
        "label": "Sadness"
    },
    {
        "body_part_token_idx": 3,
        "sentence_id": "6c957918-da1b-3653-b47b-f98ad3569c65",
        "tokens": [
            "I",
            "felt",
            "my",
            "eyes",
            "starting",
            "to",
            "roll",
            "back",
            "into",
            "my",
            "head",
            ",",
            "and",
            "staggered",
            "to",
            "the",
            "window",
            "to",
            "get",
            "a",
            "breath",
            "of",
            "fresh",
            "air",
            "."
        ],
        "lemmatized_tokens": [
            "I",
            "feel",
            "my",
            "eye",
            "start",
            "to",
            "roll",
            "back",
            "into",
            "my",
            "head",
            ",",
            "and",
            "stagger",
            "to",
            "the",
            "window",
            "to",
            "get",
            "a",
            "breath",
            "of",
            "fresh",
            "air",
            "."
        ],
        "preceding_context_tokens": [
            [
                "Copyright",
                "2007",
                "ResellRightsBlowout.com",
                "My",
                "friend",
                "had",
                "not",
                "had",
                "a",
                "bath",
                "in",
                "over",
                "three",
                "days",
                ",",
                "there",
                "where",
                "pizza",
                "boxes",
                "littered",
                "across",
                "his",
                "apartment",
                ",",
                "and",
                "a",
                "funky",
                "odor",
                "filled",
                "the",
                "room",
                "."
            ],
            [
                "As",
                "I",
                "walked",
                "into",
                "his",
                "apartment",
                ",",
                "I",
                "quickly",
                "became",
                "disorientated",
                "and",
                "started",
                "to",
                "feel",
                "myself",
                "losing",
                "consciousness",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "copyright",
                "2007",
                "resellrightsblowout.com",
                "my",
                "friend",
                "have",
                "not",
                "have",
                "a",
                "bath",
                "in",
                "over",
                "three",
                "day",
                ",",
                "there",
                "where",
                "pizza",
                "box",
                "litter",
                "across",
                "he",
                "apartment",
                ",",
                "and",
                "a",
                "funky",
                "odor",
                "fill",
                "the",
                "room",
                "."
            ],
            [
                "as",
                "I",
                "walk",
                "into",
                "he",
                "apartment",
                ",",
                "I",
                "quickly",
                "become",
                "disorientated",
                "and",
                "start",
                "to",
                "feel",
                "myself",
                "lose",
                "consciousness",
                "."
            ]
        ],
        "label": "Disgust"
    },
    {
        "body_part_token_idx": 10,
        "sentence_id": "6c957918-da1b-3653-b47b-f98ad3569c65",
        "tokens": [
            "I",
            "felt",
            "my",
            "eyes",
            "starting",
            "to",
            "roll",
            "back",
            "into",
            "my",
            "head",
            ",",
            "and",
            "staggered",
            "to",
            "the",
            "window",
            "to",
            "get",
            "a",
            "breath",
            "of",
            "fresh",
            "air",
            "."
        ],
        "lemmatized_tokens": [
            "I",
            "feel",
            "my",
            "eye",
            "start",
            "to",
            "roll",
            "back",
            "into",
            "my",
            "head",
            ",",
            "and",
            "stagger",
            "to",
            "the",
            "window",
            "to",
            "get",
            "a",
            "breath",
            "of",
            "fresh",
            "air",
            "."
        ],
        "preceding_context_tokens": [
            [
                "Copyright",
                "2007",
                "ResellRightsBlowout.com",
                "My",
                "friend",
                "had",
                "not",
                "had",
                "a",
                "bath",
                "in",
                "over",
                "three",
                "days",
                ",",
                "there",
                "where",
                "pizza",
                "boxes",
                "littered",
                "across",
                "his",
                "apartment",
                ",",
                "and",
                "a",
                "funky",
                "odor",
                "filled",
                "the",
                "room",
                "."
            ],
            [
                "As",
                "I",
                "walked",
                "into",
                "his",
                "apartment",
                ",",
                "I",
                "quickly",
                "became",
                "disorientated",
                "and",
                "started",
                "to",
                "feel",
                "myself",
                "losing",
                "consciousness",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "copyright",
                "2007",
                "resellrightsblowout.com",
                "my",
                "friend",
                "have",
                "not",
                "have",
                "a",
                "bath",
                "in",
                "over",
                "three",
                "day",
                ",",
                "there",
                "where",
                "pizza",
                "box",
                "litter",
                "across",
                "he",
                "apartment",
                ",",
                "and",
                "a",
                "funky",
                "odor",
                "fill",
                "the",
                "room",
                "."
            ],
            [
                "as",
                "I",
                "walk",
                "into",
                "he",
                "apartment",
                ",",
                "I",
                "quickly",
                "become",
                "disorientated",
                "and",
                "start",
                "to",
                "feel",
                "myself",
                "lose",
                "consciousness",
                "."
            ]
        ],
        "label": "Disgust"
    },
    {
        "body_part_token_idx": 34,
        "sentence_id": "6214e613-e712-325f-acfc-114ac720ec4e",
        "tokens": [
            "I",
            "think",
            "I",
            "got",
            "hit",
            "in",
            "the",
            "face",
            "with",
            "at",
            "least",
            "half",
            "the",
            "shells",
            "after",
            "I",
            "fired",
            "them",
            ",",
            "but",
            "even",
            "the",
            "hot",
            "metal",
            "briefly",
            "stinging",
            "me",
            "could",
            "n't",
            "tear",
            "the",
            "grin",
            "off",
            "my",
            "face",
            "."
        ],
        "lemmatized_tokens": [
            "I",
            "think",
            "I",
            "get",
            "hit",
            "in",
            "the",
            "face",
            "with",
            "at",
            "least",
            "half",
            "the",
            "shell",
            "after",
            "I",
            "fire",
            "they",
            ",",
            "but",
            "even",
            "the",
            "hot",
            "metal",
            "briefly",
            "sting",
            "I",
            "could",
            "not",
            "tear",
            "the",
            "grin",
            "off",
            "my",
            "face",
            "."
        ],
        "preceding_context_tokens": [
            [
                "I",
                "was",
                "the",
                "only",
                "girl",
                "there",
                "."
            ],
            [
                "But",
                "that",
                "did",
                "n't",
                "matter",
                "once",
                "it",
                "got",
                "down",
                "to",
                "the",
                "aiming",
                "and",
                "shooting",
                "part",
                "."
            ],
            [
                "I",
                "got",
                "to",
                "borrow",
                "a",
                "40",
                "caliber",
                "Sig",
                "Sauer",
                "P239",
                "and",
                "shot",
                "ten",
                "clips",
                "-LRB-",
                "I",
                "think",
                ")",
                "before",
                "the",
                "sweat",
                "started",
                "running",
                "into",
                "my",
                "eyes",
                "and",
                "fogging",
                "up",
                "my",
                "protective",
                "eyewear",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "I",
                "be",
                "the",
                "only",
                "girl",
                "there",
                "."
            ],
            [
                "but",
                "that",
                "do",
                "not",
                "matter",
                "once",
                "it",
                "get",
                "down",
                "to",
                "the",
                "aim",
                "and",
                "shoot",
                "part",
                "."
            ],
            [
                "I",
                "get",
                "to",
                "borrow",
                "a",
                "40",
                "caliber",
                "Sig",
                "Sauer",
                "p239",
                "and",
                "shoot",
                "ten",
                "clip",
                "-lrb-",
                "I",
                "think",
                ")",
                "before",
                "the",
                "sweat",
                "start",
                "run",
                "into",
                "my",
                "eye",
                "and",
                "fog",
                "up",
                "my",
                "protective",
                "eyewear",
                "."
            ]
        ],
        "label": "Joy"
    },
    {
        "body_part_token_idx": 38,
        "sentence_id": "64054c64-53f4-341f-87fa-a89f280403d9",
        "tokens": [
            "Much",
            "of",
            "what",
            "you",
            "have",
            "been",
            "taught",
            "has",
            "focused",
            "only",
            "on",
            "defensive",
            "spells",
            ",",
            "however",
            ",",
            "your",
            "learning",
            "on",
            "the",
            "subject",
            "of",
            "curses",
            "and",
            "hexes",
            "have",
            "been",
            "sorely",
            "lacking.",
            "She",
            "said",
            ",",
            "the",
            "smile",
            "draining",
            "slightly",
            "from",
            "her",
            "face",
            "."
        ],
        "lemmatized_tokens": [
            "much",
            "of",
            "what",
            "you",
            "have",
            "be",
            "teach",
            "have",
            "focus",
            "only",
            "on",
            "defensive",
            "spell",
            ",",
            "however",
            ",",
            "you",
            "learning",
            "on",
            "the",
            "subject",
            "of",
            "curse",
            "and",
            "hex",
            "have",
            "be",
            "sorely",
            "lacking.",
            "she",
            "say",
            ",",
            "the",
            "smile",
            "drain",
            "slightly",
            "from",
            "she",
            "face",
            "."
        ],
        "preceding_context_tokens": [
            [
                "Exactly!",
                "Professor",
                "Souris",
                "answered",
                ",",
                "her",
                "facing",
                "lightly",
                "up",
                ";",
                "glad",
                "to",
                "have",
                "gotten",
                "the",
                "answer",
                "she",
                "was",
                "looking",
                "for",
                "."
            ],
            [
                "She",
                "pointed",
                "her",
                "wand",
                "at",
                "the",
                "board",
                ",",
                "spelling",
                "out",
                "the",
                "words",
                "Curses",
                "underneath",
                "her",
                "name",
                "."
            ],
            [
                "From",
                "what",
                "I",
                "have",
                "heard",
                "your",
                "education",
                "on",
                "zee",
                "subject",
                "of",
                "zee",
                "dark",
                "arts",
                "haz",
                "bean",
                "erratic",
                "at",
                "bezt.",
                "She",
                "said",
                ",",
                "still",
                "smiling",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "Exactly!",
                "Professor",
                "Souris",
                "answer",
                ",",
                "she",
                "face",
                "lightly",
                "up",
                ";",
                "glad",
                "to",
                "have",
                "get",
                "the",
                "answer",
                "she",
                "be",
                "look",
                "for",
                "."
            ],
            [
                "she",
                "point",
                "she",
                "wand",
                "at",
                "the",
                "board",
                ",",
                "spell",
                "out",
                "the",
                "word",
                "curse",
                "underneath",
                "she",
                "name",
                "."
            ],
            [
                "from",
                "what",
                "I",
                "have",
                "hear",
                "you",
                "education",
                "on",
                "zee",
                "subject",
                "of",
                "zee",
                "dark",
                "art",
                "haz",
                "bean",
                "erratic",
                "at",
                "bezt.",
                "she",
                "say",
                ",",
                "still",
                "smile",
                "."
            ]
        ],
        "label": "Disgust"
    },
    {
        "body_part_token_idx": 46,
        "sentence_id": "9259a510-0ca8-37a5-ba2c-581ac1662a9b",
        "tokens": [
            "He",
            "tugged",
            "so",
            "ferociously",
            "my",
            "mother",
            "'s",
            "legs",
            "came",
            "out",
            "from",
            "under",
            "her",
            ",",
            "her",
            "Saucony",
            "-",
            "sneaker",
            "clad",
            "feet",
            "flailing",
            "in",
            "the",
            "air",
            ",",
            "but",
            "she",
            "still",
            "held",
            "on",
            "to",
            "the",
            "bag",
            ",",
            "not",
            "saying",
            "much",
            "of",
            "anything",
            "except",
            "for",
            "the",
            "occasional",
            "grunt",
            ",",
            "her",
            "eyebrows",
            "set",
            "in",
            "a",
            "firm",
            "line",
            "of",
            "determination",
            "."
        ],
        "lemmatized_tokens": [
            "he",
            "tug",
            "so",
            "ferociously",
            "my",
            "mother",
            "'s",
            "leg",
            "come",
            "out",
            "from",
            "under",
            "she",
            ",",
            "she",
            "Saucony",
            "-",
            "sneaker",
            "clad",
            "foot",
            "flail",
            "in",
            "the",
            "air",
            ",",
            "but",
            "she",
            "still",
            "hold",
            "on",
            "to",
            "the",
            "bag",
            ",",
            "not",
            "say",
            "much",
            "of",
            "anything",
            "except",
            "for",
            "the",
            "occasional",
            "grunt",
            ",",
            "she",
            "eyebrow",
            "set",
            "in",
            "a",
            "firm",
            "line",
            "of",
            "determination",
            "."
        ],
        "preceding_context_tokens": [
            [
                "This",
                "was",
                "not",
                "a",
                "relaxing",
                "situation",
                "!"
            ],
            [
                "I",
                "think",
                "it",
                "took",
                "me",
                "about",
                "twenty",
                "seconds",
                "to",
                "process",
                "what",
                "was",
                "happening",
                ",",
                "but",
                "as",
                "soon",
                "as",
                "I",
                "did",
                ",",
                "I",
                "started",
                "screaming",
                "at",
                "the",
                "Brazilian",
                ",",
                "using",
                "every",
                "curse",
                "word",
                "I",
                "knew",
                "in",
                "combinations",
                "like",
                "youmothershitfuckingassdoosheface",
                "!"
            ],
            [
                "And",
                "all",
                "the",
                "while",
                "the",
                "mugger",
                "was",
                "sweating",
                ",",
                "and",
                "looking",
                "slightly",
                "frazzled",
                "but",
                "pulling",
                "as",
                "hard",
                "as",
                "he",
                "could",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "this",
                "be",
                "not",
                "a",
                "relaxing",
                "situation",
                "!"
            ],
            [
                "I",
                "think",
                "it",
                "take",
                "I",
                "about",
                "twenty",
                "seconds",
                "to",
                "process",
                "what",
                "be",
                "happen",
                ",",
                "but",
                "as",
                "soon",
                "as",
                "I",
                "do",
                ",",
                "I",
                "start",
                "scream",
                "at",
                "the",
                "brazilian",
                ",",
                "use",
                "every",
                "curse",
                "word",
                "I",
                "know",
                "in",
                "combination",
                "like",
                "youmothershitfuckingassdoosheface",
                "!"
            ],
            [
                "and",
                "all",
                "the",
                "while",
                "the",
                "mugger",
                "be",
                "sweat",
                ",",
                "and",
                "look",
                "slightly",
                "frazzled",
                "but",
                "pull",
                "as",
                "hard",
                "as",
                "he",
                "could",
                "."
            ]
        ],
        "label": "Anger"
    },
    {
        "body_part_token_idx": 8,
        "sentence_id": "873afb10-258f-3ffc-ad71-25ac16df9799",
        "tokens": [
            "I",
            "still",
            "have",
            "a",
            "blank",
            "stare",
            "on",
            "my",
            "face",
            "."
        ],
        "lemmatized_tokens": [
            "I",
            "still",
            "have",
            "a",
            "blank",
            "stare",
            "on",
            "my",
            "face",
            "."
        ],
        "preceding_context_tokens": [
            [
                "And",
                "I",
                "slowly",
                "turn",
                "with",
                "the",
                "``",
                "OMFG",
                "-",
                "A-CREEPER",
                "!",
                "''"
            ],
            [
                "thought",
                "in",
                "my",
                "head",
                "."
            ],
            [
                "I",
                "look",
                "at",
                "him",
                "-LRB-",
                "I",
                "admit",
                ",",
                "he",
                "was",
                "pretty",
                "handsome",
                ")",
                "and",
                "he",
                "says",
                ",",
                "``",
                "You",
                "work",
                "at",
                "that",
                "drive",
                "-",
                "thru",
                "down",
                "the",
                "street",
                ",",
                "right",
                "?",
                "''"
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "and",
                "I",
                "slowly",
                "turn",
                "with",
                "the",
                "``",
                "omfg",
                "-",
                "a-creeper",
                "!",
                "''"
            ],
            [
                "think",
                "in",
                "my",
                "head",
                "."
            ],
            [
                "I",
                "look",
                "at",
                "he",
                "-lrb-",
                "I",
                "admit",
                ",",
                "he",
                "be",
                "pretty",
                "handsome",
                ")",
                "and",
                "he",
                "say",
                ",",
                "``",
                "you",
                "work",
                "at",
                "that",
                "drive",
                "-",
                "thru",
                "down",
                "the",
                "street",
                ",",
                "right",
                "?",
                "''"
            ]
        ],
        "label": "Surprise"
    },
    {
        "body_part_token_idx": 4,
        "sentence_id": "bcb6460f-9671-3852-af7d-f653275223e5",
        "tokens": [
            "``",
            "Both",
            "of",
            "her",
            "eyes",
            "snapped",
            "open",
            "."
        ],
        "lemmatized_tokens": [
            "``",
            "both",
            "of",
            "she",
            "eye",
            "snap",
            "open",
            "."
        ],
        "preceding_context_tokens": [
            [
                "``",
                "I",
                "wo",
                "n't",
                "let",
                "you",
                "do",
                "it",
                ".",
                "''"
            ],
            [
                "``",
                "Try",
                "to",
                "stop",
                "me",
                ".",
                "''"
            ],
            [
                "``",
                "If",
                "you",
                "dare",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "``",
                "I",
                "will",
                "not",
                "let",
                "you",
                "do",
                "it",
                ".",
                "''"
            ],
            [
                "``",
                "try",
                "to",
                "stop",
                "I",
                ".",
                "''"
            ],
            [
                "``",
                "if",
                "you",
                "dare",
                "."
            ]
        ],
        "label": "Anger"
    },
    {
        "body_part_token_idx": 3,
        "sentence_id": "599cf918-768a-35b3-a2ba-12bc52680c0d",
        "tokens": [
            "I",
            "slammed",
            "my",
            "fist",
            "against",
            "the",
            "door",
            "and",
            "yelled",
            ",",
            "Open",
            "up",
            "!"
        ],
        "lemmatized_tokens": [
            "I",
            "slam",
            "my",
            "fist",
            "against",
            "the",
            "door",
            "and",
            "yell",
            ",",
            "open",
            "up",
            "!"
        ],
        "preceding_context_tokens": [
            [
                "After",
                "pushing",
                "that",
                "thought",
                "aside",
                "I",
                "pulled",
                "a",
                "pair",
                "of",
                "clean",
                "jeans",
                "from",
                "the",
                "first",
                "drawer",
                ",",
                "then",
                "moved",
                "to",
                "the",
                "second",
                "and",
                "go",
                "out",
                "a",
                "black",
                "shirt",
                "."
            ],
            [
                "After",
                "grabbing",
                "other",
                "necessities",
                "I",
                "hurried",
                "to",
                "the",
                "bathroom",
                "and",
                "prepared",
                "to",
                "practically",
                "break",
                "down",
                "the",
                "door",
                "."
            ],
            [
                "I",
                "heard",
                "water",
                "running",
                "when",
                "I",
                "reached",
                "the",
                "door",
                "and",
                "loud",
                "whistling",
                "that",
                "was",
                "in",
                "the",
                "beat",
                "of",
                "some",
                "new",
                "song",
                "my",
                "brother",
                ",",
                "James",
                "'",
                "band",
                "had",
                "written",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "after",
                "push",
                "that",
                "think",
                "aside",
                "I",
                "pull",
                "a",
                "pair",
                "of",
                "clean",
                "jeans",
                "from",
                "the",
                "first",
                "drawer",
                ",",
                "then",
                "move",
                "to",
                "the",
                "second",
                "and",
                "go",
                "out",
                "a",
                "black",
                "shirt",
                "."
            ],
            [
                "after",
                "grab",
                "other",
                "necessity",
                "I",
                "hurry",
                "to",
                "the",
                "bathroom",
                "and",
                "prepared",
                "to",
                "practically",
                "break",
                "down",
                "the",
                "door",
                "."
            ],
            [
                "I",
                "hear",
                "water",
                "running",
                "when",
                "I",
                "reach",
                "the",
                "door",
                "and",
                "loud",
                "whistle",
                "that",
                "be",
                "in",
                "the",
                "beat",
                "of",
                "some",
                "new",
                "song",
                "my",
                "brother",
                ",",
                "James",
                "'",
                "band",
                "have",
                "write",
                "."
            ]
        ],
        "label": "Anger"
    },
    {
        "body_part_token_idx": 17,
        "sentence_id": "422267e4-5bfd-33b3-9efa-58d947975639",
        "tokens": [
            "He",
            "had",
            "a",
            "very",
            "dark",
            "complexion",
            ",",
            "dark",
            "hair",
            ",",
            "and",
            "a",
            "very",
            "intense",
            "look",
            "on",
            "his",
            "face",
            "."
        ],
        "lemmatized_tokens": [
            "he",
            "have",
            "a",
            "very",
            "dark",
            "complexion",
            ",",
            "dark",
            "hair",
            ",",
            "and",
            "a",
            "very",
            "intense",
            "look",
            "on",
            "he",
            "face",
            "."
        ],
        "preceding_context_tokens": [
            [
                "The",
                "guy",
                "had",
                "two",
                "tufts",
                "of",
                "hair",
                "near",
                "his",
                "temples",
                "and",
                "they",
                "were",
                "standing",
                "up",
                "on",
                "end",
                ",",
                "with",
                "a",
                "slight",
                "curve",
                "to",
                "each",
                ",",
                "resembling",
                "devil",
                "'s",
                "horns",
                "."
            ],
            [
                "She",
                "said",
                ",",
                "``",
                "Does",
                "n't",
                "he",
                "look",
                "like",
                "the",
                "devil",
                "?",
                "''"
            ],
            [
                "He",
                "DID",
                "!"
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "the",
                "guy",
                "have",
                "two",
                "tuft",
                "of",
                "hair",
                "near",
                "he",
                "temple",
                "and",
                "they",
                "be",
                "stand",
                "up",
                "on",
                "end",
                ",",
                "with",
                "a",
                "slight",
                "curve",
                "to",
                "each",
                ",",
                "resemble",
                "devil",
                "'s",
                "horn",
                "."
            ],
            [
                "she",
                "say",
                ",",
                "``",
                "do",
                "not",
                "he",
                "look",
                "like",
                "the",
                "devil",
                "?",
                "''"
            ],
            [
                "he",
                "do",
                "!"
            ]
        ],
        "label": "Anger"
    },
    {
        "body_part_token_idx": 5,
        "sentence_id": "ed251c5e-23b3-3772-ab02-594d77b2c40d",
        "tokens": [
            "Her",
            "confusion",
            "flashed",
            "across",
            "her",
            "face",
            "."
        ],
        "lemmatized_tokens": [
            "she",
            "confusion",
            "flash",
            "across",
            "she",
            "face",
            "."
        ],
        "preceding_context_tokens": [
            [
                "``",
                "More",
                "water",
                "?",
                "''"
            ],
            [
                "She",
                "nodded",
                "."
            ],
            [
                "``",
                "Would",
                "you",
                "like",
                "help",
                "?",
                "''"
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "``",
                "more",
                "water",
                "?",
                "''"
            ],
            [
                "she",
                "nod",
                "."
            ],
            [
                "``",
                "would",
                "you",
                "like",
                "help",
                "?",
                "''"
            ]
        ],
        "label": "Surprise"
    },
    {
        "body_part_token_idx": 1,
        "sentence_id": "60abb3ae-0420-32ea-8573-93e982fcd10f",
        "tokens": [
            "My",
            "heart",
            "still",
            "flutters",
            "when",
            "I",
            "think",
            "about",
            "it",
            ",",
            "it",
            "was",
            "just",
            "amazing",
            "."
        ],
        "lemmatized_tokens": [
            "my",
            "heart",
            "still",
            "flutter",
            "when",
            "I",
            "think",
            "about",
            "it",
            ",",
            "it",
            "be",
            "just",
            "amazing",
            "."
        ],
        "preceding_context_tokens": [
            [
                "They",
                "had",
                "a",
                "flutist",
                ",",
                "a",
                "harpist",
                ",",
                "a",
                "trumpter",
                ",",
                "someone",
                "on",
                "keyboard",
                ",",
                "two",
                "drummers",
                ",",
                "someone",
                "on",
                "double",
                "bass",
                ",",
                "three",
                "or",
                "four",
                "trumbones",
                ",",
                "three",
                "or",
                "four",
                "guitarists",
                "and",
                "a",
                "six",
                "person",
                "chior",
                ",",
                "the",
                "Tim",
                "DeLaughter",
                ",",
                "the",
                "main",
                "guy",
                "."
            ],
            [
                "Even",
                "though",
                "there",
                "was",
                "over",
                "twenty",
                "people",
                "on",
                "stage",
                ",",
                "they",
                "rocked",
                "hard",
                "."
            ],
            [
                "It",
                "was",
                "just",
                "such",
                "an",
                "amazing",
                "show",
                ",",
                "obviously",
                "the",
                "music",
                "was",
                "phenomenal",
                "but",
                "the",
                "lighting",
                "and",
                "atmosphere",
                "and",
                "venue",
                "and",
                "just",
                "every",
                "tiny",
                "detail",
                "contributed",
                "to",
                "the",
                "awesomeness",
                "of",
                "it",
                "all",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "they",
                "have",
                "a",
                "flutist",
                ",",
                "a",
                "harpist",
                ",",
                "a",
                "trumpter",
                ",",
                "someone",
                "on",
                "keyboard",
                ",",
                "two",
                "drummer",
                ",",
                "someone",
                "on",
                "double",
                "bass",
                ",",
                "three",
                "or",
                "four",
                "trumbone",
                ",",
                "three",
                "or",
                "four",
                "guitarist",
                "and",
                "a",
                "six",
                "person",
                "chior",
                ",",
                "the",
                "Tim",
                "DeLaughter",
                ",",
                "the",
                "main",
                "guy",
                "."
            ],
            [
                "even",
                "though",
                "there",
                "be",
                "over",
                "twenty",
                "people",
                "on",
                "stage",
                ",",
                "they",
                "rock",
                "hard",
                "."
            ],
            [
                "it",
                "be",
                "just",
                "such",
                "a",
                "amazing",
                "show",
                ",",
                "obviously",
                "the",
                "music",
                "be",
                "phenomenal",
                "but",
                "the",
                "lighting",
                "and",
                "atmosphere",
                "and",
                "venue",
                "and",
                "just",
                "every",
                "tiny",
                "detail",
                "contribute",
                "to",
                "the",
                "awesomeness",
                "of",
                "it",
                "all",
                "."
            ]
        ],
        "label": "Joy"
    },
    {
        "body_part_token_idx": 3,
        "sentence_id": "8f2f6e7c-5d55-3592-bc94-11f74a0e4ee8",
        "tokens": [
            "Robin",
            "raised",
            "his",
            "eyebrows",
            ",",
            "amused",
            ",",
            "but",
            "acquiesced",
            "with",
            "only",
            "a",
            "dry",
            "smirk",
            "and",
            "a",
            "mocking",
            "salute",
            "."
        ],
        "lemmatized_tokens": [
            "Robin",
            "raise",
            "he",
            "eyebrow",
            ",",
            "amused",
            ",",
            "but",
            "acquiesce",
            "with",
            "only",
            "a",
            "dry",
            "smirk",
            "and",
            "a",
            "mock",
            "salute",
            "."
        ],
        "preceding_context_tokens": [
            [
                "I",
                ",",
                "on",
                "the",
                "other",
                "hand",
                ",",
                "was",
                "looking",
                "for",
                "a",
                "drink",
                "of",
                "water",
                "``",
                "I",
                "am",
                "quite",
                "thirsty",
                "."
            ],
            [
                "Here",
                ",",
                "then",
                ",",
                "Marian",
                "took",
                "a",
                "mug",
                "from",
                "the",
                "side",
                "and",
                "handed",
                "it",
                "to",
                "Robin",
                ",",
                "Robin",
                ",",
                "go",
                "and",
                "fill",
                "this",
                "from",
                "the",
                "well",
                "in",
                "the",
                "yard",
                "."
            ],
            [
                "Go",
                "!"
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "I",
                ",",
                "on",
                "the",
                "other",
                "hand",
                ",",
                "be",
                "look",
                "for",
                "a",
                "drink",
                "of",
                "water",
                "``",
                "I",
                "be",
                "quite",
                "thirsty",
                "."
            ],
            [
                "here",
                ",",
                "then",
                ",",
                "Marian",
                "take",
                "a",
                "mug",
                "from",
                "the",
                "side",
                "and",
                "hand",
                "it",
                "to",
                "Robin",
                ",",
                "Robin",
                ",",
                "go",
                "and",
                "fill",
                "this",
                "from",
                "the",
                "well",
                "in",
                "the",
                "yard",
                "."
            ],
            [
                "go",
                "!"
            ]
        ],
        "label": "Joy"
    },
    {
        "body_part_token_idx": 5,
        "sentence_id": "fb8efc9a-6c96-35be-bdfa-1b70bf8a56a2",
        "tokens": [
            "I",
            "listened",
            "and",
            "put",
            "my",
            "head",
            "in",
            "my",
            "hand",
            "."
        ],
        "lemmatized_tokens": [
            "I",
            "listen",
            "and",
            "put",
            "my",
            "head",
            "in",
            "my",
            "hand",
            "."
        ],
        "preceding_context_tokens": [
            [
                "Helen",
                "left",
                "a",
                "voicemail",
                "tonight",
                "that",
                "said",
                "her",
                "vet",
                "indicated",
                "poor",
                "Lane",
                "was",
                "in",
                "the",
                "final",
                "stages",
                "of",
                "active",
                "Feline",
                "Leukemia",
                "."
            ],
            [
                "He",
                "was",
                "n't",
                "a",
                "candidate",
                "to",
                "have",
                "his",
                "remaining",
                "eye",
                "removed",
                "and",
                "he",
                "was",
                "dying",
                "."
            ],
            [
                "Helen",
                "'s",
                "voice",
                "cracked",
                "as",
                "she",
                "told",
                "me",
                "the",
                "story",
                "over",
                "voicemail",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "Helen",
                "leave",
                "a",
                "voicemail",
                "tonight",
                "that",
                "say",
                "she",
                "vet",
                "indicate",
                "poor",
                "Lane",
                "be",
                "in",
                "the",
                "final",
                "stage",
                "of",
                "active",
                "Feline",
                "Leukemia",
                "."
            ],
            [
                "he",
                "be",
                "not",
                "a",
                "candidate",
                "to",
                "have",
                "he",
                "remain",
                "eye",
                "remove",
                "and",
                "he",
                "be",
                "die",
                "."
            ],
            [
                "Helen",
                "'s",
                "voice",
                "crack",
                "as",
                "she",
                "tell",
                "I",
                "the",
                "story",
                "over",
                "voicemail",
                "."
            ]
        ],
        "label": "Sadness"
    },
    {
        "body_part_token_idx": 8,
        "sentence_id": "fb8efc9a-6c96-35be-bdfa-1b70bf8a56a2",
        "tokens": [
            "I",
            "listened",
            "and",
            "put",
            "my",
            "head",
            "in",
            "my",
            "hand",
            "."
        ],
        "lemmatized_tokens": [
            "I",
            "listen",
            "and",
            "put",
            "my",
            "head",
            "in",
            "my",
            "hand",
            "."
        ],
        "preceding_context_tokens": [
            [
                "Helen",
                "left",
                "a",
                "voicemail",
                "tonight",
                "that",
                "said",
                "her",
                "vet",
                "indicated",
                "poor",
                "Lane",
                "was",
                "in",
                "the",
                "final",
                "stages",
                "of",
                "active",
                "Feline",
                "Leukemia",
                "."
            ],
            [
                "He",
                "was",
                "n't",
                "a",
                "candidate",
                "to",
                "have",
                "his",
                "remaining",
                "eye",
                "removed",
                "and",
                "he",
                "was",
                "dying",
                "."
            ],
            [
                "Helen",
                "'s",
                "voice",
                "cracked",
                "as",
                "she",
                "told",
                "me",
                "the",
                "story",
                "over",
                "voicemail",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "Helen",
                "leave",
                "a",
                "voicemail",
                "tonight",
                "that",
                "say",
                "she",
                "vet",
                "indicate",
                "poor",
                "Lane",
                "be",
                "in",
                "the",
                "final",
                "stage",
                "of",
                "active",
                "Feline",
                "Leukemia",
                "."
            ],
            [
                "he",
                "be",
                "not",
                "a",
                "candidate",
                "to",
                "have",
                "he",
                "remain",
                "eye",
                "remove",
                "and",
                "he",
                "be",
                "die",
                "."
            ],
            [
                "Helen",
                "'s",
                "voice",
                "crack",
                "as",
                "she",
                "tell",
                "I",
                "the",
                "story",
                "over",
                "voicemail",
                "."
            ]
        ],
        "label": "Sadness"
    },
    {
        "body_part_token_idx": 3,
        "sentence_id": "d89c5d50-4d24-3b63-bd61-68ea78e1080d",
        "tokens": [
            "Allura",
            "shook",
            "her",
            "head",
            "."
        ],
        "lemmatized_tokens": [
            "Allura",
            "shake",
            "she",
            "head",
            "."
        ],
        "preceding_context_tokens": [
            [
                "Allura",
                "was",
                "quick",
                "to",
                "say",
                ",",
                "and",
                "Nanny",
                "gasped",
                "."
            ],
            [
                "``",
                "He",
                "has",
                "you",
                "believing",
                "his",
                "lies",
                "!",
                "''"
            ],
            [
                "``",
                "No",
                "...",
                "never",
                "that",
                ".",
                "''"
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "Allura",
                "be",
                "quick",
                "to",
                "say",
                ",",
                "and",
                "nanny",
                "gasp",
                "."
            ],
            [
                "``",
                "he",
                "have",
                "you",
                "believe",
                "he",
                "lie",
                "!",
                "''"
            ],
            [
                "``",
                "no",
                "...",
                "never",
                "that",
                ".",
                "''"
            ]
        ],
        "label": "Disgust"
    },
    {
        "body_part_token_idx": 12,
        "sentence_id": "b4f0e1fa-7953-3be1-9c2a-7d63ce17f82f",
        "tokens": [
            "I",
            "'m",
            "frozen",
            "for",
            "a",
            "few",
            "moments",
            ",",
            "Tears",
            "welling",
            "to",
            "my",
            "eyes",
            "as",
            "I",
            "try",
            "to",
            "squash",
            "the",
            "emotions",
            "."
        ],
        "lemmatized_tokens": [
            "I",
            "be",
            "freeze",
            "for",
            "a",
            "few",
            "moment",
            ",",
            "tear",
            "well",
            "to",
            "my",
            "eye",
            "as",
            "I",
            "try",
            "to",
            "squash",
            "the",
            "emotion",
            "."
        ],
        "preceding_context_tokens": [
            [
                "I",
                "have",
                "Pandora",
                "on",
                "at",
                "work",
                "and",
                "the",
                "song",
                "`",
                "My",
                "Immortal",
                "'",
                "by",
                "Evanescence",
                "comes",
                "on",
                "."
            ],
            [
                "The",
                "sadness",
                "&",
                "longing",
                "&",
                "hurt",
                "that",
                "song",
                "evokes",
                "is",
                "almost",
                "epic",
                "in",
                "its",
                "depth",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "I",
                "have",
                "Pandora",
                "on",
                "at",
                "work",
                "and",
                "the",
                "song",
                "`",
                "my",
                "Immortal",
                "'",
                "by",
                "evanescence",
                "come",
                "on",
                "."
            ],
            [
                "the",
                "sadness",
                "&",
                "longing",
                "&",
                "hurt",
                "that",
                "song",
                "evoke",
                "be",
                "almost",
                "epic",
                "in",
                "its",
                "depth",
                "."
            ]
        ],
        "label": "Sadness"
    },
    {
        "body_part_token_idx": 17,
        "sentence_id": "b7bdf205-7462-3061-b515-754a52e3f51f",
        "tokens": [
            "``",
            "She",
            "looked",
            "at",
            "him",
            "in",
            "a",
            "quizzical",
            "way",
            ",",
            "both",
            "brows",
            "once",
            "again",
            "raised",
            "and",
            "her",
            "head",
            "tilted",
            "just",
            "to",
            "the",
            "left",
            "."
        ],
        "lemmatized_tokens": [
            "``",
            "she",
            "look",
            "at",
            "he",
            "in",
            "a",
            "quizzical",
            "way",
            ",",
            "both",
            "brow",
            "once",
            "again",
            "raise",
            "and",
            "she",
            "head",
            "tilt",
            "just",
            "to",
            "the",
            "left",
            "."
        ],
        "preceding_context_tokens": [
            [
                "``",
                "I",
                "can",
                "tell",
                "when",
                "you",
                "'re",
                "lying",
                "."
            ],
            [
                "Humans",
                ",",
                "all",
                "of",
                "you",
                ",",
                "get",
                "this",
                "tone",
                "."
            ],
            [
                "This",
                "certain",
                "inflection",
                "that",
                "gives",
                "you",
                "away",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "``",
                "I",
                "can",
                "tell",
                "when",
                "you",
                "be",
                "lie",
                "."
            ],
            [
                "human",
                ",",
                "all",
                "of",
                "you",
                ",",
                "get",
                "this",
                "tone",
                "."
            ],
            [
                "this",
                "certain",
                "inflection",
                "that",
                "give",
                "you",
                "away",
                "."
            ]
        ],
        "label": "Surprise"
    },
    {
        "body_part_token_idx": 53,
        "sentence_id": "9d2b24ee-ad53-3404-a5e9-7181ec92f8bb",
        "tokens": [
            "Who",
            "-",
            "Yanagi",
            "Renji",
            ",",
            "Yagyuu",
            "HiroshiWhat",
            "-",
            "Yanagi",
            "gets",
            "a",
            "crash",
            "course",
            "in",
            "the",
            "How",
            "-",
            "Not",
            "-",
            "To",
            "-",
            "Piss",
            "-",
            "Off",
            "-",
            "Your",
            "-",
            "Friendly",
            "-",
            "Local",
            "-",
            "Hunter",
            "101",
            "course.When",
            "-",
            "TonightWhere",
            "-",
            "Random",
            "AlleywayRating",
            "-",
            "PG",
            "-",
            "13Yagyuu",
            "ducked",
            "into",
            "a",
            "back",
            "alley",
            "with",
            "dark",
            "scowl",
            "on",
            "his",
            "face",
            ",",
            "slipping",
            "the",
            "last",
            "part",
            "of",
            "his",
            "sniper",
            "rifer",
            "back",
            "into",
            "the",
            "backpack",
            "."
        ],
        "lemmatized_tokens": [
            "who",
            "-",
            "Yanagi",
            "Renji",
            ",",
            "Yagyuu",
            "HiroshiWhat",
            "-",
            "Yanagi",
            "get",
            "a",
            "crash",
            "course",
            "in",
            "the",
            "How",
            "-",
            "Not",
            "-",
            "To",
            "-",
            "Piss",
            "-",
            "Off",
            "-",
            "you",
            "-",
            "friendly",
            "-",
            "local",
            "-",
            "Hunter",
            "101",
            "course.when",
            "-",
            "TonightWhere",
            "-",
            "Random",
            "alleywayrating",
            "-",
            "pg",
            "-",
            "13yagyuu",
            "duck",
            "into",
            "a",
            "back",
            "alley",
            "with",
            "dark",
            "scowl",
            "on",
            "he",
            "face",
            ",",
            "slip",
            "the",
            "last",
            "part",
            "of",
            "he",
            "sniper",
            "rifer",
            "back",
            "into",
            "the",
            "backpack",
            "."
        ],
        "preceding_context_tokens": [],
        "preceding_context_lemmatized_tokens": [],
        "label": "Anger"
    },
    {
        "body_part_token_idx": 9,
        "sentence_id": "f29780c1-1949-32fe-87dd-4c14c4b603de",
        "tokens": [
            "asked",
            "Adam",
            ",",
            "looking",
            "kind",
            "of",
            "nervous",
            ",",
            "his",
            "eyes",
            "flitting",
            "between",
            "Butcher",
            "'s",
            "face",
            "and",
            "his",
            "own",
            "feet.Butcher",
            "stood",
            "up",
            "and",
            "said",
            ",",
            "``",
            "Come",
            "here",
            ",",
            "''",
            "smiling",
            "his",
            "encouragement",
            "when",
            "Adam",
            "looked",
            "up",
            "like",
            "a",
            "deer",
            "meeting",
            "a",
            "monster",
            "truck.Adam",
            "shuffled",
            "closer",
            "and",
            "Butcher",
            "met",
            "him",
            "the",
            "rest",
            "of",
            "the",
            "way",
            "."
        ],
        "lemmatized_tokens": [
            "ask",
            "Adam",
            ",",
            "look",
            "kind",
            "of",
            "nervous",
            ",",
            "he",
            "eye",
            "flit",
            "between",
            "Butcher",
            "'s",
            "face",
            "and",
            "he",
            "own",
            "feet.butcher",
            "stand",
            "up",
            "and",
            "say",
            ",",
            "``",
            "come",
            "here",
            ",",
            "''",
            "smile",
            "he",
            "encouragement",
            "when",
            "Adam",
            "look",
            "up",
            "like",
            "a",
            "deer",
            "meet",
            "a",
            "monster",
            "truck.adam",
            "shuffle",
            "closer",
            "and",
            "Butcher",
            "meet",
            "he",
            "the",
            "rest",
            "of",
            "the",
            "way",
            "."
        ],
        "preceding_context_tokens": [
            [
                "He",
                "found",
                "that",
                "he",
                "was",
                "fine",
                "with",
                "it",
                "."
            ],
            [
                "In",
                "fact",
                ",",
                "he",
                "might",
                "have",
                "been",
                "hoping",
                "for",
                "it",
                "without",
                "really",
                "realizing",
                "until",
                "now",
                "."
            ],
            [
                "``",
                "Okay",
                "?",
                "''"
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "he",
                "find",
                "that",
                "he",
                "be",
                "fine",
                "with",
                "it",
                "."
            ],
            [
                "in",
                "fact",
                ",",
                "he",
                "might",
                "have",
                "be",
                "hope",
                "for",
                "it",
                "without",
                "really",
                "realize",
                "until",
                "now",
                "."
            ],
            [
                "``",
                "okay",
                "?",
                "''"
            ]
        ],
        "label": "Fear"
    },
    {
        "body_part_token_idx": 6,
        "sentence_id": "107d0a06-9a4c-3833-a4df-2dcefa7d9b11",
        "tokens": [
            "I",
            "'m",
            "back",
            "to",
            "clenching",
            "my",
            "teeth",
            "at",
            "night",
            "."
        ],
        "lemmatized_tokens": [
            "I",
            "be",
            "back",
            "to",
            "clench",
            "my",
            "tooth",
            "at",
            "night",
            "."
        ],
        "preceding_context_tokens": [
            [
                "I",
                "find",
                "out",
                "if",
                "my",
                "son",
                "is",
                "measuring",
                "well",
                "."
            ],
            [
                "If",
                "my",
                "placenta",
                "is",
                "holding",
                "up",
                "well",
                "."
            ],
            [
                "Tomorrow",
                "is",
                "getting",
                "me",
                "riled",
                "up",
                "and",
                "its",
                "not",
                "even",
                "here",
                "yet",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "I",
                "find",
                "out",
                "if",
                "my",
                "son",
                "be",
                "measure",
                "well",
                "."
            ],
            [
                "if",
                "my",
                "placenta",
                "be",
                "hold",
                "up",
                "well",
                "."
            ],
            [
                "tomorrow",
                "be",
                "get",
                "I",
                "rile",
                "up",
                "and",
                "its",
                "not",
                "even",
                "here",
                "yet",
                "."
            ]
        ],
        "label": "Fear"
    },
    {
        "body_part_token_idx": 27,
        "sentence_id": "94a77098-b23a-33bc-8abf-f2768cb7d19d",
        "tokens": [
            "You",
            "truly",
            "have",
            "no",
            "recollection",
            "of",
            "what",
            "you",
            "have",
            "done",
            "in",
            "all",
            "of",
            "that",
            "time?",
            "She",
            "glares",
            "at",
            "him",
            ",",
            "gripping",
            "the",
            "bed",
            "sheets",
            "tightly",
            "in",
            "her",
            "fists",
            "."
        ],
        "lemmatized_tokens": [
            "you",
            "truly",
            "have",
            "no",
            "recollection",
            "of",
            "what",
            "you",
            "have",
            "do",
            "in",
            "all",
            "of",
            "that",
            "time?",
            "she",
            "glare",
            "at",
            "he",
            ",",
            "grip",
            "the",
            "bed",
            "sheet",
            "tightly",
            "in",
            "she",
            "fist",
            "."
        ],
        "preceding_context_tokens": [
            [
                "I",
                "swear",
                "to",
                "you",
                "by",
                "everything",
                "I",
                "know",
                "that",
                "the",
                "last",
                "thing",
                "I",
                "recall",
                "is",
                "being",
                "in",
                "Rabanastre",
                "."
            ],
            [
                "I",
                "was",
                "addressing",
                "my",
                "people",
                "and",
                "If",
                "you",
                "speak",
                "of",
                "the",
                "day",
                "following",
                "your",
                "intent",
                "to",
                "declare",
                "war",
                ",",
                "that",
                "was",
                "eight",
                "days",
                "ago.",
                "Eight",
                "days",
                ",",
                "she",
                "murmurs",
                "aloud",
                "."
            ],
            [
                "I",
                "have",
                "lost",
                "eight",
                "days",
                "Basch",
                "stays",
                "in",
                "place",
                ",",
                "his",
                "eyes",
                "still",
                "watching",
                "her",
                "shrewdly",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "I",
                "swear",
                "to",
                "you",
                "by",
                "everything",
                "I",
                "know",
                "that",
                "the",
                "last",
                "thing",
                "I",
                "recall",
                "be",
                "be",
                "in",
                "Rabanastre",
                "."
            ],
            [
                "I",
                "be",
                "address",
                "my",
                "people",
                "and",
                "if",
                "you",
                "speak",
                "of",
                "the",
                "day",
                "follow",
                "you",
                "intent",
                "to",
                "declare",
                "war",
                ",",
                "that",
                "be",
                "eight",
                "day",
                "ago.",
                "eight",
                "day",
                ",",
                "she",
                "murmur",
                "aloud",
                "."
            ],
            [
                "I",
                "have",
                "lose",
                "eight",
                "day",
                "Basch",
                "stay",
                "in",
                "place",
                ",",
                "he",
                "eye",
                "still",
                "watch",
                "she",
                "shrewdly",
                "."
            ]
        ],
        "label": "Anger"
    },
    {
        "body_part_token_idx": 6,
        "sentence_id": "f61afa07-3115-3798-bc1b-b823fdd26bbd",
        "tokens": [
            "It",
            "really",
            "made",
            "me",
            "tap",
            "my",
            "feet",
            "and",
            "smile",
            "!"
        ],
        "lemmatized_tokens": [
            "it",
            "really",
            "make",
            "I",
            "tap",
            "my",
            "foot",
            "and",
            "smile",
            "!"
        ],
        "preceding_context_tokens": [
            [
                "Here",
                "'s",
                "new",
                "and",
                "fresh",
                "mix",
                "from",
                "Amsterdam",
                "'s",
                "Soraya",
                ",",
                "the",
                "curator",
                "of",
                "the",
                "lovely",
                "Truants",
                "blog",
                "."
            ],
            [
                "Besides",
                "writing",
                "she",
                "also",
                "dj",
                "'s",
                "and",
                "handles",
                "both",
                "fields",
                "so",
                "well",
                "."
            ],
            [
                "Really",
                "tasteful",
                "mix",
                "of",
                "Techno",
                ",",
                "House",
                "and",
                "Dubsteppy",
                "tunes",
                "la",
                "Braiden",
                "and",
                "Timbaland",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "here",
                "be",
                "new",
                "and",
                "fresh",
                "mix",
                "from",
                "Amsterdam",
                "'s",
                "Soraya",
                ",",
                "the",
                "curator",
                "of",
                "the",
                "lovely",
                "Truants",
                "blog",
                "."
            ],
            [
                "besides",
                "write",
                "she",
                "also",
                "dj",
                "'s",
                "and",
                "handle",
                "both",
                "field",
                "so",
                "well",
                "."
            ],
            [
                "really",
                "tasteful",
                "mix",
                "of",
                "Techno",
                ",",
                "House",
                "and",
                "Dubsteppy",
                "tune",
                "la",
                "Braiden",
                "and",
                "Timbaland",
                "."
            ]
        ],
        "label": "Joy"
    },
    {
        "body_part_token_idx": 13,
        "sentence_id": "7b21d3ef-c13b-3873-86c9-f7033da93d3b",
        "tokens": [
            "``",
            "This",
            "is",
            "just",
            "my",
            "opinion",
            ",",
            "but",
            "...",
            "''",
            "He",
            "bit",
            "his",
            "lip",
            "."
        ],
        "lemmatized_tokens": [
            "``",
            "this",
            "be",
            "just",
            "my",
            "opinion",
            ",",
            "but",
            "...",
            "''",
            "he",
            "bite",
            "he",
            "lip",
            "."
        ],
        "preceding_context_tokens": [
            [
                "I",
                "'d",
                "have",
                "been",
                "happy",
                "just",
                "to",
                "be",
                "with",
                "him",
                "at",
                "all",
                "."
            ],
            [
                "I",
                "ca",
                "n't",
                "imagine",
                "he",
                "did",
                "it",
                "just",
                "for",
                "me",
                "."
            ],
            [
                "So",
                "why",
                "?",
                "''"
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "I",
                "would",
                "have",
                "be",
                "happy",
                "just",
                "to",
                "be",
                "with",
                "he",
                "at",
                "all",
                "."
            ],
            [
                "I",
                "can",
                "not",
                "imagine",
                "he",
                "do",
                "it",
                "just",
                "for",
                "I",
                "."
            ],
            [
                "so",
                "why",
                "?",
                "''"
            ]
        ],
        "label": "Fear"
    },
    {
        "body_part_token_idx": 6,
        "sentence_id": "e955c024-cb1b-3bc0-be52-98c7dcfa2bc5",
        "tokens": [
            "and",
            "yes",
            "tears",
            "rolls",
            "down",
            "her",
            "face",
            "when",
            "she",
            "saw",
            "her",
            "pictures",
            "with",
            "you",
            "."
        ],
        "lemmatized_tokens": [
            "and",
            "yes",
            "tear",
            "roll",
            "down",
            "she",
            "face",
            "when",
            "she",
            "see",
            "she",
            "picture",
            "with",
            "you",
            "."
        ],
        "preceding_context_tokens": [
            [
                "she",
                "feels",
                "SOME",
                "PAINs",
                "."
            ],
            [
                "too",
                "."
            ],
            [
                "and",
                "yet",
                "she",
                "did",
                "it",
                ",",
                "bearing",
                "the",
                "hurt",
                ",",
                "killing",
                "the",
                "pain",
                ",",
                "trying",
                "hard",
                "to",
                "survive",
                "and",
                "not",
                "to",
                "drowned",
                "inside",
                "those",
                "overwhelmed",
                "memories",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "she",
                "feel",
                "some",
                "pain",
                "."
            ],
            [
                "too",
                "."
            ],
            [
                "and",
                "yet",
                "she",
                "do",
                "it",
                ",",
                "bear",
                "the",
                "hurt",
                ",",
                "kill",
                "the",
                "pain",
                ",",
                "try",
                "hard",
                "to",
                "survive",
                "and",
                "not",
                "to",
                "drown",
                "inside",
                "those",
                "overwhelmed",
                "memory",
                "."
            ]
        ],
        "label": "Sadness"
    },
    {
        "body_part_token_idx": 1,
        "sentence_id": "67ae81b4-56de-34ad-ba9c-a2c935ecbf40",
        "tokens": [
            "Her",
            "face",
            "was",
            "red",
            "and",
            "her",
            "mouth",
            "was",
            "tight",
            "."
        ],
        "lemmatized_tokens": [
            "she",
            "face",
            "be",
            "red",
            "and",
            "she",
            "mouth",
            "be",
            "tight",
            "."
        ],
        "preceding_context_tokens": [
            [
                "Was",
                "n't",
                "she",
                "as",
                "happy",
                "as",
                "I",
                "was",
                "at",
                "the",
                "thought",
                "of",
                "being",
                "together",
                "?"
            ],
            [
                "I",
                "noticed",
                "the",
                "look",
                "on",
                "her",
                "face",
                "and",
                "realized",
                "she",
                "did",
                "n't",
                "look",
                "even",
                "mildly",
                "pleased",
                "to",
                "see",
                "me",
                "."
            ],
            [
                "There",
                "was",
                "no",
                "smile",
                "on",
                "her",
                "face",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "be",
                "not",
                "she",
                "as",
                "happy",
                "as",
                "I",
                "be",
                "at",
                "the",
                "thought",
                "of",
                "be",
                "together",
                "?"
            ],
            [
                "I",
                "notice",
                "the",
                "look",
                "on",
                "she",
                "face",
                "and",
                "realize",
                "she",
                "do",
                "not",
                "look",
                "even",
                "mildly",
                "pleased",
                "to",
                "see",
                "I",
                "."
            ],
            [
                "there",
                "be",
                "no",
                "smile",
                "on",
                "she",
                "face",
                "."
            ]
        ],
        "label": "Anger"
    },
    {
        "body_part_token_idx": 6,
        "sentence_id": "67ae81b4-56de-34ad-ba9c-a2c935ecbf40",
        "tokens": [
            "Her",
            "face",
            "was",
            "red",
            "and",
            "her",
            "mouth",
            "was",
            "tight",
            "."
        ],
        "lemmatized_tokens": [
            "she",
            "face",
            "be",
            "red",
            "and",
            "she",
            "mouth",
            "be",
            "tight",
            "."
        ],
        "preceding_context_tokens": [
            [
                "Was",
                "n't",
                "she",
                "as",
                "happy",
                "as",
                "I",
                "was",
                "at",
                "the",
                "thought",
                "of",
                "being",
                "together",
                "?"
            ],
            [
                "I",
                "noticed",
                "the",
                "look",
                "on",
                "her",
                "face",
                "and",
                "realized",
                "she",
                "did",
                "n't",
                "look",
                "even",
                "mildly",
                "pleased",
                "to",
                "see",
                "me",
                "."
            ],
            [
                "There",
                "was",
                "no",
                "smile",
                "on",
                "her",
                "face",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "be",
                "not",
                "she",
                "as",
                "happy",
                "as",
                "I",
                "be",
                "at",
                "the",
                "thought",
                "of",
                "be",
                "together",
                "?"
            ],
            [
                "I",
                "notice",
                "the",
                "look",
                "on",
                "she",
                "face",
                "and",
                "realize",
                "she",
                "do",
                "not",
                "look",
                "even",
                "mildly",
                "pleased",
                "to",
                "see",
                "I",
                "."
            ],
            [
                "there",
                "be",
                "no",
                "smile",
                "on",
                "she",
                "face",
                "."
            ]
        ],
        "label": "Anger"
    },
    {
        "body_part_token_idx": 4,
        "sentence_id": "13f17611-045e-32cb-a0fd-ee3391cb6052",
        "tokens": [
            "He",
            "'d",
            "tapped",
            "his",
            "foot",
            ",",
            "fidgeted",
            ",",
            "stared",
            "at",
            "the",
            "clock",
            ",",
            "yawned",
            "-",
            "any",
            "action",
            "he",
            "could",
            "to",
            "show",
            "his",
            "disinterest",
            "."
        ],
        "lemmatized_tokens": [
            "he",
            "have",
            "tap",
            "he",
            "foot",
            ",",
            "fidget",
            ",",
            "stare",
            "at",
            "the",
            "clock",
            ",",
            "yawn",
            "-",
            "any",
            "action",
            "he",
            "could",
            "to",
            "show",
            "he",
            "disinterest",
            "."
        ],
        "preceding_context_tokens": [
            [
                "Still",
                ",",
                "he",
                "waited",
                "."
            ],
            [
                "Minho",
                "burst",
                "out",
                "of",
                "the",
                "East",
                "Building",
                "and",
                "jogged",
                "toward",
                "the",
                "tennis",
                "courts",
                "."
            ],
            [
                "The",
                "babbling",
                ",",
                "self",
                "-",
                "centered",
                "teacher",
                "had",
                "kept",
                "going",
                "on",
                "about",
                "how",
                "to",
                "study",
                "effectively",
                "or",
                "some",
                "similar",
                "mundane",
                "subject",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "still",
                ",",
                "he",
                "wait",
                "."
            ],
            [
                "Minho",
                "burst",
                "out",
                "of",
                "the",
                "East",
                "Building",
                "and",
                "jog",
                "toward",
                "the",
                "tennis",
                "court",
                "."
            ],
            [
                "the",
                "babble",
                ",",
                "self",
                "-",
                "center",
                "teacher",
                "have",
                "keep",
                "go",
                "on",
                "about",
                "how",
                "to",
                "study",
                "effectively",
                "or",
                "some",
                "similar",
                "mundane",
                "subject",
                "."
            ]
        ],
        "label": "Sadness"
    },
    {
        "body_part_token_idx": 13,
        "sentence_id": "b02ab6df-1e41-3b3d-b8ec-bc00bb1c367b",
        "tokens": [
            "Her",
            "father",
            "was",
            "hanging",
            "up",
            "the",
            "phone",
            ",",
            "a",
            "slight",
            "frown",
            "on",
            "his",
            "face",
            "."
        ],
        "lemmatized_tokens": [
            "she",
            "father",
            "be",
            "hang",
            "up",
            "the",
            "phone",
            ",",
            "a",
            "slight",
            "frown",
            "on",
            "he",
            "face",
            "."
        ],
        "preceding_context_tokens": [
            [
                "She",
                "could",
                "n't",
                "regret",
                "loving",
                "him",
                "."
            ],
            [
                "But",
                "Jim",
                "was",
                "already",
                "an",
                "hour",
                "late",
                "to",
                "work",
                "."
            ],
            [
                "She",
                "refilled",
                "a",
                "few",
                "coffee",
                "cups",
                "and",
                "collected",
                "empty",
                "plates",
                "before",
                "heading",
                "back",
                "to",
                "the",
                "kitchen",
                ",",
                "the",
                "restaurant",
                "sounding",
                "strangely",
                "quiet",
                "without",
                "Jim",
                "'s",
                "guitar",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "she",
                "could",
                "not",
                "regret",
                "love",
                "he",
                "."
            ],
            [
                "but",
                "Jim",
                "be",
                "already",
                "a",
                "hour",
                "late",
                "to",
                "work",
                "."
            ],
            [
                "she",
                "refill",
                "a",
                "few",
                "coffee",
                "cup",
                "and",
                "collect",
                "empty",
                "plate",
                "before",
                "head",
                "back",
                "to",
                "the",
                "kitchen",
                ",",
                "the",
                "restaurant",
                "sound",
                "strangely",
                "quiet",
                "without",
                "Jim",
                "'s",
                "guitar",
                "."
            ]
        ],
        "label": "Anger"
    },
    {
        "body_part_token_idx": 20,
        "sentence_id": "7071018e-9034-3592-bb26-1d731275f8db",
        "tokens": [
            "Through",
            "the",
            "years",
            ",",
            "the",
            "weeks",
            ",",
            "the",
            "day",
            ",",
            "the",
            "hours",
            ",",
            "the",
            "minutes",
            "-",
            "the",
            "curve",
            "of",
            "her",
            "lips",
            "melted",
            "through",
            "everything",
            "."
        ],
        "lemmatized_tokens": [
            "through",
            "the",
            "year",
            ",",
            "the",
            "week",
            ",",
            "the",
            "day",
            ",",
            "the",
            "hour",
            ",",
            "the",
            "minute",
            "-",
            "the",
            "curve",
            "of",
            "she",
            "lip",
            "melt",
            "through",
            "everything",
            "."
        ],
        "preceding_context_tokens": [
            [
                "Next",
                "to",
                "him",
                ",",
                "Toni",
                "'s",
                "lips",
                "curled",
                "into",
                "a",
                "smile",
                "."
            ],
            [
                "Her",
                "soft",
                "cheeks",
                "seemed",
                "to",
                "glow",
                "a",
                "little",
                "."
            ],
            [
                "Her",
                "perfect",
                "eyes",
                "shone",
                ",",
                "and",
                "her",
                "small",
                "body",
                "grew",
                "warm",
                "beside",
                "him",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "next",
                "to",
                "he",
                ",",
                "Toni",
                "'s",
                "lip",
                "curl",
                "into",
                "a",
                "smile",
                "."
            ],
            [
                "she",
                "soft",
                "cheek",
                "seem",
                "to",
                "glow",
                "a",
                "little",
                "."
            ],
            [
                "she",
                "perfect",
                "eye",
                "shine",
                ",",
                "and",
                "she",
                "small",
                "body",
                "grow",
                "warm",
                "beside",
                "he",
                "."
            ]
        ],
        "label": "Joy"
    },
    {
        "body_part_token_idx": 15,
        "sentence_id": "45c05cf8-10b3-3f58-a340-6144d6bba7d3",
        "tokens": [
            "``",
            "Wha",
            "-",
            ",",
            "''",
            "she",
            "stopped",
            "to",
            "lick",
            "her",
            "lips",
            "again",
            "and",
            "clear",
            "her",
            "throat",
            ",",
            "``",
            "What",
            "the",
            "hell",
            "do",
            "you",
            "think",
            "you",
            "'re",
            "doing",
            "?",
            "''"
        ],
        "lemmatized_tokens": [
            "``",
            "Wha",
            "-",
            ",",
            "''",
            "she",
            "stop",
            "to",
            "lick",
            "she",
            "lip",
            "again",
            "and",
            "clear",
            "she",
            "throat",
            ",",
            "``",
            "what",
            "the",
            "hell",
            "do",
            "you",
            "think",
            "you",
            "be",
            "do",
            "?",
            "''"
        ],
        "preceding_context_tokens": [
            [
                "He",
                "was",
                "rock",
                "hard",
                "against",
                "her",
                "hip",
                "and",
                "he",
                "ground",
                "himself",
                "against",
                "her",
                "a",
                "little",
                "before",
                "he",
                "could",
                "stop",
                "himself",
                "."
            ],
            [
                "His",
                "face",
                "was",
                "so",
                "close",
                "to",
                "hers",
                "that",
                "he",
                "felt",
                "the",
                "ghost",
                "of",
                "her",
                "tongue",
                "sweep",
                "across",
                "his",
                "lips",
                "as",
                "it",
                "darted",
                "out",
                "to",
                "lick",
                "hers",
                "."
            ],
            [
                "He",
                "could",
                "feel",
                "her",
                "breath",
                "coming",
                "out",
                "fast",
                "and",
                "hot",
                "against",
                "his",
                "face",
                "and",
                "he",
                "really",
                "did",
                "groan",
                "when",
                "she",
                "wiggled",
                "again",
                "against",
                "his",
                "thigh",
                "again",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "he",
                "be",
                "rock",
                "hard",
                "against",
                "she",
                "hip",
                "and",
                "he",
                "grind",
                "himself",
                "against",
                "she",
                "a",
                "little",
                "before",
                "he",
                "could",
                "stop",
                "himself",
                "."
            ],
            [
                "he",
                "face",
                "be",
                "so",
                "close",
                "to",
                "hers",
                "that",
                "he",
                "feel",
                "the",
                "ghost",
                "of",
                "she",
                "tongue",
                "sweep",
                "across",
                "he",
                "lip",
                "as",
                "it",
                "dart",
                "out",
                "to",
                "lick",
                "hers",
                "."
            ],
            [
                "he",
                "could",
                "feel",
                "she",
                "breath",
                "come",
                "out",
                "fast",
                "and",
                "hot",
                "against",
                "he",
                "face",
                "and",
                "he",
                "really",
                "do",
                "groan",
                "when",
                "she",
                "wiggle",
                "again",
                "against",
                "he",
                "thigh",
                "again",
                "."
            ]
        ],
        "label": "Anger"
    },
    {
        "body_part_token_idx": 21,
        "sentence_id": "2d2329e9-4630-3e5d-91da-90de976158b7",
        "tokens": [
            "I",
            "bit",
            "down",
            "on",
            "my",
            "lower",
            "lip",
            ",",
            "trying",
            "as",
            "hard",
            "as",
            "I",
            "can",
            "to",
            "force",
            "back",
            "another",
            "lump",
            "in",
            "my",
            "throat",
            "."
        ],
        "lemmatized_tokens": [
            "I",
            "bite",
            "down",
            "on",
            "my",
            "lower",
            "lip",
            ",",
            "try",
            "as",
            "hard",
            "as",
            "I",
            "can",
            "to",
            "force",
            "back",
            "another",
            "lump",
            "in",
            "my",
            "throat",
            "."
        ],
        "preceding_context_tokens": [
            [
                "``",
                "I",
                "did",
                "n't",
                "really",
                "want",
                "to",
                "go",
                "back",
                "to",
                "the",
                "flat",
                "."
            ],
            [
                "I",
                "-",
                "I",
                "...",
                "could",
                "n't",
                "face",
                "it",
                ".",
                "''"
            ],
            [
                "Shit",
                ",",
                "Sian",
                "do",
                "n't",
                "you",
                "dare",
                "cry",
                "again",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "``",
                "I",
                "do",
                "not",
                "really",
                "want",
                "to",
                "go",
                "back",
                "to",
                "the",
                "flat",
                "."
            ],
            [
                "I",
                "-",
                "I",
                "...",
                "could",
                "not",
                "face",
                "it",
                ".",
                "''"
            ],
            [
                "shit",
                ",",
                "Sian",
                "do",
                "not",
                "you",
                "dare",
                "cry",
                "again",
                "."
            ]
        ],
        "label": "Sadness"
    },
    {
        "body_part_token_idx": 22,
        "sentence_id": "92f259d2-b1cb-30ed-b4df-b2714266854c",
        "tokens": [
            "I",
            "did",
            "n't",
            "know",
            "why",
            ",",
            "but",
            "the",
            "act",
            "of",
            "maintaining",
            "the",
            "position",
            "while",
            "being",
            "slapped",
            "brought",
            "tears",
            "of",
            "frustration",
            "to",
            "my",
            "eyes",
            "."
        ],
        "lemmatized_tokens": [
            "I",
            "do",
            "not",
            "know",
            "why",
            ",",
            "but",
            "the",
            "act",
            "of",
            "maintain",
            "the",
            "position",
            "while",
            "be",
            "slap",
            "bring",
            "tear",
            "of",
            "frustration",
            "to",
            "my",
            "eye",
            "."
        ],
        "preceding_context_tokens": [
            [
                "Backhanded",
                "it",
                "."
            ],
            [
                "Then",
                "slapped",
                "me",
                "."
            ],
            [
                "Again",
                ",",
                "and",
                "again",
                ",",
                "and",
                "again",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "backhand",
                "it",
                "."
            ],
            [
                "then",
                "slap",
                "I",
                "."
            ],
            [
                "again",
                ",",
                "and",
                "again",
                ",",
                "and",
                "again",
                "."
            ]
        ],
        "label": "Anger"
    },
    {
        "body_part_token_idx": 4,
        "sentence_id": "76f8afff-c10a-34da-8114-f464c617da9a",
        "tokens": [
            "Ryutaro",
            "could",
            "feel",
            "his",
            "heart",
            "to",
            "start",
            "beating",
            "fast",
            "."
        ],
        "lemmatized_tokens": [
            "Ryutaro",
            "could",
            "feel",
            "he",
            "heart",
            "to",
            "start",
            "beat",
            "fast",
            "."
        ],
        "preceding_context_tokens": [
            [
                "Chinen",
                "smiled",
                "at",
                "the",
                "younger",
                "."
            ],
            [
                "``",
                "Um...i",
                "-",
                "its",
                "not",
                "a",
                "problem",
                "...",
                "I",
                "just",
                "...",
                "hate",
                "seeing",
                "you",
                "sad",
                "...",
                "''",
                "There",
                "was",
                "a",
                "silence",
                "spread",
                "through",
                "the",
                "air",
                "."
            ],
            [
                "It",
                "was",
                "like",
                "the",
                "world",
                "stopped",
                ",",
                "as",
                "they",
                "sat",
                "there",
                ",",
                "staring",
                "at",
                "each",
                "other",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "Chinen",
                "smile",
                "at",
                "the",
                "younger",
                "."
            ],
            [
                "``",
                "Um...i",
                "-",
                "its",
                "not",
                "a",
                "problem",
                "...",
                "I",
                "just",
                "...",
                "hate",
                "see",
                "you",
                "sad",
                "...",
                "''",
                "there",
                "be",
                "a",
                "silence",
                "spread",
                "through",
                "the",
                "air",
                "."
            ],
            [
                "it",
                "be",
                "like",
                "the",
                "world",
                "stop",
                ",",
                "as",
                "they",
                "sit",
                "there",
                ",",
                "stare",
                "at",
                "each",
                "other",
                "."
            ]
        ],
        "label": "Surprise"
    },
    {
        "body_part_token_idx": 14,
        "sentence_id": "8740d0cd-a3db-3c06-bded-e10bed246f9c",
        "tokens": [
            "So",
            "I",
            "took",
            "one",
            "of",
            "him",
            ",",
            "but",
            "he",
            "still",
            "had",
            "tears",
            "in",
            "his",
            "eyes",
            "."
        ],
        "lemmatized_tokens": [
            "so",
            "I",
            "take",
            "one",
            "of",
            "he",
            ",",
            "but",
            "he",
            "still",
            "have",
            "tear",
            "in",
            "he",
            "eye",
            "."
        ],
        "preceding_context_tokens": [
            [
                "And",
                "I",
                "passed",
                "the",
                "camera",
                "around",
                "and",
                "had",
                "the",
                "kids",
                "take",
                "pictures",
                "of",
                "themselves",
                "."
            ],
            [
                "hehe",
                "."
            ],
            [
                "Joe",
                "was",
                "trying",
                "SO",
                "hard",
                "to",
                "take",
                "a",
                "photo",
                "of",
                "himself",
                "and",
                "could",
                "n't",
                "get",
                "it",
                "to",
                "work",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "and",
                "I",
                "pass",
                "the",
                "camera",
                "around",
                "and",
                "have",
                "the",
                "kid",
                "take",
                "picture",
                "of",
                "themselves",
                "."
            ],
            [
                "hehe",
                "."
            ],
            [
                "Joe",
                "be",
                "try",
                "so",
                "hard",
                "to",
                "take",
                "a",
                "photo",
                "of",
                "himself",
                "and",
                "could",
                "not",
                "get",
                "it",
                "to",
                "work",
                "."
            ]
        ],
        "label": "Anger"
    },
    {
        "body_part_token_idx": 16,
        "sentence_id": "e3565a3f-0d41-3ae2-8244-247f7120ab5f",
        "tokens": [
            "he",
            "only",
            "stands",
            "to",
            "help",
            "his",
            "girlfriend",
            "off",
            "the",
            "floor",
            ",",
            "and",
            "joo",
            "falls",
            "to",
            "her",
            "knees",
            ",",
            "not",
            "wanting",
            "to",
            "believe",
            "that",
            "this",
            "woman",
            "had",
            "taken",
            "her",
            "place",
            "in",
            "such",
            "a",
            "short",
            "time",
            "."
        ],
        "lemmatized_tokens": [
            "he",
            "only",
            "stand",
            "to",
            "help",
            "he",
            "girlfriend",
            "off",
            "the",
            "floor",
            ",",
            "and",
            "joo",
            "fall",
            "to",
            "she",
            "knee",
            ",",
            "not",
            "want",
            "to",
            "believe",
            "that",
            "this",
            "woman",
            "have",
            "take",
            "she",
            "place",
            "in",
            "such",
            "a",
            "short",
            "time",
            "."
        ],
        "preceding_context_tokens": [
            [
                "she",
                "just",
                "stood",
                "there",
                "and",
                "watched",
                ",",
                "stared",
                ",",
                "stunned",
                ",",
                "shunned",
                "by",
                "the",
                "bitterly",
                "cold",
                "wind",
                "."
            ],
            [
                "and",
                "then",
                "she",
                "kicked",
                "down",
                "the",
                "door",
                ",",
                "and",
                "waited",
                "with",
                "baited",
                "breath",
                "for",
                "his",
                "reaction",
                "."
            ],
            [
                "did",
                "he",
                "really",
                "leave",
                "her",
                "behind",
                "?"
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "she",
                "just",
                "stand",
                "there",
                "and",
                "watch",
                ",",
                "stare",
                ",",
                "stun",
                ",",
                "shun",
                "by",
                "the",
                "bitterly",
                "cold",
                "wind",
                "."
            ],
            [
                "and",
                "then",
                "she",
                "kick",
                "down",
                "the",
                "door",
                ",",
                "and",
                "wait",
                "with",
                "baited",
                "breath",
                "for",
                "he",
                "reaction",
                "."
            ],
            [
                "do",
                "he",
                "really",
                "leave",
                "she",
                "behind",
                "?"
            ]
        ],
        "label": "Sadness"
    },
    {
        "body_part_token_idx": 7,
        "sentence_id": "470005ba-4e83-3abc-96fb-8aeadec1bec8",
        "tokens": [
            "In",
            "fact",
            ",",
            "she",
            "sits",
            "with",
            "her",
            "mouth",
            "wide",
            "open",
            "."
        ],
        "lemmatized_tokens": [
            "in",
            "fact",
            ",",
            "she",
            "sit",
            "with",
            "she",
            "mouth",
            "wide",
            "open",
            "."
        ],
        "preceding_context_tokens": [
            [
                "I",
                "remain",
                "completely",
                "flabergasted",
                "."
            ],
            [
                "I",
                "look",
                "to",
                "my",
                "roommate",
                "for",
                "help",
                "."
            ],
            [
                "She",
                "'s",
                "just",
                "as",
                "confused",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "I",
                "remain",
                "completely",
                "flabergast",
                "."
            ],
            [
                "I",
                "look",
                "to",
                "my",
                "roommate",
                "for",
                "help",
                "."
            ],
            [
                "she",
                "be",
                "just",
                "as",
                "confused",
                "."
            ]
        ],
        "label": "Surprise"
    },
    {
        "body_part_token_idx": 10,
        "sentence_id": "b5470834-af7c-3ff3-a012-eaa19a7eb7d0",
        "tokens": [
            "A",
            "wave",
            "of",
            "something",
            "sharp",
            "and",
            "heavy",
            "swelled",
            "in",
            "his",
            "chest",
            ";",
            "he",
            "'s",
            "not",
            "used",
            "to",
            "not",
            "knowing",
            "where",
            "to",
            "go",
            "."
        ],
        "lemmatized_tokens": [
            "a",
            "wave",
            "of",
            "something",
            "sharp",
            "and",
            "heavy",
            "swell",
            "in",
            "he",
            "chest",
            ";",
            "he",
            "be",
            "not",
            "use",
            "to",
            "not",
            "know",
            "where",
            "to",
            "go",
            "."
        ],
        "preceding_context_tokens": [
            [
                "There",
                ",",
                "he",
                "stood",
                "not",
                "knowing",
                "what",
                "to",
                "do",
                "until",
                "the",
                "door",
                "closed",
                "and",
                "he",
                "was",
                "left",
                "with",
                "pressing",
                ",",
                "anticipating",
                "silence",
                "."
            ],
            [
                "He",
                "stabbed",
                "at",
                "GF",
                "'",
                "and",
                "tapped",
                "his",
                "foot",
                "all",
                "the",
                "way",
                "down",
                "."
            ],
            [
                "He",
                "rarely",
                "felt",
                "this",
                "impatient",
                "with",
                "anything",
                "but",
                "halfway",
                "through",
                "he",
                "was",
                "convinced",
                "that",
                "the",
                "gods",
                "of",
                "elevators",
                "were",
                "tormenting",
                "him",
                "for",
                "wrongdoings",
                "in",
                "a",
                "past",
                "life.He",
                "took",
                "a",
                "deep",
                "breath",
                "when",
                "the",
                "door",
                "slid",
                "open",
                ",",
                "and",
                "suddenly",
                "there",
                "were",
                "too",
                "many",
                "directions",
                "and",
                "he",
                "was",
                "fumbling",
                "without",
                "a",
                "compass",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "there",
                ",",
                "he",
                "stand",
                "not",
                "know",
                "what",
                "to",
                "do",
                "until",
                "the",
                "door",
                "closed",
                "and",
                "he",
                "be",
                "leave",
                "with",
                "press",
                ",",
                "anticipate",
                "silence",
                "."
            ],
            [
                "he",
                "stab",
                "at",
                "gf",
                "'",
                "and",
                "tap",
                "he",
                "foot",
                "all",
                "the",
                "way",
                "down",
                "."
            ],
            [
                "he",
                "rarely",
                "feel",
                "this",
                "impatient",
                "with",
                "anything",
                "but",
                "halfway",
                "through",
                "he",
                "be",
                "convince",
                "that",
                "the",
                "god",
                "of",
                "elevator",
                "be",
                "torment",
                "he",
                "for",
                "wrongdoing",
                "in",
                "a",
                "past",
                "life.He",
                "take",
                "a",
                "deep",
                "breath",
                "when",
                "the",
                "door",
                "slide",
                "open",
                ",",
                "and",
                "suddenly",
                "there",
                "be",
                "too",
                "many",
                "direction",
                "and",
                "he",
                "be",
                "fumble",
                "without",
                "a",
                "compass",
                "."
            ]
        ],
        "label": "Fear"
    },
    {
        "body_part_token_idx": 21,
        "sentence_id": "cd76b467-9fe9-338d-9aa2-36ca561c3109",
        "tokens": [
            "He",
            "let",
            "me",
            "go",
            "and",
            "looked",
            "at",
            "me",
            "for",
            "a",
            "long",
            "moment",
            ",",
            "and",
            "then",
            "he",
            "smiled",
            ",",
            "shaking",
            "slowly",
            "his",
            "head",
            "."
        ],
        "lemmatized_tokens": [
            "he",
            "let",
            "I",
            "go",
            "and",
            "look",
            "at",
            "I",
            "for",
            "a",
            "long",
            "moment",
            ",",
            "and",
            "then",
            "he",
            "smile",
            ",",
            "shake",
            "slowly",
            "he",
            "head",
            "."
        ],
        "preceding_context_tokens": [
            [
                "He",
                "stopped",
                "short",
                "in",
                "front",
                "of",
                "me",
                ",",
                "and",
                "after",
                "a",
                "moment",
                "'s",
                "hesitation",
                "he",
                "drew",
                "me",
                "into",
                "an",
                "embrace",
                "."
            ],
            [
                "``",
                "Boy",
                "!"
            ],
            [
                "I",
                "'m",
                "so",
                "happy",
                "to",
                "see",
                "you",
                "again",
                ".",
                "''"
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "he",
                "stop",
                "short",
                "in",
                "front",
                "of",
                "I",
                ",",
                "and",
                "after",
                "a",
                "moment",
                "'s",
                "hesitation",
                "he",
                "draw",
                "I",
                "into",
                "a",
                "embrace",
                "."
            ],
            [
                "``",
                "boy",
                "!"
            ],
            [
                "I",
                "be",
                "so",
                "happy",
                "to",
                "see",
                "you",
                "again",
                ".",
                "''"
            ]
        ],
        "label": "Joy"
    },
    {
        "body_part_token_idx": 1,
        "sentence_id": "825c2f68-ad4f-3dfb-87fe-25cc39e06660",
        "tokens": [
            "My",
            "cheeks",
            "flushed",
            "and",
            "my",
            "heart",
            "raced",
            "."
        ],
        "lemmatized_tokens": [
            "my",
            "cheek",
            "flush",
            "and",
            "my",
            "heart",
            "race",
            "."
        ],
        "preceding_context_tokens": [
            [
                "As",
                "my",
                "eyes",
                "rolled",
                "up",
                "her",
                "buxom",
                "shape",
                ",",
                "she",
                "shot",
                "me",
                "a",
                "glance",
                "from",
                "her",
                "black",
                "-",
                "rim",
                "glasses",
                "."
            ],
            [
                "A",
                "smile",
                "grew",
                "from",
                "cheek",
                "to",
                "chiseled",
                "cheek",
                "on",
                "the",
                "rounded",
                "moon",
                "of",
                "her",
                "face",
                "."
            ],
            [
                "Her",
                "eyes",
                "shot",
                "away",
                "and",
                "color",
                "bloomed",
                "on",
                "her",
                "cheeks",
                "as",
                "she",
                "continued",
                "to",
                "chat",
                "with",
                "her",
                "friend.I",
                "'d",
                "been",
                "caught",
                "!"
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "as",
                "my",
                "eye",
                "roll",
                "up",
                "she",
                "buxom",
                "shape",
                ",",
                "she",
                "shoot",
                "I",
                "a",
                "glance",
                "from",
                "she",
                "black",
                "-",
                "rim",
                "glass",
                "."
            ],
            [
                "a",
                "smile",
                "grow",
                "from",
                "cheek",
                "to",
                "chisel",
                "cheek",
                "on",
                "the",
                "rounded",
                "moon",
                "of",
                "she",
                "face",
                "."
            ],
            [
                "she",
                "eye",
                "shoot",
                "away",
                "and",
                "color",
                "bloom",
                "on",
                "she",
                "cheek",
                "as",
                "she",
                "continue",
                "to",
                "chat",
                "with",
                "she",
                "friend.i",
                "have",
                "be",
                "catch",
                "!"
            ]
        ],
        "label": "Fear"
    },
    {
        "body_part_token_idx": 5,
        "sentence_id": "825c2f68-ad4f-3dfb-87fe-25cc39e06660",
        "tokens": [
            "My",
            "cheeks",
            "flushed",
            "and",
            "my",
            "heart",
            "raced",
            "."
        ],
        "lemmatized_tokens": [
            "my",
            "cheek",
            "flush",
            "and",
            "my",
            "heart",
            "race",
            "."
        ],
        "preceding_context_tokens": [
            [
                "As",
                "my",
                "eyes",
                "rolled",
                "up",
                "her",
                "buxom",
                "shape",
                ",",
                "she",
                "shot",
                "me",
                "a",
                "glance",
                "from",
                "her",
                "black",
                "-",
                "rim",
                "glasses",
                "."
            ],
            [
                "A",
                "smile",
                "grew",
                "from",
                "cheek",
                "to",
                "chiseled",
                "cheek",
                "on",
                "the",
                "rounded",
                "moon",
                "of",
                "her",
                "face",
                "."
            ],
            [
                "Her",
                "eyes",
                "shot",
                "away",
                "and",
                "color",
                "bloomed",
                "on",
                "her",
                "cheeks",
                "as",
                "she",
                "continued",
                "to",
                "chat",
                "with",
                "her",
                "friend.I",
                "'d",
                "been",
                "caught",
                "!"
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "as",
                "my",
                "eye",
                "roll",
                "up",
                "she",
                "buxom",
                "shape",
                ",",
                "she",
                "shoot",
                "I",
                "a",
                "glance",
                "from",
                "she",
                "black",
                "-",
                "rim",
                "glass",
                "."
            ],
            [
                "a",
                "smile",
                "grow",
                "from",
                "cheek",
                "to",
                "chisel",
                "cheek",
                "on",
                "the",
                "rounded",
                "moon",
                "of",
                "she",
                "face",
                "."
            ],
            [
                "she",
                "eye",
                "shoot",
                "away",
                "and",
                "color",
                "bloom",
                "on",
                "she",
                "cheek",
                "as",
                "she",
                "continue",
                "to",
                "chat",
                "with",
                "she",
                "friend.i",
                "have",
                "be",
                "catch",
                "!"
            ]
        ],
        "label": "Surprise"
    },
    {
        "body_part_token_idx": 14,
        "sentence_id": "5f4c64c9-e62d-3aa0-b923-61f959e34de7",
        "tokens": [
            "``",
            "Oh",
            ",",
            "Christ",
            ",",
            "the",
            "glitter",
            ",",
            "''",
            "Adrienne",
            "laughed",
            ",",
            "shaking",
            "her",
            "head",
            "in",
            "amusement",
            "."
        ],
        "lemmatized_tokens": [
            "``",
            "oh",
            ",",
            "Christ",
            ",",
            "the",
            "glitter",
            ",",
            "''",
            "Adrienne",
            "laugh",
            ",",
            "shake",
            "she",
            "head",
            "in",
            "amusement",
            "."
        ],
        "preceding_context_tokens": [
            [
                "There",
                "were",
                ",",
                "however",
                ",",
                "pyramid",
                "studs",
                "down",
                "the",
                "outseam",
                "of",
                "each",
                "leg",
                ",",
                "however",
                "."
            ],
            [
                "``",
                "Think",
                "of",
                "'em",
                "like",
                "crotchless",
                "pants",
                "."
            ],
            [
                "I",
                "have",
                "n't",
                "worn",
                "them",
                "in",
                "forever",
                "so",
                "they",
                "might",
                "not",
                "be",
                "as",
                "long",
                "as",
                "my",
                "normal",
                "pants",
                ".",
                "''"
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "there",
                "be",
                ",",
                "however",
                ",",
                "pyramid",
                "stud",
                "down",
                "the",
                "outseam",
                "of",
                "each",
                "leg",
                ",",
                "however",
                "."
            ],
            [
                "``",
                "think",
                "of",
                "'em",
                "like",
                "crotchless",
                "pants",
                "."
            ],
            [
                "I",
                "have",
                "not",
                "wear",
                "they",
                "in",
                "forever",
                "so",
                "they",
                "might",
                "not",
                "be",
                "as",
                "long",
                "as",
                "my",
                "normal",
                "pants",
                ".",
                "''"
            ]
        ],
        "label": "Joy"
    },
    {
        "body_part_token_idx": 41,
        "sentence_id": "e0f56cd4-defa-3dd4-8699-f91c5dfea782",
        "tokens": [
            "And",
            "this",
            "pal",
            "of",
            "mine",
            ",",
            "along",
            "with",
            "another",
            "friend",
            "'s",
            "mum",
            "went",
            "up",
            "to",
            "the",
            "stage",
            "to",
            "''",
            "meet",
            "the",
            "bride",
            "''",
            "-",
            "Now",
            ",",
            "whenever",
            "I",
            "actually",
            "land",
            "up",
            "on",
            "the",
            "stage",
            ",",
            "I",
            "'m",
            "like",
            "...",
            "shuffling",
            "my",
            "feet",
            "about",
            ",",
            "totally",
            "at",
            "a",
            "loss",
            "as",
            "to",
            "what",
            "should",
            "I",
            "SAY",
            ",",
            "-LRB-",
            "except",
            "Salam",
            ")",
            "."
        ],
        "lemmatized_tokens": [
            "and",
            "this",
            "pal",
            "of",
            "mine",
            ",",
            "along",
            "with",
            "another",
            "friend",
            "'s",
            "mum",
            "go",
            "up",
            "to",
            "the",
            "stage",
            "to",
            "''",
            "meet",
            "the",
            "bride",
            "''",
            "-",
            "now",
            ",",
            "whenever",
            "I",
            "actually",
            "land",
            "up",
            "on",
            "the",
            "stage",
            ",",
            "I",
            "be",
            "like",
            "...",
            "shuffling",
            "my",
            "foot",
            "about",
            ",",
            "totally",
            "at",
            "a",
            "loss",
            "as",
            "to",
            "what",
            "should",
            "I",
            "say",
            ",",
            "-LRB-",
            "except",
            "Salam",
            ")",
            "."
        ],
        "preceding_context_tokens": [
            [
                "One",
                "incident",
                "I",
                "'ll",
                "relate",
                "."
            ],
            [
                "So",
                "what",
                "happened",
                "was",
                "that",
                "this",
                "cousin",
                "of",
                "mine",
                "-LRB-",
                "the",
                "bride",
                ")",
                "was",
                "in",
                "my",
                "school",
                "-",
                "so",
                "other",
                "friends",
                "were",
                "also",
                "there",
                "."
            ],
            [
                "Alif",
                "Bay",
                "Pay",
                "was",
                "also",
                "there",
                "-LRB-",
                "bffffff",
                "ca",
                "n't",
                "stop",
                "the",
                "fs",
                ")",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "one",
                "incident",
                "I",
                "will",
                "relate",
                "."
            ],
            [
                "so",
                "what",
                "happen",
                "be",
                "that",
                "this",
                "cousin",
                "of",
                "mine",
                "-lrb-_VBD",
                "the",
                "bride",
                ")",
                "be",
                "in",
                "my",
                "school",
                "-",
                "so",
                "other",
                "friend",
                "be",
                "also",
                "there",
                "."
            ],
            [
                "Alif",
                "Bay",
                "Pay",
                "be",
                "also",
                "there",
                "-lrb-",
                "bffffff",
                "can",
                "not",
                "stop",
                "the",
                "f",
                ")",
                "."
            ]
        ],
        "label": "Fear"
    },
    {
        "body_part_token_idx": 14,
        "sentence_id": "bbf9a115-c784-3dcd-9174-9712e11c3b03",
        "tokens": [
            "I",
            "it",
            "'s",
            "not",
            "all",
            "I",
            "mean",
            "Emma",
            "raised",
            "a",
            "hand",
            "and",
            "shook",
            "her",
            "head",
            "."
        ],
        "lemmatized_tokens": [
            "I",
            "it",
            "be",
            "not",
            "all",
            "I",
            "mean",
            "Emma",
            "raise",
            "a",
            "hand",
            "and",
            "shake",
            "she",
            "head",
            "."
        ],
        "preceding_context_tokens": [
            [
                "She",
                "made",
                "a",
                "quick",
                "mental",
                "note",
                "to",
                "get",
                "Angie",
                "Bragnaugh",
                "the",
                "best",
                "thank",
                "you",
                "gift",
                "she",
                "could",
                "find",
                "."
            ],
            [
                "Just",
                "as",
                "Pepper",
                "was",
                "on",
                "the",
                "edge",
                "of",
                "sleep",
                "again",
                ",",
                "a",
                "strong",
                "but",
                "gentle",
                "voice",
                "stirred",
                "her",
                "."
            ],
            [
                "I",
                "'m",
                "pretty",
                "sure",
                "the",
                "things",
                "they",
                "say",
                "on",
                "the",
                "television",
                "are",
                "an",
                "exaggeration",
                ",",
                "at",
                "best.",
                "Pepper",
                "held",
                "her",
                "breath",
                "and",
                "raised",
                "her",
                "head",
                "slowly",
                ",",
                "carefully",
                "searching",
                "Emma",
                "'s",
                "eyes",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "she",
                "make",
                "a",
                "quick",
                "mental",
                "note",
                "to",
                "get",
                "Angie",
                "Bragnaugh",
                "the",
                "best",
                "thank",
                "you",
                "gift",
                "she",
                "could",
                "find",
                "."
            ],
            [
                "just",
                "as",
                "Pepper",
                "be",
                "on",
                "the",
                "edge",
                "of",
                "sleep",
                "again",
                ",",
                "a",
                "strong",
                "but",
                "gentle",
                "voice",
                "stir",
                "she",
                "."
            ],
            [
                "I",
                "be",
                "pretty",
                "sure",
                "the",
                "thing",
                "they",
                "say",
                "on",
                "the",
                "television",
                "be",
                "a",
                "exaggeration",
                ",",
                "at",
                "best.",
                "Pepper",
                "hold",
                "she",
                "breath",
                "and",
                "raise",
                "she",
                "head",
                "slowly",
                ",",
                "carefully",
                "search",
                "Emma",
                "'s",
                "eye",
                "."
            ]
        ],
        "label": "Disgust"
    },
    {
        "body_part_token_idx": 22,
        "sentence_id": "ff93d959-bad0-3a0c-a7b8-5252069326d2",
        "tokens": [
            "I",
            "paused",
            "and",
            "thought",
            "about",
            "what",
            "he",
            "was",
            "saying",
            ",",
            "blinking",
            "my",
            "eyes",
            "repeatedly",
            ",",
            "staring",
            "at",
            "his",
            "dimples",
            "forming",
            "on",
            "his",
            "cheeks",
            "."
        ],
        "lemmatized_tokens": [
            "I",
            "pause",
            "and",
            "think",
            "about",
            "what",
            "he",
            "be",
            "say",
            ",",
            "blink",
            "my",
            "eye",
            "repeatedly",
            ",",
            "stare",
            "at",
            "he",
            "dimple",
            "form",
            "on",
            "he",
            "cheek",
            "."
        ],
        "preceding_context_tokens": [
            [
                "I",
                "'m",
                "his",
                "best",
                "friend",
                "."
            ],
            [
                "I",
                "'ll",
                "know",
                "how",
                "it",
                "really",
                "is",
                "."
            ],
            [
                "Just",
                "come",
                "upstairs",
                "with",
                "me",
                "so",
                "no",
                "one",
                "else",
                "can",
                "hear",
                ".",
                "''"
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "I",
                "be",
                "he",
                "best",
                "friend",
                "."
            ],
            [
                "I",
                "will",
                "know",
                "how",
                "it",
                "really",
                "be",
                "."
            ],
            [
                "just",
                "come",
                "upstairs",
                "with",
                "I",
                "so",
                "no",
                "one",
                "else",
                "can",
                "hear",
                ".",
                "''"
            ]
        ],
        "label": "Joy"
    },
    {
        "body_part_token_idx": 3,
        "sentence_id": "f48ce416-f8d3-3e92-8631-5d7499a7e703",
        "tokens": [
            "He",
            "closed",
            "his",
            "eyes",
            "."
        ],
        "lemmatized_tokens": [
            "he",
            "close",
            "he",
            "eye",
            "."
        ],
        "preceding_context_tokens": [
            [
                "Zarkon",
                "nodded",
                ",",
                "and",
                "Borrh",
                "an",
                "held",
                "her",
                "breath",
                ",",
                "holding",
                "his",
                "hand",
                "for",
                "support",
                ";",
                "he",
                "gripped",
                "in",
                "kind",
                "."
            ],
            [
                "If",
                "all",
                "goes",
                "well",
                ",",
                "you",
                "'ll",
                "have",
                "a",
                "son",
                "."
            ],
            [
                "One",
                "son",
                ",",
                "two",
                "hearts",
                ",",
                "Zarkon",
                "whispered",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "Zarkon",
                "nod",
                ",",
                "and",
                "Borrh",
                "a",
                "hold",
                "she",
                "breath",
                ",",
                "hold",
                "he",
                "hand",
                "for",
                "support",
                ";",
                "he",
                "grip",
                "in",
                "kind",
                "."
            ],
            [
                "if",
                "all",
                "go",
                "well",
                ",",
                "you",
                "will",
                "have",
                "a",
                "son",
                "."
            ],
            [
                "one",
                "son",
                ",",
                "two",
                "heart",
                ",",
                "Zarkon",
                "whisper",
                "."
            ]
        ],
        "label": "Fear"
    },
    {
        "body_part_token_idx": 1,
        "sentence_id": "fcad4f51-9678-39ff-8f23-f0d0be9ee2ec",
        "tokens": [
            "My",
            "heart",
            "starts",
            "pounding",
            "as",
            "my",
            "eyes",
            "scroll",
            "up",
            "the",
            "dress",
            "and",
            "it",
            "was",
            "Scarlett",
            "."
        ],
        "lemmatized_tokens": [
            "my",
            "heart",
            "start",
            "pound",
            "as",
            "my",
            "eye",
            "scroll",
            "up",
            "the",
            "dress",
            "and",
            "it",
            "be",
            "Scarlett",
            "."
        ],
        "preceding_context_tokens": [
            [
                "He",
                "makes",
                "my",
                "drink",
                "and",
                "we",
                "watch",
                "the",
                "game",
                "up",
                "on",
                "the",
                "big",
                "screen",
                "."
            ],
            [
                "We",
                "talk",
                "about",
                "how",
                "the",
                "cherry",
                "reminds",
                "us",
                "of",
                "the",
                "clit",
                "and",
                "then",
                "I",
                "eat",
                "the",
                "cherry",
                "and",
                "we",
                "laugh",
                "at",
                "what",
                "a",
                "jackass",
                "I",
                "still",
                "am",
                ",",
                "after",
                "all",
                "these",
                "years",
                "."
            ],
            [
                "I",
                "'m",
                "laughing",
                "and",
                "I",
                "see",
                "red",
                ";",
                "a",
                "red",
                "dress",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "he",
                "make",
                "my",
                "drink",
                "and",
                "we",
                "watch",
                "the",
                "game",
                "up",
                "on",
                "the",
                "big",
                "screen",
                "."
            ],
            [
                "we",
                "talk",
                "about",
                "how",
                "the",
                "cherry",
                "remind",
                "we",
                "of",
                "the",
                "clit",
                "and",
                "then",
                "I",
                "eat",
                "the",
                "cherry",
                "and",
                "we",
                "laugh",
                "at",
                "what",
                "a",
                "jackass",
                "I",
                "still",
                "be",
                ",",
                "after",
                "all",
                "these",
                "year",
                "."
            ],
            [
                "I",
                "be",
                "laugh",
                "and",
                "I",
                "see",
                "red",
                ";",
                "a",
                "red",
                "dress",
                "."
            ]
        ],
        "label": "Surprise"
    },
    {
        "body_part_token_idx": 1,
        "sentence_id": "2b51949c-9cd3-3dc4-9094-8a2b012dc227",
        "tokens": [
            "His",
            "skin",
            "felt",
            "disgusting",
            "and",
            "tight",
            "on",
            "his",
            "body",
            "and",
            "he",
            "wished",
            "for",
            "unconsciousness",
            "to",
            "escape",
            "existence",
            "for",
            "a",
            "while",
            "."
        ],
        "lemmatized_tokens": [
            "he",
            "skin",
            "feel",
            "disgusting",
            "and",
            "tight",
            "on",
            "he",
            "body",
            "and",
            "he",
            "wish",
            "for",
            "unconsciousness",
            "to",
            "escape",
            "existence",
            "for",
            "a",
            "while",
            "."
        ],
        "preceding_context_tokens": [
            [
                "Images",
                "of",
                "the",
                "events",
                "happening",
                "the",
                "day",
                "before",
                "flashed",
                "behind",
                "his",
                "eyelids",
                "."
            ],
            [
                "A",
                "choked",
                "sob",
                "made",
                "his",
                "body",
                "tremble",
                "as",
                "he",
                "wrapped",
                "sore",
                "limbs",
                "around",
                "his",
                "middle",
                "and",
                "curled",
                "into",
                "a",
                "ball",
                "under",
                "the",
                "warm",
                "blankets",
                "."
            ],
            [
                "He",
                "tried",
                "to",
                "fall",
                "asleep",
                "again",
                "to",
                "no",
                "avail",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "image",
                "of",
                "the",
                "event",
                "happen",
                "the",
                "day",
                "before",
                "flash",
                "behind",
                "he",
                "eyelid",
                "."
            ],
            [
                "a",
                "choke",
                "sob",
                "make",
                "he",
                "body",
                "tremble",
                "as",
                "he",
                "wrap",
                "sore",
                "limb",
                "around",
                "he",
                "middle",
                "and",
                "curl",
                "into",
                "a",
                "ball",
                "under",
                "the",
                "warm",
                "blanket",
                "."
            ],
            [
                "he",
                "try",
                "to",
                "fall",
                "asleep",
                "again",
                "to",
                "no",
                "avail",
                "."
            ]
        ],
        "label": "Disgust"
    },
    {
        "body_part_token_idx": 18,
        "sentence_id": "d80882b5-382a-3fa2-b27a-d4a9b6ca3bde",
        "tokens": [
            "Staying",
            "with",
            "a",
            "friend",
            "in",
            "Auburn",
            ",",
            "we",
            "awoke",
            "on",
            "a",
            "Wednesday",
            "morning",
            ",",
            "walked",
            "outside",
            "and",
            "my",
            "jaw",
            "just",
            "dropped",
            "."
        ],
        "lemmatized_tokens": [
            "stay",
            "with",
            "a",
            "friend",
            "in",
            "auburn",
            ",",
            "we",
            "awake",
            "on",
            "a",
            "Wednesday",
            "morning",
            ",",
            "walk",
            "outside",
            "and",
            "my",
            "jaw",
            "just",
            "drop",
            "."
        ],
        "preceding_context_tokens": [
            [
                "But",
                "despite",
                "all",
                "of",
                "its",
                "potential",
                "depressing",
                "effects",
                ",",
                "winter",
                "at",
                "Bates",
                "is",
                "MAGICAL",
                "."
            ],
            [
                "And",
                "I",
                "say",
                "magical",
                "because",
                "I",
                "mean",
                "it",
                "'s",
                "of",
                "or",
                "pertaining",
                "to",
                "magic",
                "and",
                "mysteriously",
                "enchanting",
                "."
            ],
            [
                "My",
                "favorite",
                "winter",
                "day",
                "this",
                "academic",
                "year",
                "would",
                "have",
                "to",
                "be",
                "the",
                "ice",
                "storm",
                "in",
                "February",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "but",
                "despite",
                "all",
                "of",
                "its",
                "potential",
                "depressing",
                "effect",
                ",",
                "winter",
                "at",
                "Bates",
                "be",
                "magical",
                "."
            ],
            [
                "and",
                "I",
                "say",
                "magical",
                "because",
                "I",
                "mean",
                "it",
                "be",
                "of",
                "or",
                "pertain",
                "to",
                "magic",
                "and",
                "mysteriously",
                "enchanting",
                "."
            ],
            [
                "my",
                "favorite",
                "winter",
                "day",
                "this",
                "academic",
                "year",
                "would",
                "have",
                "to",
                "be",
                "the",
                "ice",
                "storm",
                "in",
                "February",
                "."
            ]
        ],
        "label": "Surprise"
    },
    {
        "body_part_token_idx": 20,
        "sentence_id": "657d9b92-ec6a-38e1-b4c0-bc376b79d16f",
        "tokens": [
            "You",
            "could",
            "say",
            "I",
            "am",
            "lucky",
            "I",
            "guess",
            ",",
            "when",
            "I",
            "cry",
            "I",
            "do",
            "n't",
            "make",
            "a",
            "sound",
            "and",
            "my",
            "eyes",
            "never",
            "turn",
            "red",
            ",",
            "the",
            "tears",
            "just",
            "flow",
            "like",
            "rain",
            "."
        ],
        "lemmatized_tokens": [
            "you",
            "could",
            "say",
            "I",
            "be",
            "lucky",
            "I",
            "guess",
            ",",
            "when",
            "I",
            "cry",
            "I",
            "do",
            "not",
            "make",
            "a",
            "sound",
            "and",
            "my",
            "eye",
            "never",
            "turn",
            "red",
            ",",
            "the",
            "tear",
            "just",
            "flow",
            "like",
            "rain",
            "."
        ],
        "preceding_context_tokens": [
            [
                "I",
                "had",
                "instantly",
                "packed",
                "a",
                "suitcase",
                "and",
                "cried",
                "softly",
                "to",
                "myself",
                "and",
                "waited",
                "for",
                "morning",
                "to",
                "come",
                "and",
                "the",
                "sun",
                "to",
                "peek",
                "through",
                "my",
                "window",
                ",",
                "I",
                "would",
                "not",
                "sleep",
                "this",
                "night.I",
                "am",
                "suddenly",
                "jerked",
                "back",
                "to",
                "the",
                "present",
                "when",
                "I",
                "feel",
                "cool",
                "crisp",
                "water",
                "dripping",
                "onto",
                "my",
                "hand",
                "and",
                "taste",
                "my",
                "own",
                "salty",
                "tears",
                "."
            ],
            [
                "I",
                "quickly",
                "reach",
                "up",
                "to",
                "wipe",
                "them",
                "away",
                "and",
                "look",
                "up",
                "to",
                "Trent",
                "and",
                "Nina",
                "at",
                "the",
                "alter",
                "holding",
                "hands",
                "smiling",
                "at",
                "each",
                "other",
                ",",
                "``",
                "I",
                "do",
                ",",
                "''",
                "they",
                "both",
                "say",
                "in",
                "unison",
                "."
            ],
            [
                "My",
                "head",
                "drops",
                "to",
                "conceal",
                "the",
                "tears",
                "now",
                "flowing",
                "freely",
                "from",
                "my",
                "eyes",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "I",
                "have",
                "instantly",
                "pack",
                "a",
                "suitcase",
                "and",
                "cry",
                "softly",
                "to",
                "myself",
                "and",
                "wait",
                "for",
                "morning",
                "to",
                "come",
                "and",
                "the",
                "sun",
                "to",
                "peek",
                "through",
                "my",
                "window",
                ",",
                "I",
                "would",
                "not",
                "sleep",
                "this",
                "night.i",
                "be",
                "suddenly",
                "jerk",
                "back",
                "to",
                "the",
                "present",
                "when",
                "I",
                "feel",
                "cool",
                "crisp",
                "water",
                "drip",
                "onto",
                "my",
                "hand",
                "and",
                "taste",
                "my",
                "own",
                "salty",
                "tear",
                "."
            ],
            [
                "I",
                "quickly",
                "reach",
                "up",
                "to",
                "wipe",
                "they",
                "away",
                "and",
                "look",
                "up",
                "to",
                "Trent",
                "and",
                "Nina",
                "at",
                "the",
                "alter",
                "hold",
                "hand",
                "smile",
                "at",
                "each",
                "other",
                ",",
                "``",
                "I",
                "do",
                ",",
                "''",
                "they",
                "both",
                "say",
                "in",
                "unison",
                "."
            ],
            [
                "my",
                "head",
                "drop",
                "to",
                "conceal",
                "the",
                "tear",
                "now",
                "flow",
                "freely",
                "from",
                "my",
                "eye",
                "."
            ]
        ],
        "label": "Sadness"
    },
    {
        "body_part_token_idx": 5,
        "sentence_id": "e92a18c2-c1be-3073-9a74-10f6048eb36f",
        "tokens": [
            "-LRB-",
            "HUGE",
            "grin",
            "on",
            "my",
            "face",
            "now",
            ".",
            ")"
        ],
        "lemmatized_tokens": [
            "-lrb-",
            "huge",
            "grin",
            "on",
            "my",
            "face",
            "now",
            ".",
            ")"
        ],
        "preceding_context_tokens": [
            [
                "Why",
                "???"
            ],
            [
                "-LRB-",
                "Big",
                "grin",
                "on",
                "my",
                "face",
                "at",
                "this",
                "point",
                ".",
                ")"
            ],
            [
                "``",
                "I",
                "wanted",
                "to",
                "ask",
                "you",
                "out",
                ".",
                "''"
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "why",
                "???"
            ],
            [
                "-lrb-",
                "big",
                "grin",
                "on",
                "my",
                "face",
                "at",
                "this",
                "point",
                ".",
                ")"
            ],
            [
                "``",
                "I",
                "want",
                "to",
                "ask",
                "you",
                "out",
                ".",
                "''"
            ]
        ],
        "label": "Joy"
    },
    {
        "body_part_token_idx": 6,
        "sentence_id": "572b87b9-8e8c-324b-9f0c-e15769d67545",
        "tokens": [
            "Jude",
            "exhaled",
            ",",
            "and",
            "closed",
            "his",
            "eyes",
            "."
        ],
        "lemmatized_tokens": [
            "Jude",
            "exhale",
            ",",
            "and",
            "close",
            "he",
            "eye",
            "."
        ],
        "preceding_context_tokens": [
            [
                "A",
                "simple",
                "tree",
                ",",
                "any",
                "color",
                "you",
                "'d",
                "like",
                ",",
                "even",
                "pink.",
                "He",
                "made",
                "the",
                "tree",
                ",",
                "and",
                "was",
                "currently",
                "resting",
                "by",
                "its",
                "trunk",
                ",",
                "just",
                "about",
                "ready",
                "to",
                "fall",
                "asleep",
                "."
            ],
            [
                "They",
                "had",
                "all",
                "the",
                "time",
                "they",
                "needed",
                "to",
                "create",
                "the",
                "world",
                ",",
                "and",
                "Jude",
                "wanted",
                "to",
                "enjoy",
                "the",
                "wide",
                "open",
                "space",
                "first",
                "before",
                "populating",
                "it",
                "with",
                "buildings",
                "and",
                "citizens",
                "."
            ],
            [
                "Also",
                ",",
                "creating",
                "the",
                "world",
                "gave",
                "him",
                "a",
                "tired",
                "feeling",
                "in",
                "his",
                "chest",
                ",",
                "like",
                "one",
                "would",
                "experience",
                "after",
                "not",
                "having",
                "enough",
                "sleep",
                ",",
                "only",
                "a",
                "bit",
                "more",
                "pleasant",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "a",
                "simple",
                "tree",
                ",",
                "any",
                "color",
                "you",
                "would",
                "like",
                ",",
                "even",
                "pink.",
                "he",
                "make",
                "the",
                "tree",
                ",",
                "and",
                "be",
                "currently",
                "rest",
                "by",
                "its",
                "trunk",
                ",",
                "just",
                "about",
                "ready",
                "to",
                "fall",
                "asleep",
                "."
            ],
            [
                "they",
                "have",
                "all",
                "the",
                "time",
                "they",
                "need",
                "to",
                "create",
                "the",
                "world",
                ",",
                "and",
                "Jude",
                "want",
                "to",
                "enjoy",
                "the",
                "wide",
                "open",
                "space",
                "first",
                "before",
                "populate",
                "it",
                "with",
                "building",
                "and",
                "citizen",
                "."
            ],
            [
                "also",
                ",",
                "create",
                "the",
                "world",
                "give",
                "he",
                "a",
                "tired",
                "feeling",
                "in",
                "he",
                "chest",
                ",",
                "like",
                "one",
                "would",
                "experience",
                "after",
                "not",
                "have",
                "enough",
                "sleep",
                ",",
                "only",
                "a",
                "bit",
                "more",
                "pleasant",
                "."
            ]
        ],
        "label": "Joy"
    },
    {
        "body_part_token_idx": 14,
        "sentence_id": "d289e564-aa8a-3172-8947-197d3ae544b1",
        "tokens": [
            "how",
            "thoughtful",
            ":-]",
            "haha",
            "beni",
            "with",
            "his",
            "stick",
            "dari",
            "half",
            "smiling",
            "half",
            "bawling",
            "her",
            "eyes",
            "out",
            "candi",
            "being",
            "the",
            "oldest",
            ",",
            "therefore",
            "the",
            "bossiest",
            ",",
            "put",
            "gloria",
            "in",
            "the",
            "stroller",
            "with",
            "2",
            "teddybears",
            "and",
            "pushed",
            "her",
            "around",
            "for",
            "a",
            "LONG",
            "time",
            "!"
        ],
        "lemmatized_tokens": [
            "how",
            "thoughtful",
            ":-]",
            "haha",
            "beni",
            "with",
            "he",
            "stick",
            "dari",
            "half",
            "smile",
            "half",
            "bawl",
            "she",
            "eye",
            "out",
            "candi",
            "be",
            "the",
            "oldest",
            ",",
            "therefore",
            "the",
            "bossiest",
            ",",
            "put",
            "gloria",
            "in",
            "the",
            "stroller",
            "with",
            "2",
            "teddybear",
            "and",
            "push",
            "she",
            "around",
            "for",
            "a",
            "long",
            "time",
            "!"
        ],
        "preceding_context_tokens": [
            [
                "we",
                "met",
                "up",
                "with",
                "darilis",
                "and",
                "daniela",
                "eventually",
                ",",
                "so",
                "then",
                "the",
                "kiddos",
                "all",
                "got",
                "to",
                "play",
                "together",
                "!"
            ],
            [
                "here",
                "'s",
                "a",
                "few",
                "pics",
                "and",
                "videos",
                "-",
                "enjoy",
                "!"
            ],
            [
                "apparently",
                "darilis",
                "was",
                "VERY",
                "scared",
                "of",
                "beni",
                "so",
                "candi",
                "was",
                "helping",
                "dari",
                "come",
                "back",
                "to",
                "her",
                "mom",
                "here",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "we",
                "meet",
                "up",
                "with",
                "darilis",
                "and",
                "daniela",
                "eventually",
                ",",
                "so",
                "then",
                "the",
                "kiddo",
                "all",
                "get",
                "to",
                "play",
                "together",
                "!"
            ],
            [
                "here",
                "be",
                "a",
                "few",
                "pic",
                "and",
                "video",
                "-",
                "enjoy",
                "!"
            ],
            [
                "apparently",
                "darilis",
                "be",
                "very",
                "scared",
                "of",
                "beni",
                "so",
                "candi",
                "be",
                "help",
                "dari",
                "come",
                "back",
                "to",
                "she",
                "mom",
                "here",
                "."
            ]
        ],
        "label": "Sadness"
    },
    {
        "body_part_token_idx": 1,
        "sentence_id": "3750e490-728d-311d-bc06-8729462de449",
        "tokens": [
            "His",
            "eyes",
            "widened",
            "in",
            "order",
            "to",
            "take",
            "in",
            "the",
            "whole",
            "new",
            "scene",
            "into",
            "his",
            "simple",
            "mind",
            "."
        ],
        "lemmatized_tokens": [
            "he",
            "eye",
            "widen",
            "in",
            "order",
            "to",
            "take",
            "in",
            "the",
            "whole",
            "new",
            "scene",
            "into",
            "he",
            "simple",
            "mind",
            "."
        ],
        "preceding_context_tokens": [
            [
                "In",
                "his",
                "imagination",
                ",",
                "this",
                "door",
                "hid",
                "a",
                "huge",
                "secret",
                "which",
                "was",
                "waiting",
                "for",
                "him",
                "to",
                "discover",
                "."
            ],
            [
                "He",
                "opened",
                "the",
                "door",
                "cautiously",
                "."
            ],
            [
                "His",
                "eyes",
                "darted",
                "around",
                "the",
                "dim",
                "area",
                ",",
                "with",
                "weeds",
                "and",
                "bushes",
                "which",
                "were",
                "looming",
                "over",
                "the",
                "little",
                "boy",
                "himself",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "in",
                "he",
                "imagination",
                ",",
                "this",
                "door",
                "hide",
                "a",
                "huge",
                "secret",
                "which",
                "be",
                "wait",
                "for",
                "he",
                "to",
                "discover",
                "."
            ],
            [
                "he",
                "open",
                "the",
                "door",
                "cautiously",
                "."
            ],
            [
                "he",
                "eye",
                "dart",
                "around",
                "the",
                "dim",
                "area",
                ",",
                "with",
                "weed",
                "and",
                "bush",
                "which",
                "be",
                "loom",
                "over",
                "the",
                "little",
                "boy",
                "himself",
                "."
            ]
        ],
        "label": "Surprise"
    },
    {
        "body_part_token_idx": 1,
        "sentence_id": "7777c92d-6ed1-34db-8eb6-bf66162b6bd3",
        "tokens": [
            "My",
            "stomach",
            "even",
            "started",
            "giving",
            "me",
            "fits",
            "."
        ],
        "lemmatized_tokens": [
            "my",
            "stomach",
            "even",
            "start",
            "give",
            "I",
            "fit",
            "."
        ],
        "preceding_context_tokens": [
            [
                "Not",
                "to",
                "mention",
                "I",
                "had",
                "to",
                "work",
                "with",
                "the",
                "most",
                "crabbiest",
                "manager",
                ",",
                "too",
                "."
            ],
            [
                "I",
                "had",
                "an",
                "UBER",
                "headache",
                "last",
                "night",
                "."
            ],
            [
                "It",
                "had",
                "been",
                "bugging",
                "me",
                "all",
                "day",
                ",",
                "but",
                "after",
                "`",
                "rack",
                "diving",
                "'",
                "it",
                "was",
                "terrible",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "not",
                "to",
                "mention",
                "I",
                "have",
                "to",
                "work",
                "with",
                "the",
                "most",
                "crabbiest",
                "manager",
                ",",
                "too",
                "."
            ],
            [
                "I",
                "have",
                "a",
                "UBER",
                "headache",
                "last",
                "night",
                "."
            ],
            [
                "it",
                "have",
                "be",
                "bug",
                "I",
                "all",
                "day",
                ",",
                "but",
                "after",
                "`",
                "rack",
                "diving",
                "'",
                "it",
                "be",
                "terrible",
                "."
            ]
        ],
        "label": "Disgust"
    },
    {
        "body_part_token_idx": 27,
        "sentence_id": "cc3a41c6-c0ce-3f41-9019-ea41b9ab6d62",
        "tokens": [
            "He",
            "put",
            "down",
            "the",
            "piece",
            "he",
            "'d",
            "been",
            "examining",
            "and",
            ",",
            "after",
            "another",
            "dubious",
            "look",
            "at",
            "Duo",
            "'s",
            "coat",
            "and",
            "Wufei",
            "'s",
            "sword",
            ",",
            "he",
            "crossed",
            "his",
            "arms",
            "above",
            "a",
            "rounded",
            "belly",
            "."
        ],
        "lemmatized_tokens": [
            "he",
            "put",
            "down",
            "the",
            "piece",
            "he",
            "have",
            "be",
            "examine",
            "and",
            ",",
            "after",
            "another",
            "dubious",
            "look",
            "at",
            "Duo",
            "'s",
            "coat",
            "and",
            "Wufei",
            "'s",
            "sword",
            ",",
            "he",
            "cross",
            "he",
            "arm",
            "above",
            "a",
            "rounded",
            "belly",
            "."
        ],
        "preceding_context_tokens": [
            [
                "The",
                "only",
                "other",
                "person",
                "in",
                "the",
                "workshop",
                "was",
                "a",
                "thickset",
                "bald",
                "man",
                "behind",
                "the",
                "counter",
                "."
            ],
            [
                "He",
                "had",
                "a",
                "finger",
                "on",
                "the",
                "page",
                "of",
                "a",
                "thick",
                ",",
                "dog",
                "-",
                "eared",
                "instruction",
                "manual",
                "and",
                "he",
                "was",
                "holding",
                "up",
                "a",
                "piece",
                "of",
                "machined",
                "metal",
                ",",
                "but",
                "he",
                "'d",
                "stopped",
                "studying",
                "it",
                "when",
                "Duo",
                "and",
                "Wufei",
                "had",
                "entered",
                "the",
                "shop",
                "."
            ],
            [
                "He",
                "was",
                "scrutinizing",
                "them",
                "suspiciously",
                ",",
                "giving",
                "them",
                "the",
                "straightforward",
                ",",
                "weighing",
                "look",
                "that",
                "Wufei",
                "was",
                "fast",
                "recognizing",
                "as",
                "a",
                "Freeport",
                "trademark",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "the",
                "only",
                "other",
                "person",
                "in",
                "the",
                "workshop",
                "be",
                "a",
                "thickset",
                "bald",
                "man",
                "behind",
                "the",
                "counter",
                "."
            ],
            [
                "he",
                "have",
                "a",
                "finger",
                "on",
                "the",
                "page",
                "of",
                "a",
                "thick",
                ",",
                "dog",
                "-",
                "eared",
                "instruction",
                "manual",
                "and",
                "he",
                "be",
                "hold",
                "up",
                "a",
                "piece",
                "of",
                "machined",
                "metal",
                ",",
                "but",
                "he",
                "would",
                "stop",
                "study",
                "it",
                "when",
                "Duo",
                "and",
                "Wufei",
                "have",
                "enter",
                "the",
                "shop",
                "."
            ],
            [
                "he",
                "be",
                "scrutinize",
                "they",
                "suspiciously",
                ",",
                "give",
                "they",
                "the",
                "straightforward",
                ",",
                "weigh",
                "look",
                "that",
                "Wufei",
                "be",
                "fast",
                "recognize",
                "as",
                "a",
                "Freeport",
                "trademark",
                "."
            ]
        ],
        "label": "Disgust"
    },
    {
        "body_part_token_idx": 17,
        "sentence_id": "19c7bca4-d204-346f-94fb-1ded43dedf11",
        "tokens": [
            "Bella",
            ",",
            "I",
            "'m",
            "so",
            "happy",
            "that",
            "you",
            "'re",
            "home.",
            "I",
            "smiled",
            "as",
            "tears",
            "slid",
            "down",
            "my",
            "cheeks",
            "."
        ],
        "lemmatized_tokens": [
            "Bella",
            ",",
            "I",
            "be",
            "so",
            "happy",
            "that",
            "you",
            "be",
            "home.",
            "I",
            "smile",
            "as",
            "tear",
            "slide",
            "down",
            "my",
            "cheek",
            "."
        ],
        "preceding_context_tokens": [
            [
                "***",
                "I",
                "dialled",
                "the",
                "number",
                "with",
                "trembling",
                "hands",
                "."
            ],
            [
                "Please",
                "do",
                "n't",
                "let",
                "Edward",
                "pick",
                "up",
                "please",
                "do",
                "n't",
                "let",
                "Edward",
                "pick",
                "up",
                "Please",
                "do",
                "n't",
                "let",
                "``",
                "Bella!",
                "Alice?",
                "I",
                "almost",
                "choked",
                "on",
                "an",
                "unexpected",
                "sob",
                "."
            ],
            [
                "Yes",
                ",",
                "it",
                "'s",
                "me",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "***",
                "I",
                "dial",
                "the",
                "number",
                "with",
                "tremble",
                "hand",
                "."
            ],
            [
                "please",
                "do",
                "not",
                "let",
                "Edward",
                "pick",
                "up",
                "please",
                "do",
                "not",
                "let",
                "Edward",
                "pick",
                "up",
                "please",
                "do",
                "not",
                "let",
                "``",
                "Bella!",
                "Alice?",
                "I",
                "almost",
                "choke",
                "on",
                "a",
                "unexpected",
                "sob",
                "."
            ],
            [
                "yes",
                ",",
                "it",
                "be",
                "I",
                "."
            ]
        ],
        "label": "Joy"
    },
    {
        "body_part_token_idx": 5,
        "sentence_id": "53a7ca7e-5384-3b21-aa06-a12541563fb7",
        "tokens": [
            "Finally",
            ",",
            "he",
            "drops",
            "his",
            "head",
            "slightly",
            "and",
            "sighs",
            "."
        ],
        "lemmatized_tokens": [
            "finally",
            ",",
            "he",
            "drop",
            "he",
            "head",
            "slightly",
            "and",
            "sigh",
            "."
        ],
        "preceding_context_tokens": [
            [
                "Giving",
                "in",
                "would",
                "mean",
                "a",
                "lot",
                "to",
                "him",
                "."
            ],
            [
                "It",
                "would",
                "be",
                "giving",
                "up",
                "years",
                "of",
                "repression",
                "and",
                "not",
                "caring",
                "about",
                "things",
                "."
            ],
            [
                "Brendon",
                "is",
                "giving",
                "him",
                "his",
                "best",
                "hopeful",
                "expression",
                ",",
                "his",
                "lower",
                "lip",
                "jutting",
                "out",
                "slightly",
                "and",
                "begging",
                "him",
                "to",
                "say",
                "yes",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "give",
                "in",
                "would",
                "mean",
                "a",
                "lot",
                "to",
                "he",
                "."
            ],
            [
                "it",
                "would",
                "be",
                "give",
                "up",
                "year",
                "of",
                "repression",
                "and",
                "not",
                "care",
                "about",
                "thing",
                "."
            ],
            [
                "Brendon",
                "be",
                "give",
                "he",
                "he",
                "best",
                "hopeful",
                "expression",
                ",",
                "he",
                "lower",
                "lip",
                "jut",
                "out",
                "slightly",
                "and",
                "beg",
                "he",
                "to",
                "say",
                "yes",
                "."
            ]
        ],
        "label": "Disgust"
    },
    {
        "body_part_token_idx": 14,
        "sentence_id": "d9923797-0409-3af3-88ef-bcd18cbeca3e",
        "tokens": [
            "god",
            "i",
            "cant",
            "even",
            "see",
            "straight",
            "cuz",
            "i",
            "have",
            "so",
            "many",
            "tears",
            "in",
            "my",
            "eyes",
            "."
        ],
        "lemmatized_tokens": [
            "god",
            "i",
            "cant",
            "even",
            "see",
            "straight",
            "cuz",
            "i",
            "have",
            "so",
            "many",
            "tear",
            "in",
            "my",
            "eye",
            "."
        ],
        "preceding_context_tokens": [
            [
                "she",
                "did",
                "nt",
                "even",
                "call",
                "me",
                "today",
                "."
            ],
            [
                "i",
                "guess",
                "she",
                "'s",
                "not",
                "allowed",
                "to",
                "."
            ],
            [
                "i",
                "hate",
                "this",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "she",
                "do",
                "nt",
                "even",
                "call",
                "I",
                "today",
                "."
            ],
            [
                "i",
                "guess",
                "she",
                "be",
                "not",
                "allow",
                "to",
                "."
            ],
            [
                "i",
                "hate",
                "this",
                "."
            ]
        ],
        "label": "Sadness"
    },
    {
        "body_part_token_idx": 18,
        "sentence_id": "6ff1a047-e2d0-3969-80ed-b198455a3d37",
        "tokens": [
            "The",
            "thought",
            "of",
            "spending",
            "Merlin",
            "only",
            "knows",
            "how",
            "many",
            "nights",
            "with",
            "Malfoy",
            "made",
            "him",
            "feel",
            "sick",
            "to",
            "his",
            "stomach",
            "."
        ],
        "lemmatized_tokens": [
            "the",
            "thought",
            "of",
            "spending",
            "Merlin",
            "only",
            "know",
            "how",
            "many",
            "night",
            "with",
            "Malfoy",
            "make",
            "he",
            "feel",
            "sick",
            "to",
            "he",
            "stomach",
            "."
        ],
        "preceding_context_tokens": [
            [
                "You",
                "'re",
                "job",
                "for",
                "tonight",
                ",",
                "and",
                "as",
                "many",
                "nights",
                "as",
                "it",
                "takes",
                "you",
                "to",
                "finish",
                "it",
                ",",
                "is",
                "to",
                "polish",
                "all",
                "of",
                "the",
                "suits",
                "of",
                "armor",
                "in",
                "this",
                "room",
                "inside",
                "and",
                "out",
                ",",
                "she",
                "said",
                "pausing",
                "to",
                "make",
                "sure",
                "that",
                "they",
                "understood",
                "then",
                "continued",
                ",",
                "without",
                "using",
                "any",
                "magic.",
                "You",
                "have",
                "got",
                "to",
                "be",
                "joking",
                ",",
                "Malfoy",
                "said",
                "agitated",
                "."
            ],
            [
                "It",
                "'ll",
                "take",
                "ages",
                "to",
                "polish",
                "all",
                "these",
                "."
            ],
            [
                "There",
                "has",
                "to",
                "be",
                "at",
                "least",
                "fifty",
                "of",
                "them.",
                "Ron",
                "was",
                "of",
                "the",
                "same",
                "mind",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "you",
                "be",
                "job",
                "for",
                "tonight",
                ",",
                "and",
                "as",
                "many",
                "night",
                "as",
                "it",
                "take",
                "you",
                "to",
                "finish",
                "it",
                ",",
                "be",
                "to",
                "polish",
                "all",
                "of",
                "the",
                "suit",
                "of",
                "armor",
                "in",
                "this",
                "room",
                "inside",
                "and",
                "out",
                ",",
                "she",
                "say",
                "pause",
                "to",
                "make",
                "sure",
                "that",
                "they",
                "understand",
                "then",
                "continue",
                ",",
                "without",
                "use",
                "any",
                "magic.",
                "you",
                "have",
                "get",
                "to",
                "be",
                "joke",
                ",",
                "Malfoy",
                "say",
                "agitated",
                "."
            ],
            [
                "it",
                "will",
                "take",
                "age",
                "to",
                "polish",
                "all",
                "these",
                "."
            ],
            [
                "there",
                "have",
                "to",
                "be",
                "at",
                "least",
                "fifty",
                "of",
                "them.",
                "Ron",
                "be",
                "of",
                "the",
                "same",
                "mind",
                "."
            ]
        ],
        "label": "Disgust"
    },
    {
        "body_part_token_idx": 13,
        "sentence_id": "356b4c1c-f0b8-394d-bfdc-577da96a34e5",
        "tokens": [
            "``",
            "York",
            "'s",
            "agreed",
            "to",
            "a",
            "truce",
            "...",
            "of",
            "sorts",
            "...",
            "''",
            "His",
            "eyes",
            "closed",
            ",",
            "brows",
            "knitting",
            "together",
            "briefly",
            "before",
            "he",
            "relaxed",
            "again",
            "."
        ],
        "lemmatized_tokens": [
            "``",
            "York",
            "'s",
            "agree",
            "to",
            "a",
            "truce",
            "...",
            "of",
            "sort",
            "...",
            "''",
            "he",
            "eye",
            "closed",
            ",",
            "brow",
            "knit",
            "together",
            "briefly",
            "before",
            "he",
            "relax",
            "again",
            "."
        ],
        "preceding_context_tokens": [
            [
                "``",
                "Indeed",
                ",",
                "my",
                "lord",
                "?",
                "''"
            ],
            [
                "Christopher",
                "moved",
                "to",
                "the",
                "foot",
                "of",
                "the",
                "bed",
                "and",
                "spoke",
                "with",
                "an",
                "air",
                "of",
                "polite",
                "interest",
                "a",
                "courtier",
                "might",
                "'ve",
                "employed",
                "in",
                "court",
                "."
            ],
            [
                "John",
                "nodded",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "``",
                "indeed",
                ",",
                "my",
                "lord",
                "?",
                "''"
            ],
            [
                "Christopher",
                "move",
                "to",
                "the",
                "foot",
                "of",
                "the",
                "bed",
                "and",
                "speak",
                "with",
                "a",
                "air",
                "of",
                "polite",
                "interest",
                "a",
                "courtier",
                "might",
                "have",
                "employ",
                "in",
                "court",
                "."
            ],
            [
                "John",
                "nod",
                "."
            ]
        ],
        "label": "Fear"
    },
    {
        "body_part_token_idx": 3,
        "sentence_id": "3f3081de-bc32-38fe-8528-b096406b4c41",
        "tokens": [
            "I",
            "shut",
            "my",
            "eyes",
            "and",
            "let",
            "the",
            "tears",
            "take",
            "over",
            "."
        ],
        "lemmatized_tokens": [
            "I",
            "shut",
            "my",
            "eye",
            "and",
            "let",
            "the",
            "tear",
            "take",
            "over",
            "."
        ],
        "preceding_context_tokens": [
            [
                "I",
                "threw",
                "myself",
                "half",
                "way",
                "out",
                "of",
                "my",
                "bed",
                "and",
                "pulled",
                "myself",
                "to",
                "the",
                "ground",
                "where",
                "it",
                "embraced",
                "me",
                "."
            ],
            [
                "My",
                "fingernails",
                "dug",
                "into",
                "the",
                "carpet",
                "as",
                "I",
                "gasped",
                "for",
                "air",
                "."
            ],
            [
                "No",
                ",",
                "I",
                "did",
                "n't",
                "have",
                "a",
                "lump",
                "in",
                "my",
                "throat",
                ",",
                "instead",
                "there",
                "sat",
                "a",
                "boulder",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "I",
                "throw",
                "myself",
                "half",
                "way",
                "out",
                "of",
                "my",
                "bed",
                "and",
                "pull",
                "myself",
                "to",
                "the",
                "ground",
                "where",
                "it",
                "embrace",
                "I",
                "."
            ],
            [
                "my",
                "fingernail",
                "dig",
                "into",
                "the",
                "carpet",
                "as",
                "I",
                "gasp",
                "for",
                "air",
                "."
            ],
            [
                "no",
                ",",
                "I",
                "do",
                "not",
                "have",
                "a",
                "lump",
                "in",
                "my",
                "throat",
                ",",
                "instead",
                "there",
                "sit",
                "a",
                "boulder",
                "."
            ]
        ],
        "label": "Sadness"
    },
    {
        "body_part_token_idx": 9,
        "sentence_id": "f592266b-65f9-3ca0-92e9-e0aa90ef0af5",
        "tokens": [
            "He",
            "risked",
            "another",
            "look",
            "at",
            "her",
            ",",
            "but",
            "her",
            "eyes",
            "were",
            "locked",
            "with",
            "the",
            "Doctor",
            "'s",
            "."
        ],
        "lemmatized_tokens": [
            "he",
            "risk",
            "another",
            "look",
            "at",
            "she",
            ",",
            "but",
            "she",
            "eye",
            "be",
            "lock",
            "with",
            "the",
            "Doctor",
            "'s",
            "."
        ],
        "preceding_context_tokens": [
            [
                "``",
                "How",
                "long",
                "has",
                "it",
                "been",
                "for",
                "you",
                "?",
                "''"
            ],
            [
                "``",
                "Four",
                "years",
                ",",
                "I",
                "suppose",
                "."
            ],
            [
                "Give",
                "or",
                "take",
                ".",
                "''"
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "``",
                "how",
                "long",
                "have",
                "it",
                "be",
                "for",
                "you",
                "?",
                "''"
            ],
            [
                "``",
                "four",
                "year",
                ",",
                "I",
                "suppose",
                "."
            ],
            [
                "give",
                "or",
                "take",
                ".",
                "''"
            ]
        ],
        "label": "Sadness"
    },
    {
        "body_part_token_idx": 21,
        "sentence_id": "999739f2-3c04-3dff-b74c-11679b30875b",
        "tokens": [
            "Kai",
            "was",
            "silent",
            "for",
            "a",
            "long",
            "moment",
            ",",
            "but",
            "then",
            "he",
            "finally",
            "let",
            "out",
            "a",
            "sigh",
            ",",
            "and",
            "just",
            "shook",
            "his",
            "head",
            ".",
            "''"
        ],
        "lemmatized_tokens": [
            "Kai",
            "be",
            "silent",
            "for",
            "a",
            "long",
            "moment",
            ",",
            "but",
            "then",
            "he",
            "finally",
            "let",
            "out",
            "a",
            "sigh",
            ",",
            "and",
            "just",
            "shake",
            "he",
            "head",
            ".",
            "''"
        ],
        "preceding_context_tokens": [
            [
                "Still",
                "believed",
                "them",
                ",",
                "and",
                "always",
                "would",
                "."
            ],
            [
                "``",
                "I",
                "should",
                "n't",
                "have",
                "to",
                "spell",
                "this",
                "out",
                "for",
                "you",
                ",",
                "but",
                "that",
                "'s",
                "the",
                "sort",
                "of",
                "woman",
                "Ilia",
                "is",
                "."
            ],
            [
                "You",
                "should",
                "go",
                "after",
                "her",
                ",",
                "or",
                "at",
                "least",
                "keep",
                "the",
                "idea",
                "open",
                "for",
                "some",
                "time",
                "down",
                "the",
                "road",
                ".",
                "''"
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "still",
                "believe",
                "they",
                ",",
                "and",
                "always",
                "would",
                "."
            ],
            [
                "``",
                "I",
                "should",
                "not",
                "have",
                "to",
                "spell",
                "this",
                "out",
                "for",
                "you",
                ",",
                "but",
                "that",
                "be",
                "the",
                "sort",
                "of",
                "woman",
                "Ilia",
                "be",
                "."
            ],
            [
                "you",
                "should",
                "go",
                "after",
                "she",
                ",",
                "or",
                "at",
                "least",
                "keep",
                "the",
                "idea",
                "open",
                "for",
                "some",
                "time",
                "down",
                "the",
                "road",
                ".",
                "''"
            ]
        ],
        "label": "Disgust"
    },
    {
        "body_part_token_idx": 2,
        "sentence_id": "0aa32183-a26f-3757-8ad3-41557f470ac8",
        "tokens": [
            "pounding",
            "my",
            "fists",
            "and",
            "screaming",
            "to",
            "a",
            "god",
            "that",
            "is",
            "not",
            "there",
            ";",
            "it",
            "'s",
            "sad",
            "there",
            "had",
            "to",
            "be",
            "a",
            "battle",
            "sad",
            "i",
            "had",
            "to",
            "loose",
            "."
        ],
        "lemmatized_tokens": [
            "pound",
            "my",
            "fist",
            "and",
            "scream",
            "to",
            "a",
            "god",
            "that",
            "be",
            "not",
            "there",
            ";",
            "it",
            "be",
            "sad",
            "there",
            "have",
            "to",
            "be",
            "a",
            "battle",
            "sad",
            "i",
            "have",
            "to",
            "loose",
            "."
        ],
        "preceding_context_tokens": [
            [
                "i",
                "fought",
                ",",
                "now",
                "i",
                "'ve",
                "receded",
                "."
            ],
            [
                "i",
                "thought",
                "i",
                "had",
                "what",
                "it",
                "was",
                "i",
                "needed",
                "...",
                "how",
                "could",
                "i",
                "possibly",
                "be",
                "so",
                "conceded",
                "?"
            ],
            [
                "that",
                "pain",
                "in",
                "my",
                "heart",
                "has",
                "exceeded",
                "that",
                "which",
                "any",
                "man",
                "should",
                "bear",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "i",
                "fight",
                ",",
                "now",
                "i",
                "have",
                "recede",
                "."
            ],
            [
                "i",
                "think",
                "i",
                "have",
                "what",
                "it",
                "be",
                "i",
                "need",
                "...",
                "how",
                "could",
                "i",
                "possibly",
                "be",
                "so",
                "concede",
                "?"
            ],
            [
                "that",
                "pain",
                "in",
                "my",
                "heart",
                "have",
                "exceed",
                "that",
                "which",
                "any",
                "man",
                "should",
                "bear",
                "."
            ]
        ],
        "label": "Anger"
    },
    {
        "body_part_token_idx": 12,
        "sentence_id": "1144e95f-9b99-3644-a469-c760d534db9b",
        "tokens": [
            "The",
            "scene",
            "faded",
            "and",
            "Dean",
            "stood",
            "there",
            "with",
            "a",
            "smile",
            "on",
            "his",
            "face",
            "."
        ],
        "lemmatized_tokens": [
            "the",
            "scene",
            "fade",
            "and",
            "Dean",
            "stand",
            "there",
            "with",
            "a",
            "smile",
            "on",
            "he",
            "face",
            "."
        ],
        "preceding_context_tokens": [
            [
                "``",
                "Oh",
                "$",
                "that",
                "does",
                "n't",
                "answer",
                "my",
                "question",
                "about",
                "where",
                "he",
                "is",
                "now",
                ",",
                "though",
                "!",
                "''"
            ],
            [
                "John",
                "replied",
                "gruffly",
                "."
            ],
            [
                "Still",
                "not",
                "looking",
                "up",
                ",",
                "the",
                "preteen",
                "said",
                ",",
                "``",
                "He",
                "just",
                "went",
                "to",
                "fill",
                "up",
                "the",
                "car",
                ",",
                "thought",
                "the",
                "tank",
                "was",
                "n't",
                "full",
                "enough",
                "for",
                "tonight",
                ".",
                "''"
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "``",
                "oh",
                "$",
                "that",
                "do",
                "not",
                "answer",
                "my",
                "question",
                "about",
                "where",
                "he",
                "be",
                "now",
                ",",
                "though",
                "!",
                "''"
            ],
            [
                "John",
                "reply",
                "gruffly",
                "."
            ],
            [
                "still",
                "not",
                "look",
                "up",
                ",",
                "the",
                "preteen",
                "say",
                ",",
                "``",
                "he",
                "just",
                "go",
                "to",
                "fill",
                "up",
                "the",
                "car",
                ",",
                "think",
                "the",
                "tank",
                "be",
                "not",
                "full",
                "enough",
                "for",
                "tonight",
                ".",
                "''"
            ]
        ],
        "label": "Joy"
    },
    {
        "body_part_token_idx": 18,
        "sentence_id": "4545fb9a-da41-3d98-99c9-37eafdb1c853",
        "tokens": [
            "The",
            "propellers",
            "had",
            "come",
            "right",
            "out",
            "of",
            "the",
            "water",
            ",",
            "like",
            "teeth",
            ",",
            "like",
            "a",
            "woman",
            "with",
            "her",
            "mouth",
            "open",
            ",",
            "and",
            "crying",
            "towards",
            "heaven",
            "for",
            "release",
            "."
        ],
        "lemmatized_tokens": [
            "the",
            "propeller",
            "have",
            "come",
            "right",
            "out",
            "of",
            "the",
            "water",
            ",",
            "like",
            "tooth",
            ",",
            "like",
            "a",
            "woman",
            "with",
            "she",
            "mouth",
            "open",
            ",",
            "and",
            "cry",
            "towards",
            "heaven",
            "for",
            "release",
            "."
        ],
        "preceding_context_tokens": [
            [
                "Ellen",
                "felt",
                "every",
                "crack",
                "and",
                "every",
                "sig",
                "of",
                "the",
                "great",
                "ship",
                "in",
                "her",
                "bones",
                "and",
                "yet",
                "it",
                "all",
                "fell",
                "apart",
                "so",
                "quick",
                "."
            ],
            [
                "The",
                "water",
                "rose",
                "and",
                "lapped",
                "at",
                "the",
                "polished",
                "deck",
                "and",
                "people",
                "ran",
                "and",
                "screamed",
                ",",
                "with",
                "nowhere",
                "to",
                "go",
                "."
            ],
            [
                "They",
                "watched",
                "from",
                "the",
                "lifeboats",
                ",",
                "so",
                "afraid",
                "that",
                ",",
                "at",
                "the",
                "last",
                "moment",
                ",",
                "the",
                "whole",
                "ocean",
                "would",
                "somehow",
                "open",
                "and",
                "take",
                "them",
                "all",
                "down",
                "with",
                "Titanic",
                ",",
                "punishment",
                "for",
                "the",
                "sin",
                "of",
                "pride",
                ",",
                "for",
                "imagining",
                "that",
                "there",
                "was",
                "anything",
                "in",
                "the",
                "whole",
                "wide",
                "world",
                "that",
                "God",
                "could",
                "n't",
                "sink",
                ",",
                "if",
                "he",
                "chose",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "Ellen",
                "feel",
                "every",
                "crack",
                "and",
                "every",
                "sig",
                "of",
                "the",
                "great",
                "ship",
                "in",
                "she",
                "bone",
                "and",
                "yet",
                "it",
                "all",
                "fall",
                "apart",
                "so",
                "quick",
                "."
            ],
            [
                "the",
                "water",
                "rise",
                "and",
                "lap",
                "at",
                "the",
                "polished",
                "deck",
                "and",
                "people",
                "run",
                "and",
                "scream",
                ",",
                "with",
                "nowhere",
                "to",
                "go",
                "."
            ],
            [
                "they",
                "watch",
                "from",
                "the",
                "lifeboat",
                ",",
                "so",
                "afraid",
                "that",
                ",",
                "at",
                "the",
                "last",
                "moment",
                ",",
                "the",
                "whole",
                "ocean",
                "would",
                "somehow",
                "open",
                "and",
                "take",
                "they",
                "all",
                "down",
                "with",
                "Titanic",
                ",",
                "punishment",
                "for",
                "the",
                "sin",
                "of",
                "pride",
                ",",
                "for",
                "imagine",
                "that",
                "there",
                "be",
                "anything",
                "in",
                "the",
                "whole",
                "wide",
                "world",
                "that",
                "God",
                "could",
                "not",
                "sink",
                ",",
                "if",
                "he",
                "choose",
                "."
            ]
        ],
        "label": "Sadness"
    },
    {
        "body_part_token_idx": 1,
        "sentence_id": "6159393c-9c2f-311a-afa1-a51fc1bb056e",
        "tokens": [
            "My",
            "mouth",
            "was",
            "dry",
            ",",
            "skin",
            "cold",
            ",",
            "in",
            "a",
            "sudden",
            "adrenal",
            "response",
            "."
        ],
        "lemmatized_tokens": [
            "my",
            "mouth",
            "be",
            "dry",
            ",",
            "skin",
            "cold",
            ",",
            "in",
            "a",
            "sudden",
            "adrenal",
            "response",
            "."
        ],
        "preceding_context_tokens": [
            [
                "I",
                "gripped",
                "the",
                "strap",
                "as",
                "if",
                "it",
                "were",
                "my",
                "last",
                "chance",
                ",",
                "slipping",
                "away.Ray",
                "'s",
                "smile",
                "disappeared",
                "."
            ],
            [
                "He",
                "looked",
                "down",
                "at",
                "my",
                "hand",
                "and",
                "then",
                "followed",
                "the",
                "line",
                "of",
                "my",
                "arm",
                "slowly",
                "up",
                "to",
                "my",
                "face",
                "."
            ],
            [
                "Ray",
                "'s",
                "eyes",
                "were",
                "hard",
                ",",
                "fists",
                "clenching",
                "as",
                "his",
                "body",
                "began",
                "vibrating",
                "with",
                "a",
                "tension",
                "I",
                "remembered",
                "from",
                "that",
                "afternoon",
                "by",
                "the",
                "lake",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "I",
                "grip",
                "the",
                "strap",
                "as",
                "if",
                "it",
                "be",
                "my",
                "last",
                "chance",
                ",",
                "slip",
                "away.ray",
                "'s",
                "smile",
                "disappear",
                "."
            ],
            [
                "he",
                "look",
                "down",
                "at",
                "my",
                "hand",
                "and",
                "then",
                "follow",
                "the",
                "line",
                "of",
                "my",
                "arm",
                "slowly",
                "up",
                "to",
                "my",
                "face",
                "."
            ],
            [
                "Ray",
                "'s",
                "eye",
                "be",
                "hard",
                ",",
                "fist",
                "clench",
                "as",
                "he",
                "body",
                "begin",
                "vibrate",
                "with",
                "a",
                "tension",
                "I",
                "remember",
                "from",
                "that",
                "afternoon",
                "by",
                "the",
                "lake",
                "."
            ]
        ],
        "label": "Fear"
    },
    {
        "body_part_token_idx": 33,
        "sentence_id": "e2794201-e243-3e06-a8f7-d6396f57e93f",
        "tokens": [
            "She",
            "stopped",
            "just",
            "inside",
            "the",
            "door",
            "--",
            "the",
            "length",
            "of",
            "two",
            "or",
            "three",
            "small",
            "tables",
            "from",
            "where",
            "the",
            "family",
            "sat",
            "--",
            "with",
            "one",
            "hand",
            "resting",
            "on",
            "the",
            "handle",
            "and",
            "the",
            "other",
            "on",
            "her",
            "hip",
            "."
        ],
        "lemmatized_tokens": [
            "she",
            "stop",
            "just",
            "inside",
            "the",
            "door",
            "--",
            "the",
            "length",
            "of",
            "two",
            "or",
            "three",
            "small",
            "table",
            "from",
            "where",
            "the",
            "family",
            "sit",
            "--",
            "with",
            "one",
            "hand",
            "rest",
            "on",
            "the",
            "handle",
            "and",
            "the",
            "other",
            "on",
            "she",
            "hip",
            "."
        ],
        "preceding_context_tokens": [
            [
                "After",
                "a",
                "couple",
                "of",
                "minutes",
                ",",
                "Mom",
                "went",
                "back",
                "outside",
                ",",
                "alone",
                "."
            ],
            [
                "Danny",
                ",",
                "who",
                "had",
                "gone",
                "to",
                "get",
                "some",
                "food",
                ",",
                "returned",
                "and",
                "sat",
                "down",
                "to",
                "eat",
                ",",
                "while",
                "she",
                "was",
                "out",
                "."
            ],
            [
                "Before",
                "long",
                ",",
                "though",
                ",",
                "Mom",
                "returned",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "after",
                "a",
                "couple",
                "of",
                "minute",
                ",",
                "Mom",
                "go",
                "back",
                "outside",
                ",",
                "alone",
                "."
            ],
            [
                "Danny",
                ",",
                "who",
                "have",
                "go",
                "to",
                "get",
                "some",
                "food",
                ",",
                "return",
                "and",
                "sit",
                "down",
                "to",
                "eat",
                ",",
                "while",
                "she",
                "be",
                "out",
                "."
            ],
            [
                "before",
                "long",
                ",",
                "though",
                ",",
                "Mom",
                "return",
                "."
            ]
        ],
        "label": "Anger"
    },
    {
        "body_part_token_idx": 15,
        "sentence_id": "89159f51-4393-36c9-9ac8-91092f09f2bf",
        "tokens": [
            "Thomas",
            "threw",
            "out.Sure",
            "enough",
            ",",
            "Angela",
            "still",
            "had",
            "a",
            "total",
            "look",
            "of",
            "shock",
            "on",
            "her",
            "face",
            "."
        ],
        "lemmatized_tokens": [
            "Thomas",
            "throw",
            "out.sure",
            "enough",
            ",",
            "Angela",
            "still",
            "have",
            "a",
            "total",
            "look",
            "of",
            "shock",
            "on",
            "she",
            "face",
            "."
        ],
        "preceding_context_tokens": [
            [
                "``",
                "We",
                "can",
                "handle",
                "it",
                ",",
                "whatever",
                "it",
                "is",
                "!",
                "''"
            ],
            [
                "``",
                "With",
                "the",
                "pout",
                "that",
                "'s",
                "on",
                "your",
                "face",
                ",",
                "you",
                "look",
                "a",
                "little",
                "immature",
                "to",
                "handle",
                "it",
                ",",
                "''",
                "Chelsea",
                "teased",
                "."
            ],
            [
                "``",
                "Well",
                ",",
                "Angie",
                "looks",
                "like",
                "she",
                "might",
                "faint",
                ",",
                "whatever",
                "it",
                "was",
                "!",
                "''"
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "``",
                "we",
                "can",
                "handle",
                "it",
                ",",
                "whatever",
                "it",
                "be",
                "!",
                "''"
            ],
            [
                "``",
                "with",
                "the",
                "pout",
                "that",
                "be",
                "on",
                "you",
                "face",
                ",",
                "you",
                "look",
                "a",
                "little",
                "immature",
                "to",
                "handle",
                "it",
                ",",
                "''",
                "Chelsea",
                "tease",
                "."
            ],
            [
                "``",
                "well",
                ",",
                "Angie",
                "look",
                "like",
                "she",
                "might",
                "faint",
                ",",
                "whatever",
                "it",
                "be",
                "!",
                "''"
            ]
        ],
        "label": "Surprise"
    },
    {
        "body_part_token_idx": 1,
        "sentence_id": "604b6580-4615-3f13-8aaf-9f6bd1079a06",
        "tokens": [
            "My",
            "heart",
            "started",
            "to",
            "do",
            "flip",
            "flops",
            "...",
            "could",
            "this",
            "be",
            "??"
        ],
        "lemmatized_tokens": [
            "my",
            "heart",
            "start",
            "to",
            "do",
            "flip",
            "flop",
            "...",
            "could",
            "this",
            "be",
            "??"
        ],
        "preceding_context_tokens": [
            [
                "I",
                "showed",
                "him",
                "the",
                "stick",
                "and",
                "asked",
                "if",
                "he",
                "could",
                "see",
                "the",
                "+",
                "sign",
                "."
            ],
            [
                "He",
                "said",
                "he",
                "could",
                "see",
                "something",
                "'",
                "."
            ],
            [
                "It",
                "was",
                "n't",
                "very",
                "dark",
                "but",
                "he",
                "confirmed",
                "that",
                "there",
                "was",
                "something",
                "'",
                "there",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "I",
                "show",
                "he",
                "the",
                "stick",
                "and",
                "ask",
                "if",
                "he",
                "could",
                "see",
                "the",
                "+",
                "sign",
                "."
            ],
            [
                "he",
                "say",
                "he",
                "could",
                "see",
                "something",
                "'",
                "."
            ],
            [
                "it",
                "be",
                "not",
                "very",
                "dark",
                "but",
                "he",
                "confirm",
                "that",
                "there",
                "be",
                "something",
                "'",
                "there",
                "."
            ]
        ],
        "label": "Fear"
    },
    {
        "body_part_token_idx": 20,
        "sentence_id": "7a53f4bb-fcde-31a3-9706-9f22c1e008b1",
        "tokens": [
            "I",
            "could",
            "n't",
            "have",
            "written",
            "a",
            "regualar",
            "blog",
            "because",
            "I",
            "'m",
            "way",
            "too",
            "distracted",
            ",",
            "fear",
            "has",
            "hold",
            "of",
            "my",
            "fingers",
            "."
        ],
        "lemmatized_tokens": [
            "I",
            "could",
            "not",
            "have",
            "write",
            "a",
            "regualar",
            "blog",
            "because",
            "I",
            "be",
            "way",
            "too",
            "distracted",
            ",",
            "fear",
            "have",
            "hold",
            "of",
            "my",
            "finger",
            "."
        ],
        "preceding_context_tokens": [
            [
                "There",
                "are",
                "few",
                "things",
                "that",
                "frighten",
                "me",
                "to",
                "the",
                "bone",
                "."
            ],
            [
                "Most",
                "of",
                "those",
                "I",
                "can",
                "avoid",
                "."
            ],
            [
                "But",
                "today",
                "I",
                "have",
                "to",
                "face",
                "my",
                "fears",
                "for",
                "a",
                "few",
                "hours",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "there",
                "be",
                "few",
                "thing",
                "that",
                "frighten",
                "I",
                "to",
                "the",
                "bone",
                "."
            ],
            [
                "most",
                "of",
                "those",
                "I",
                "can",
                "avoid",
                "."
            ],
            [
                "but",
                "today",
                "I",
                "have",
                "to",
                "face",
                "my",
                "fear",
                "for",
                "a",
                "few",
                "hour",
                "."
            ]
        ],
        "label": "Fear"
    },
    {
        "body_part_token_idx": 1,
        "sentence_id": "5d63bb41-4498-39a5-b803-f1513e14efef",
        "tokens": [
            "His",
            "lips",
            "quirked",
            "up",
            "into",
            "a",
            "contented",
            ",",
            "self",
            "-",
            "satisfied",
            "smile",
            "."
        ],
        "lemmatized_tokens": [
            "he",
            "lip",
            "quirk",
            "up",
            "into",
            "a",
            "contented",
            ",",
            "self",
            "-",
            "satisfied",
            "smile",
            "."
        ],
        "preceding_context_tokens": [
            [
                "``",
                "Peter",
                ",",
                "''",
                "she",
                "manages",
                "to",
                "call",
                "out",
                ",",
                "disgusting",
                "herself",
                "with",
                "the",
                "weak",
                "hoarseness",
                "of",
                "her",
                "voice",
                "."
            ],
            [
                "A",
                "smooth",
                ",",
                "velvety",
                "voice",
                "whispered",
                "into",
                "her",
                "ear",
                "."
            ],
            [
                "``",
                "I",
                "took",
                "care",
                "of",
                "him",
                "when",
                "you",
                "did",
                "n't",
                ",",
                "''",
                "said",
                "the",
                "demon",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "``",
                "Peter",
                ",",
                "''",
                "she",
                "manage",
                "to",
                "call",
                "out",
                ",",
                "disgusting",
                "herself",
                "with",
                "the",
                "weak",
                "hoarseness",
                "of",
                "she",
                "voice",
                "."
            ],
            [
                "a",
                "smooth",
                ",",
                "velvety",
                "voice",
                "whisper",
                "into",
                "she",
                "ear",
                "."
            ],
            [
                "``",
                "I",
                "take",
                "care",
                "of",
                "he",
                "when",
                "you",
                "do",
                "not",
                ",",
                "''",
                "say",
                "the",
                "demon",
                "."
            ]
        ],
        "label": "Joy"
    },
    {
        "body_part_token_idx": 8,
        "sentence_id": "4c0f79ed-c1b9-3ca4-98f4-4f0b00905f99",
        "tokens": [
            "Then",
            "I",
            "looked",
            "in",
            "the",
            "mirror",
            "and",
            "my",
            "eyes",
            "fell",
            "down",
            "the",
            "moment",
            "I",
            "saw",
            "my",
            "reflection",
            "."
        ],
        "lemmatized_tokens": [
            "then",
            "I",
            "look",
            "in",
            "the",
            "mirror",
            "and",
            "my",
            "eye",
            "fall",
            "down",
            "the",
            "moment",
            "I",
            "see",
            "my",
            "reflection",
            "."
        ],
        "preceding_context_tokens": [
            [
                "There",
                "'s",
                "no",
                "way",
                "that",
                "he",
                "is",
                "still",
                "going",
                "to",
                "listen",
                "to",
                "me",
                "now",
                "that",
                "he",
                "gotten",
                "what",
                "he",
                "want",
                "."
            ],
            [
                "'",
                "With",
                "a",
                "large",
                "effort",
                "I",
                "got",
                "back",
                "up",
                ",",
                "leaving",
                "my",
                "clothes",
                "behind",
                "on",
                "the",
                "floor",
                "and",
                "waggled",
                "to",
                "my",
                "bathroom",
                "."
            ],
            [
                "There",
                "I",
                "filled",
                "a",
                "glass",
                "with",
                "water",
                "and",
                "drank",
                "it",
                "quickly",
                "to",
                "release",
                "myself",
                "from",
                "the",
                "sake",
                "aftertaste",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "there",
                "be",
                "no",
                "way",
                "that",
                "he",
                "be",
                "still",
                "go",
                "to",
                "listen",
                "to",
                "I",
                "now",
                "that",
                "he",
                "get",
                "what",
                "he",
                "want",
                "."
            ],
            [
                "'",
                "with",
                "a",
                "large",
                "effort",
                "I",
                "get",
                "back",
                "up",
                ",",
                "leave",
                "my",
                "clothes",
                "behind",
                "on",
                "the",
                "floor",
                "and",
                "waggle",
                "to",
                "my",
                "bathroom",
                "."
            ],
            [
                "there",
                "I",
                "fill",
                "a",
                "glass",
                "with",
                "water",
                "and",
                "drink",
                "it",
                "quickly",
                "to",
                "release",
                "myself",
                "from",
                "the",
                "sake",
                "aftertaste",
                "."
            ]
        ],
        "label": "Disgust"
    },
    {
        "body_part_token_idx": 5,
        "sentence_id": "3405b6e6-694f-39b9-a797-9059d26c9a80",
        "tokens": [
            "Seeing",
            "that",
            "look",
            "on",
            "her",
            "face",
            "did",
            "nothing",
            "to",
            "quell",
            "the",
            "feeling",
            "of",
            "foreboding",
            "that",
            "was",
            "steadily",
            "engulfing",
            "me",
            "."
        ],
        "lemmatized_tokens": [
            "see",
            "that",
            "look",
            "on",
            "she",
            "face",
            "do",
            "nothing",
            "to",
            "quell",
            "the",
            "feeling",
            "of",
            "forebode",
            "that",
            "be",
            "steadily",
            "engulf",
            "I",
            "."
        ],
        "preceding_context_tokens": [
            [
                "She",
                "has",
                "n't",
                "told",
                "you?",
                "I",
                "could",
                "feel",
                "panic",
                "rising",
                "in",
                "my",
                "chest",
                "."
            ],
            [
                "Tell",
                "me",
                "what",
                "?"
            ],
            [
                "What",
                "are",
                "you",
                "on",
                "about?",
                "I",
                "do",
                "n't",
                "recollect",
                "ever",
                "seeing",
                "Luna",
                "nervous",
                "in",
                "all",
                "of",
                "the",
                "years",
                "that",
                "I",
                "'ve",
                "known",
                "her",
                ",",
                "but",
                "she",
                "was",
                "looking",
                "positively",
                "uncomfortable",
                "right",
                "now",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "she",
                "have",
                "not",
                "tell",
                "you?",
                "I",
                "could",
                "feel",
                "panic",
                "rise",
                "in",
                "my",
                "chest",
                "."
            ],
            [
                "tell",
                "I",
                "what",
                "?"
            ],
            [
                "what",
                "be",
                "you",
                "on",
                "about?",
                "I",
                "do",
                "not",
                "recollect",
                "ever",
                "see",
                "Luna",
                "nervous",
                "in",
                "all",
                "of",
                "the",
                "year",
                "that",
                "I",
                "have",
                "know",
                "she",
                ",",
                "but",
                "she",
                "be",
                "look",
                "positively",
                "uncomfortable",
                "right",
                "now",
                "."
            ]
        ],
        "label": "Fear"
    },
    {
        "body_part_token_idx": 3,
        "sentence_id": "d988eefa-2355-35ac-a55e-065e2e2906c2",
        "tokens": [
            "She",
            "licked",
            "her",
            "lips",
            "quickly",
            ",",
            "finding",
            "her",
            "eyes",
            "running",
            "over",
            "his",
            "chest",
            ",",
            "making",
            "her",
            "heart",
            "pound",
            "in",
            "need",
            ",",
            "drowning",
            "out",
            "the",
            "sounds",
            "of",
            "the",
            "night",
            "around",
            "them",
            "."
        ],
        "lemmatized_tokens": [
            "she",
            "lick",
            "she",
            "lip",
            "quickly",
            ",",
            "find",
            "she",
            "eye",
            "run",
            "over",
            "he",
            "chest",
            ",",
            "make",
            "she",
            "heart",
            "pound",
            "in",
            "need",
            ",",
            "drown",
            "out",
            "the",
            "sound",
            "of",
            "the",
            "night",
            "around",
            "they",
            "."
        ],
        "preceding_context_tokens": [
            [
                "``",
                "I",
                "know",
                ".",
                "''"
            ],
            [
                "she",
                "whispered",
                ",",
                "nodding",
                "her",
                "head",
                "slowly",
                ",",
                "her",
                "smile",
                "growing",
                "wider",
                "."
            ],
            [
                "``",
                "I",
                "'ve",
                "always",
                "known",
                ".",
                "''"
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "``",
                "I",
                "know",
                ".",
                "''"
            ],
            [
                "she",
                "whisper",
                ",",
                "nod",
                "she",
                "head",
                "slowly",
                ",",
                "she",
                "smile",
                "grow",
                "wider",
                "."
            ],
            [
                "``",
                "I",
                "have",
                "always",
                "know",
                ".",
                "''"
            ]
        ],
        "label": "Joy"
    },
    {
        "body_part_token_idx": 3,
        "sentence_id": "0a98bbb6-65d7-3d1d-95fc-78ab8d4630b6",
        "tokens": [
            "I",
            "raised",
            "my",
            "eyebrows",
            "suspiciously",
            "."
        ],
        "lemmatized_tokens": [
            "I",
            "raise",
            "my",
            "eyebrow",
            "suspiciously",
            "."
        ],
        "preceding_context_tokens": [
            [
                "I",
                "did",
                "n't",
                "want",
                "to",
                "explain",
                "what",
                "everyone",
                "wondered",
                "."
            ],
            [
                "I",
                "did",
                "n't",
                "want",
                "to",
                "explain",
                "that",
                "I",
                "had",
                "no",
                "idea",
                "how",
                "to",
                "explain",
                "how",
                "I",
                "felt",
                "."
            ],
            [
                "``",
                "I",
                "can",
                "give",
                "you",
                "her",
                "phone",
                "number",
                ",",
                "''",
                "Yuri",
                "volunteered",
                "excitedly",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "I",
                "do",
                "not",
                "want",
                "to",
                "explain",
                "what",
                "everyone",
                "wonder",
                "."
            ],
            [
                "I",
                "do",
                "not",
                "want",
                "to",
                "explain",
                "that",
                "I",
                "have",
                "no",
                "idea",
                "how",
                "to",
                "explain",
                "how",
                "I",
                "feel",
                "."
            ],
            [
                "``",
                "I",
                "can",
                "give",
                "you",
                "she",
                "phone",
                "number",
                ",",
                "''",
                "Yuri",
                "volunteer",
                "excitedly",
                "."
            ]
        ],
        "label": "Fear"
    },
    {
        "body_part_token_idx": 15,
        "sentence_id": "b5e0c620-8b55-3f9a-b24c-d5a99418d740",
        "tokens": [
            "Then",
            "did",
            "the",
            "same",
            "thing",
            "with",
            "my",
            "voice",
            ",",
            "''",
            "she",
            "recounts",
            ",",
            "shaking",
            "her",
            "head",
            "slowly",
            "as",
            "she",
            "hands",
            "the",
            "rings",
            "over",
            "one",
            "by",
            "one",
            "."
        ],
        "lemmatized_tokens": [
            "then",
            "do",
            "the",
            "same",
            "thing",
            "with",
            "my",
            "voice",
            ",",
            "''",
            "she",
            "recount",
            ",",
            "shake",
            "she",
            "head",
            "slowly",
            "as",
            "she",
            "hand",
            "the",
            "ring",
            "over",
            "one",
            "by",
            "one",
            "."
        ],
        "preceding_context_tokens": [
            [
                "``",
                "Jerk",
                ",",
                "''",
                "Chastity",
                "labels",
                "him",
                "."
            ],
            [
                "``",
                "Nothing",
                "externally",
                "."
            ],
            [
                "She",
                "was",
                "messing",
                "with",
                "the",
                "sound",
                "of",
                "the",
                "stereo",
                "in",
                "my",
                "rig",
                ",",
                "muting",
                "it",
                "and",
                "unmuting",
                "it",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "``",
                "jerk",
                ",",
                "''",
                "Chastity",
                "label",
                "he",
                "."
            ],
            [
                "``",
                "nothing",
                "externally",
                "."
            ],
            [
                "she",
                "be",
                "mess",
                "with",
                "the",
                "sound",
                "of",
                "the",
                "stereo",
                "in",
                "my",
                "rig",
                ",",
                "mute",
                "it",
                "and",
                "unmute",
                "it",
                "."
            ]
        ],
        "label": "Disgust"
    },
    {
        "body_part_token_idx": 1,
        "sentence_id": "12010f77-c4f6-3606-8f41-14efac45c819",
        "tokens": [
            "My",
            "heart",
            "immediately",
            "hurt",
            "."
        ],
        "lemmatized_tokens": [
            "my",
            "heart",
            "immediately",
            "hurt",
            "."
        ],
        "preceding_context_tokens": [
            [
                "January",
                "18",
                ",",
                "2011",
                "by",
                "Chet",
                "I",
                "noticed",
                "that",
                "she",
                "had",
                "left",
                "the",
                "hair",
                "dryer",
                "on",
                "the",
                "sink",
                "counter",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "January",
                "18",
                ",",
                "2011",
                "by",
                "Chet",
                "I",
                "notice",
                "that",
                "she",
                "have",
                "leave",
                "the",
                "hair",
                "dryer",
                "on",
                "the",
                "sink",
                "counter",
                "."
            ]
        ],
        "label": "Anger"
    },
    {
        "body_part_token_idx": 13,
        "sentence_id": "cdc6fe69-1fa1-3d86-8316-8b7962ed0f01",
        "tokens": [
            "I",
            "never",
            "have",
            "fallen",
            "for",
            "weaklings",
            ",",
            "though",
            "...",
            "''",
            "He",
            "shook",
            "his",
            "head",
            "a",
            "bit",
            "."
        ],
        "lemmatized_tokens": [
            "I",
            "never",
            "have",
            "fall",
            "for",
            "weakling",
            ",",
            "though",
            "...",
            "''",
            "he",
            "shake",
            "he",
            "head",
            "a",
            "bit",
            "."
        ],
        "preceding_context_tokens": [
            [
                "``",
                "Because",
                "I",
                "know",
                "that",
                "'s",
                "not",
                "who",
                "you",
                "are",
                "anymore",
                ".",
                "''"
            ],
            [
                "A",
                "slow",
                "smile",
                "crept",
                "onto",
                "her",
                "face",
                ",",
                "and",
                "he",
                "actually",
                "saw",
                "a",
                "slight",
                "hint",
                "of",
                "pride",
                "in",
                "her",
                "eyes",
                "."
            ],
            [
                "``",
                "I",
                "always",
                "knew",
                "you",
                "were",
                "strong",
                ",",
                "but",
                "I",
                "never",
                "imagined",
                "you",
                "might",
                "be",
                "among",
                "the",
                "toughest",
                "in",
                "the",
                "world",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "``",
                "because",
                "I",
                "know",
                "that",
                "be",
                "not",
                "who",
                "you",
                "be",
                "anymore",
                ".",
                "''"
            ],
            [
                "a",
                "slow",
                "smile",
                "creep",
                "onto",
                "she",
                "face",
                ",",
                "and",
                "he",
                "actually",
                "see",
                "a",
                "slight",
                "hint",
                "of",
                "pride",
                "in",
                "she",
                "eye",
                "."
            ],
            [
                "``",
                "I",
                "always",
                "know",
                "you",
                "be",
                "strong",
                ",",
                "but",
                "I",
                "never",
                "imagine",
                "you",
                "might",
                "be",
                "among",
                "the",
                "toughest",
                "in",
                "the",
                "world",
                "."
            ]
        ],
        "label": "Disgust"
    },
    {
        "body_part_token_idx": 1,
        "sentence_id": "5581a791-93a7-34c5-b8f0-6e535ea51363",
        "tokens": [
            "Her",
            "eyes",
            "widened",
            "and",
            "her",
            "mouth",
            "opened",
            "in",
            "a",
            "belated",
            "protest",
            ",",
            "but",
            "her",
            "objections",
            "were",
            "overridden",
            "by",
            "another",
            "incoming",
            "call",
            "."
        ],
        "lemmatized_tokens": [
            "she",
            "eye",
            "widen",
            "and",
            "she",
            "mouth",
            "open",
            "in",
            "a",
            "belated",
            "protest",
            ",",
            "but",
            "she",
            "objection",
            "be",
            "override",
            "by",
            "another",
            "incoming",
            "call",
            "."
        ],
        "preceding_context_tokens": [
            [
                "~",
                "/",
                "~",
                "/",
                "~",
                "/",
                "~",
                "/",
                "~",
                "/",
                "~",
                "6",
                "days",
                "ago",
                "~",
                "/",
                "~",
                "/",
                "~",
                "/",
                "~",
                "/",
                "~",
                "/",
                "~",
                "``",
                "Stay",
                "the",
                "hell",
                "away",
                "from",
                "my",
                "son",
                ",",
                "Luthor",
                "!"
            ],
            [
                "If",
                "I",
                "catch",
                "you",
                "anywhere",
                "near",
                "him",
                ",",
                "you",
                "'ll",
                "end",
                "up",
                "with",
                "more",
                "holes",
                "in",
                "you",
                "than",
                "you",
                "started",
                "with",
                "!",
                "''"
            ],
            [
                "Jonathan",
                "Kent",
                "slammed",
                "the",
                "phone",
                "'s",
                "receiver",
                "into",
                "the",
                "cradle",
                "hard",
                "enough",
                "that",
                "Martha",
                "heard",
                "the",
                "plastic",
                "crack",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "~",
                "/",
                "~",
                "/",
                "~",
                "/",
                "~",
                "/",
                "~",
                "/",
                "~",
                "6",
                "day",
                "ago",
                "~",
                "/",
                "~",
                "/",
                "~",
                "/",
                "~",
                "/",
                "~",
                "/",
                "~",
                "``",
                "stay",
                "the",
                "hell",
                "away",
                "from",
                "my",
                "son",
                ",",
                "Luthor",
                "!"
            ],
            [
                "if",
                "I",
                "catch",
                "you",
                "anywhere",
                "near",
                "he",
                ",",
                "you",
                "will",
                "end",
                "up",
                "with",
                "more",
                "hole",
                "in",
                "you",
                "than",
                "you",
                "start",
                "with",
                "!",
                "''"
            ],
            [
                "Jonathan",
                "Kent",
                "slam",
                "the",
                "phone",
                "'s",
                "receiver",
                "into",
                "the",
                "cradle",
                "hard",
                "enough",
                "that",
                "Martha",
                "hear",
                "the",
                "plastic",
                "crack",
                "."
            ]
        ],
        "label": "Surprise"
    },
    {
        "body_part_token_idx": 5,
        "sentence_id": "5581a791-93a7-34c5-b8f0-6e535ea51363",
        "tokens": [
            "Her",
            "eyes",
            "widened",
            "and",
            "her",
            "mouth",
            "opened",
            "in",
            "a",
            "belated",
            "protest",
            ",",
            "but",
            "her",
            "objections",
            "were",
            "overridden",
            "by",
            "another",
            "incoming",
            "call",
            "."
        ],
        "lemmatized_tokens": [
            "she",
            "eye",
            "widen",
            "and",
            "she",
            "mouth",
            "open",
            "in",
            "a",
            "belated",
            "protest",
            ",",
            "but",
            "she",
            "objection",
            "be",
            "override",
            "by",
            "another",
            "incoming",
            "call",
            "."
        ],
        "preceding_context_tokens": [
            [
                "~",
                "/",
                "~",
                "/",
                "~",
                "/",
                "~",
                "/",
                "~",
                "/",
                "~",
                "6",
                "days",
                "ago",
                "~",
                "/",
                "~",
                "/",
                "~",
                "/",
                "~",
                "/",
                "~",
                "/",
                "~",
                "``",
                "Stay",
                "the",
                "hell",
                "away",
                "from",
                "my",
                "son",
                ",",
                "Luthor",
                "!"
            ],
            [
                "If",
                "I",
                "catch",
                "you",
                "anywhere",
                "near",
                "him",
                ",",
                "you",
                "'ll",
                "end",
                "up",
                "with",
                "more",
                "holes",
                "in",
                "you",
                "than",
                "you",
                "started",
                "with",
                "!",
                "''"
            ],
            [
                "Jonathan",
                "Kent",
                "slammed",
                "the",
                "phone",
                "'s",
                "receiver",
                "into",
                "the",
                "cradle",
                "hard",
                "enough",
                "that",
                "Martha",
                "heard",
                "the",
                "plastic",
                "crack",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "~",
                "/",
                "~",
                "/",
                "~",
                "/",
                "~",
                "/",
                "~",
                "/",
                "~",
                "6",
                "day",
                "ago",
                "~",
                "/",
                "~",
                "/",
                "~",
                "/",
                "~",
                "/",
                "~",
                "/",
                "~",
                "``",
                "stay",
                "the",
                "hell",
                "away",
                "from",
                "my",
                "son",
                ",",
                "Luthor",
                "!"
            ],
            [
                "if",
                "I",
                "catch",
                "you",
                "anywhere",
                "near",
                "he",
                ",",
                "you",
                "will",
                "end",
                "up",
                "with",
                "more",
                "hole",
                "in",
                "you",
                "than",
                "you",
                "start",
                "with",
                "!",
                "''"
            ],
            [
                "Jonathan",
                "Kent",
                "slam",
                "the",
                "phone",
                "'s",
                "receiver",
                "into",
                "the",
                "cradle",
                "hard",
                "enough",
                "that",
                "Martha",
                "hear",
                "the",
                "plastic",
                "crack",
                "."
            ]
        ],
        "label": "Surprise"
    },
    {
        "body_part_token_idx": 29,
        "sentence_id": "c01c57de-f29f-346b-a646-e293ecbdd0a8",
        "tokens": [
            "Pulling",
            "Kibum",
            "'s",
            "hands",
            "until",
            "he",
            "fell",
            "against",
            "the",
            "older",
            "man",
            "'s",
            "broad",
            "chest",
            ",",
            "frown",
            "still",
            "pulling",
            "his",
            "sleek",
            "eye",
            "brows",
            "together",
            "in",
            "the",
            "middle",
            "and",
            "leaving",
            "his",
            "lips",
            "in",
            "a",
            "pout",
            "."
        ],
        "lemmatized_tokens": [
            "pull",
            "Kibum",
            "'s",
            "hand",
            "until",
            "he",
            "fall",
            "against",
            "the",
            "older",
            "man",
            "'s",
            "broad",
            "chest",
            ",",
            "frown",
            "still",
            "pull",
            "he",
            "sleek",
            "eye",
            "brow",
            "together",
            "in",
            "the",
            "middle",
            "and",
            "leave",
            "he",
            "lip",
            "in",
            "a",
            "pout",
            "."
        ],
        "preceding_context_tokens": [
            [
                "He",
                "'d",
                "been",
                "hearing",
                "the",
                "same",
                "thing",
                "from",
                "people",
                "his",
                "own",
                "age",
                "for",
                "years",
                "now",
                "."
            ],
            [
                "He",
                "did",
                "n't",
                "think",
                "he",
                "'d",
                "have",
                "to",
                "deal",
                "with",
                "the",
                "same",
                "shit",
                "from",
                "his",
                "...",
                "friend",
                "."
            ],
            [
                "Thankfully",
                ",",
                "Jonghyun",
                "was",
                "quick",
                "to",
                "react",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "he",
                "have",
                "be",
                "hear",
                "the",
                "same",
                "thing",
                "from",
                "people",
                "he",
                "own",
                "age",
                "for",
                "year",
                "now",
                "."
            ],
            [
                "he",
                "do",
                "not",
                "think",
                "he",
                "would",
                "have",
                "to",
                "deal",
                "with",
                "the",
                "same",
                "shit",
                "from",
                "he",
                "...",
                "friend",
                "."
            ],
            [
                "thankfully",
                ",",
                "Jonghyun",
                "be",
                "quick",
                "to",
                "react",
                "."
            ]
        ],
        "label": "Anger"
    },
    {
        "body_part_token_idx": 2,
        "sentence_id": "f18ffd69-713e-3be4-a014-872cc68ad2f1",
        "tokens": [
            "Biting",
            "his",
            "lip",
            ",",
            "he",
            "pretends",
            "to",
            "not",
            "have",
            "heard",
            "it",
            ",",
            "and",
            "shoves",
            "his",
            "clothes",
            "into",
            "the",
            "laundry",
            "basket",
            "."
        ],
        "lemmatized_tokens": [
            "bite",
            "he",
            "lip",
            ",",
            "he",
            "pretend",
            "to",
            "not",
            "have",
            "hear",
            "it",
            ",",
            "and",
            "shove",
            "he",
            "clothes",
            "into",
            "the",
            "laundry",
            "basket",
            "."
        ],
        "preceding_context_tokens": [
            [
                "He",
                "'s",
                "halfway",
                "through",
                "searching",
                "for",
                "his",
                "lyric",
                "book",
                "when",
                "there",
                "'s",
                "a",
                "knock",
                "on",
                "the",
                "door",
                "."
            ],
            [
                "He",
                "pauses",
                ",",
                "clothes",
                "raised",
                "in",
                "his",
                "hands",
                ",",
                "and",
                "his",
                "heart",
                "slides",
                "down",
                "to",
                "his",
                "feet",
                "."
            ],
            [
                "He",
                "'s",
                "certain",
                "he",
                "knows",
                "who",
                "is",
                "waiting",
                "outside",
                "his",
                "door",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "he",
                "be",
                "halfway",
                "through",
                "search",
                "for",
                "he",
                "lyric",
                "book",
                "when",
                "there",
                "be",
                "a",
                "knock",
                "on",
                "the",
                "door",
                "."
            ],
            [
                "he",
                "pause",
                ",",
                "clothes",
                "raise",
                "in",
                "he",
                "hand",
                ",",
                "and",
                "he",
                "heart",
                "slide",
                "down",
                "to",
                "he",
                "foot",
                "."
            ],
            [
                "he",
                "be",
                "certain",
                "he",
                "know",
                "who",
                "be",
                "wait",
                "outside",
                "he",
                "door",
                "."
            ]
        ],
        "label": "Fear"
    },
    {
        "body_part_token_idx": 22,
        "sentence_id": "a8af882b-96fa-31f3-b68b-3ed5740fcde5",
        "tokens": [
            "Now",
            ",",
            "when",
            "I",
            "look",
            "at",
            "this",
            "cluster",
            ",",
            "it",
            "does",
            "n't",
            "surprize",
            "me",
            "but",
            "it",
            "does",
            "bring",
            "a",
            "smile",
            "to",
            "my",
            "face",
            "knowing",
            "that",
            "I",
            "'ve",
            "indeed",
            "grown",
            "out",
            "of",
            "it",
            "and",
            "am",
            "learning",
            "to",
            "find",
            "my",
            "own",
            "happiness",
            "."
        ],
        "lemmatized_tokens": [
            "now",
            ",",
            "when",
            "I",
            "look",
            "at",
            "this",
            "cluster",
            ",",
            "it",
            "do",
            "not",
            "surprize",
            "I",
            "but",
            "it",
            "do",
            "bring",
            "a",
            "smile",
            "to",
            "my",
            "face",
            "know",
            "that",
            "I",
            "have",
            "indeed",
            "grow",
            "out",
            "of",
            "it",
            "and",
            "be",
            "learn",
            "to",
            "find",
            "my",
            "own",
            "happiness",
            "."
        ],
        "preceding_context_tokens": [
            [
                "The",
                "Old",
                "Blog",
                "Cluster",
                "vs.",
                "The",
                "Present",
                "Day",
                "Cluster",
                "As",
                "obvious",
                ",",
                "the",
                "Old",
                "Blog",
                "cluster",
                "is",
                "dominated",
                "with",
                "words",
                "like",
                ":",
                "-",
                "dark",
                "-",
                "cold",
                "-",
                "foul",
                "-",
                "sobbed",
                "-",
                "sadness",
                "-",
                "emotions",
                "-",
                "honor",
                "-",
                "divided",
                "-",
                "bitter",
                "-",
                "cynical",
                "-",
                "lost",
                "-",
                "and",
                "so",
                "on",
                "."
            ],
            [
                "I",
                "honestly",
                "did",
                "n't",
                "realize",
                "that",
                "I",
                "was",
                "writing",
                "all",
                "these",
                "negative",
                "words",
                "."
            ],
            [
                "I",
                "was",
                "merely",
                "writing",
                "as",
                "I",
                "felt",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "the",
                "Old",
                "Blog",
                "Cluster",
                "vs.",
                "the",
                "Present",
                "Day",
                "Cluster",
                "as",
                "obvious",
                ",",
                "the",
                "Old",
                "Blog",
                "cluster",
                "be",
                "dominate",
                "with",
                "word",
                "like",
                ":",
                "-",
                "dark",
                "-",
                "cold",
                "-",
                "foul",
                "-",
                "sob",
                "-",
                "sadness",
                "-",
                "emotion",
                "-",
                "honor",
                "-",
                "divide",
                "-",
                "bitter",
                "-",
                "cynical",
                "-",
                "lost",
                "-",
                "and",
                "so",
                "on",
                "."
            ],
            [
                "I",
                "honestly",
                "do",
                "not",
                "realize",
                "that",
                "I",
                "be",
                "write",
                "all",
                "these",
                "negative",
                "word",
                "."
            ],
            [
                "I",
                "be",
                "merely",
                "write",
                "as",
                "I",
                "feel",
                "."
            ]
        ],
        "label": "Joy"
    },
    {
        "body_part_token_idx": 9,
        "sentence_id": "6ee04bef-bc75-38fe-a5ea-df4f77d02094",
        "tokens": [
            "She",
            "let",
            "out",
            "a",
            "slow",
            "breath",
            ",",
            "hanging",
            "her",
            "head",
            "slightly",
            "."
        ],
        "lemmatized_tokens": [
            "she",
            "let",
            "out",
            "a",
            "slow",
            "breath",
            ",",
            "hang",
            "she",
            "head",
            "slightly",
            "."
        ],
        "preceding_context_tokens": [
            [
                "She",
                "could",
                "see",
                "the",
                "anger",
                "and",
                "discomfort",
                "in",
                "his",
                "eyes",
                "."
            ],
            [
                "He",
                "finally",
                "said",
                ",",
                "``",
                "I",
                "ca",
                "n't",
                "say",
                "I",
                "blame",
                "you",
                "for",
                "not",
                "sticking",
                "around",
                "for",
                "this",
                "one",
                ".",
                "''"
            ],
            [
                "``",
                "Was",
                "n't",
                "what",
                "I",
                "asked",
                ".",
                "''"
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "she",
                "could",
                "see",
                "the",
                "anger",
                "and",
                "discomfort",
                "in",
                "he",
                "eye",
                "."
            ],
            [
                "he",
                "finally",
                "say",
                ",",
                "``",
                "I",
                "can",
                "not",
                "say",
                "I",
                "blame",
                "you",
                "for",
                "not",
                "stick",
                "around",
                "for",
                "this",
                "one",
                ".",
                "''"
            ],
            [
                "``",
                "be",
                "not",
                "what",
                "I",
                "ask",
                ".",
                "''"
            ]
        ],
        "label": "Disgust"
    },
    {
        "body_part_token_idx": 20,
        "sentence_id": "35f208e3-65f5-3f4a-8b8f-d99e3a70598c",
        "tokens": [
            "So",
            "the",
            "little",
            "girl",
            ",",
            "maybe",
            "about",
            "eight",
            "years",
            "old",
            ",",
            "is",
            "starting",
            "to",
            "get",
            "this",
            "terrified",
            "look",
            "on",
            "her",
            "face",
            ",",
            "and",
            "she",
            "'s",
            "trying",
            "to",
            "throw",
            "the",
            "bread",
            "farther",
            "to",
            "get",
            "them",
            "to",
            "go",
            "away",
            "--",
            "which",
            "of",
            "course",
            "has",
            "the",
            "opposite",
            "effect",
            "."
        ],
        "lemmatized_tokens": [
            "so",
            "the",
            "little",
            "girl",
            ",",
            "maybe",
            "about",
            "eight",
            "year",
            "old",
            ",",
            "be",
            "start",
            "to",
            "get",
            "this",
            "terrified",
            "look",
            "on",
            "she",
            "face",
            ",",
            "and",
            "she",
            "be",
            "try",
            "to",
            "throw",
            "the",
            "bread",
            "farther",
            "to",
            "get",
            "they",
            "to",
            "go",
            "away",
            "--",
            "which",
            "of",
            "course",
            "have",
            "the",
            "opposite",
            "effect",
            "."
        ],
        "preceding_context_tokens": [
            [
                "There",
                "was",
                "a",
                "grandmother",
                "and",
                "a",
                "granddaughter",
                ",",
                "who",
                "were",
                "making",
                "the",
                "rookie",
                "mistake",
                "of",
                "feeding",
                "the",
                "seagulls",
                "."
            ],
            [
                "If",
                "you",
                "'ve",
                "spent",
                "any",
                "time",
                "on",
                "the",
                "Eastern",
                "Shore",
                ",",
                "you",
                "know",
                "how",
                "aggressive",
                "these",
                "birds",
                "are",
                "."
            ],
            [
                "I",
                "had",
                "one",
                "steal",
                "a",
                "fry",
                "right",
                "out",
                "of",
                "my",
                "hand",
                ",",
                "just",
                "before",
                "I",
                "was",
                "going",
                "to",
                "eat",
                "it",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "there",
                "be",
                "a",
                "grandmother",
                "and",
                "a",
                "granddaughter",
                ",",
                "who",
                "be",
                "make",
                "the",
                "rookie",
                "mistake",
                "of",
                "feed",
                "the",
                "seagull",
                "."
            ],
            [
                "if",
                "you",
                "have",
                "spend",
                "any",
                "time",
                "on",
                "the",
                "Eastern",
                "Shore",
                ",",
                "you",
                "know",
                "how",
                "aggressive",
                "these",
                "bird",
                "be",
                "."
            ],
            [
                "I",
                "have",
                "one",
                "steal",
                "a",
                "fry",
                "right",
                "out",
                "of",
                "my",
                "hand",
                ",",
                "just",
                "before",
                "I",
                "be",
                "go",
                "to",
                "eat",
                "it",
                "."
            ]
        ],
        "label": "Fear"
    },
    {
        "body_part_token_idx": 4,
        "sentence_id": "f0c20f19-053e-3505-b884-a9e783360b50",
        "tokens": [
            "He",
            "just",
            "shrugged",
            "his",
            "shoulders",
            ",",
            "and",
            "continued",
            "eating",
            "his",
            "food",
            "."
        ],
        "lemmatized_tokens": [
            "he",
            "just",
            "shrug",
            "he",
            "shoulder",
            ",",
            "and",
            "continue",
            "eat",
            "he",
            "food",
            "."
        ],
        "preceding_context_tokens": [
            [
                "I",
                "showed",
                "him",
                "what",
                "I",
                "meant",
                ",",
                "he",
                "looked",
                "at",
                "me",
                "for",
                "a",
                "moment",
                "before",
                "going",
                ",",
                "``",
                "leave",
                "me",
                "alone",
                "''",
                "joking",
                "around",
                ",",
                "but",
                "I",
                "was",
                "serious",
                "."
            ],
            [
                "He",
                "told",
                "me",
                "that",
                "it",
                "was",
                "because",
                "he",
                "was",
                "so",
                "tall",
                ",",
                "but",
                "I",
                "'m",
                "taller",
                "than",
                "him",
                "sitting",
                "down",
                ",",
                "and",
                "pointed",
                "it",
                "out",
                "to",
                "him",
                "."
            ],
            [
                "That",
                "I",
                "use",
                "table",
                "manners",
                "and",
                "did",
                "n't",
                "dribble",
                "food",
                "on",
                "my",
                "clothing",
                "or",
                "anything",
                "else",
                "for",
                "that",
                "matter",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "I",
                "show",
                "he",
                "what",
                "I",
                "mean",
                ",",
                "he",
                "look",
                "at",
                "I",
                "for",
                "a",
                "moment",
                "before",
                "go",
                ",",
                "``",
                "leave",
                "I",
                "alone",
                "''",
                "joke",
                "around",
                ",",
                "but",
                "I",
                "be",
                "serious",
                "."
            ],
            [
                "he",
                "tell",
                "I",
                "that",
                "it",
                "be",
                "because",
                "he",
                "be",
                "so",
                "tall",
                ",",
                "but",
                "I",
                "be",
                "taller",
                "than",
                "he",
                "sit",
                "down",
                ",",
                "and",
                "point",
                "it",
                "out",
                "to",
                "he",
                "."
            ],
            [
                "that",
                "I",
                "use",
                "table",
                "manners",
                "and",
                "do",
                "not",
                "dribble",
                "food",
                "on",
                "my",
                "clothing",
                "or",
                "anything",
                "else",
                "for",
                "that",
                "matter",
                "."
            ]
        ],
        "label": "Disgust"
    },
    {
        "body_part_token_idx": 1,
        "sentence_id": "56111c23-a0ce-3e53-a237-2d50514a43e1",
        "tokens": [
            "Her",
            "eyes",
            "shone",
            "even",
            "brighter",
            ",",
            "and",
            "that",
            "dimple",
            "reappeared",
            "."
        ],
        "lemmatized_tokens": [
            "she",
            "eye",
            "shine",
            "even",
            "brighter",
            ",",
            "and",
            "that",
            "dimple",
            "reappear",
            "."
        ],
        "preceding_context_tokens": [
            [
                "He",
                "began",
                "to",
                "talk",
                "to",
                "her",
                "about",
                "his",
                "plans",
                "for",
                "having",
                "the",
                "men",
                "in",
                "their",
                "youth",
                "group",
                "stay",
                "overnight",
                "one",
                "Friday",
                ",",
                "and",
                "the",
                "women",
                "the",
                "next",
                "."
            ],
            [
                "About",
                "how",
                "a",
                "particular",
                "speaker",
                "had",
                "agreed",
                "to",
                "do",
                "both",
                "weekends",
                "for",
                "them",
                "."
            ],
            [
                "About",
                "campfires",
                "and",
                "sleeping",
                "bags",
                "and",
                "s'mores",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "he",
                "begin",
                "to",
                "talk",
                "to",
                "she",
                "about",
                "he",
                "plan",
                "for",
                "have",
                "the",
                "man",
                "in",
                "they",
                "youth",
                "group",
                "stay",
                "overnight",
                "one",
                "Friday",
                ",",
                "and",
                "the",
                "woman",
                "the",
                "next",
                "."
            ],
            [
                "about",
                "how",
                "a",
                "particular",
                "speaker",
                "have",
                "agree",
                "to",
                "do",
                "both",
                "weekend",
                "for",
                "they",
                "."
            ],
            [
                "about",
                "campfire",
                "and",
                "sleep",
                "bag",
                "and",
                "s'more",
                "."
            ]
        ],
        "label": "Joy"
    },
    {
        "body_part_token_idx": 28,
        "sentence_id": "806e793f-f276-3172-be07-768fec321249",
        "tokens": [
            "Randa",
            "had",
            "not",
            "closed",
            "the",
            "door",
            "securely",
            "and",
            "the",
            "door",
            "started",
            "creeping",
            "open",
            "ever",
            "so",
            "slowly",
            "-LRB-",
            "Serena",
            "saw",
            "this",
            "and",
            "remained",
            "frozen",
            "solid",
            "with",
            "part",
            "of",
            "her",
            "mouth",
            "open",
            "since",
            "it",
            "was",
            "too",
            "late",
            "to",
            "do",
            "anything",
            "at",
            "that",
            "point",
            ")",
            "--",
            "Randa",
            "had",
            "been",
            "standing",
            "like",
            "a",
            "man",
            "over",
            "the",
            "toilet",
            "taking",
            "a",
            "piss",
            "like",
            "a",
            "man",
            "."
        ],
        "lemmatized_tokens": [
            "Randa",
            "have",
            "not",
            "close",
            "the",
            "door",
            "securely",
            "and",
            "the",
            "door",
            "start",
            "creep",
            "open",
            "ever",
            "so",
            "slowly",
            "-lrb-",
            "Serena",
            "see",
            "this",
            "and",
            "remain",
            "frozen",
            "solid",
            "with",
            "part",
            "of",
            "she",
            "mouth",
            "open",
            "since",
            "it",
            "be",
            "too",
            "late",
            "to",
            "do",
            "anything",
            "at",
            "that",
            "point",
            ")",
            "--",
            "Randa",
            "have",
            "be",
            "stand",
            "like",
            "a",
            "man",
            "over",
            "the",
            "toilet",
            "take",
            "a",
            "piss",
            "like",
            "a",
            "man",
            "."
        ],
        "preceding_context_tokens": [
            [
                "Yes",
                ",",
                "I",
                "said",
                "balls",
                "."
            ],
            [
                "Then",
                "Randa",
                "walked",
                "past",
                "me",
                "to",
                "go",
                "into",
                "the",
                "bathroom",
                "shutting",
                "the",
                "door",
                "behind",
                "her",
                "."
            ],
            [
                "I",
                "could",
                "immediately",
                "hear",
                "the",
                "rush",
                "of",
                "piss",
                "pouring",
                "into",
                "the",
                "toilet",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "yes",
                ",",
                "I",
                "say",
                "ball",
                "."
            ],
            [
                "then",
                "Randa",
                "walk",
                "past",
                "I",
                "to",
                "go",
                "into",
                "the",
                "bathroom",
                "shut",
                "the",
                "door",
                "behind",
                "she",
                "."
            ],
            [
                "I",
                "could",
                "immediately",
                "hear",
                "the",
                "rush",
                "of",
                "piss",
                "pour",
                "into",
                "the",
                "toilet",
                "."
            ]
        ],
        "label": "Surprise"
    },
    {
        "body_part_token_idx": 3,
        "sentence_id": "74b250c4-553e-3982-832e-0577b747da1a",
        "tokens": [
            "He",
            "placed",
            "his",
            "hands",
            "flat",
            "on",
            "the",
            "table",
            ",",
            "digging",
            "his",
            "nails",
            "into",
            "the",
            "wood",
            "."
        ],
        "lemmatized_tokens": [
            "he",
            "place",
            "he",
            "hand",
            "flat",
            "on",
            "the",
            "table",
            ",",
            "dig",
            "he",
            "nail",
            "into",
            "the",
            "wood",
            "."
        ],
        "preceding_context_tokens": [
            [
                "Her",
                "eyes",
                "softened",
                "."
            ],
            [
                "``",
                "That",
                "leaves",
                "you",
                "very",
                "few",
                "options",
                "."
            ],
            [
                "``",
                "It",
                "took",
                "a",
                "moment",
                "to",
                "realise",
                "the",
                "implications",
                ",",
                "the",
                "reason",
                "for",
                "her",
                "sobriety",
                "and",
                "the",
                "unexpected",
                "ability",
                "to",
                "refuse",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "she",
                "eye",
                "soften",
                "."
            ],
            [
                "``",
                "that",
                "leave",
                "you",
                "very",
                "few",
                "option",
                "."
            ],
            [
                "``",
                "it",
                "take",
                "a",
                "moment",
                "to",
                "realise",
                "the",
                "implication",
                ",",
                "the",
                "reason",
                "for",
                "she",
                "sobriety",
                "and",
                "the",
                "unexpected",
                "ability",
                "to",
                "refuse",
                "."
            ]
        ],
        "label": "Anger"
    },
    {
        "body_part_token_idx": 11,
        "sentence_id": "74b250c4-553e-3982-832e-0577b747da1a",
        "tokens": [
            "He",
            "placed",
            "his",
            "hands",
            "flat",
            "on",
            "the",
            "table",
            ",",
            "digging",
            "his",
            "nails",
            "into",
            "the",
            "wood",
            "."
        ],
        "lemmatized_tokens": [
            "he",
            "place",
            "he",
            "hand",
            "flat",
            "on",
            "the",
            "table",
            ",",
            "dig",
            "he",
            "nail",
            "into",
            "the",
            "wood",
            "."
        ],
        "preceding_context_tokens": [
            [
                "Her",
                "eyes",
                "softened",
                "."
            ],
            [
                "``",
                "That",
                "leaves",
                "you",
                "very",
                "few",
                "options",
                "."
            ],
            [
                "``",
                "It",
                "took",
                "a",
                "moment",
                "to",
                "realise",
                "the",
                "implications",
                ",",
                "the",
                "reason",
                "for",
                "her",
                "sobriety",
                "and",
                "the",
                "unexpected",
                "ability",
                "to",
                "refuse",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "she",
                "eye",
                "soften",
                "."
            ],
            [
                "``",
                "that",
                "leave",
                "you",
                "very",
                "few",
                "option",
                "."
            ],
            [
                "``",
                "it",
                "take",
                "a",
                "moment",
                "to",
                "realise",
                "the",
                "implication",
                ",",
                "the",
                "reason",
                "for",
                "she",
                "sobriety",
                "and",
                "the",
                "unexpected",
                "ability",
                "to",
                "refuse",
                "."
            ]
        ],
        "label": "Anger"
    },
    {
        "body_part_token_idx": 7,
        "sentence_id": "c8a4b078-f06f-34c7-8f80-053626ed2232",
        "tokens": [
            "A",
            "surprised",
            "Lieutenant",
            "Russom",
            "jumped",
            "to",
            "her",
            "feet",
            "as",
            "the",
            "two",
            "materialized",
            "a",
            "few",
            "feet",
            "away",
            "from",
            "her",
            "."
        ],
        "lemmatized_tokens": [
            "a",
            "surprised",
            "Lieutenant",
            "Russom",
            "jump",
            "to",
            "she",
            "foot",
            "as",
            "the",
            "two",
            "materialize",
            "a",
            "few",
            "foot",
            "away",
            "from",
            "she",
            "."
        ],
        "preceding_context_tokens": [
            [
                "Less",
                "then",
                "an",
                "hour",
                "later",
                ",",
                "the",
                "two",
                "women",
                "were",
                "in",
                "the",
                "transporter",
                "room",
                "heading",
                "to",
                "where",
                "the",
                "crew",
                "decided",
                "to",
                "erect",
                "a",
                "campsite",
                "for",
                "all",
                "who",
                "did",
                "n't",
                "want",
                "to",
                "stay",
                "alone",
                "in",
                "the",
                "wilderness",
                "."
            ],
            [
                "The",
                "encampment",
                "was",
                "made",
                "up",
                "of",
                "several",
                "circles",
                "of",
                "tents",
                "in",
                "various",
                "sizes",
                "around",
                "the",
                "remains",
                "of",
                "a",
                "bonfire",
                "circled",
                "with",
                "rocks",
                "."
            ],
            [
                "``",
                "Captain",
                "!",
                "''"
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "less",
                "then",
                "a",
                "hour",
                "later",
                ",",
                "the",
                "two",
                "woman",
                "be",
                "in",
                "the",
                "transporter",
                "room",
                "head",
                "to",
                "where",
                "the",
                "crew",
                "decide",
                "to",
                "erect",
                "a",
                "campsite",
                "for",
                "all",
                "who",
                "do",
                "not",
                "want",
                "to",
                "stay",
                "alone",
                "in",
                "the",
                "wilderness",
                "."
            ],
            [
                "the",
                "encampment",
                "be",
                "make",
                "up",
                "of",
                "several",
                "circle",
                "of",
                "tent",
                "in",
                "various",
                "size",
                "around",
                "the",
                "remains",
                "of",
                "a",
                "bonfire",
                "circle",
                "with",
                "rock",
                "."
            ],
            [
                "``",
                "Captain",
                "!",
                "''"
            ]
        ],
        "label": "Surprise"
    },
    {
        "body_part_token_idx": 1,
        "sentence_id": "c9a0ccc8-0333-3c13-bbe7-49507be4423c",
        "tokens": [
            "His",
            "eyes",
            "are",
            "wide",
            "and",
            "dazed",
            ",",
            "like",
            "he",
            "'s",
            "just",
            "discovered",
            "the",
            "secrets",
            "of",
            "the",
            "universe",
            ",",
            "and",
            "I",
            "ca",
            "n't",
            "help",
            "but",
            "smile",
            "."
        ],
        "lemmatized_tokens": [
            "he",
            "eye",
            "be",
            "wide",
            "and",
            "dazed",
            ",",
            "like",
            "he",
            "be",
            "just",
            "discover",
            "the",
            "secret",
            "of",
            "the",
            "universe",
            ",",
            "and",
            "I",
            "can",
            "not",
            "help",
            "but",
            "smile",
            "."
        ],
        "preceding_context_tokens": [
            [
                "Where",
                "did",
                "he",
                "learn",
                "to",
                "do",
                "this",
                "?"
            ],
            [
                "I",
                "know",
                "it",
                "'s",
                "not",
                "something",
                "I",
                "taught",
                "him",
                ",",
                "not",
                "when",
                "I",
                "remember",
                "the",
                "way",
                "I",
                "washed",
                "him",
                "when",
                "we",
                "were",
                "last",
                "together",
                ",",
                "turning",
                "him",
                "this",
                "way",
                "and",
                "that",
                ",",
                "scrubbing",
                "him",
                "like",
                "some",
                "kind",
                "of",
                "unwanted",
                "animal",
                "instead",
                "of",
                "the",
                "treasured",
                "childe",
                "he",
                "is",
                "."
            ],
            [
                "I",
                "toss",
                "the",
                "washcloth",
                "aside",
                "and",
                "reach",
                "for",
                "the",
                "clean",
                "towel",
                ",",
                "drying",
                "him",
                "carefully",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "where",
                "do",
                "he",
                "learn",
                "to",
                "do",
                "this",
                "?"
            ],
            [
                "I",
                "know",
                "it",
                "be",
                "not",
                "something",
                "I",
                "teach",
                "he",
                ",",
                "not",
                "when",
                "I",
                "remember",
                "the",
                "way",
                "I",
                "wash",
                "he",
                "when",
                "we",
                "be",
                "last",
                "together",
                ",",
                "turn",
                "he",
                "this",
                "way",
                "and",
                "that",
                ",",
                "scrub",
                "he",
                "like",
                "some",
                "kind",
                "of",
                "unwanted",
                "animal",
                "instead",
                "of",
                "the",
                "treasure",
                "childe",
                "he",
                "be",
                "."
            ],
            [
                "I",
                "toss",
                "the",
                "washcloth",
                "aside",
                "and",
                "reach",
                "for",
                "the",
                "clean",
                "towel",
                ",",
                "dry",
                "he",
                "carefully",
                "."
            ]
        ],
        "label": "Joy"
    },
    {
        "body_part_token_idx": 16,
        "sentence_id": "46c11855-48e5-3924-89b0-90e219deec6e",
        "tokens": [
            "I",
            "was",
            "so",
            "eager",
            "and",
            "excited",
            "to",
            "leave",
            "to",
            "the",
            "point",
            "I",
            "had",
            "butterflies",
            "in",
            "my",
            "stomach",
            "."
        ],
        "lemmatized_tokens": [
            "I",
            "be",
            "so",
            "eager",
            "and",
            "excited",
            "to",
            "leave",
            "to",
            "the",
            "point",
            "I",
            "have",
            "butterfly",
            "in",
            "my",
            "stomach",
            "."
        ],
        "preceding_context_tokens": [
            [
                "Why",
                "?"
            ],
            [
                "I",
                "prefer",
                "celebrating",
                "the",
                "most",
                "joyous",
                "of",
                "all",
                "holidays",
                "in",
                "the",
                "tropics",
                "rather",
                "than",
                "in",
                "the",
                "freezing",
                "cold",
                "temperatures",
                "that",
                "Mother",
                "Nature",
                "likes",
                "unleashing",
                "on",
                "us",
                "kind",
                "folks",
                "up",
                "here",
                "."
            ],
            [
                "The",
                "night",
                "before",
                "I",
                "departed",
                "I",
                "did",
                "n't",
                "sleep",
                "a",
                "wink",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "why",
                "?"
            ],
            [
                "I",
                "prefer",
                "celebrate",
                "the",
                "most",
                "joyous",
                "of",
                "all",
                "holiday",
                "in",
                "the",
                "tropics",
                "rather",
                "than",
                "in",
                "the",
                "freezing",
                "cold",
                "temperature",
                "that",
                "Mother",
                "Nature",
                "like",
                "unleash",
                "on",
                "we",
                "kind",
                "folk",
                "up",
                "here",
                "."
            ],
            [
                "the",
                "night",
                "before",
                "I",
                "depart",
                "I",
                "do",
                "not",
                "sleep",
                "a",
                "wink",
                "."
            ]
        ],
        "label": "Surprise"
    },
    {
        "body_part_token_idx": 4,
        "sentence_id": "0e50a9b0-27a6-3c60-b6e0-a0c793e7bc98",
        "tokens": [
            "The",
            "knotting",
            "in",
            "his",
            "stomach",
            "was",
            "back",
            ",",
            "just",
            "like",
            "how",
            "it",
            "was",
            "when",
            "he",
            "had",
            "confronted",
            "Manaphy",
            "at",
            "the",
            "school",
            "swimming",
            "pool",
            "."
        ],
        "lemmatized_tokens": [
            "the",
            "knotting",
            "in",
            "he",
            "stomach",
            "be",
            "back",
            ",",
            "just",
            "like",
            "how",
            "it",
            "be",
            "when",
            "he",
            "have",
            "confront",
            "Manaphy",
            "at",
            "the",
            "school",
            "swimming",
            "pool",
            "."
        ],
        "preceding_context_tokens": [
            [
                "-LRB-",
                "or",
                "maybe",
                "the",
                "main",
                "room",
                "i",
                "dunnoe",
                "D8",
                ")",
                "When",
                ":",
                "Sometime",
                "August",
                "7thRating",
                ":",
                "PG",
                "(",
                "ooc",
                ":",
                "fff",
                "me",
                "and",
                "my",
                "lame",
                "titles",
                ")",
                "With",
                "so",
                "many",
                "bits",
                "and",
                "pieces",
                "of",
                "memories",
                "that",
                "he",
                "had",
                "yet",
                "to",
                "regain",
                "from",
                "the",
                "two",
                "nights",
                "of",
                "messing",
                "up",
                "fellow",
                "students",
                "'",
                "rooms",
                ",",
                "Kirby",
                "wondered",
                "who",
                "else",
                "saw",
                "him",
                "causing",
                "so",
                "many",
                "problems",
                "during",
                "that",
                "time",
                "as",
                "he",
                "reluctantly",
                "made",
                "his",
                "way",
                "to",
                "the",
                "dorm",
                "'s",
                "main",
                "room",
                "to",
                "meet",
                "up",
                "with",
                "the",
                "blue",
                "-",
                "haired",
                "prince",
                "."
            ],
            [
                "Although",
                "he",
                "perfectly",
                "remembered",
                "what",
                "he",
                "had",
                "done",
                "to",
                "Manaphy",
                "'s",
                "room",
                ",",
                "the",
                "pink",
                "boy",
                "could",
                "n't",
                "exactly",
                "remember",
                "what",
                "he",
                "did",
                "while",
                "he",
                "was",
                "in",
                "Marth",
                "'s",
                "room.From",
                "the",
                "bits",
                "and",
                "pieces",
                "he",
                "could",
                "gather",
                "were",
                "``",
                "photographs",
                "''",
                "and",
                "something",
                "about",
                "growing",
                "something",
                "."
            ],
            [
                "Did",
                "he",
                "water",
                "some",
                "plants",
                "while",
                "he",
                "was",
                "Marth",
                "'s",
                "room?But",
                "nonetheless",
                ",",
                "he",
                "did",
                "feel",
                "horrible",
                "for",
                "pulling",
                "off",
                "whatever",
                "pranks",
                "he",
                "had",
                "done",
                ",",
                "and",
                "the",
                "two",
                "needed",
                "to",
                "talk",
                "about",
                "it.Kirby",
                "poked",
                "his",
                "head",
                "out",
                "into",
                "the",
                "dormitory",
                "'s",
                "main",
                "room",
                "from",
                "the",
                "hallway",
                "he",
                "came",
                "walking",
                "from",
                ",",
                "wondering",
                "if",
                "the",
                "other",
                "had",
                "already",
                "arrived",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "-lrb-",
                "or",
                "maybe",
                "the",
                "main",
                "room",
                "i",
                "dunnoe",
                "d8",
                ")",
                "when",
                ":",
                "sometime",
                "August",
                "7thrating",
                ":",
                "pg",
                "(",
                "ooc",
                ":",
                "fff",
                "I",
                "and",
                "my",
                "lame",
                "title",
                ")",
                "with",
                "so",
                "many",
                "bit",
                "and",
                "piece",
                "of",
                "memory",
                "that",
                "he",
                "have",
                "yet",
                "to",
                "regain",
                "from",
                "the",
                "two",
                "night",
                "of",
                "mess",
                "up",
                "fellow",
                "student",
                "'",
                "room",
                ",",
                "Kirby",
                "wonder",
                "who",
                "else",
                "see",
                "he",
                "cause",
                "so",
                "many",
                "problem",
                "during",
                "that",
                "time",
                "as",
                "he",
                "reluctantly",
                "make",
                "he",
                "way",
                "to",
                "the",
                "dorm",
                "'s",
                "main",
                "room",
                "to",
                "meet",
                "up",
                "with",
                "the",
                "blue",
                "-",
                "haired",
                "prince",
                "."
            ],
            [
                "although",
                "he",
                "perfectly",
                "remember",
                "what",
                "he",
                "have",
                "do",
                "to",
                "Manaphy",
                "'s",
                "room",
                ",",
                "the",
                "pink",
                "boy",
                "could",
                "not",
                "exactly",
                "remember",
                "what",
                "he",
                "do",
                "while",
                "he",
                "be",
                "in",
                "Marth",
                "'s",
                "room.From",
                "the",
                "bit",
                "and",
                "piece",
                "he",
                "could",
                "gather",
                "be",
                "``",
                "photograph",
                "''",
                "and",
                "something",
                "about",
                "grow",
                "something",
                "."
            ],
            [
                "do",
                "he",
                "water",
                "some",
                "plant",
                "while",
                "he",
                "be",
                "Marth",
                "'s",
                "room?but",
                "nonetheless",
                ",",
                "he",
                "do",
                "feel",
                "horrible",
                "for",
                "pull",
                "off",
                "whatever",
                "prank",
                "he",
                "have",
                "do",
                ",",
                "and",
                "the",
                "two",
                "need",
                "to",
                "talk",
                "about",
                "it.Kirby",
                "poke",
                "he",
                "head",
                "out",
                "into",
                "the",
                "dormitory",
                "'s",
                "main",
                "room",
                "from",
                "the",
                "hallway",
                "he",
                "come",
                "walk",
                "from",
                ",",
                "wonder",
                "if",
                "the",
                "other",
                "have",
                "already",
                "arrive",
                "."
            ]
        ],
        "label": "Sadness"
    },
    {
        "body_part_token_idx": 5,
        "sentence_id": "7b08eb37-2c9f-3ed5-a685-387b6eeefaff",
        "tokens": [
            "I",
            "felt",
            "fire",
            "in",
            "my",
            "stomach",
            "."
        ],
        "lemmatized_tokens": [
            "I",
            "feel",
            "fire",
            "in",
            "my",
            "stomach",
            "."
        ],
        "preceding_context_tokens": [
            [
                "The",
                "whole",
                "time",
                "we",
                "'re",
                "watching",
                "the",
                "movie",
                ",",
                "Blake",
                "and",
                "Jack",
                "are",
                "on",
                "the",
                "couch",
                "making",
                "conversation",
                "I",
                "could",
                "vaguely",
                "hear",
                "."
            ],
            [
                "I",
                "did",
                "n't",
                "care",
                "."
            ],
            [
                "I",
                "started",
                "having",
                "a",
                "Knight",
                "Attack",
                "in",
                "Blake",
                "'s",
                "home",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "the",
                "whole",
                "time",
                "we",
                "be",
                "watch",
                "the",
                "movie",
                ",",
                "Blake",
                "and",
                "Jack",
                "be",
                "on",
                "the",
                "couch",
                "make",
                "conversation",
                "I",
                "could",
                "vaguely",
                "hear",
                "."
            ],
            [
                "I",
                "do",
                "not",
                "care",
                "."
            ],
            [
                "I",
                "start",
                "have",
                "a",
                "Knight",
                "Attack",
                "in",
                "Blake",
                "'s",
                "home",
                "."
            ]
        ],
        "label": "Anger"
    },
    {
        "body_part_token_idx": 3,
        "sentence_id": "5f5580b9-d53f-3302-8294-d199b4e2d345",
        "tokens": [
            "Tsuzuki",
            "scratched",
            "his",
            "head",
            "."
        ],
        "lemmatized_tokens": [
            "Tsuzuki",
            "scratch",
            "he",
            "head",
            "."
        ],
        "preceding_context_tokens": [
            [
                "``",
                "She",
                "started",
                "shaking",
                "violently",
                "as",
                "both",
                "the",
                "thought",
                "of",
                "the",
                "devil",
                "and",
                "his",
                "eyes",
                "scared",
                "her",
                "."
            ],
            [
                "She",
                "pushed",
                "away",
                "from",
                "him",
                "and",
                "ran",
                "down",
                "the",
                "hallway",
                "as",
                "she",
                "disappeared",
                "into",
                "thin",
                "air",
                "."
            ],
            [
                "``",
                "Now",
                "where",
                "did",
                "she",
                "get",
                "to",
                "?",
                "''"
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "``",
                "she",
                "start",
                "shake",
                "violently",
                "as",
                "both",
                "the",
                "thought",
                "of",
                "the",
                "devil",
                "and",
                "he",
                "eye",
                "scare",
                "she",
                "."
            ],
            [
                "she",
                "push",
                "away",
                "from",
                "he",
                "and",
                "run",
                "down",
                "the",
                "hallway",
                "as",
                "she",
                "disappear",
                "into",
                "thin",
                "air",
                "."
            ],
            [
                "``",
                "now",
                "where",
                "do",
                "she",
                "get",
                "to",
                "?",
                "''"
            ]
        ],
        "label": "Surprise"
    },
    {
        "body_part_token_idx": 10,
        "sentence_id": "c4097ef6-8b4f-338e-9195-1827a4eef041",
        "tokens": [
            "``",
            "Do",
            "you",
            "-",
            "``",
            "he",
            "sighed",
            "and",
            "rubbed",
            "his",
            "face",
            "with",
            "his",
            "hand",
            "."
        ],
        "lemmatized_tokens": [
            "``",
            "do",
            "you",
            "-",
            "``",
            "he",
            "sigh",
            "and",
            "rub",
            "he",
            "face",
            "with",
            "he",
            "hand",
            "."
        ],
        "preceding_context_tokens": [
            [
                "``",
                "What",
                "about",
                "you",
                "?",
                "''"
            ],
            [
                "Garbo",
                "shrugged",
                ",",
                "``",
                "could",
                "n't",
                "sleep",
                ".",
                "''"
            ],
            [
                "He",
                "mumbled",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "``",
                "what",
                "about",
                "you",
                "?",
                "''"
            ],
            [
                "Garbo",
                "shrug",
                ",",
                "``",
                "could",
                "not",
                "sleep",
                ".",
                "''"
            ],
            [
                "he",
                "mumble",
                "."
            ]
        ],
        "label": "Fear"
    },
    {
        "body_part_token_idx": 13,
        "sentence_id": "c4097ef6-8b4f-338e-9195-1827a4eef041",
        "tokens": [
            "``",
            "Do",
            "you",
            "-",
            "``",
            "he",
            "sighed",
            "and",
            "rubbed",
            "his",
            "face",
            "with",
            "his",
            "hand",
            "."
        ],
        "lemmatized_tokens": [
            "``",
            "do",
            "you",
            "-",
            "``",
            "he",
            "sigh",
            "and",
            "rub",
            "he",
            "face",
            "with",
            "he",
            "hand",
            "."
        ],
        "preceding_context_tokens": [
            [
                "``",
                "What",
                "about",
                "you",
                "?",
                "''"
            ],
            [
                "Garbo",
                "shrugged",
                ",",
                "``",
                "could",
                "n't",
                "sleep",
                ".",
                "''"
            ],
            [
                "He",
                "mumbled",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "``",
                "what",
                "about",
                "you",
                "?",
                "''"
            ],
            [
                "Garbo",
                "shrug",
                ",",
                "``",
                "could",
                "not",
                "sleep",
                ".",
                "''"
            ],
            [
                "he",
                "mumble",
                "."
            ]
        ],
        "label": "Fear"
    },
    {
        "body_part_token_idx": 31,
        "sentence_id": "2cd47955-568c-3801-9f0d-b77d775276a3",
        "tokens": [
            "My",
            "girl",
            "got",
            "mad",
            "at",
            "both",
            "of",
            "us",
            ",",
            "yelled",
            "at",
            "me",
            ",",
            "&",
            "then",
            "gave",
            "the",
            "woman",
            "the",
            "big",
            "''",
            "L",
            "''",
            "for",
            "''",
            "Loser",
            "''",
            "sign",
            "&",
            "stuck",
            "her",
            "tongue",
            "out",
            "at",
            "the",
            "old",
            "bat",
            "."
        ],
        "lemmatized_tokens": [
            "my",
            "girl",
            "get",
            "mad",
            "at",
            "both",
            "of",
            "we",
            ",",
            "yell",
            "at",
            "I",
            ",",
            "&",
            "then",
            "give",
            "the",
            "woman",
            "the",
            "big",
            "''",
            "l",
            "''",
            "for",
            "''",
            "Loser",
            "''",
            "sign",
            "&",
            "stick",
            "she",
            "tongue",
            "out",
            "at",
            "the",
            "old",
            "bat",
            "."
        ],
        "preceding_context_tokens": [
            [
                "I",
                "actually",
                "had",
                "tears",
                "in",
                "my",
                "eyes",
                ",",
                "watching",
                "the",
                "two",
                "of",
                "them",
                "."
            ],
            [
                "It",
                "was",
                "way",
                "cooler",
                "than",
                "anything",
                "happening",
                "on",
                "the",
                "stage",
                "."
            ],
            [
                "My",
                "daughter",
                "then",
                "got",
                "embarrassed",
                "by",
                "one",
                "of",
                "my",
                "dance",
                "moves",
                ",",
                "which",
                "she",
                "said",
                "was",
                "making",
                "a",
                "woman",
                "near",
                "us",
                "give",
                "me",
                "the",
                "stink",
                "eye",
                "-",
                "the",
                "bitch",
                "who",
                "originally",
                "was",
                "sitting",
                "in",
                "our",
                "seats",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "I",
                "actually",
                "have",
                "tear",
                "in",
                "my",
                "eye",
                ",",
                "watch",
                "the",
                "two",
                "of",
                "they",
                "."
            ],
            [
                "it",
                "be",
                "way",
                "cooler",
                "than",
                "anything",
                "happen",
                "on",
                "the",
                "stage",
                "."
            ],
            [
                "my",
                "daughter",
                "then",
                "get",
                "embarrassed",
                "by",
                "one",
                "of",
                "my",
                "dance",
                "move",
                ",",
                "which",
                "she",
                "say",
                "be",
                "make",
                "a",
                "woman",
                "near",
                "we",
                "give",
                "I",
                "the",
                "stink",
                "eye",
                "-",
                "the",
                "bitch",
                "who",
                "originally",
                "be",
                "sit",
                "in",
                "we",
                "seat",
                "."
            ]
        ],
        "label": "Anger"
    },
    {
        "body_part_token_idx": 4,
        "sentence_id": "749feab3-cb9a-3da5-bc31-c2f28080c1b5",
        "tokens": [
            "So",
            "I",
            "nodded",
            "my",
            "head",
            "and",
            "went",
            "upstairs.I",
            "moved",
            "the",
            "black",
            "bag",
            "and",
            "put",
            "it",
            "in",
            "my",
            "wardrobe",
            "."
        ],
        "lemmatized_tokens": [
            "so",
            "I",
            "nod",
            "my",
            "head",
            "and",
            "go",
            "upstairs.I",
            "move",
            "the",
            "black",
            "bag",
            "and",
            "put",
            "it",
            "in",
            "my",
            "wardrobe",
            "."
        ],
        "preceding_context_tokens": [
            [
                "It",
                "was",
                "only",
                "half",
                "seven",
                "but",
                "I",
                "just",
                "felt",
                "exhausted",
                "."
            ],
            [
                "``",
                "I",
                "'ll",
                "bring",
                "it",
                "up",
                "to",
                "you",
                "if",
                "want",
                "''",
                "My",
                "mum",
                "offered",
                "."
            ],
            [
                "I",
                "could",
                "n't",
                "be",
                "bothered",
                "arguing",
                "with",
                "her",
                "and",
                "she",
                "clearly",
                "was",
                "n't",
                "going",
                "to",
                "back",
                "down",
                "I",
                "was",
                "having",
                "a",
                "cuppa",
                "if",
                "wanted",
                "it",
                "or",
                "not",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "it",
                "be",
                "only",
                "half",
                "seven",
                "but",
                "I",
                "just",
                "feel",
                "exhausted",
                "."
            ],
            [
                "``",
                "I",
                "will",
                "bring",
                "it",
                "up",
                "to",
                "you",
                "if",
                "want",
                "''",
                "my",
                "mum",
                "offer",
                "."
            ],
            [
                "I",
                "could",
                "not",
                "be",
                "bother",
                "argue",
                "with",
                "she",
                "and",
                "she",
                "clearly",
                "be",
                "not",
                "go",
                "to",
                "back",
                "down",
                "I",
                "be",
                "have",
                "a",
                "cuppa",
                "if",
                "want",
                "it",
                "or",
                "not",
                "."
            ]
        ],
        "label": "Disgust"
    },
    {
        "body_part_token_idx": 3,
        "sentence_id": "8fb55a72-11b8-34f1-9636-a0ca74f05581",
        "tokens": [
            "I",
            "shook",
            "my",
            "head",
            "at",
            "the",
            "child",
            "'s",
            "impatience",
            "before",
            "I",
            "realized",
            "that",
            ",",
            "in",
            "some",
            "ways",
            ",",
            "I",
            "still",
            "acted",
            "in",
            "quite",
            "the",
            "same",
            "manner",
            "."
        ],
        "lemmatized_tokens": [
            "I",
            "shake",
            "my",
            "head",
            "at",
            "the",
            "child",
            "'s",
            "impatience",
            "before",
            "I",
            "realize",
            "that",
            ",",
            "in",
            "some",
            "way",
            ",",
            "I",
            "still",
            "act",
            "in",
            "quite",
            "the",
            "same",
            "manner",
            "."
        ],
        "preceding_context_tokens": [
            [
                "The",
                "toddler",
                "yelled",
                "in",
                "protest",
                "as",
                "the",
                "mother",
                "attempted",
                "to",
                "pull",
                "it",
                "out",
                "of",
                "her",
                "grasp",
                "."
            ],
            [
                "Finally",
                ",",
                "she",
                "succeeded",
                "and",
                "quickly",
                "picked",
                "off",
                "the",
                "bits",
                "of",
                "dirt",
                "it",
                "had",
                "gathered",
                "of",
                "the",
                "floor",
                "before",
                "giving",
                "it",
                "back",
                "."
            ],
            [
                "The",
                "child",
                "stopped",
                "wailing",
                ",",
                "but",
                "not",
                "before",
                "she",
                "had",
                "released",
                "a",
                "torrent",
                "of",
                "tears",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "the",
                "toddler",
                "yell",
                "in",
                "protest",
                "as",
                "the",
                "mother",
                "attempt",
                "to",
                "pull",
                "it",
                "out",
                "of",
                "she",
                "grasp",
                "."
            ],
            [
                "finally",
                ",",
                "she",
                "succeed",
                "and",
                "quickly",
                "pick",
                "off",
                "the",
                "bit",
                "of",
                "dirt",
                "it",
                "have",
                "gather",
                "of",
                "the",
                "floor",
                "before",
                "give",
                "it",
                "back",
                "."
            ],
            [
                "the",
                "child",
                "stop",
                "wail",
                ",",
                "but",
                "not",
                "before",
                "she",
                "have",
                "release",
                "a",
                "torrent",
                "of",
                "tear",
                "."
            ]
        ],
        "label": "Disgust"
    },
    {
        "body_part_token_idx": 27,
        "sentence_id": "e4fa4976-7983-3d68-b9b7-194b6ff89a68",
        "tokens": [
            "I",
            "was",
            "so",
            "joyous",
            "about",
            "the",
            "deluge",
            "of",
            "water",
            "from",
            "the",
            "sky",
            "last",
            "night",
            ",",
            "that",
            "I",
            "spent",
            "ample",
            "time",
            "relishing",
            "in",
            "it",
            "...",
            "throwing",
            "back",
            "my",
            "head",
            ",",
            "closing",
            "my",
            "eyes",
            ",",
            "and",
            "just",
            "letting",
            "it",
            "pour",
            "down",
            "on",
            "me",
            "."
        ],
        "lemmatized_tokens": [
            "I",
            "be",
            "so",
            "joyous",
            "about",
            "the",
            "deluge",
            "of",
            "water",
            "from",
            "the",
            "sky",
            "last",
            "night",
            ",",
            "that",
            "I",
            "spend",
            "ample",
            "time",
            "relish",
            "in",
            "it",
            "...",
            "throw",
            "back",
            "my",
            "head",
            ",",
            "close",
            "my",
            "eye",
            ",",
            "and",
            "just",
            "let",
            "it",
            "pour",
            "down",
            "on",
            "I",
            "."
        ],
        "preceding_context_tokens": [],
        "preceding_context_lemmatized_tokens": [],
        "label": "Joy"
    },
    {
        "body_part_token_idx": 31,
        "sentence_id": "e4fa4976-7983-3d68-b9b7-194b6ff89a68",
        "tokens": [
            "I",
            "was",
            "so",
            "joyous",
            "about",
            "the",
            "deluge",
            "of",
            "water",
            "from",
            "the",
            "sky",
            "last",
            "night",
            ",",
            "that",
            "I",
            "spent",
            "ample",
            "time",
            "relishing",
            "in",
            "it",
            "...",
            "throwing",
            "back",
            "my",
            "head",
            ",",
            "closing",
            "my",
            "eyes",
            ",",
            "and",
            "just",
            "letting",
            "it",
            "pour",
            "down",
            "on",
            "me",
            "."
        ],
        "lemmatized_tokens": [
            "I",
            "be",
            "so",
            "joyous",
            "about",
            "the",
            "deluge",
            "of",
            "water",
            "from",
            "the",
            "sky",
            "last",
            "night",
            ",",
            "that",
            "I",
            "spend",
            "ample",
            "time",
            "relish",
            "in",
            "it",
            "...",
            "throw",
            "back",
            "my",
            "head",
            ",",
            "close",
            "my",
            "eye",
            ",",
            "and",
            "just",
            "let",
            "it",
            "pour",
            "down",
            "on",
            "I",
            "."
        ],
        "preceding_context_tokens": [],
        "preceding_context_lemmatized_tokens": [],
        "label": "Joy"
    },
    {
        "body_part_token_idx": 3,
        "sentence_id": "bd626e2b-5da4-30ce-b523-e7c6c78eebb7",
        "tokens": [
            "I",
            "closed",
            "my",
            "eyes",
            "and",
            "took",
            "a",
            "deep",
            "breath",
            "."
        ],
        "lemmatized_tokens": [
            "I",
            "close",
            "my",
            "eye",
            "and",
            "take",
            "a",
            "deep",
            "breath",
            "."
        ],
        "preceding_context_tokens": [
            [
                "Just",
                "two",
                "adults",
                "out",
                "on",
                "a",
                "snowy",
                "evening",
                "."
            ],
            [
                "But",
                "like",
                "all",
                "good",
                "things",
                ",",
                "this",
                "too",
                "came",
                "to",
                "an",
                "end",
                "."
            ],
            [
                "And",
                "now",
                ",",
                "we",
                "are",
                "bursting",
                "at",
                "the",
                "seams",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "just",
                "two",
                "adult",
                "out",
                "on",
                "a",
                "snowy",
                "evening",
                "."
            ],
            [
                "but",
                "like",
                "all",
                "good",
                "thing",
                ",",
                "this",
                "too",
                "come",
                "to",
                "a",
                "end",
                "."
            ],
            [
                "and",
                "now",
                ",",
                "we",
                "be",
                "burst",
                "at",
                "the",
                "seam",
                "."
            ]
        ],
        "label": "Sadness"
    },
    {
        "body_part_token_idx": 13,
        "sentence_id": "6b48f31f-2031-33fc-a072-7ae821cceb29",
        "tokens": [
            "Aargh",
            ",",
            "the",
            "look",
            "of",
            "frenzy",
            "must",
            "have",
            "been",
            "written",
            "all",
            "over",
            "my",
            "face",
            "as",
            "I",
            "tried",
            "to",
            "corall",
            "the",
            "older",
            "kids",
            "and",
            "placate",
            "my",
            "little",
            "one",
            "with",
            "a",
            "granola",
            "bar",
            "because",
            "it",
            "was",
            "dinner",
            "time",
            "ye",
            "know",
            "."
        ],
        "lemmatized_tokens": [
            "Aargh",
            ",",
            "the",
            "look",
            "of",
            "frenzy",
            "must",
            "have",
            "be",
            "write",
            "all",
            "over",
            "my",
            "face",
            "as",
            "I",
            "try",
            "to",
            "corall",
            "the",
            "older",
            "kid",
            "and",
            "placate",
            "my",
            "little",
            "one",
            "with",
            "a",
            "granola",
            "bar",
            "because",
            "it",
            "be",
            "dinner",
            "time",
            "ye",
            "know",
            "."
        ],
        "preceding_context_tokens": [
            [
                "For",
                "about",
                "FIVE",
                "minutes",
                "!"
            ],
            [
                "Then",
                "it",
                "got",
                "really",
                "old",
                "and",
                "I",
                "wanted",
                "him",
                "back",
                "in",
                "that",
                "shopping",
                "cart",
                "!"
            ],
            [
                "We",
                "headed",
                "to",
                "the",
                "check",
                "outs",
                "where",
                "I",
                "usually",
                "opt",
                "for",
                "the",
                "easier",
                "self",
                "check",
                "out",
                "aisle",
                ",",
                "but",
                "I",
                "realised",
                "with",
                "horror",
                "as",
                "I",
                "looked",
                "at",
                "the",
                "huge",
                "lines",
                "of",
                "people",
                "with",
                "mammoth",
                "sized",
                "mounds",
                "of",
                "shopping",
                "that",
                "I",
                "was",
                "in",
                "the",
                "one",
                "blooming",
                "Walmart",
                "that",
                "did",
                "n't",
                "have",
                "them",
                "!"
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "for",
                "about",
                "five",
                "minute",
                "!"
            ],
            [
                "then",
                "it",
                "get",
                "really",
                "old",
                "and",
                "I",
                "want",
                "he",
                "back",
                "in",
                "that",
                "shopping",
                "cart",
                "!"
            ],
            [
                "we",
                "head",
                "to",
                "the",
                "check",
                "out",
                "where",
                "I",
                "usually",
                "opt",
                "for",
                "the",
                "easier",
                "self",
                "check",
                "out",
                "aisle",
                ",",
                "but",
                "I",
                "realise",
                "with",
                "horror",
                "as",
                "I",
                "look",
                "at",
                "the",
                "huge",
                "line",
                "of",
                "people",
                "with",
                "mammoth",
                "sized",
                "mound",
                "of",
                "shopping",
                "that",
                "I",
                "be",
                "in",
                "the",
                "one",
                "bloom",
                "Walmart",
                "that",
                "do",
                "not",
                "have",
                "they",
                "!"
            ]
        ],
        "label": "Anger"
    },
    {
        "body_part_token_idx": 28,
        "sentence_id": "b0e39064-085b-3c45-90fc-dab2cf3e2fb9",
        "tokens": [
            "Angel",
            "pulled",
            "up",
            "his",
            "shirt",
            "and",
            "took",
            "out",
            "a",
            "gun",
            "that",
            "was",
            "in",
            "the",
            "waistband",
            "of",
            "his",
            "jeans",
            ";",
            "while",
            "Jerry",
            "just",
            "sat",
            "in",
            "the",
            "back",
            "shaking",
            "his",
            "head",
            ",",
            "it",
            "had",
            "been",
            "a",
            "long",
            "time",
            "since",
            "he",
            "had",
            "held",
            "a",
            "gun",
            "let",
            "alone",
            "used",
            "one",
            "."
        ],
        "lemmatized_tokens": [
            "Angel",
            "pull",
            "up",
            "he",
            "shirt",
            "and",
            "take",
            "out",
            "a",
            "gun",
            "that",
            "be",
            "in",
            "the",
            "waistband",
            "of",
            "he",
            "jeans",
            ";",
            "while",
            "Jerry",
            "just",
            "sit",
            "in",
            "the",
            "back",
            "shake",
            "he",
            "head",
            ",",
            "it",
            "have",
            "be",
            "a",
            "long",
            "time",
            "since",
            "he",
            "have",
            "hold",
            "a",
            "gun",
            "let",
            "alone",
            "use",
            "one",
            "."
        ],
        "preceding_context_tokens": [
            [
                "When",
                "they",
                "did",
                "find",
                "him",
                "the",
                "people",
                "who",
                "had",
                "taken",
                "him",
                "had",
                "better",
                "run",
                "and",
                "fast",
                "."
            ],
            [
                "There",
                "is",
                "no",
                "wrath",
                "worse",
                "then",
                "that",
                "of",
                "a",
                "Mercer",
                "'s",
                "."
            ],
            [
                "He",
                "looked",
                "a",
                "head",
                "at",
                "the",
                "meatpacking",
                "locker",
                "getting",
                "closer",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "when",
                "they",
                "do",
                "find",
                "he",
                "the",
                "people",
                "who",
                "have",
                "take",
                "he",
                "have",
                "better",
                "run",
                "and",
                "fast",
                "."
            ],
            [
                "there",
                "be",
                "no",
                "wrath",
                "worse",
                "then",
                "that",
                "of",
                "a",
                "Mercer",
                "'s",
                "."
            ],
            [
                "he",
                "look",
                "a",
                "head",
                "at",
                "the",
                "meatpacking",
                "locker",
                "get",
                "closer",
                "."
            ]
        ],
        "label": "Disgust"
    },
    {
        "body_part_token_idx": 1,
        "sentence_id": "dbc05d50-d53b-3bef-bf1a-f840ae01a48d",
        "tokens": [
            "My",
            "lips",
            "tremble",
            "again",
            ",",
            "this",
            "time",
            "in",
            "fear",
            "."
        ],
        "lemmatized_tokens": [
            "my",
            "lip",
            "tremble",
            "again",
            ",",
            "this",
            "time",
            "in",
            "fear",
            "."
        ],
        "preceding_context_tokens": [
            [
                "Go",
                "back",
                "."
            ],
            [
                "I",
                "take",
                "another",
                "cautious",
                "step",
                "in",
                "the",
                "direction",
                "I",
                "thought",
                "the",
                "voice",
                "was",
                "coming",
                "from",
                "and",
                "I",
                "immediately",
                "regret",
                "it",
                "."
            ],
            [
                "A",
                "sudden",
                "unsettling",
                "feeling",
                "washes",
                "over",
                "me",
                ",",
                "sending",
                "a",
                "deep",
                "shiver",
                "through",
                "my",
                "body",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "go",
                "back",
                "."
            ],
            [
                "I",
                "take",
                "another",
                "cautious",
                "step",
                "in",
                "the",
                "direction",
                "I",
                "think",
                "the",
                "voice",
                "be",
                "come",
                "from",
                "and",
                "I",
                "immediately",
                "regret",
                "it",
                "."
            ],
            [
                "a",
                "sudden",
                "unsettling",
                "feeling",
                "wash",
                "over",
                "I",
                ",",
                "send",
                "a",
                "deep",
                "shiver",
                "through",
                "my",
                "body",
                "."
            ]
        ],
        "label": "Fear"
    },
    {
        "body_part_token_idx": 37,
        "sentence_id": "c117f973-3059-3eb5-a206-871b42dbf0d3",
        "tokens": [
            "While",
            "a",
            "good",
            "driver",
            ",",
            "fairer",
            "with",
            "the",
            "wheel",
            "than",
            "Azkadellia",
            ",",
            "who",
            "'d",
            "rather",
            "ride",
            "a",
            "horse",
            "than",
            "command",
            "a",
            "sluggish",
            "vehicle",
            ",",
            "Thisbe",
            "'s",
            "knuckles",
            "were",
            "a",
            "little",
            "on",
            "the",
            "white",
            "side",
            ",",
            "and",
            "her",
            "mouth",
            "was",
            "pressed",
            "in",
            "a",
            "determined",
            "line",
            "that",
            "reminded",
            "Azkadellia",
            "greatly",
            "of",
            "Glitch",
            "."
        ],
        "lemmatized_tokens": [
            "while",
            "a",
            "good",
            "driver",
            ",",
            "fairer",
            "with",
            "the",
            "wheel",
            "than",
            "Azkadellia",
            ",",
            "who",
            "have",
            "rather",
            "ride",
            "a",
            "horse",
            "than",
            "command",
            "a",
            "sluggish",
            "vehicle",
            ",",
            "Thisbe",
            "'s",
            "knuckle",
            "be",
            "a",
            "little",
            "on",
            "the",
            "white",
            "side",
            ",",
            "and",
            "she",
            "mouth",
            "be",
            "press",
            "in",
            "a",
            "determined",
            "line",
            "that",
            "remind",
            "Azkadellia",
            "greatly",
            "of",
            "glitch",
            "."
        ],
        "preceding_context_tokens": [
            [
                "She",
                "had",
                "n't",
                "noticed",
                "much",
                "of",
                "the",
                "drive",
                "from",
                "Central",
                "City",
                "to",
                "Finaqua",
                ",",
                "except",
                "that",
                "it",
                "was",
                "pouring",
                "rain",
                "."
            ],
            [
                "The",
                "calm",
                "slosh",
                "-",
                "shloop",
                "of",
                "the",
                "windshield",
                "wipers",
                "and",
                "the",
                "fall",
                "of",
                "drops",
                "atop",
                "the",
                "car",
                "roof",
                "were",
                "the",
                "only",
                "sounds",
                "for",
                "spans",
                "."
            ],
            [
                "Thisbe",
                ",",
                "behind",
                "the",
                "wheel",
                ",",
                "with",
                "Azkadellia",
                "situated",
                "in",
                "the",
                "front",
                "seat",
                "beside",
                "her",
                ",",
                "had",
                "refused",
                "to",
                "say",
                "very",
                "much",
                ",",
                "once",
                "announcing",
                "when",
                "they",
                "had",
                "left",
                "behind",
                "Pernic",
                "for",
                "Euclid",
                ",",
                "and",
                "again",
                "when",
                "the",
                "Euclid",
                "borders",
                "were",
                "crossed",
                ",",
                "and",
                "Finaqua",
                "began",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "she",
                "have",
                "not",
                "notice",
                "much",
                "of",
                "the",
                "drive",
                "from",
                "Central",
                "City",
                "to",
                "Finaqua",
                ",",
                "except",
                "that",
                "it",
                "be",
                "pour",
                "rain",
                "."
            ],
            [
                "the",
                "calm",
                "slosh",
                "-",
                "shloop",
                "of",
                "the",
                "windshield",
                "wiper",
                "and",
                "the",
                "fall",
                "of",
                "drop",
                "atop",
                "the",
                "car",
                "roof",
                "be",
                "the",
                "only",
                "sound",
                "for",
                "span",
                "."
            ],
            [
                "Thisbe",
                ",",
                "behind",
                "the",
                "wheel",
                ",",
                "with",
                "Azkadellia",
                "situate",
                "in",
                "the",
                "front",
                "seat",
                "beside",
                "she",
                ",",
                "have",
                "refuse",
                "to",
                "say",
                "very",
                "much",
                ",",
                "once",
                "announce",
                "when",
                "they",
                "have",
                "leave",
                "behind",
                "Pernic",
                "for",
                "Euclid",
                ",",
                "and",
                "again",
                "when",
                "the",
                "Euclid",
                "border",
                "be",
                "cross",
                ",",
                "and",
                "Finaqua",
                "begin",
                "."
            ]
        ],
        "label": "Fear"
    },
    {
        "body_part_token_idx": 17,
        "sentence_id": "cb3ac80a-52a5-3b25-9334-fd7610602246",
        "tokens": [
            "But",
            "when",
            "I",
            "got",
            "back",
            "to",
            "the",
            "kitchen",
            "it",
            "was",
            "dark",
            ",",
            "and",
            "Karlo",
            "was",
            "scratching",
            "his",
            "head",
            "."
        ],
        "lemmatized_tokens": [
            "but",
            "when",
            "I",
            "get",
            "back",
            "to",
            "the",
            "kitchen",
            "it",
            "be",
            "dark",
            ",",
            "and",
            "Karlo",
            "be",
            "scratch",
            "he",
            "head",
            "."
        ],
        "preceding_context_tokens": [
            [
                "The",
                "placement",
                "of",
                "the",
                "beams",
                "and",
                "the",
                "power",
                ",",
                "and",
                "the",
                "length",
                "of",
                "the",
                "track",
                "...",
                "it",
                "was",
                "all",
                "coming",
                "together",
                "before",
                "my",
                "very",
                "eyes",
                "."
            ],
            [
                "I",
                "was",
                "the",
                "smart",
                "one",
                "that",
                "insisted",
                "on",
                "shutting",
                "off",
                "the",
                "fuse",
                "that",
                "controls",
                "the",
                "power",
                "to",
                "the",
                "kitchen",
                "lights",
                "so",
                "it",
                "was",
                "my",
                "job",
                "to",
                "run",
                "down",
                "to",
                "the",
                "basement",
                "to",
                "flip",
                "the",
                "switch",
                "back",
                "on",
                "at",
                "fuse",
                "box",
                "."
            ],
            [
                "I",
                "literally",
                "ran",
                "back",
                "up",
                "the",
                "stairs",
                "in",
                "anticipation",
                "of",
                "seeing",
                "my",
                "beautiful",
                "pendants",
                "all",
                "lit",
                "up",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "the",
                "placement",
                "of",
                "the",
                "beam",
                "and",
                "the",
                "power",
                ",",
                "and",
                "the",
                "length",
                "of",
                "the",
                "track",
                "...",
                "it",
                "be",
                "all",
                "come",
                "together",
                "before",
                "my",
                "very",
                "eye",
                "."
            ],
            [
                "I",
                "be",
                "the",
                "smart",
                "one",
                "that",
                "insist",
                "on",
                "shut",
                "off",
                "the",
                "fuse",
                "that",
                "control",
                "the",
                "power",
                "to",
                "the",
                "kitchen",
                "light",
                "so",
                "it",
                "be",
                "my",
                "job",
                "to",
                "run",
                "down",
                "to",
                "the",
                "basement",
                "to",
                "flip",
                "the",
                "switch",
                "back",
                "on",
                "at",
                "fuse",
                "box",
                "."
            ],
            [
                "I",
                "literally",
                "run",
                "back",
                "up",
                "the",
                "stair",
                "in",
                "anticipation",
                "of",
                "see",
                "my",
                "beautiful",
                "pendant",
                "all",
                "light",
                "up",
                "."
            ]
        ],
        "label": "Surprise"
    },
    {
        "body_part_token_idx": 1,
        "sentence_id": "5f538b38-e2cc-3bd7-93d5-3a394153d956",
        "tokens": [
            "My",
            "jaw",
            "dropped",
            "as",
            "I",
            "squealed",
            "with",
            "delight",
            "."
        ],
        "lemmatized_tokens": [
            "my",
            "jaw",
            "drop",
            "as",
            "I",
            "squeal",
            "with",
            "delight",
            "."
        ],
        "preceding_context_tokens": [
            [
                "Get",
                "over",
                "it",
                "."
            ],
            [
                "It",
                "was",
                "very",
                "quick",
                "and",
                "a",
                "shocking",
                "occurrence",
                "for",
                "both",
                "my",
                "mother",
                "and",
                "I.",
                "Rachele",
                "was",
                "covered",
                "in",
                "more",
                "mud",
                "then",
                "Rosetta",
                "had",
                "been",
                "and",
                "also",
                "taken",
                "a",
                "handful",
                "of",
                "wet",
                "dirt",
                "in",
                "her",
                "hand",
                "when",
                "she",
                "got",
                "up",
                "."
            ],
            [
                "Laughing",
                ",",
                "she",
                "took",
                "the",
                "balls",
                "of",
                "mud",
                "and",
                "spread",
                "it",
                "over",
                "my",
                "mothers",
                "white",
                "shirt",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "get",
                "over",
                "it",
                "."
            ],
            [
                "it",
                "be",
                "very",
                "quick",
                "and",
                "a",
                "shocking",
                "occurrence",
                "for",
                "both",
                "my",
                "mother",
                "and",
                "I.",
                "Rachele",
                "be",
                "cover",
                "in",
                "more",
                "mud",
                "then",
                "Rosetta",
                "have",
                "be",
                "and",
                "also",
                "take",
                "a",
                "handful",
                "of",
                "wet",
                "dirt",
                "in",
                "she",
                "hand",
                "when",
                "she",
                "get",
                "up",
                "."
            ],
            [
                "laugh",
                ",",
                "she",
                "take",
                "the",
                "ball",
                "of",
                "mud",
                "and",
                "spread",
                "it",
                "over",
                "my",
                "mother",
                "white",
                "shirt",
                "."
            ]
        ],
        "label": "Surprise"
    },
    {
        "body_part_token_idx": 3,
        "sentence_id": "9856b36e-ab1d-309d-8a96-d84b1f802226",
        "tokens": [
            "He",
            "shook",
            "his",
            "head",
            "and",
            "chuckled",
            "to",
            "himself",
            "before",
            "leaning",
            "down",
            "and",
            "pressing",
            "his",
            "forehead",
            "to",
            "his",
            "best",
            "friend",
            "'s",
            "."
        ],
        "lemmatized_tokens": [
            "he",
            "shake",
            "he",
            "head",
            "and",
            "chuckle",
            "to",
            "himself",
            "before",
            "lean",
            "down",
            "and",
            "press",
            "he",
            "forehead",
            "to",
            "he",
            "best",
            "friend",
            "'s",
            "."
        ],
        "preceding_context_tokens": [
            [
                "Not",
                "for",
                "the",
                "first",
                "time",
                "that",
                "night",
                ",",
                "he",
                "could",
                "feel",
                "warmth",
                "slowly",
                "creeping",
                "up",
                "his",
                "neck",
                "and",
                "he",
                "took",
                "deep",
                ",",
                "steadying",
                "breaths",
                ",",
                "hoping",
                "it",
                "did",
                "n't",
                "seem",
                "too",
                "conspicuous.Bert",
                "leaned",
                "forward",
                ",",
                "sitting",
                "up",
                "and",
                "pressing",
                "close",
                "to",
                "Quinn",
                "'s",
                "neck",
                ",",
                "looking",
                "up",
                "with",
                "concern",
                "stitched",
                "across",
                "his",
                "forehead",
                "."
            ],
            [
                "``",
                "Anything",
                "I",
                "should",
                "be",
                "worried",
                "about",
                "?"
            ],
            [
                "``",
                "Quinn",
                "felt",
                "an",
                "almost",
                "overwhelming",
                "urge",
                "to",
                "look",
                "away",
                "and",
                "stare",
                "a",
                "hole",
                "into",
                "the",
                "hardwood",
                "floor",
                "in",
                "front",
                "of",
                "him",
                ",",
                "or",
                "to",
                "just",
                "push",
                "off",
                "and",
                "start",
                "walking",
                ",",
                "but",
                "this",
                "was",
                "Bert",
                "and",
                "his",
                "eyes",
                "had",
                "that",
                "wide",
                ",",
                "glassy",
                "look",
                "they",
                "got",
                "when",
                "Bert",
                "was",
                "a",
                "little",
                "nervous",
                ",",
                "a",
                "little",
                "worried",
                ",",
                "and",
                "Quinn",
                "could",
                "n't",
                "just",
                "break",
                "away",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "not",
                "for",
                "the",
                "first",
                "time",
                "that",
                "night",
                ",",
                "he",
                "could",
                "feel",
                "warmth",
                "slowly",
                "creep",
                "up",
                "he",
                "neck",
                "and",
                "he",
                "take",
                "deep",
                ",",
                "steadying",
                "breath",
                ",",
                "hope",
                "it",
                "do",
                "not",
                "seem",
                "too",
                "conspicuous.bert",
                "lean",
                "forward",
                ",",
                "sit",
                "up",
                "and",
                "press",
                "close",
                "to",
                "Quinn",
                "'s",
                "neck",
                ",",
                "look",
                "up",
                "with",
                "concern",
                "stitch",
                "across",
                "he",
                "forehead",
                "."
            ],
            [
                "``",
                "anything",
                "I",
                "should",
                "be",
                "worried",
                "about",
                "?"
            ],
            [
                "``",
                "Quinn",
                "feel",
                "a",
                "almost",
                "overwhelming",
                "urge",
                "to",
                "look",
                "away",
                "and",
                "stare",
                "a",
                "hole",
                "into",
                "the",
                "hardwood",
                "floor",
                "in",
                "front",
                "of",
                "he",
                ",",
                "or",
                "to",
                "just",
                "push",
                "off",
                "and",
                "start",
                "walk",
                ",",
                "but",
                "this",
                "be",
                "Bert",
                "and",
                "he",
                "eye",
                "have",
                "that",
                "wide",
                ",",
                "glassy",
                "look",
                "they",
                "get",
                "when",
                "Bert",
                "be",
                "a",
                "little",
                "nervous",
                ",",
                "a",
                "little",
                "worried",
                ",",
                "and",
                "Quinn",
                "could",
                "not",
                "just",
                "break",
                "away",
                "."
            ]
        ],
        "label": "Joy"
    },
    {
        "body_part_token_idx": 12,
        "sentence_id": "4e5bd26b-bbee-3f3f-8c0d-9e703785a3cc",
        "tokens": [
            "His",
            "eyes",
            "could",
            "n't",
            "help",
            "but",
            "accuse",
            "her.The",
            "one",
            "side",
            "of",
            "her",
            "lips",
            "lifted",
            "up",
            "to",
            "a",
            "grin",
            ",",
            "but",
            "she",
            "still",
            "answered",
            "."
        ],
        "lemmatized_tokens": [
            "he",
            "eye",
            "could",
            "not",
            "help",
            "but",
            "accuse",
            "her.the",
            "one",
            "side",
            "of",
            "she",
            "lip",
            "lift",
            "up",
            "to",
            "a",
            "grin",
            ",",
            "but",
            "she",
            "still",
            "answer",
            "."
        ],
        "preceding_context_tokens": [
            [
                "Sighing",
                ",",
                "Sam",
                "opened",
                "the",
                "back",
                "door",
                "and",
                "sat",
                "down",
                "."
            ],
            [
                "The",
                "ride",
                "to",
                "their",
                "motel",
                "was",
                "pretty",
                "much",
                "silent",
                ",",
                "except",
                "for",
                "the",
                "girl",
                "humming",
                "along",
                "to",
                "the",
                "crackly",
                "radio",
                "."
            ],
            [
                "She",
                "pulled",
                "onto",
                "the",
                "road",
                "where",
                "they",
                "were",
                "staying",
                ",",
                "and",
                "Sam",
                "could",
                "n't",
                "help",
                "but",
                "ask",
                ",",
                "How",
                "d'you",
                "know",
                "that",
                "we",
                "were",
                "staying",
                "here",
                "?"
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "sigh",
                ",",
                "Sam",
                "open",
                "the",
                "back",
                "door",
                "and",
                "sit",
                "down",
                "."
            ],
            [
                "the",
                "ride",
                "to",
                "they",
                "motel",
                "be",
                "pretty",
                "much",
                "silent",
                ",",
                "except",
                "for",
                "the",
                "girl",
                "hum",
                "along",
                "to",
                "the",
                "crackly",
                "radio",
                "."
            ],
            [
                "she",
                "pull",
                "onto",
                "the",
                "road",
                "where",
                "they",
                "be",
                "stay",
                ",",
                "and",
                "Sam",
                "could",
                "not",
                "help",
                "but",
                "ask",
                ",",
                "how",
                "d'you",
                "know",
                "that",
                "we",
                "be",
                "stay",
                "here",
                "?"
            ]
        ],
        "label": "Joy"
    },
    {
        "body_part_token_idx": 1,
        "sentence_id": "fc267f53-fa10-353d-ab82-a96ebbdce219",
        "tokens": [
            "His",
            "eyes",
            "were",
            "tired",
            ",",
            "worn",
            ",",
            "not",
            "only",
            "from",
            "the",
            "road",
            "but",
            "from",
            "the",
            "lying",
            "."
        ],
        "lemmatized_tokens": [
            "he",
            "eye",
            "be",
            "tired",
            ",",
            "worn",
            ",",
            "not",
            "only",
            "from",
            "the",
            "road",
            "but",
            "from",
            "the",
            "lying",
            "."
        ],
        "preceding_context_tokens": [
            [
                "Tell",
                "me",
                ",",
                "and",
                "ill",
                "go",
                "back",
                ",",
                "and",
                "tell",
                "her",
                "it",
                "was",
                "a",
                "joke",
                "that",
                "you",
                "and",
                "I",
                "came",
                "up",
                "with",
                "for",
                "her",
                "and",
                "Lee.",
                "Brian",
                "said",
                ",",
                "quickly.Jimmy",
                "stayed",
                "silent",
                ",",
                "as",
                "much",
                "as",
                "he",
                "wanted",
                "to",
                ",",
                "he",
                "could",
                "n't",
                "say",
                "that",
                "he",
                "did",
                "n't",
                "think",
                "about",
                "Brian",
                "more",
                "than",
                "his",
                "girl",
                "his",
                "own",
                "wife",
                "."
            ],
            [
                "That",
                "when",
                "he",
                "should",
                "be",
                "focusing",
                "on",
                "her",
                ",",
                "he",
                "was",
                "having",
                "delusions",
                "about",
                "his",
                "guitarist",
                ",",
                "his",
                "best",
                "friend",
                "."
            ],
            [
                "Exactly",
                "Brian",
                "said",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "tell",
                "I",
                ",",
                "and",
                "ill",
                "go",
                "back",
                ",",
                "and",
                "tell",
                "she",
                "it",
                "be",
                "a",
                "joke",
                "that",
                "you",
                "and",
                "I",
                "come",
                "up",
                "with",
                "for",
                "she",
                "and",
                "Lee.",
                "Brian",
                "say",
                ",",
                "quickly.Jimmy",
                "stay",
                "silent",
                ",",
                "as",
                "much",
                "as",
                "he",
                "want",
                "to",
                ",",
                "he",
                "could",
                "not",
                "say",
                "that",
                "he",
                "do",
                "not",
                "think",
                "about",
                "Brian",
                "more",
                "than",
                "he",
                "girl",
                "he",
                "own",
                "wife",
                "."
            ],
            [
                "that",
                "when",
                "he",
                "should",
                "be",
                "focus",
                "on",
                "she",
                ",",
                "he",
                "be",
                "have",
                "delusion",
                "about",
                "he",
                "guitarist",
                ",",
                "he",
                "best",
                "friend",
                "."
            ],
            [
                "exactly",
                "Brian",
                "say",
                "."
            ]
        ],
        "label": "Sadness"
    },
    {
        "body_part_token_idx": 7,
        "sentence_id": "aadbfe50-7133-3634-ab2b-333c556f9749",
        "tokens": [
            "Claude",
            "followed",
            "his",
            "gaze",
            "and",
            "felt",
            "his",
            "mouth",
            "go",
            "dry",
            "."
        ],
        "lemmatized_tokens": [
            "Claude",
            "follow",
            "he",
            "gaze",
            "and",
            "feel",
            "he",
            "mouth",
            "go",
            "dry",
            "."
        ],
        "preceding_context_tokens": [
            [
                "He",
                "did",
                "n't",
                "have",
                "time",
                "to",
                "react",
                "before",
                "Bennet",
                "rushed",
                "forward",
                "and",
                "shoved",
                "him",
                "out",
                "of",
                "the",
                "way",
                ";",
                "a",
                "cracking",
                "line",
                "of",
                "electricity",
                "missed",
                "his",
                "head",
                "by",
                "inches",
                ",",
                "and",
                "Claude",
                "saw",
                "the",
                "bolt",
                "fry",
                "an",
                "unlucky",
                "security",
                "guard",
                "as",
                "he",
                "and",
                "Bennet",
                "slammed",
                "into",
                "the",
                "wall",
                "."
            ],
            [
                "Claude",
                "grabbed",
                "Bennet",
                "'s",
                "arm",
                "and",
                "turned",
                "invisible",
                ";",
                "he",
                "caught",
                "Bennet",
                "'s",
                "eye",
                "and",
                "crossed",
                "one",
                "finger",
                "over",
                "his",
                "lips",
                "."
            ],
            [
                "Bennet",
                "gave",
                "him",
                "a",
                "quick",
                "nod",
                "of",
                "understanding",
                ",",
                "then",
                "jerked",
                "his",
                "head",
                "towards",
                "the",
                "end",
                "of",
                "the",
                "hallway",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "he",
                "do",
                "not",
                "have",
                "time",
                "to",
                "react",
                "before",
                "Bennet",
                "rush",
                "forward",
                "and",
                "shove",
                "he",
                "out",
                "of",
                "the",
                "way",
                ";",
                "a",
                "crack",
                "line",
                "of",
                "electricity",
                "miss",
                "he",
                "head",
                "by",
                "inch",
                ",",
                "and",
                "Claude",
                "see",
                "the",
                "bolt",
                "fry",
                "a",
                "unlucky",
                "security",
                "guard",
                "as",
                "he",
                "and",
                "Bennet",
                "slam",
                "into",
                "the",
                "wall",
                "."
            ],
            [
                "Claude",
                "grab",
                "Bennet",
                "'s",
                "arm",
                "and",
                "turn",
                "invisible",
                ";",
                "he",
                "catch",
                "Bennet",
                "'s",
                "eye",
                "and",
                "cross",
                "one",
                "finger",
                "over",
                "he",
                "lip",
                "."
            ],
            [
                "Bennet",
                "give",
                "he",
                "a",
                "quick",
                "nod",
                "of",
                "understanding",
                ",",
                "then",
                "jerk",
                "he",
                "head",
                "towards",
                "the",
                "end",
                "of",
                "the",
                "hallway",
                "."
            ]
        ],
        "label": "Fear"
    },
    {
        "body_part_token_idx": 46,
        "sentence_id": "26aba9d8-f222-34c9-8981-9114f90d51f9",
        "tokens": [
            "So",
            "Arthur",
            "held",
            "Merlin",
            "close",
            "to",
            "him",
            "until",
            "the",
            "boy",
            "'s",
            "trembling",
            "lessened",
            ",",
            "and",
            "until",
            "the",
            "fire",
            "had",
            "burned",
            "low",
            "and",
            "the",
            "sky",
            "grew",
            "light",
            "with",
            "the",
            "dawn",
            ",",
            "and",
            "he",
            "found",
            "that",
            "-",
            "despite",
            "the",
            "knot",
            "of",
            "worry",
            "that",
            "was",
            "eating",
            "away",
            "at",
            "his",
            "chest",
            "-",
            "this",
            "was",
            "the",
            "most",
            "content",
            "that",
            "he",
            "had",
            "ever",
            "been",
            "."
        ],
        "lemmatized_tokens": [
            "so",
            "Arthur",
            "hold",
            "Merlin",
            "close",
            "to",
            "he",
            "until",
            "the",
            "boy",
            "'s",
            "tremble",
            "lessen",
            ",",
            "and",
            "until",
            "the",
            "fire",
            "have",
            "burn",
            "low",
            "and",
            "the",
            "sky",
            "grow",
            "light",
            "with",
            "the",
            "dawn",
            ",",
            "and",
            "he",
            "find",
            "that",
            "-",
            "despite",
            "the",
            "knot",
            "of",
            "worry",
            "that",
            "be",
            "eat",
            "away",
            "at",
            "he",
            "chest",
            "-",
            "this",
            "be",
            "the",
            "most",
            "content",
            "that",
            "he",
            "have",
            "ever",
            "be",
            "."
        ],
        "preceding_context_tokens": [
            [
                "It",
                "did",
                "n't",
                "even",
                "matter",
                "that",
                "Arthur",
                "had",
                "just",
                "let",
                "his",
                "guard",
                "down",
                "completely",
                ",",
                "or",
                "that",
                "Merlin",
                "was",
                "probably",
                "too",
                "ill",
                "to",
                "even",
                "notice",
                "that",
                "he",
                "was",
                "there",
                "."
            ],
            [
                "Arthur",
                "had",
                "discovered",
                "that",
                "he",
                "cared",
                "for",
                "Merlin",
                "just",
                "as",
                "much",
                "as",
                "he",
                "cared",
                "for",
                "himself",
                "-",
                "and",
                "perhaps",
                "even",
                "more",
                "than",
                "that",
                "."
            ],
            [
                "And",
                "he",
                "knew",
                "that",
                "in",
                "this",
                "moment",
                ",",
                "Merlin",
                "was",
                "vulnerable",
                "and",
                "sick",
                "and",
                "miserable",
                ",",
                "and",
                "he",
                "needed",
                "someone",
                "to",
                "be",
                "there",
                "for",
                "him",
                ",",
                "and",
                "Arthur",
                "knew",
                "that",
                "he",
                "could",
                "find",
                "it",
                "within",
                "himself",
                "to",
                "be",
                "that",
                "person",
                ",",
                "no",
                "matter",
                "how",
                "hard",
                "it",
                "was",
                "for",
                "him",
                "to",
                "do",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "it",
                "do",
                "not",
                "even",
                "matter",
                "that",
                "Arthur",
                "have",
                "just",
                "let",
                "he",
                "guard",
                "down",
                "completely",
                ",",
                "or",
                "that",
                "Merlin",
                "be",
                "probably",
                "too",
                "ill",
                "to",
                "even",
                "notice",
                "that",
                "he",
                "be",
                "there",
                "."
            ],
            [
                "Arthur",
                "have",
                "discover",
                "that",
                "he",
                "care",
                "for",
                "Merlin",
                "just",
                "as",
                "much",
                "as",
                "he",
                "care",
                "for",
                "himself",
                "-",
                "and",
                "perhaps",
                "even",
                "more",
                "than",
                "that",
                "."
            ],
            [
                "and",
                "he",
                "know",
                "that",
                "in",
                "this",
                "moment",
                ",",
                "Merlin",
                "be",
                "vulnerable",
                "and",
                "sick",
                "and",
                "miserable",
                ",",
                "and",
                "he",
                "need",
                "someone",
                "to",
                "be",
                "there",
                "for",
                "he",
                ",",
                "and",
                "Arthur",
                "know",
                "that",
                "he",
                "could",
                "find",
                "it",
                "within",
                "himself",
                "to",
                "be",
                "that",
                "person",
                ",",
                "no",
                "matter",
                "how",
                "hard",
                "it",
                "be",
                "for",
                "he",
                "to",
                "do",
                "."
            ]
        ],
        "label": "Fear"
    },
    {
        "body_part_token_idx": 3,
        "sentence_id": "05d35b04-69e5-3065-b35f-717e8a8ee2be",
        "tokens": [
            "She",
            "shook",
            "her",
            "head",
            ",",
            "``",
            "But",
            "this",
            "is",
            "n't",
            "about",
            "Batman",
            "."
        ],
        "lemmatized_tokens": [
            "she",
            "shake",
            "she",
            "head",
            ",",
            "``",
            "but",
            "this",
            "be",
            "not",
            "about",
            "Batman",
            "."
        ],
        "preceding_context_tokens": [
            [
                "She",
                "continued",
                ",",
                "``",
                "Vigilantes",
                "are",
                "when",
                "common",
                "people",
                "get",
                "some",
                "substance",
                "or",
                "another",
                "and",
                "use",
                "it",
                "to",
                "empower",
                "themselves",
                "to",
                "fight",
                "crime",
                ".",
                "''"
            ],
            [
                "``",
                "Like",
                "Batman",
                ",",
                "''",
                "I",
                "muttered",
                ",",
                "still",
                "put",
                "out",
                "."
            ],
            [
                "``",
                "Batman",
                "does",
                "n't",
                "have",
                "superpowers",
                ",",
                "he",
                "only",
                "trained",
                "himself",
                "to",
                "become",
                "the",
                "highest",
                "form",
                "of",
                "human",
                "fitness",
                ",",
                "''",
                "she",
                "scolded",
                "me",
                "seriously",
                ",",
                "reminding",
                "me",
                "of",
                "one",
                "of",
                "the",
                "reasons",
                "I",
                "fell",
                "for",
                "her",
                "like",
                "I",
                "did",
                ",",
                "she",
                "was",
                "into",
                "the",
                "same",
                "things",
                "I",
                "was",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "she",
                "continue",
                ",",
                "``",
                "vigilante",
                "be",
                "when",
                "common",
                "people",
                "get",
                "some",
                "substance",
                "or",
                "another",
                "and",
                "use",
                "it",
                "to",
                "empower",
                "themselves",
                "to",
                "fight",
                "crime",
                ".",
                "''"
            ],
            [
                "``",
                "like",
                "Batman",
                ",",
                "''",
                "I",
                "mutter",
                ",",
                "still",
                "put",
                "out",
                "."
            ],
            [
                "``",
                "Batman",
                "do",
                "not",
                "have",
                "superpower",
                ",",
                "he",
                "only",
                "train",
                "himself",
                "to",
                "become",
                "the",
                "highest",
                "form",
                "of",
                "human",
                "fitness",
                ",",
                "''",
                "she",
                "scold",
                "I",
                "seriously",
                ",",
                "remind",
                "I",
                "of",
                "one",
                "of",
                "the",
                "reason",
                "I",
                "fall",
                "for",
                "she",
                "like",
                "I",
                "do",
                ",",
                "she",
                "be",
                "into",
                "the",
                "same",
                "thing",
                "I",
                "be",
                "."
            ]
        ],
        "label": "Disgust"
    },
    {
        "body_part_token_idx": 1,
        "sentence_id": "0a5e2581-aa86-3856-96be-6086464a7e58",
        "tokens": [
            "Her",
            "shoulders",
            "set",
            "as",
            "she",
            "pulls",
            "her",
            "arms",
            "from",
            "their",
            "fold",
            "again",
            ",",
            "hands",
            "curling",
            "into",
            "loose",
            "fists",
            "at",
            "her",
            "sides",
            "."
        ],
        "lemmatized_tokens": [
            "she",
            "shoulder",
            "set",
            "as",
            "she",
            "pull",
            "she",
            "arm",
            "from",
            "they",
            "fold",
            "again",
            ",",
            "hand",
            "curl",
            "into",
            "loose",
            "fist",
            "at",
            "she",
            "side",
            "."
        ],
        "preceding_context_tokens": [
            [
                "he",
                "asks",
                "her",
                "without",
                "preamble",
                "."
            ],
            [
                "``",
                "So",
                ",",
                "''",
                "Ellen",
                "replies",
                "."
            ],
            [
                "Clipping",
                "out",
                "the",
                "word",
                "singly",
                "in",
                "a",
                "clear",
                ",",
                "sharp",
                "voice",
                ",",
                "she",
                "lifts",
                "her",
                "chin",
                "and",
                "looks",
                "up",
                "at",
                "Creed",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "he",
                "ask",
                "she",
                "without",
                "preamble",
                "."
            ],
            [
                "``",
                "so",
                ",",
                "''",
                "Ellen",
                "reply",
                "."
            ],
            [
                "clip",
                "out",
                "the",
                "word",
                "singly",
                "in",
                "a",
                "clear",
                ",",
                "sharp",
                "voice",
                ",",
                "she",
                "lift",
                "she",
                "chin",
                "and",
                "look",
                "up",
                "at",
                "creed",
                "."
            ]
        ],
        "label": "Anger"
    },
    {
        "body_part_token_idx": 21,
        "sentence_id": "ad6f8037-a3bc-3ebb-8e45-a4e96e44697c",
        "tokens": [
            "He",
            "glanced",
            "up",
            "at",
            "dad",
            ",",
            "who",
            "was",
            "standing",
            "still",
            "and",
            "silent",
            "across",
            "the",
            "room",
            ",",
            "his",
            "pained",
            "heart",
            "in",
            "his",
            "eyes",
            "."
        ],
        "lemmatized_tokens": [
            "he",
            "glance",
            "up",
            "at",
            "dad",
            ",",
            "who",
            "be",
            "stand",
            "still",
            "and",
            "silent",
            "across",
            "the",
            "room",
            ",",
            "he",
            "pained",
            "heart",
            "in",
            "he",
            "eye",
            "."
        ],
        "preceding_context_tokens": [
            [
                "He",
                "does",
                "n't",
                "care",
                "what",
                "he",
                "takes",
                "from",
                "us",
                "and",
                "we",
                "never",
                "ask",
                "him",
                "for",
                "anything",
                "."
            ],
            [
                "All",
                "I",
                "ever",
                "wanted",
                "was",
                "something",
                "of",
                "my",
                "own",
                ",",
                "why",
                "is",
                "that",
                "so",
                "wrong",
                ",",
                "Dean",
                "?",
                "''"
            ],
            [
                "Dean",
                "choked",
                "back",
                "his",
                "own",
                "tears",
                "and",
                "tightened",
                "his",
                "fierce",
                "hold",
                "around",
                "Sam",
                "'s",
                "little",
                "weeping",
                "figure",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "he",
                "do",
                "not",
                "care",
                "what",
                "he",
                "take",
                "from",
                "we",
                "and",
                "we",
                "never",
                "ask",
                "he",
                "for",
                "anything",
                "."
            ],
            [
                "all",
                "I",
                "ever",
                "want",
                "be",
                "something",
                "of",
                "my",
                "own",
                ",",
                "why",
                "be",
                "that",
                "so",
                "wrong",
                ",",
                "Dean",
                "?",
                "''"
            ],
            [
                "Dean",
                "choke",
                "back",
                "he",
                "own",
                "tear",
                "and",
                "tighten",
                "he",
                "fierce",
                "hold",
                "around",
                "Sam",
                "'s",
                "little",
                "weep",
                "figure",
                "."
            ]
        ],
        "label": "Sadness"
    },
    {
        "body_part_token_idx": 16,
        "sentence_id": "6c815d58-4edb-3d82-9819-0e298def20d2",
        "tokens": [
            "When",
            "Sibylline",
            "finished",
            "her",
            "tale",
            "and",
            "pleaded",
            "with",
            "Nefario",
            "for",
            "his",
            "aide",
            ",",
            "he",
            "curled",
            "his",
            "lips",
            "back",
            "into",
            "a",
            "wicked",
            "grin",
            "and",
            "Fable",
            "cringed",
            ",",
            "waiting",
            "for",
            "a",
            "hideous",
            "laugh",
            "."
        ],
        "lemmatized_tokens": [
            "when",
            "Sibylline",
            "finish",
            "she",
            "tale",
            "and",
            "plead",
            "with",
            "Nefario",
            "for",
            "he",
            "aide",
            ",",
            "he",
            "curl",
            "he",
            "lip",
            "back",
            "into",
            "a",
            "wicked",
            "grin",
            "and",
            "fable",
            "cringe",
            ",",
            "wait",
            "for",
            "a",
            "hideous",
            "laugh",
            "."
        ],
        "preceding_context_tokens": [
            [
                "Sibylline",
                ",",
                "convincing",
                "herself",
                "he",
                "could",
                "do",
                "no",
                "real",
                "harm",
                ",",
                "stepped",
                "forward",
                "."
            ],
            [
                "She",
                "explained",
                "their",
                "situation",
                "and",
                "their",
                "dire",
                "need",
                "for",
                "his",
                "assistance",
                "."
            ],
            [
                "He",
                "seemed",
                "untrusting",
                "at",
                "first",
                "and",
                "developed",
                "a",
                "strange",
                "habit",
                "of",
                "shaking",
                "his",
                "dead",
                ",",
                "as",
                "if",
                "in",
                "disbelief",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "sibylline",
                ",",
                "convincing",
                "herself",
                "he",
                "could",
                "do",
                "no",
                "real",
                "harm",
                ",",
                "step",
                "forward",
                "."
            ],
            [
                "she",
                "explain",
                "they",
                "situation",
                "and",
                "they",
                "dire",
                "need",
                "for",
                "he",
                "assistance",
                "."
            ],
            [
                "he",
                "seem",
                "untrusting",
                "at",
                "first",
                "and",
                "develop",
                "a",
                "strange",
                "habit",
                "of",
                "shake",
                "he",
                "dead",
                ",",
                "as",
                "if",
                "in",
                "disbelief",
                "."
            ]
        ],
        "label": "Joy"
    },
    {
        "body_part_token_idx": 14,
        "sentence_id": "fec3ec97-5b76-3f2d-abe5-3d800fd8829b",
        "tokens": [
            "Dad",
            "flipped",
            "his",
            "long",
            "hair",
            "out",
            "of",
            "his",
            "eyes",
            "and",
            "leaned",
            "backward",
            ",",
            "his",
            "mouth",
            "open",
            "wide",
            "with",
            "laughter",
            "and",
            "joy",
            ",",
            "Marv",
            "tried",
            "to",
            "pounce",
            "him",
            "but",
            "it",
            "'s",
            "hard",
            "to",
            "be",
            "menacing",
            "with",
            "a",
            "doggy",
            "paddle",
            "."
        ],
        "lemmatized_tokens": [
            "Dad",
            "flip",
            "he",
            "long",
            "hair",
            "out",
            "of",
            "he",
            "eye",
            "and",
            "lean",
            "backward",
            ",",
            "he",
            "mouth",
            "open",
            "wide",
            "with",
            "laughter",
            "and",
            "joy",
            ",",
            "Marv",
            "try",
            "to",
            "pounce",
            "he",
            "but",
            "it",
            "be",
            "hard",
            "to",
            "be",
            "menacing",
            "with",
            "a",
            "doggy",
            "paddle",
            "."
        ],
        "preceding_context_tokens": [
            [
                "``",
                "No",
                "!",
                "''"
            ],
            [
                "I",
                "screamed",
                "as",
                "I",
                "charged",
                "for",
                "the",
                "beach",
                ",",
                "but",
                "a",
                "figure",
                "emerged",
                "underneath",
                "her",
                ",",
                "laughing",
                "hysterically",
                "as",
                "Quorra",
                "fell",
                "backward",
                "into",
                "the",
                "warm",
                "water",
                "."
            ],
            [
                "His",
                "hair",
                "and",
                "beard",
                "were",
                "gray",
                ",",
                "his",
                "old",
                "man",
                "body",
                "less",
                "than",
                "perfect",
                "but",
                "booming",
                "with",
                "authority",
                ",",
                "and",
                "kindness",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "``",
                "no",
                "!",
                "''"
            ],
            [
                "I",
                "scream",
                "as",
                "I",
                "charge",
                "for",
                "the",
                "beach",
                ",",
                "but",
                "a",
                "figure",
                "emerge",
                "underneath",
                "she",
                ",",
                "laugh",
                "hysterically",
                "as",
                "Quorra",
                "fall",
                "backward",
                "into",
                "the",
                "warm",
                "water",
                "."
            ],
            [
                "he",
                "hair",
                "and",
                "beard",
                "be",
                "gray",
                ",",
                "he",
                "old",
                "man",
                "body",
                "less",
                "than",
                "perfect",
                "but",
                "booming",
                "with",
                "authority",
                ",",
                "and",
                "kindness",
                "."
            ]
        ],
        "label": "Joy"
    },
    {
        "body_part_token_idx": 3,
        "sentence_id": "833d1742-68f8-35b6-8f55-f9391bd8df44",
        "tokens": [
            "He",
            "tilted",
            "his",
            "head",
            "to",
            "the",
            "side",
            ",",
            "slightly",
            "."
        ],
        "lemmatized_tokens": [
            "he",
            "tilt",
            "he",
            "head",
            "to",
            "the",
            "side",
            ",",
            "slightly",
            "."
        ],
        "preceding_context_tokens": [
            [
                "Her",
                "eyes",
                "finally",
                "rose",
                "to",
                "his",
                "."
            ],
            [
                "He",
                "could",
                "detect",
                "a",
                "faint",
                "arrogance",
                "in",
                "her",
                "tone",
                "when",
                "she",
                "added",
                ",",
                "``",
                "I",
                "can",
                "handle",
                "you",
                "."
            ],
            [
                "``",
                "Was",
                "that",
                "right",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "she",
                "eye",
                "finally",
                "rise",
                "to",
                "he",
                "."
            ],
            [
                "he",
                "could",
                "detect",
                "a",
                "faint",
                "arrogance",
                "in",
                "she",
                "tone",
                "when",
                "she",
                "add",
                ",",
                "``",
                "I",
                "can",
                "handle",
                "you",
                "."
            ],
            [
                "``",
                "be",
                "that",
                "right",
                "."
            ]
        ],
        "label": "Surprise"
    },
    {
        "body_part_token_idx": 1,
        "sentence_id": "ca662234-735b-3b3a-93a4-03fd1d830743",
        "tokens": [
            "Her",
            "eyes",
            "went",
            "big",
            "."
        ],
        "lemmatized_tokens": [
            "she",
            "eye",
            "go",
            "big",
            "."
        ],
        "preceding_context_tokens": [
            [
                "Then",
                "she",
                "pulled",
                "him",
                "close",
                "."
            ],
            [
                "And",
                "just",
                "what",
                "IS",
                "your",
                "name?",
                "They",
                "stopped",
                "around",
                "the",
                "corner",
                "where",
                "things",
                "were",
                "quiet",
                "."
            ],
            [
                "Ruprecht",
                "Wankermann",
                ",",
                "he",
                "bristled",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "then",
                "she",
                "pull",
                "he",
                "close",
                "."
            ],
            [
                "and",
                "just",
                "what",
                "be",
                "you",
                "name?",
                "they",
                "stop",
                "around",
                "the",
                "corner",
                "where",
                "thing",
                "be",
                "quiet",
                "."
            ],
            [
                "Ruprecht",
                "Wankermann",
                ",",
                "he",
                "bristle",
                "."
            ]
        ],
        "label": "Surprise"
    },
    {
        "body_part_token_idx": 13,
        "sentence_id": "e739c4a1-b4ba-35fc-8ad2-7a78bf7570f9",
        "tokens": [
            "I",
            "put",
            "a",
            "hand",
            "to",
            "my",
            "brow",
            "furrowed",
            "with",
            "worry",
            "and",
            "closed",
            "my",
            "eyes",
            "."
        ],
        "lemmatized_tokens": [
            "I",
            "put",
            "a",
            "hand",
            "to",
            "my",
            "brow",
            "furrow",
            "with",
            "worry",
            "and",
            "close",
            "my",
            "eye",
            "."
        ],
        "preceding_context_tokens": [
            [
                "Please",
                "."
            ],
            [
                "There",
                "'s",
                "no",
                "need",
                "to",
                "raise",
                "your",
                "voice",
                "."
            ],
            [
                "I",
                "'m",
                "sitting",
                "right",
                "here",
                ".",
                "''"
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "please",
                "."
            ],
            [
                "there",
                "be",
                "no",
                "need",
                "to",
                "raise",
                "you",
                "voice",
                "."
            ],
            [
                "I",
                "be",
                "sit",
                "right",
                "here",
                ".",
                "''"
            ]
        ],
        "label": "Fear"
    },
    {
        "body_part_token_idx": 12,
        "sentence_id": "98557147-1a96-3570-a862-6ebae54ed280",
        "tokens": [
            "-LRB-",
            "He",
            "could",
            "n't",
            "have",
            "had",
            "a",
            "more",
            "disgusted",
            "look",
            "on",
            "his",
            "face",
            "."
        ],
        "lemmatized_tokens": [
            "-LRB-",
            "he",
            "could",
            "not",
            "have",
            "have",
            "a",
            "more",
            "disgusted",
            "look",
            "on",
            "he",
            "face",
            "."
        ],
        "preceding_context_tokens": [
            [
                "Is",
                "it",
                "my",
                "perfume",
                "?"
            ],
            [
                "-LRB-",
                "thinking",
                "that",
                "he",
                "thought",
                "I",
                "smelt",
                "good",
                ",",
                "because",
                "I",
                "did",
                "and",
                "my",
                "perfume",
                "smells",
                "awesome",
                ".",
                ")"
            ],
            [
                "Peer",
                ":",
                "No",
                ",",
                "I",
                "am",
                "pretty",
                "sure",
                "I",
                "can",
                "smell",
                "your",
                "hair",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "be",
                "it",
                "my",
                "perfume",
                "?"
            ],
            [
                "-lrb-",
                "thinking",
                "that",
                "he",
                "think",
                "I",
                "smell",
                "good",
                ",",
                "because",
                "I",
                "do",
                "and",
                "my",
                "perfume",
                "smell",
                "awesome",
                ".",
                ")"
            ],
            [
                "peer",
                ":",
                "no",
                ",",
                "I",
                "be",
                "pretty",
                "sure",
                "I",
                "can",
                "smell",
                "you",
                "hair",
                "."
            ]
        ],
        "label": "Disgust"
    },
    {
        "body_part_token_idx": 9,
        "sentence_id": "c7a364e7-8139-3bdd-94c9-bc835bfd64c5",
        "tokens": [
            "He",
            "hair",
            "was",
            "sprawled",
            "all",
            "around",
            "her",
            ",",
            "her",
            "arms",
            "were",
            "spread",
            "out",
            "beside",
            "her",
            "and",
            "her",
            "were",
            "straight",
            "out",
            "."
        ],
        "lemmatized_tokens": [
            "he",
            "hair",
            "be",
            "sprawl",
            "all",
            "around",
            "she",
            ",",
            "she",
            "arm",
            "be",
            "spread",
            "out",
            "beside",
            "she",
            "and",
            "she",
            "be",
            "straight",
            "out",
            "."
        ],
        "preceding_context_tokens": [
            [
                "You",
                "could",
                "see",
                "the",
                "stars",
                "and",
                "the",
                "moon",
                "which",
                "was",
                "very",
                "unlikely",
                "from",
                "the",
                "sky",
                "usually",
                "being",
                "covered",
                "in",
                "clouds",
                "."
            ],
            [
                "He",
                "did",
                "n't",
                "even",
                "think",
                "about",
                "walking",
                "through",
                "the",
                "front",
                "door",
                "of",
                "the",
                "house",
                ",",
                "he",
                "knew",
                "exactly",
                "where",
                "his",
                "girlfriend",
                "would",
                "be",
                "."
            ],
            [
                "As",
                "he",
                "entered",
                "the",
                "backyard",
                "quietly",
                "he",
                "saw",
                "her",
                "laying",
                "on",
                "her",
                "back",
                "on",
                "the",
                "grass",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "you",
                "could",
                "see",
                "the",
                "star",
                "and",
                "the",
                "moon",
                "which",
                "be",
                "very",
                "unlikely",
                "from",
                "the",
                "sky",
                "usually",
                "be",
                "cover",
                "in",
                "cloud",
                "."
            ],
            [
                "he",
                "do",
                "not",
                "even",
                "think",
                "about",
                "walk",
                "through",
                "the",
                "front",
                "door",
                "of",
                "the",
                "house",
                ",",
                "he",
                "know",
                "exactly",
                "where",
                "he",
                "girlfriend",
                "would",
                "be",
                "."
            ],
            [
                "as",
                "he",
                "enter",
                "the",
                "backyard",
                "quietly",
                "he",
                "see",
                "she",
                "lay",
                "on",
                "she",
                "back",
                "on",
                "the",
                "grass",
                "."
            ]
        ],
        "label": "Joy"
    },
    {
        "body_part_token_idx": 5,
        "sentence_id": "41b70a47-d336-38ca-97cf-dc22e5ebb318",
        "tokens": [
            "Again",
            ",",
            "I",
            "nodded",
            "my",
            "head",
            "."
        ],
        "lemmatized_tokens": [
            "again",
            ",",
            "I",
            "nod",
            "my",
            "head",
            "."
        ],
        "preceding_context_tokens": [
            [
                "Sunkyu",
                "woke",
                "up",
                "and",
                "approach",
                "us",
                "."
            ],
            [
                "``",
                "Oppa",
                ",",
                "you",
                "'re",
                "awake",
                "?",
                "''"
            ],
            [
                "she",
                "said",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "Sunkyu",
                "wake",
                "up",
                "and",
                "approach",
                "we",
                "."
            ],
            [
                "``",
                "oppa",
                ",",
                "you",
                "be",
                "awake",
                "?",
                "''"
            ],
            [
                "she",
                "say",
                "."
            ]
        ],
        "label": "Sadness"
    },
    {
        "body_part_token_idx": 1,
        "sentence_id": "392f55f5-8e8e-3329-a887-2a8398c965b1",
        "tokens": [
            "My",
            "jaw",
            "is",
            "set",
            "tight",
            ",",
            "to",
            "the",
            "point",
            "I",
            "wake",
            "up",
            "with",
            "an",
            "aching",
            "face.Thursday",
            "night",
            ",",
            "I",
            "had",
            "an",
            "early",
            "dinner",
            "with",
            "friends",
            "."
        ],
        "lemmatized_tokens": [
            "my",
            "jaw",
            "be",
            "set",
            "tight",
            ",",
            "to",
            "the",
            "point",
            "I",
            "wake",
            "up",
            "with",
            "a",
            "ache",
            "face.thursday",
            "night",
            ",",
            "I",
            "have",
            "a",
            "early",
            "dinner",
            "with",
            "friend",
            "."
        ],
        "preceding_context_tokens": [
            [
                "Lately",
                "it",
                "seems",
                "I",
                "am",
                "walking",
                "around",
                "with",
                "a",
                "perma",
                "-",
                "scowl",
                "on",
                "my",
                "face",
                "."
            ],
            [
                "My",
                "eyebrows",
                "huddle",
                "together",
                "like",
                "two",
                "old",
                "men",
                "discussing",
                "politics",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "lately",
                "it",
                "seem",
                "I",
                "be",
                "walk",
                "around",
                "with",
                "a",
                "perma",
                "-",
                "scowl",
                "on",
                "my",
                "face",
                "."
            ],
            [
                "my",
                "eyebrow",
                "huddle",
                "together",
                "like",
                "two",
                "old",
                "man",
                "discuss",
                "politics",
                "."
            ]
        ],
        "label": "Anger"
    },
    {
        "body_part_token_idx": 1,
        "sentence_id": "7405e0c4-a821-3c5e-b0ca-8882b5aaf9ac",
        "tokens": [
            "My",
            "heart",
            "feels",
            "like",
            "it",
            "'s",
            "dancing",
            "all",
            "inside",
            "of",
            "me",
            "."
        ],
        "lemmatized_tokens": [
            "my",
            "heart",
            "feel",
            "like",
            "it",
            "be",
            "dance",
            "all",
            "inside",
            "of",
            "I",
            "."
        ],
        "preceding_context_tokens": [
            [
                "He",
                "still",
                "has",
                "his",
                "keys",
                "on",
                "the",
                "Grand",
                "Marnier",
                "keychain",
                "I",
                "gave",
                "him",
                "!!!"
            ],
            [
                "I",
                "still",
                "have",
                "my",
                "Master",
                "Shake",
                "keychain",
                "on",
                "mine",
                "!"
            ],
            [
                "holy",
                "crap",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "he",
                "still",
                "have",
                "he",
                "key",
                "on",
                "the",
                "Grand",
                "Marnier",
                "keychain",
                "I",
                "give",
                "he",
                "!!!"
            ],
            [
                "I",
                "still",
                "have",
                "my",
                "Master",
                "Shake",
                "keychain",
                "on",
                "mine",
                "!"
            ],
            [
                "holy",
                "crap",
                "."
            ]
        ],
        "label": "Surprise"
    },
    {
        "body_part_token_idx": 1,
        "sentence_id": "ac38d717-c3ae-395b-8dd8-d1c4694685e0",
        "tokens": [
            "My",
            "hands",
            "were",
            "trembling",
            "with",
            "the",
            "life",
            "of",
            "her",
            "."
        ],
        "lemmatized_tokens": [
            "my",
            "hand",
            "be",
            "tremble",
            "with",
            "the",
            "life",
            "of",
            "she",
            "."
        ],
        "preceding_context_tokens": [
            [
                "No",
                ",",
                "yes",
                "."
            ],
            [
                "She",
                "does",
                "look",
                "dead",
                "."
            ],
            [
                "But",
                "last",
                "night",
                ",",
                "I",
                "know",
                "she",
                "was",
                "not",
                "dead",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "no",
                ",",
                "yes",
                "."
            ],
            [
                "she",
                "do",
                "look",
                "dead",
                "."
            ],
            [
                "but",
                "last",
                "night",
                ",",
                "I",
                "know",
                "she",
                "be",
                "not",
                "dead",
                "."
            ]
        ],
        "label": "Fear"
    },
    {
        "body_part_token_idx": 37,
        "sentence_id": "78fa3e75-c2ba-3470-939f-aa07463ede01",
        "tokens": [
            "It",
            "was",
            "n't",
            "working",
            "very",
            "well",
            "though",
            ",",
            "as",
            "the",
            "face",
            "of",
            "his",
            "wife",
            "sitting",
            "in",
            "the",
            "Impala",
            "beside",
            "him",
            ",",
            "laughing",
            "at",
            "one",
            "of",
            "his",
            "jokes",
            "changed",
            "into",
            "that",
            "of",
            "his",
            "geeky",
            "little",
            "brother",
            "rolling",
            "his",
            "eyes",
            "at",
            "him",
            "at",
            "exactly",
            "the",
            "same",
            "joke",
            "."
        ],
        "lemmatized_tokens": [
            "it",
            "be",
            "not",
            "work",
            "very",
            "well",
            "though",
            ",",
            "as",
            "the",
            "face",
            "of",
            "he",
            "wife",
            "sit",
            "in",
            "the",
            "Impala",
            "beside",
            "he",
            ",",
            "laugh",
            "at",
            "one",
            "of",
            "he",
            "joke",
            "change",
            "into",
            "that",
            "of",
            "he",
            "geeky",
            "little",
            "brother",
            "roll",
            "he",
            "eye",
            "at",
            "he",
            "at",
            "exactly",
            "the",
            "same",
            "joke",
            "."
        ],
        "preceding_context_tokens": [
            [
                "Finally",
                "he",
                "found",
                "a",
                "way",
                "that",
                "at",
                "least",
                "partially",
                "helped",
                "-",
                "keeping",
                "the",
                "music",
                "turned",
                "up",
                "at",
                "highest",
                "possible",
                "volume",
                "during",
                "work",
                "and",
                "the",
                "TV",
                "running",
                "during",
                "the",
                "evenings",
                "."
            ],
            [
                "Only",
                "at",
                "night",
                ",",
                "when",
                "everything",
                "was",
                "quiet",
                ",",
                "there",
                "was",
                "nothing",
                "else",
                "to",
                "do",
                "than",
                "to",
                "listen",
                "to",
                "his",
                "own",
                "thoughts",
                "."
            ],
            [
                "So",
                "he",
                "tried",
                "to",
                "replace",
                "them",
                "with",
                "memories",
                "of",
                "this",
                "life",
                ",",
                "memories",
                "of",
                "his",
                "`",
                "normal",
                "'",
                "childhood",
                ",",
                "of",
                "Lisa",
                "and",
                "the",
                "kids",
                "and",
                "of",
                "working",
                "with",
                "his",
                "dad",
                "every",
                "day",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "finally",
                "he",
                "find",
                "a",
                "way",
                "that",
                "at",
                "least",
                "partially",
                "help",
                "-",
                "keep",
                "the",
                "music",
                "turn",
                "up",
                "at",
                "highest",
                "possible",
                "volume",
                "during",
                "work",
                "and",
                "the",
                "tv",
                "running",
                "during",
                "the",
                "evening",
                "."
            ],
            [
                "only",
                "at",
                "night",
                ",",
                "when",
                "everything",
                "be",
                "quiet",
                ",",
                "there",
                "be",
                "nothing",
                "else",
                "to",
                "do",
                "than",
                "to",
                "listen",
                "to",
                "he",
                "own",
                "thought",
                "."
            ],
            [
                "so",
                "he",
                "try",
                "to",
                "replace",
                "they",
                "with",
                "memory",
                "of",
                "this",
                "life",
                ",",
                "memory",
                "of",
                "he",
                "`",
                "normal",
                "'",
                "childhood",
                ",",
                "of",
                "Lisa",
                "and",
                "the",
                "kid",
                "and",
                "of",
                "work",
                "with",
                "he",
                "dad",
                "every",
                "day",
                "."
            ]
        ],
        "label": "Disgust"
    },
    {
        "body_part_token_idx": 16,
        "sentence_id": "9c603409-cc82-3fa4-a6fd-79d4985995da",
        "tokens": [
            "Mizuki",
            "relieved",
            "her",
            "of",
            "the",
            "towel",
            "and",
            "got",
            "a",
            "new",
            "one",
            ",",
            "a",
            "smile",
            "on",
            "her",
            "face",
            ",",
            "before",
            "going",
            "to",
            "bed",
            "."
        ],
        "lemmatized_tokens": [
            "Mizuki",
            "relieve",
            "she",
            "of",
            "the",
            "towel",
            "and",
            "get",
            "a",
            "new",
            "one",
            ",",
            "a",
            "smile",
            "on",
            "she",
            "face",
            ",",
            "before",
            "go",
            "to",
            "bed",
            "."
        ],
        "preceding_context_tokens": [
            [
                "He",
                "heaved",
                "and",
                "sobbed",
                "alternately",
                "as",
                "she",
                "wiped",
                "some",
                "of",
                "the",
                "water",
                "off",
                "his",
                "face",
                "and",
                "neck",
                "with",
                "a",
                "towel",
                "."
            ],
            [
                "The",
                "heaving",
                "slowed",
                "to",
                "gentler",
                "breathing",
                "."
            ],
            [
                "She",
                "sighed",
                "with",
                "relief",
                "and",
                "sat",
                "beside",
                "the",
                "bed",
                ",",
                "still",
                "holding",
                "his",
                "hand",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "he",
                "heave",
                "and",
                "sob",
                "alternately",
                "as",
                "she",
                "wipe",
                "some",
                "of",
                "the",
                "water",
                "off",
                "he",
                "face",
                "and",
                "neck",
                "with",
                "a",
                "towel",
                "."
            ],
            [
                "the",
                "heaving",
                "slow",
                "to",
                "gentler",
                "breathing",
                "."
            ],
            [
                "she",
                "sigh",
                "with",
                "relief",
                "and",
                "sit",
                "beside",
                "the",
                "bed",
                ",",
                "still",
                "hold",
                "he",
                "hand",
                "."
            ]
        ],
        "label": "Joy"
    },
    {
        "body_part_token_idx": 6,
        "sentence_id": "9c587394-d73c-3f67-80f6-85e2dc11ba77",
        "tokens": [
            "``",
            "Stubbornly",
            ",",
            "Junsu",
            "turned",
            "his",
            "head",
            "and",
            "glared",
            "at",
            "the",
            "wall",
            "as",
            "he",
            "kept",
            "his",
            "own",
            "hands",
            "above",
            "his",
            "head",
            "."
        ],
        "lemmatized_tokens": [
            "``",
            "stubbornly",
            ",",
            "Junsu",
            "turn",
            "he",
            "head",
            "and",
            "glare",
            "at",
            "the",
            "wall",
            "as",
            "he",
            "keep",
            "he",
            "own",
            "hand",
            "above",
            "he",
            "head",
            "."
        ],
        "preceding_context_tokens": [
            [
                "He",
                "had",
                "hoped",
                "his",
                "shirt",
                "would",
                "n't",
                "get",
                "sticky",
                "but",
                "by",
                "moving",
                ",",
                "the",
                "ice",
                "cream",
                "traveled",
                "faster",
                "down",
                "his",
                "chest",
                "and",
                "past",
                "the",
                "crevices",
                "of",
                "his",
                "abs",
                ",",
                "nearly",
                "to",
                "his",
                "open",
                "pants",
                "."
            ],
            [
                "Yoochun",
                "laughed",
                "when",
                "Junsu",
                "hissed",
                "from",
                "the",
                "cold",
                "and",
                "got",
                "off",
                "his",
                "boyfriend",
                "slightly",
                "to",
                "tug",
                "his",
                "pants",
                "down",
                "a",
                "little",
                "more",
                "."
            ],
            [
                "``",
                "Admit",
                "it",
                ",",
                "you",
                "like",
                "having",
                "ice",
                "cream",
                "on",
                "you",
                ".",
                "''"
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "he",
                "have",
                "hope",
                "he",
                "shirt",
                "would",
                "not",
                "get",
                "sticky",
                "but",
                "by",
                "move",
                ",",
                "the",
                "ice",
                "cream",
                "travel",
                "faster",
                "down",
                "he",
                "chest",
                "and",
                "past",
                "the",
                "crevice",
                "of",
                "he",
                "abs",
                ",",
                "nearly",
                "to",
                "he",
                "open",
                "pants",
                "."
            ],
            [
                "Yoochun",
                "laugh",
                "when",
                "Junsu",
                "hiss",
                "from",
                "the",
                "cold",
                "and",
                "get",
                "off",
                "he",
                "boyfriend",
                "slightly",
                "to",
                "tug",
                "he",
                "pants",
                "down",
                "a",
                "little",
                "more",
                "."
            ],
            [
                "``",
                "admit",
                "it",
                ",",
                "you",
                "like",
                "have",
                "ice",
                "cream",
                "on",
                "you",
                ".",
                "''"
            ]
        ],
        "label": "Disgust"
    },
    {
        "body_part_token_idx": 20,
        "sentence_id": "9c587394-d73c-3f67-80f6-85e2dc11ba77",
        "tokens": [
            "``",
            "Stubbornly",
            ",",
            "Junsu",
            "turned",
            "his",
            "head",
            "and",
            "glared",
            "at",
            "the",
            "wall",
            "as",
            "he",
            "kept",
            "his",
            "own",
            "hands",
            "above",
            "his",
            "head",
            "."
        ],
        "lemmatized_tokens": [
            "``",
            "stubbornly",
            ",",
            "Junsu",
            "turn",
            "he",
            "head",
            "and",
            "glare",
            "at",
            "the",
            "wall",
            "as",
            "he",
            "keep",
            "he",
            "own",
            "hand",
            "above",
            "he",
            "head",
            "."
        ],
        "preceding_context_tokens": [
            [
                "He",
                "had",
                "hoped",
                "his",
                "shirt",
                "would",
                "n't",
                "get",
                "sticky",
                "but",
                "by",
                "moving",
                ",",
                "the",
                "ice",
                "cream",
                "traveled",
                "faster",
                "down",
                "his",
                "chest",
                "and",
                "past",
                "the",
                "crevices",
                "of",
                "his",
                "abs",
                ",",
                "nearly",
                "to",
                "his",
                "open",
                "pants",
                "."
            ],
            [
                "Yoochun",
                "laughed",
                "when",
                "Junsu",
                "hissed",
                "from",
                "the",
                "cold",
                "and",
                "got",
                "off",
                "his",
                "boyfriend",
                "slightly",
                "to",
                "tug",
                "his",
                "pants",
                "down",
                "a",
                "little",
                "more",
                "."
            ],
            [
                "``",
                "Admit",
                "it",
                ",",
                "you",
                "like",
                "having",
                "ice",
                "cream",
                "on",
                "you",
                ".",
                "''"
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "he",
                "have",
                "hope",
                "he",
                "shirt",
                "would",
                "not",
                "get",
                "sticky",
                "but",
                "by",
                "move",
                ",",
                "the",
                "ice",
                "cream",
                "travel",
                "faster",
                "down",
                "he",
                "chest",
                "and",
                "past",
                "the",
                "crevice",
                "of",
                "he",
                "abs",
                ",",
                "nearly",
                "to",
                "he",
                "open",
                "pants",
                "."
            ],
            [
                "Yoochun",
                "laugh",
                "when",
                "Junsu",
                "hiss",
                "from",
                "the",
                "cold",
                "and",
                "get",
                "off",
                "he",
                "boyfriend",
                "slightly",
                "to",
                "tug",
                "he",
                "pants",
                "down",
                "a",
                "little",
                "more",
                "."
            ],
            [
                "``",
                "admit",
                "it",
                ",",
                "you",
                "like",
                "have",
                "ice",
                "cream",
                "on",
                "you",
                ".",
                "''"
            ]
        ],
        "label": "Disgust"
    },
    {
        "body_part_token_idx": 10,
        "sentence_id": "3550951e-7732-307d-9a9a-98db21eb9822",
        "tokens": [
            "``",
            "When",
            "she",
            "turned",
            "around",
            "two",
            "tears",
            "slid",
            "down",
            "her",
            "cheeks",
            "."
        ],
        "lemmatized_tokens": [
            "``",
            "when",
            "she",
            "turn",
            "around",
            "two",
            "tear",
            "slide",
            "down",
            "she",
            "cheek",
            "."
        ],
        "preceding_context_tokens": [
            [
                "``",
                "Sara",
                "huffed",
                "and",
                "strode",
                "to",
                "the",
                "door",
                "opening",
                "it",
                "slightly",
                "before",
                "he",
                "continued",
                "."
            ],
            [
                "``",
                "Either",
                "I",
                "do",
                "it",
                "or",
                "one",
                "of",
                "the",
                "police",
                "men",
                "do",
                "it",
                "."
            ],
            [
                "They",
                "wo",
                "n't",
                "be",
                "as",
                "caring",
                "as",
                "I",
                "will",
                "-",
                "but",
                "I",
                "'ll",
                "let",
                "you",
                "choose",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "``",
                "Sara",
                "huff",
                "and",
                "stride",
                "to",
                "the",
                "door",
                "open",
                "it",
                "slightly",
                "before",
                "he",
                "continue",
                "."
            ],
            [
                "``",
                "either",
                "I",
                "do",
                "it",
                "or",
                "one",
                "of",
                "the",
                "police",
                "man",
                "do",
                "it",
                "."
            ],
            [
                "they",
                "will",
                "not",
                "be",
                "as",
                "care",
                "as",
                "I",
                "will",
                "-",
                "but",
                "I",
                "will",
                "let",
                "you",
                "choose",
                "."
            ]
        ],
        "label": "Sadness"
    },
    {
        "body_part_token_idx": 2,
        "sentence_id": "683e73b4-25f6-31f7-9874-666220c5b1d0",
        "tokens": [
            "'",
            "Her",
            "face",
            "brightened",
            "as",
            "she",
            "turned",
            "and",
            "said",
            "under",
            "her",
            "breath",
            ",",
            "Speaking",
            "of",
            "the",
            "devil",
            "'",
            "Harry",
            "turned",
            "quickly",
            "and",
            "saw",
            "Ginny",
            "walking",
            "into",
            "the",
            "caf",
            "."
        ],
        "lemmatized_tokens": [
            "'",
            "she",
            "face",
            "brighten",
            "as",
            "she",
            "turn",
            "and",
            "say",
            "under",
            "she",
            "breath",
            ",",
            "speak",
            "of",
            "the",
            "devil",
            "'",
            "Harry",
            "turn",
            "quickly",
            "and",
            "see",
            "Ginny",
            "walk",
            "into",
            "the",
            "caf",
            "."
        ],
        "preceding_context_tokens": [
            [
                "'",
                "I",
                "'m",
                "sure",
                ".",
                "'"
            ],
            [
                "She",
                "laughed",
                "."
            ],
            [
                "I",
                "have",
                "a",
                "feeling",
                "she",
                "would",
                "have",
                "preferred",
                "that",
                "as",
                "well",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "'",
                "I",
                "be",
                "sure",
                ".",
                "'"
            ],
            [
                "she",
                "laugh",
                "."
            ],
            [
                "I",
                "have",
                "a",
                "feeling",
                "she",
                "would",
                "have",
                "prefer",
                "that",
                "as",
                "well",
                "."
            ]
        ],
        "label": "Joy"
    },
    {
        "body_part_token_idx": 4,
        "sentence_id": "ac122661-1530-3470-b261-c3c1582631ba",
        "tokens": [
            "He",
            "had",
            "swiped",
            "his",
            "hand",
            "through",
            "his",
            "hair",
            "then",
            ",",
            "smiling",
            "down",
            "at",
            "her",
            "when",
            "she",
            "looked",
            "up",
            "from",
            "her",
            "book",
            "."
        ],
        "lemmatized_tokens": [
            "he",
            "have",
            "swipe",
            "he",
            "hand",
            "through",
            "he",
            "hair",
            "then",
            ",",
            "smile",
            "down",
            "at",
            "she",
            "when",
            "she",
            "look",
            "up",
            "from",
            "she",
            "book",
            "."
        ],
        "preceding_context_tokens": [
            [
                "However",
                ",",
                "she",
                "had",
                "been",
                "so",
                "engaged",
                "in",
                "her",
                "reading",
                "that",
                "she",
                "had",
                "not",
                "exactly",
                "heard",
                "the",
                "door",
                "to",
                "the",
                "store",
                "open",
                ",",
                "or",
                "seen",
                "the",
                "so",
                "called",
                "enemy",
                "walk",
                "in",
                "and",
                "stare",
                "at",
                "her",
                ",",
                "smiling",
                "at",
                "the",
                "choice",
                "of",
                "book",
                "she",
                "chose",
                "-",
                "which",
                "just",
                "happened",
                "to",
                "be",
                ",",
                "yes",
                ",",
                "you",
                "guessed",
                "it",
                ",",
                "blue",
                "."
            ],
            [
                "She",
                "had",
                "been",
                "so",
                "engaged",
                "in",
                "her",
                "novel",
                ",",
                "that",
                "when",
                "she",
                "looked",
                "up",
                "and",
                "saw",
                "him",
                "there",
                ",",
                "she",
                "had",
                "only",
                "arched",
                "her",
                "eyebrow",
                "and",
                "defiantly",
                ",",
                "looked",
                "back",
                "down",
                ",",
                "trying",
                "to",
                "prove",
                "something",
                "."
            ],
            [
                "He",
                "had",
                "smirked",
                "at",
                "that",
                ",",
                "finding",
                "it",
                "incredibly",
                "cute",
                "and",
                "endearing",
                ",",
                "which",
                "was",
                "a",
                "shock",
                "in",
                "itself",
                ",",
                "for",
                "his",
                "kind",
                "did",
                "not",
                "do",
                "that",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "however",
                ",",
                "she",
                "have",
                "be",
                "so",
                "engaged",
                "in",
                "she",
                "reading",
                "that",
                "she",
                "have",
                "not",
                "exactly",
                "hear",
                "the",
                "door",
                "to",
                "the",
                "store",
                "open",
                ",",
                "or",
                "see",
                "the",
                "so",
                "call",
                "enemy",
                "walk",
                "in",
                "and",
                "stare",
                "at",
                "she",
                ",",
                "smile",
                "at",
                "the",
                "choice",
                "of",
                "book",
                "she",
                "choose",
                "-",
                "which",
                "just",
                "happen",
                "to",
                "be",
                ",",
                "yes",
                ",",
                "you",
                "guess",
                "it",
                ",",
                "blue",
                "."
            ],
            [
                "she",
                "have",
                "be",
                "so",
                "engaged",
                "in",
                "she",
                "novel",
                ",",
                "that",
                "when",
                "she",
                "look",
                "up",
                "and",
                "see",
                "he",
                "there",
                ",",
                "she",
                "have",
                "only",
                "arch",
                "she",
                "eyebrow",
                "and",
                "defiantly",
                ",",
                "look",
                "back",
                "down",
                ",",
                "try",
                "to",
                "prove",
                "something",
                "."
            ],
            [
                "he",
                "have",
                "smirk",
                "at",
                "that",
                ",",
                "find",
                "it",
                "incredibly",
                "cute",
                "and",
                "endearing",
                ",",
                "which",
                "be",
                "a",
                "shock",
                "in",
                "itself",
                ",",
                "for",
                "he",
                "kind",
                "do",
                "not",
                "do",
                "that",
                "."
            ]
        ],
        "label": "Joy"
    },
    {
        "body_part_token_idx": 6,
        "sentence_id": "af5d7aa4-a5cd-32f5-8ae0-9e79ea0d9c57",
        "tokens": [
            "Of",
            "course",
            "not.",
            "She",
            "shuffled",
            "her",
            "feet",
            "."
        ],
        "lemmatized_tokens": [
            "of",
            "course",
            "not.",
            "she",
            "shuffle",
            "she",
            "foot",
            "."
        ],
        "preceding_context_tokens": [
            [
                "Not",
                "like",
                "that.",
                "None",
                "of",
                "them",
                "?"
            ],
            [
                "Is",
                "there",
                "anyone",
                "you",
                "ARE",
                "interested",
                "in?",
                "Francoise",
                "blushed",
                "so",
                "red",
                "I",
                "thought",
                "she",
                "'d",
                "faint",
                "."
            ],
            [
                "N",
                "-",
                "no",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "not",
                "like",
                "that.",
                "none",
                "of",
                "they",
                "?"
            ],
            [
                "be",
                "there",
                "anyone",
                "you",
                "be",
                "interested",
                "in?",
                "Francoise",
                "blush",
                "so",
                "red",
                "I",
                "think",
                "she",
                "would",
                "faint",
                "."
            ],
            [
                "n",
                "-",
                "no",
                "."
            ]
        ],
        "label": "Fear"
    },
    {
        "body_part_token_idx": 16,
        "sentence_id": "45149382-3ac1-3540-bc0b-1469764ca7ee",
        "tokens": [
            "Joe",
            "cringed",
            "as",
            "he",
            "listened",
            "to",
            "Kevin",
            "leave",
            "the",
            "room",
            ",",
            "a",
            "strange",
            "pressure",
            "twisting",
            "his",
            "stomach",
            "."
        ],
        "lemmatized_tokens": [
            "Joe",
            "cringe",
            "as",
            "he",
            "listen",
            "to",
            "Kevin",
            "leave",
            "the",
            "room",
            ",",
            "a",
            "strange",
            "pressure",
            "twist",
            "he",
            "stomach",
            "."
        ],
        "preceding_context_tokens": [
            [
                "He",
                "paused",
                ",",
                "his",
                "foot",
                "falls",
                "stopping",
                "."
            ],
            [
                "``",
                "Just",
                "steal",
                "one",
                "of",
                "his",
                "stupid",
                "posters",
                ",",
                "see",
                "how",
                "he",
                "likes",
                "it",
                "when",
                "he",
                "ca",
                "n't",
                "find",
                "his",
                "precious",
                "Joe",
                ".",
                "''"
            ],
            [
                "Kevin",
                "smirked",
                "grabbing",
                "one",
                "of",
                "the",
                "rolled",
                "up",
                "posters",
                "from",
                "the",
                "ground",
                ",",
                "gripping",
                "the",
                "paper",
                "in",
                "his",
                "hand",
                "and",
                "heading",
                "back",
                "to",
                "his",
                "room",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "he",
                "pause",
                ",",
                "he",
                "foot",
                "fall",
                "stop",
                "."
            ],
            [
                "``",
                "just",
                "steal",
                "one",
                "of",
                "he",
                "stupid",
                "poster",
                ",",
                "see",
                "how",
                "he",
                "like",
                "it",
                "when",
                "he",
                "can",
                "not",
                "find",
                "he",
                "precious",
                "Joe",
                ".",
                "''"
            ],
            [
                "Kevin",
                "smirk",
                "grab",
                "one",
                "of",
                "the",
                "roll",
                "up",
                "poster",
                "from",
                "the",
                "ground",
                ",",
                "grip",
                "the",
                "paper",
                "in",
                "he",
                "hand",
                "and",
                "head",
                "back",
                "to",
                "he",
                "room",
                "."
            ]
        ],
        "label": "Disgust"
    },
    {
        "body_part_token_idx": 4,
        "sentence_id": "cad9d7d6-6a8f-3f4b-914d-9320f721cae1",
        "tokens": [
            "Seriously",
            ",",
            "sometimes",
            "my",
            "heart",
            "physically",
            "aches",
            "for",
            "what",
            "people",
            "go",
            "through",
            "here",
            "."
        ],
        "lemmatized_tokens": [
            "seriously",
            ",",
            "sometimes",
            "my",
            "heart",
            "physically",
            "ache",
            "for",
            "what",
            "people",
            "go",
            "through",
            "here",
            "."
        ],
        "preceding_context_tokens": [
            [
                "Not",
                "bad",
                "considering",
                "how",
                "much",
                "we",
                "were",
                "able",
                "to",
                "fit",
                "into",
                "the",
                "time",
                "proceeding",
                "it",
                "but",
                "still",
                "pretty",
                "ridiculous",
                "."
            ],
            [
                "After",
                "morning",
                "work",
                ",",
                "teaching",
                "at",
                "the",
                "school",
                ",",
                "and",
                "what",
                "seemed",
                "like",
                "a",
                "stream",
                "of",
                "visitors",
                "-LRB-",
                "seriously",
                ",",
                "do",
                "they",
                "time",
                "that",
                "?",
                ")"
            ],
            [
                "I",
                "took",
                "our",
                "neighbors",
                "to",
                "a",
                "clinic",
                "because",
                "after",
                "over",
                "a",
                "week",
                "of",
                "their",
                "eldest",
                "daughter",
                "have",
                "excruciating",
                "pain",
                "from",
                "an",
                "infected",
                "tooth",
                "I",
                "finally",
                "realized",
                "they",
                "were",
                "not",
                "taking",
                "her",
                "because",
                "they",
                "did",
                "not",
                "have",
                "the",
                "5,000",
                "Tsh",
                "-LRB-",
                "about",
                "$",
                "3.50",
                ")",
                "to",
                "pay",
                "for",
                "the",
                "tooth",
                "to",
                "be",
                "removed",
                "and",
                "they",
                "were",
                "unsure",
                "how",
                "much",
                "bribe",
                "would",
                "be",
                "required",
                "at",
                "the",
                "government",
                "hospital",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "not",
                "bad",
                "consider",
                "how",
                "much",
                "we",
                "be",
                "able",
                "to",
                "fit",
                "into",
                "the",
                "time",
                "proceed",
                "it",
                "but",
                "still",
                "pretty",
                "ridiculous",
                "."
            ],
            [
                "after",
                "morning",
                "work",
                ",",
                "teach",
                "at",
                "the",
                "school",
                ",",
                "and",
                "what",
                "seem",
                "like",
                "a",
                "stream",
                "of",
                "visitor",
                "-lrb-",
                "seriously",
                ",",
                "do",
                "they",
                "time",
                "that",
                "?",
                ")"
            ],
            [
                "I",
                "take",
                "we",
                "neighbor",
                "to",
                "a",
                "clinic",
                "because",
                "after",
                "over",
                "a",
                "week",
                "of",
                "they",
                "eldest",
                "daughter",
                "have",
                "excruciating",
                "pain",
                "from",
                "a",
                "infected",
                "tooth",
                "I",
                "finally",
                "realize",
                "they",
                "be",
                "not",
                "take",
                "she",
                "because",
                "they",
                "do",
                "not",
                "have",
                "the",
                "5,000",
                "Tsh",
                "-LRB-",
                "about",
                "$",
                "3.50",
                ")",
                "to",
                "pay",
                "for",
                "the",
                "tooth",
                "to",
                "be",
                "remove",
                "and",
                "they",
                "be",
                "unsure",
                "how",
                "much",
                "bribe",
                "would",
                "be",
                "require",
                "at",
                "the",
                "government",
                "hospital",
                "."
            ]
        ],
        "label": "Sadness"
    },
    {
        "body_part_token_idx": 4,
        "sentence_id": "04bd2a94-dd9a-38ec-a0a6-f78649121d09",
        "tokens": [
            "Minho",
            "said",
            "rolling",
            "his",
            "eyes",
            "."
        ],
        "lemmatized_tokens": [
            "Minho",
            "say",
            "roll",
            "he",
            "eye",
            "."
        ],
        "preceding_context_tokens": [
            [
                "``",
                "I",
                "$",
                "you",
                "'re",
                "always",
                "asleep",
                ".",
                "''"
            ],
            [
                "Taemin",
                "finally",
                "managed",
                "to",
                "say",
                ",",
                "and",
                "the",
                "other",
                "boy",
                "rolled",
                "his",
                "eyes",
                "before",
                ",",
                "in",
                "a",
                "swift",
                "movement",
                ",",
                "shoving",
                "the",
                "papers",
                "off",
                "Taemin",
                "'s",
                "desk",
                "and",
                "have",
                "them",
                "flutter",
                "to",
                "the",
                "ground",
                "."
            ],
            [
                "``",
                "I",
                "do",
                "n't",
                "need",
                "your",
                "notes",
                ".",
                "''"
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "``",
                "I",
                "$",
                "you",
                "be",
                "always",
                "asleep",
                ".",
                "''"
            ],
            [
                "Taemin",
                "finally",
                "manage",
                "to",
                "say",
                ",",
                "and",
                "the",
                "other",
                "boy",
                "roll",
                "he",
                "eye",
                "before",
                ",",
                "in",
                "a",
                "swift",
                "movement",
                ",",
                "shove",
                "the",
                "papers",
                "off",
                "Taemin",
                "'s",
                "desk",
                "and",
                "have",
                "they",
                "flutter",
                "to",
                "the",
                "ground",
                "."
            ],
            [
                "``",
                "I",
                "do",
                "not",
                "need",
                "you",
                "note",
                ".",
                "''"
            ]
        ],
        "label": "Disgust"
    },
    {
        "body_part_token_idx": 9,
        "sentence_id": "b465eeed-e48b-350a-97e0-9244abdaa0f5",
        "tokens": [
            "I",
            "asked",
            "-LRB-",
            "with",
            "a",
            "pleading",
            "look",
            "in",
            "my",
            "eyes",
            ")",
            ",",
            "``",
            "can",
            "I",
            "leave",
            "the",
            "apple",
            "store",
            "?",
            "''"
        ],
        "lemmatized_tokens": [
            "I",
            "ask",
            "-LRB-",
            "with",
            "a",
            "plead",
            "look",
            "in",
            "my",
            "eye",
            ")",
            ",",
            "``",
            "can",
            "I",
            "leave",
            "the",
            "apple",
            "store",
            "?",
            "''"
        ],
        "preceding_context_tokens": [
            [
                "So",
                "the",
                "Genius",
                "says",
                "that",
                "he",
                "can",
                "still",
                "see",
                "my",
                "hard",
                "drive",
                "which",
                "is",
                "great",
                "news",
                "and",
                "could",
                "try",
                "to",
                "back",
                "it",
                "up",
                "onto",
                "an",
                "external",
                "hard",
                "drive",
                "for",
                "me",
                "if",
                "I",
                "would",
                "want",
                "to",
                "do",
                "that",
                "."
            ],
            [
                "I",
                "quickly",
                "agree",
                "because",
                "the",
                "thought",
                "of",
                "losing",
                "all",
                "those",
                "pictures",
                "is",
                "something",
                "I",
                "had",
                "n't",
                "come",
                "to",
                "terms",
                "with",
                "yet",
                "."
            ],
            [
                "So",
                "he",
                "begins",
                "that",
                "process",
                "and",
                "tells",
                "me",
                "it",
                "could",
                "take",
                "a",
                "while",
                "and",
                "that",
                "I",
                "could",
                "play",
                "around",
                "the",
                "store",
                "if",
                "I",
                "wanted",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "so",
                "the",
                "genius",
                "say",
                "that",
                "he",
                "can",
                "still",
                "see",
                "my",
                "hard",
                "drive",
                "which",
                "be",
                "great",
                "news",
                "and",
                "could",
                "try",
                "to",
                "back",
                "it",
                "up",
                "onto",
                "a",
                "external",
                "hard",
                "drive",
                "for",
                "I",
                "if",
                "I",
                "would",
                "want",
                "to",
                "do",
                "that",
                "."
            ],
            [
                "I",
                "quickly",
                "agree",
                "because",
                "the",
                "thought",
                "of",
                "lose",
                "all",
                "those",
                "picture",
                "be",
                "something",
                "I",
                "have",
                "not",
                "come",
                "to",
                "term",
                "with",
                "yet",
                "."
            ],
            [
                "so",
                "he",
                "begin",
                "that",
                "process",
                "and",
                "tell",
                "I",
                "it",
                "could",
                "take",
                "a",
                "while",
                "and",
                "that",
                "I",
                "could",
                "play",
                "around",
                "the",
                "store",
                "if",
                "I",
                "want",
                "."
            ]
        ],
        "label": "Fear"
    },
    {
        "body_part_token_idx": 21,
        "sentence_id": "aa4624b6-b45d-3dc9-8b3a-43ed8bda5a87",
        "tokens": [
            "He",
            "said",
            "he",
            "has",
            "no",
            "idea",
            "what",
            "he",
            "first",
            "said",
            "to",
            "her",
            ",",
            "but",
            "it",
            "must",
            "'ve",
            "been",
            "rambling",
            "because",
            "his",
            "heart",
            "was",
            "shaking",
            "and",
            "it",
            "was",
            "exillerating",
            "."
        ],
        "lemmatized_tokens": [
            "he",
            "say",
            "he",
            "have",
            "no",
            "idea",
            "what",
            "he",
            "first",
            "say",
            "to",
            "she",
            ",",
            "but",
            "it",
            "must",
            "have",
            "be",
            "ramble",
            "because",
            "he",
            "heart",
            "be",
            "shake",
            "and",
            "it",
            "be",
            "exillerate",
            "."
        ],
        "preceding_context_tokens": [
            [
                "They",
                "were",
                "in",
                "the",
                "same",
                "class",
                "at",
                "the",
                "Art",
                "Institute",
                "of",
                "Chicago",
                "and",
                "the",
                "first",
                "time",
                "they",
                "met",
                ",",
                "she",
                "said",
                ",",
                "he",
                "looked",
                "like",
                "a",
                "giant",
                "bright",
                "smiling",
                "lion",
                "ready",
                "to",
                "lick",
                "her",
                "!"
            ],
            [
                "With",
                "his",
                "little",
                "orange",
                "freckles",
                "and",
                "light",
                "red",
                "hair",
                ",",
                "I",
                "can",
                "totally",
                "imagine",
                "that",
                "'s",
                "what",
                "it",
                "must",
                "'ve",
                "felt",
                "like",
                "."
            ],
            [
                "It",
                "was",
                "just",
                "Louisa",
                "and",
                "me",
                "first",
                "and",
                "then",
                "after",
                "that",
                "I",
                "went",
                "to",
                "get",
                "Dan",
                "to",
                "ask",
                "him",
                "the",
                "same",
                "thing",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "they",
                "be",
                "in",
                "the",
                "same",
                "class",
                "at",
                "the",
                "Art",
                "Institute",
                "of",
                "Chicago",
                "and",
                "the",
                "first",
                "time",
                "they",
                "meet",
                ",",
                "she",
                "say",
                ",",
                "he",
                "look",
                "like",
                "a",
                "giant",
                "bright",
                "smile",
                "lion",
                "ready",
                "to",
                "lick",
                "she",
                "!"
            ],
            [
                "with",
                "he",
                "little",
                "orange",
                "freckle",
                "and",
                "light",
                "red",
                "hair",
                ",",
                "I",
                "can",
                "totally",
                "imagine",
                "that",
                "be",
                "what",
                "it",
                "must",
                "have",
                "feel",
                "like",
                "."
            ],
            [
                "it",
                "be",
                "just",
                "Louisa",
                "and",
                "I",
                "first",
                "and",
                "then",
                "after",
                "that",
                "I",
                "go",
                "to",
                "get",
                "Dan",
                "to",
                "ask",
                "he",
                "the",
                "same",
                "thing",
                "."
            ]
        ],
        "label": "Surprise"
    },
    {
        "body_part_token_idx": 11,
        "sentence_id": "ac9c95be-0ebf-3048-9af9-410898b29b43",
        "tokens": [
            "Just",
            "what",
            "I",
            "needed",
            "now",
            ",",
            "I",
            "thought",
            ",",
            "rolling",
            "my",
            "eyes",
            "in",
            "exasperation",
            "."
        ],
        "lemmatized_tokens": [
            "just",
            "what",
            "I",
            "need",
            "now",
            ",",
            "I",
            "think",
            ",",
            "roll",
            "my",
            "eye",
            "in",
            "exasperation",
            "."
        ],
        "preceding_context_tokens": [
            [
                "``",
                "I",
                "have",
                "reasons",
                "for",
                "my",
                "decision",
                ".",
                "''"
            ],
            [
                "``",
                "Reasons",
                "?",
                "''"
            ],
            [
                "Great",
                ",",
                "he",
                "was",
                "going",
                "to",
                "be",
                "stubborn",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "``",
                "I",
                "have",
                "reason",
                "for",
                "my",
                "decision",
                ".",
                "''"
            ],
            [
                "``",
                "reason",
                "?",
                "''"
            ],
            [
                "Great",
                ",",
                "he",
                "be",
                "go",
                "to",
                "be",
                "stubborn",
                "."
            ]
        ],
        "label": "Disgust"
    },
    {
        "body_part_token_idx": 10,
        "sentence_id": "5368ed1d-0d80-3505-a7b4-17366023c16f",
        "tokens": [
            "Isaiah",
            "was",
            "flushed",
            "with",
            "life",
            "and",
            "kosher",
            "beer",
            ",",
            "his",
            "eyes",
            "were",
            "shining",
            "."
        ],
        "lemmatized_tokens": [
            "Isaiah",
            "be",
            "flush",
            "with",
            "life",
            "and",
            "kosher",
            "beer",
            ",",
            "he",
            "eye",
            "be",
            "shine",
            "."
        ],
        "preceding_context_tokens": [
            [
                "``",
                "Tell",
                "me",
                "about",
                "him",
                "."
            ],
            [
                "Tell",
                "me",
                "about",
                "Isaiah",
                "Elian",
                "Yadin",
                ".",
                "''"
            ],
            [
                "David",
                "looked",
                "at",
                "the",
                "photo",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "``",
                "tell",
                "I",
                "about",
                "he",
                "."
            ],
            [
                "tell",
                "I",
                "about",
                "Isaiah",
                "Elian",
                "Yadin",
                ".",
                "''"
            ],
            [
                "David",
                "look",
                "at",
                "the",
                "photo",
                "."
            ]
        ],
        "label": "Joy"
    },
    {
        "body_part_token_idx": 2,
        "sentence_id": "3173d414-03ea-3b80-8d01-78061acad8ef",
        "tokens": [
            "Letting",
            "his",
            "hand",
            "drop",
            "back",
            "into",
            "his",
            "lap",
            ",",
            "he",
            "allowed",
            "his",
            "gaze",
            "to",
            "drift",
            "down",
            ",",
            "memorizing",
            "every",
            "detail",
            "of",
            "the",
            "long",
            ",",
            "thick",
            "shaft",
            "in",
            "front",
            "of",
            "him",
            "."
        ],
        "lemmatized_tokens": [
            "let",
            "he",
            "hand",
            "drop",
            "back",
            "into",
            "he",
            "lap",
            ",",
            "he",
            "allow",
            "he",
            "gaze",
            "to",
            "drift",
            "down",
            ",",
            "memorize",
            "every",
            "detail",
            "of",
            "the",
            "long",
            ",",
            "thick",
            "shaft",
            "in",
            "front",
            "of",
            "he",
            "."
        ],
        "preceding_context_tokens": [
            [
                "He",
                "blinked",
                "slowly",
                "and",
                "swallowed",
                "thickly",
                "as",
                "a",
                "hint",
                "of",
                "a",
                "smile",
                "ghosted",
                "across",
                "his",
                "face",
                "."
            ],
            [
                "Despite",
                "the",
                "way",
                "they",
                "stood",
                "out",
                ",",
                "in",
                "his",
                "opinion",
                ",",
                "they",
                "did",
                "n't",
                "detract",
                "from",
                "his",
                "overall",
                "beauty",
                "."
            ],
            [
                "In",
                "fact",
                ",",
                "he",
                "found",
                "them",
                "oddly",
                "striking",
                ",",
                "and",
                "they",
                "seemed",
                "to",
                "suit",
                "him",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "he",
                "blink",
                "slowly",
                "and",
                "swallow",
                "thickly",
                "as",
                "a",
                "hint",
                "of",
                "a",
                "smile",
                "ghost",
                "across",
                "he",
                "face",
                "."
            ],
            [
                "despite",
                "the",
                "way",
                "they",
                "stand",
                "out",
                ",",
                "in",
                "he",
                "opinion",
                ",",
                "they",
                "do",
                "not",
                "detract",
                "from",
                "he",
                "overall",
                "beauty",
                "."
            ],
            [
                "in",
                "fact",
                ",",
                "he",
                "find",
                "they",
                "oddly",
                "striking",
                ",",
                "and",
                "they",
                "seem",
                "to",
                "suit",
                "he",
                "."
            ]
        ],
        "label": "Surprise"
    },
    {
        "body_part_token_idx": 7,
        "sentence_id": "f70c66fe-200f-3766-9c19-9e2fa9e933f5",
        "tokens": [
            "Laura",
            "resisted",
            "the",
            "urge",
            "to",
            "roll",
            "her",
            "eyes",
            "."
        ],
        "lemmatized_tokens": [
            "Laura",
            "resist",
            "the",
            "urge",
            "to",
            "roll",
            "she",
            "eye",
            "."
        ],
        "preceding_context_tokens": [
            [
                "Do",
                "n't",
                "think",
                "they",
                "'re",
                "done",
                "yet.",
                "He",
                "grumbled",
                "just",
                "loud",
                "enough",
                "for",
                "them",
                "to",
                "hear",
                "."
            ],
            [
                "His",
                "hand",
                "reached",
                "for",
                "her",
                "back",
                "again",
                ",",
                "this",
                "time",
                "sliding",
                "subtly",
                "under",
                "her",
                "jacket",
                ",",
                "thumb",
                "stroking",
                "her",
                "skin",
                "reassuringly",
                "through",
                "thin",
                "layers",
                "of",
                "fabric.Lee",
                "'s",
                "bright",
                "grin",
                "refused",
                "to",
                "dim",
                ",",
                "despite",
                "the",
                "newly",
                "impatient",
                "look",
                "in",
                "his",
                "eyes",
                "."
            ],
            [
                "Dad",
                ",",
                "Racetrack",
                "found",
                "a",
                "computer",
                "in",
                "a",
                "military",
                "bunker.",
                "He",
                "explained",
                "slowly",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "do",
                "not",
                "think",
                "they",
                "be",
                "do",
                "yet.",
                "he",
                "grumble",
                "just",
                "loud",
                "enough",
                "for",
                "they",
                "to",
                "hear",
                "."
            ],
            [
                "he",
                "hand",
                "reach",
                "for",
                "she",
                "back",
                "again",
                ",",
                "this",
                "time",
                "slide",
                "subtly",
                "under",
                "she",
                "jacket",
                ",",
                "thumb",
                "stroke",
                "she",
                "skin",
                "reassuringly",
                "through",
                "thin",
                "layer",
                "of",
                "fabric.lee",
                "'s",
                "bright",
                "grin",
                "refuse",
                "to",
                "dim",
                ",",
                "despite",
                "the",
                "newly",
                "impatient",
                "look",
                "in",
                "he",
                "eye",
                "."
            ],
            [
                "Dad",
                ",",
                "racetrack",
                "find",
                "a",
                "computer",
                "in",
                "a",
                "military",
                "bunker.",
                "he",
                "explain",
                "slowly",
                "."
            ]
        ],
        "label": "Disgust"
    },
    {
        "body_part_token_idx": 12,
        "sentence_id": "9fffa58f-be32-3cbc-bb72-07df5d76a9c7",
        "tokens": [
            "I",
            "stood",
            "in",
            "the",
            "back",
            "and",
            "flipped",
            "through",
            "a",
            "book",
            ",",
            "my",
            "forehead",
            "deeply",
            "furrowed",
            "as",
            "though",
            "I",
            "was",
            "seriously",
            "seeking",
            "answers",
            "to",
            "the",
            "universe",
            "."
        ],
        "lemmatized_tokens": [
            "I",
            "stand",
            "in",
            "the",
            "back",
            "and",
            "flip",
            "through",
            "a",
            "book",
            ",",
            "my",
            "forehead",
            "deeply",
            "furrow",
            "as",
            "though",
            "I",
            "be",
            "seriously",
            "seek",
            "answer",
            "to",
            "the",
            "universe",
            "."
        ],
        "preceding_context_tokens": [
            [
                "While",
                "getting",
                "a",
                "book",
                "in",
                "the",
                "back",
                "of",
                "the",
                "room",
                ",",
                "I",
                "passed",
                "the",
                "area",
                "where",
                "the",
                "trench",
                "coats",
                "were",
                "hanging",
                "on",
                "hooks",
                "."
            ],
            [
                "The",
                "area",
                "resembled",
                "a",
                "long",
                "walk",
                "-",
                "in",
                "closet",
                "."
            ],
            [
                "Once",
                "in",
                "that",
                "area",
                ",",
                "you",
                "could",
                "not",
                "see",
                "the",
                "classroom",
                "--",
                "and",
                "the",
                "classroom",
                ",",
                "and",
                "more",
                "importantly",
                ",",
                "the",
                "teacher",
                ",",
                "could",
                "not",
                "see",
                "you",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "while",
                "get",
                "a",
                "book",
                "in",
                "the",
                "back",
                "of",
                "the",
                "room",
                ",",
                "I",
                "pass",
                "the",
                "area",
                "where",
                "the",
                "trench",
                "coat",
                "be",
                "hang",
                "on",
                "hook",
                "."
            ],
            [
                "the",
                "area",
                "resemble",
                "a",
                "long",
                "walk",
                "-",
                "in",
                "closet",
                "."
            ],
            [
                "once",
                "in",
                "that",
                "area",
                ",",
                "you",
                "could",
                "not",
                "see",
                "the",
                "classroom",
                "--",
                "and",
                "the",
                "classroom",
                ",",
                "and",
                "more",
                "importantly",
                ",",
                "the",
                "teacher",
                ",",
                "could",
                "not",
                "see",
                "you",
                "."
            ]
        ],
        "label": "Fear"
    },
    {
        "body_part_token_idx": 12,
        "sentence_id": "30174966-aab4-34d9-a042-ccd64fcdb2b3",
        "tokens": [
            "I",
            "can",
            "assure",
            "you",
            "I",
            "had",
            "a",
            "huge",
            "frown",
            "sitting",
            "on",
            "my",
            "face",
            "the",
            "entire",
            "time.The",
            "bosses",
            "were",
            "easy",
            ",",
            "albeit",
            "I",
            "struggled",
            "with",
            "Mercedes",
            "against",
            "the",
            "Cauldron",
            "because",
            "apparently",
            "she",
            "'s",
            "a",
            "closet",
            "fan",
            "of",
            "slip",
            "'n'",
            "slide",
            "or",
            "something",
            "."
        ],
        "lemmatized_tokens": [
            "I",
            "can",
            "assure",
            "you",
            "I",
            "have",
            "a",
            "huge",
            "frown",
            "sit",
            "on",
            "my",
            "face",
            "the",
            "entire",
            "time.the",
            "boss",
            "be",
            "easy",
            ",",
            "albeit",
            "I",
            "struggle",
            "with",
            "Mercedes",
            "against",
            "the",
            "Cauldron",
            "because",
            "apparently",
            "she",
            "be",
            "a",
            "closet",
            "fan",
            "of",
            "slip",
            "'n'",
            "slide",
            "or",
            "something",
            "."
        ],
        "preceding_context_tokens": [
            [
                "That",
                ",",
                "and",
                "I",
                "'d",
                "feel",
                "a",
                "little",
                "dread",
                "if",
                "I",
                "were",
                "to",
                "play",
                "the",
                "good",
                "ending",
                "first",
                "and",
                "then",
                "play",
                "to",
                "see",
                "everyone",
                "get",
                "slaughtered.I",
                "have",
                "to",
                "say",
                "I",
                "felt",
                "the",
                "worst",
                "seeing",
                "Mercedes",
                "and",
                "Ingway",
                "'s",
                "scene",
                "together",
                "in",
                "the",
                "bad",
                "ending",
                ",",
                "this",
                "was",
                "easily",
                "the",
                "most",
                "dramatic",
                "out",
                "of",
                "the",
                "false",
                "-",
                "ending",
                "scenes",
                "."
            ],
            [
                "Second",
                "easily",
                "goes",
                "to",
                "Oswald",
                "'s",
                "bad",
                "ending",
                "against",
                "Onyx",
                "."
            ],
            [
                "I",
                "never",
                "did",
                "like",
                "that",
                "guy",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "that",
                ",",
                "and",
                "I",
                "would",
                "feel",
                "a",
                "little",
                "dread",
                "if",
                "I",
                "be",
                "to",
                "play",
                "the",
                "good",
                "ending",
                "first",
                "and",
                "then",
                "play",
                "to",
                "see",
                "everyone",
                "get",
                "slaughtered.I",
                "have",
                "to",
                "say",
                "I",
                "feel",
                "the",
                "worst",
                "see",
                "Mercedes",
                "and",
                "Ingway",
                "'s",
                "scene",
                "together",
                "in",
                "the",
                "bad",
                "ending",
                ",",
                "this",
                "be",
                "easily",
                "the",
                "most",
                "dramatic",
                "out",
                "of",
                "the",
                "false",
                "-",
                "end",
                "scene",
                "."
            ],
            [
                "second",
                "easily",
                "go",
                "to",
                "Oswald",
                "'s",
                "bad",
                "end",
                "against",
                "Onyx",
                "."
            ],
            [
                "I",
                "never",
                "do",
                "like",
                "that",
                "guy",
                "."
            ]
        ],
        "label": "Disgust"
    },
    {
        "body_part_token_idx": 11,
        "sentence_id": "d2a02464-ccef-30f4-90df-3584955b27f5",
        "tokens": [
            "Dan",
            "Dan",
            "ca",
            "n't",
            "help",
            "the",
            "shiver",
            "that",
            "runs",
            "down",
            "his",
            "spine",
            "at",
            "the",
            "whispered",
            "words",
            "."
        ],
        "lemmatized_tokens": [
            "Dan",
            "Dan",
            "can",
            "not",
            "help",
            "the",
            "shiver",
            "that",
            "run",
            "down",
            "he",
            "spine",
            "at",
            "the",
            "whisper",
            "word",
            "."
        ],
        "preceding_context_tokens": [
            [
                "He",
                "leans",
                "in",
                "so",
                "close",
                "that",
                "his",
                "breath",
                "tickles",
                "Dan",
                "'s",
                "ear",
                "."
            ],
            [
                "``",
                "Just",
                "you",
                "wait",
                ".",
                "''"
            ],
            [
                "He",
                "then",
                "turns",
                "back",
                "to",
                "the",
                "counter",
                ",",
                "and",
                "matter",
                "-",
                "of",
                "-",
                "factly",
                "dishes",
                "up",
                "his",
                "soup",
                ",",
                "carrying",
                "it",
                "to",
                "the",
                "table",
                "and",
                "raising",
                "an",
                "eyebrow",
                "at",
                "Dan",
                "as",
                "he",
                "passes",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "he",
                "lean",
                "in",
                "so",
                "close",
                "that",
                "he",
                "breath",
                "tickle",
                "Dan",
                "'s",
                "ear",
                "."
            ],
            [
                "``",
                "just",
                "you",
                "wait",
                ".",
                "''"
            ],
            [
                "he",
                "then",
                "turn",
                "back",
                "to",
                "the",
                "counter",
                ",",
                "and",
                "matter",
                "-",
                "of",
                "-",
                "factly",
                "dish",
                "up",
                "he",
                "soup",
                ",",
                "carry",
                "it",
                "to",
                "the",
                "table",
                "and",
                "raise",
                "a",
                "eyebrow",
                "at",
                "Dan",
                "as",
                "he",
                "pass",
                "."
            ]
        ],
        "label": "Fear"
    },
    {
        "body_part_token_idx": 9,
        "sentence_id": "8cd44a96-a162-3a86-80fc-033eac91f029",
        "tokens": [
            "\\",
            "Names",
            ",",
            "Do",
            "n't",
            "Shoot",
            "Neal",
            "squeezed",
            "his",
            "eyes",
            "shut",
            ",",
            "took",
            "a",
            "deep",
            "breath",
            ",",
            "swallowed",
            ",",
            "and",
            "pushed",
            "open",
            "the",
            "door",
            "to",
            "the",
            "woman",
            "'s",
            "bedroom",
            ",",
            "raising",
            "both",
            "hands",
            "as",
            "he",
            "did",
            "so",
            "."
        ],
        "lemmatized_tokens": [
            "\\",
            "name",
            ",",
            "do",
            "not",
            "shoot",
            "Neal",
            "squeeze",
            "he",
            "eye",
            "shut",
            ",",
            "take",
            "a",
            "deep",
            "breath",
            ",",
            "swallow",
            ",",
            "and",
            "push",
            "open",
            "the",
            "door",
            "to",
            "the",
            "woman",
            "'s",
            "bedroom",
            ",",
            "raise",
            "both",
            "hand",
            "as",
            "he",
            "do",
            "so",
            "."
        ],
        "preceding_context_tokens": [
            [
                "Not",
                "mine",
                "."
            ],
            [
                "Feedback",
                ":",
                "Reviews",
                "and",
                "flames",
                "are",
                "welcome",
                "."
            ],
            [
                "-LRB-",
                "They",
                "make",
                "it",
                "look",
                "like",
                "I",
                "'m",
                "writing",
                "fast",
                ")",
                "Notes",
                ":",
                "Just",
                "a",
                "bunch",
                "of",
                "drabbly",
                "things",
                "that",
                "were",
                "n't",
                "quite",
                "long",
                "enough",
                "to",
                "post",
                "as",
                "stories",
                "themselves",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "not",
                "mine",
                "."
            ],
            [
                "feedback",
                ":",
                "review",
                "and",
                "flame",
                "be",
                "welcome",
                "."
            ],
            [
                "-lrb-",
                "they",
                "make",
                "it",
                "look",
                "like",
                "I",
                "be",
                "write",
                "fast",
                ")",
                "Notes",
                ":",
                "just",
                "a",
                "bunch",
                "of",
                "drabbly",
                "thing",
                "that",
                "be",
                "not",
                "quite",
                "long",
                "enough",
                "to",
                "post",
                "as",
                "story",
                "themselves",
                "."
            ]
        ],
        "label": "Fear"
    },
    {
        "body_part_token_idx": 7,
        "sentence_id": "e5161100-c374-3f41-872d-08236158b950",
        "tokens": [
            "Kevin",
            "kept",
            "his",
            "gaze",
            "fixated",
            "on",
            "his",
            "feet",
            "."
        ],
        "lemmatized_tokens": [
            "Kevin",
            "keep",
            "he",
            "gaze",
            "fixate",
            "on",
            "he",
            "foot",
            "."
        ],
        "preceding_context_tokens": [
            [
                "He",
                "did",
                "n't",
                "want",
                "things",
                "between",
                "them",
                "to",
                "spiral",
                "down",
                "so",
                "bitterly",
                "."
            ],
            [
                "Eli",
                "walked",
                "over",
                "to",
                "Kevin",
                "."
            ],
            [
                "He",
                "placed",
                "his",
                "hand",
                "on",
                "Kevin",
                "'s",
                "shoulder",
                ",",
                "hoping",
                "to",
                "pacify",
                "him",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "he",
                "do",
                "not",
                "want",
                "thing",
                "between",
                "they",
                "to",
                "spiral",
                "down",
                "so",
                "bitterly",
                "."
            ],
            [
                "Eli",
                "walk",
                "over",
                "to",
                "Kevin",
                "."
            ],
            [
                "he",
                "place",
                "he",
                "hand",
                "on",
                "Kevin",
                "'s",
                "shoulder",
                ",",
                "hope",
                "to",
                "pacify",
                "he",
                "."
            ]
        ],
        "label": "Fear"
    },
    {
        "body_part_token_idx": 1,
        "sentence_id": "be1a4604-335d-3e53-8562-1a632662f469",
        "tokens": [
            "His",
            "eyes",
            "widened",
            ",",
            "as",
            "he",
            "could",
            "do",
            "nothing",
            "but",
            "watch",
            "as",
            "his",
            "weapon",
            "slowly",
            "sailed",
            "next",
            "to",
            "Chelly",
            "."
        ],
        "lemmatized_tokens": [
            "he",
            "eye",
            "widen",
            ",",
            "as",
            "he",
            "could",
            "do",
            "nothing",
            "but",
            "watch",
            "as",
            "he",
            "weapon",
            "slowly",
            "sail",
            "next",
            "to",
            "Chelly",
            "."
        ],
        "preceding_context_tokens": [
            [
                "He",
                "looked",
                "up",
                "."
            ],
            [
                "Chelly",
                "was",
                "moving",
                "her",
                "hand",
                "again",
                "."
            ],
            [
                "He",
                "felt",
                "something",
                "tug",
                "at",
                "his",
                "belt",
                ",",
                "and",
                "looking",
                "down",
                ",",
                "saw",
                "one",
                "of",
                "his",
                "sai",
                "being",
                "lifted",
                "into",
                "the",
                "air",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "he",
                "look",
                "up",
                "."
            ],
            [
                "Chelly",
                "be",
                "move",
                "she",
                "hand",
                "again",
                "."
            ],
            [
                "he",
                "feel",
                "something",
                "tug",
                "at",
                "he",
                "belt",
                ",",
                "and",
                "look",
                "down",
                ",",
                "see",
                "one",
                "of",
                "he",
                "sai",
                "be",
                "lift",
                "into",
                "the",
                "air",
                "."
            ]
        ],
        "label": "Surprise"
    },
    {
        "body_part_token_idx": 28,
        "sentence_id": "861043de-7e7f-35cd-9e05-2744ff34bde6",
        "tokens": [
            "Geez",
            ",",
            "and",
            "I",
            "'m",
            "having",
            "a",
            "hard",
            "enough",
            "time",
            "paying",
            "for",
            "my",
            "own",
            "wedding!Anyway",
            ",",
            "I",
            "checked",
            "flights",
            "later",
            "in",
            "the",
            "week",
            "only",
            "to",
            "almost",
            "gouge",
            "my",
            "eyes",
            "out",
            "when",
            "I",
            "saw",
            "how",
            "much",
            "flights",
            "were",
            "now",
            "going",
            "for",
            "."
        ],
        "lemmatized_tokens": [
            "Geez",
            ",",
            "and",
            "I",
            "be",
            "have",
            "a",
            "hard",
            "enough",
            "time",
            "pay",
            "for",
            "my",
            "own",
            "wedding!anyway",
            ",",
            "I",
            "check",
            "flight",
            "later",
            "in",
            "the",
            "week",
            "only",
            "to",
            "almost",
            "gouge",
            "my",
            "eye",
            "out",
            "when",
            "I",
            "see",
            "how",
            "much",
            "flight",
            "be",
            "now",
            "go",
            "for",
            "."
        ],
        "preceding_context_tokens": [
            [
                "Last",
                "I",
                "checked",
                ",",
                "it",
                "'s",
                "now",
                "August",
                "and",
                "somehow",
                "I",
                "had",
                "n't",
                "arranged",
                "all",
                "of",
                "my",
                "travel",
                "plans",
                "yet",
                "-",
                "what",
                "'s",
                "happening",
                "to",
                "me",
                "!!!"
            ],
            [
                "Last",
                "week",
                ",",
                "I",
                "checked",
                "the",
                "flights",
                "down",
                "there",
                "and",
                "they",
                "were",
                "a",
                "whopping",
                "$",
                "274",
                "each",
                "for",
                "a",
                "direct",
                "flight",
                "."
            ],
            [
                "Doing",
                "the",
                "math",
                "for",
                "flight",
                "and",
                "hotel",
                ",",
                "I",
                "was",
                "looking",
                "at",
                "a",
                "grand",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "last",
                "I",
                "check",
                ",",
                "it",
                "be",
                "now",
                "August",
                "and",
                "somehow",
                "I",
                "have",
                "not",
                "arrange",
                "all",
                "of",
                "my",
                "travel",
                "plan",
                "yet",
                "-",
                "what",
                "be",
                "happen",
                "to",
                "I",
                "!!!"
            ],
            [
                "last",
                "week",
                ",",
                "I",
                "check",
                "the",
                "flight",
                "down",
                "there",
                "and",
                "they",
                "be",
                "a",
                "whopping",
                "$",
                "274",
                "each",
                "for",
                "a",
                "direct",
                "flight",
                "."
            ],
            [
                "do",
                "the",
                "math",
                "for",
                "flight",
                "and",
                "hotel",
                ",",
                "I",
                "be",
                "look",
                "at",
                "a",
                "grand",
                "."
            ]
        ],
        "label": "Surprise"
    },
    {
        "body_part_token_idx": 9,
        "sentence_id": "64621895-bdb1-37ec-a6a5-83fd2d07f139",
        "tokens": [
            "The",
            "very",
            "thought",
            "put",
            "a",
            "bad",
            "taste",
            "into",
            "her",
            "mouth",
            "."
        ],
        "lemmatized_tokens": [
            "the",
            "very",
            "think",
            "put",
            "a",
            "bad",
            "taste",
            "into",
            "she",
            "mouth",
            "."
        ],
        "preceding_context_tokens": [
            [
                "At",
                "least",
                "Valtome",
                "had",
                "n't",
                "the",
                "nerve",
                "to",
                "ask",
                "her",
                "personally",
                ",",
                "though",
                "using",
                "his",
                "nephew",
                "was",
                "almost",
                "as",
                "bad",
                "."
            ],
            [
                "He",
                "was",
                "supposed",
                "to",
                "be",
                "a",
                "decent",
                "deputy",
                "commander",
                ";",
                "he",
                "was",
                "normal",
                ",",
                "relatively",
                "speaking",
                "."
            ],
            [
                "Too",
                "bad",
                "she",
                "would",
                "rather",
                "die",
                "than",
                "marry",
                "into",
                "that",
                "house",
                "or",
                "forge",
                "any",
                "relation",
                "whatsoever",
                "between",
                "herself",
                "and",
                "the",
                "duke",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "at",
                "least",
                "Valtome",
                "have",
                "not",
                "the",
                "nerve",
                "to",
                "ask",
                "she",
                "personally",
                ",",
                "though",
                "use",
                "he",
                "nephew",
                "be",
                "almost",
                "as",
                "bad",
                "."
            ],
            [
                "he",
                "be",
                "suppose",
                "to",
                "be",
                "a",
                "decent",
                "deputy",
                "commander",
                ";",
                "he",
                "be",
                "normal",
                ",",
                "relatively",
                "speak",
                "."
            ],
            [
                "too",
                "bad",
                "she",
                "would",
                "rather",
                "die",
                "than",
                "marry",
                "into",
                "that",
                "house",
                "or",
                "forge",
                "any",
                "relation",
                "whatsoever",
                "between",
                "herself",
                "and",
                "the",
                "duke",
                "."
            ]
        ],
        "label": "Disgust"
    },
    {
        "body_part_token_idx": 10,
        "sentence_id": "7fb7aae9-65c4-34c1-84db-0b657215c614",
        "tokens": [
            "She",
            "herself",
            "felt",
            "protest",
            "rising",
            "as",
            "buzzing",
            "electricity",
            "in",
            "her",
            "throat",
            ",",
            "a",
            "strange",
            "ringing",
            "that",
            "padded",
            "forth",
            "her",
            "attempt",
            "at",
            "words",
            ",",
            "which",
            "emanated",
            "as",
            "a",
            "weak",
            "whimper",
            "."
        ],
        "lemmatized_tokens": [
            "she",
            "herself",
            "feel",
            "protest",
            "rise",
            "as",
            "buzz",
            "electricity",
            "in",
            "she",
            "throat",
            ",",
            "a",
            "strange",
            "ring",
            "that",
            "padded",
            "forth",
            "she",
            "attempt",
            "at",
            "word",
            ",",
            "which",
            "emanate",
            "as",
            "a",
            "weak",
            "whimper",
            "."
        ],
        "preceding_context_tokens": [
            [
                "Jeff",
                "began",
                "fingering",
                "pensively",
                "at",
                "the",
                "leather",
                "-",
                "bound",
                "book",
                "with",
                "the",
                "gold",
                "foil",
                "cursive",
                "of",
                "the",
                "restaurant",
                "name",
                "engraved",
                ",",
                "tracing",
                "softly",
                "the",
                "fleshy",
                "roundness",
                "of",
                "his",
                "index",
                "finger",
                "around",
                "the",
                "writing",
                "."
            ],
            [
                "Julia",
                "watched",
                "his",
                "lazy",
                "motions",
                "with",
                "a",
                "tenured",
                "interest",
                ",",
                "her",
                "eyes",
                "dancing",
                "over",
                "his",
                "animated",
                "hand",
                "before",
                "her",
                "gaze",
                "lifted",
                "to",
                "his",
                "."
            ],
            [
                "With",
                "an",
                "ounce",
                "of",
                "mental",
                "permission",
                ",",
                "he",
                "snapped",
                "up",
                "the",
                "checkbook",
                ",",
                "slipping",
                "precariously",
                "a",
                "plastic",
                "card",
                "she",
                "had",
                "n't",
                "known",
                "he",
                "possessed",
                "without",
                "a",
                "word",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "Jeff",
                "begin",
                "finger",
                "pensively",
                "at",
                "the",
                "leather",
                "-",
                "bind",
                "book",
                "with",
                "the",
                "gold",
                "foil",
                "cursive",
                "of",
                "the",
                "restaurant",
                "name",
                "engrave",
                ",",
                "trace",
                "softly",
                "the",
                "fleshy",
                "roundness",
                "of",
                "he",
                "index",
                "finger",
                "around",
                "the",
                "writing",
                "."
            ],
            [
                "Julia",
                "watch",
                "he",
                "lazy",
                "motion",
                "with",
                "a",
                "tenured",
                "interest",
                ",",
                "she",
                "eye",
                "dance",
                "over",
                "he",
                "animated",
                "hand",
                "before",
                "she",
                "gaze",
                "lift",
                "to",
                "he",
                "."
            ],
            [
                "with",
                "a",
                "ounce",
                "of",
                "mental",
                "permission",
                ",",
                "he",
                "snap",
                "up",
                "the",
                "checkbook",
                ",",
                "slip",
                "precariously",
                "a",
                "plastic",
                "card",
                "she",
                "have",
                "not",
                "know",
                "he",
                "possess",
                "without",
                "a",
                "word",
                "."
            ]
        ],
        "label": "Fear"
    },
    {
        "body_part_token_idx": 39,
        "sentence_id": "1d93ebee-c7ca-38e1-aef8-317f685dc504",
        "tokens": [
            "-",
            "I",
            "did",
            "n't",
            "want",
            "to",
            "bother",
            "you",
            "so",
            "I",
            "never",
            "insisted",
            "on",
            "speaking",
            "to",
            "you",
            "when",
            "you",
            "were",
            "busy",
            "since",
            "I",
            "know",
            "how",
            "much",
            "work",
            "means",
            "to",
            "you",
            "-",
            "''",
            "``",
            "Grimmjow",
            ",",
            "''",
            "Ulquiorra",
            "interrupted",
            ",",
            "his",
            "cheeks",
            "a",
            "slight",
            "pink",
            "."
        ],
        "lemmatized_tokens": [
            "-",
            "I",
            "do",
            "not",
            "want",
            "to",
            "bother",
            "you",
            "so",
            "I",
            "never",
            "insist",
            "on",
            "speak",
            "to",
            "you",
            "when",
            "you",
            "be",
            "busy",
            "since",
            "I",
            "know",
            "how",
            "much",
            "work",
            "mean",
            "to",
            "you",
            "-",
            "''",
            "``",
            "Grimmjow",
            ",",
            "''",
            "Ulquiorra",
            "interrupt",
            ",",
            "he",
            "cheek",
            "a",
            "slight",
            "pink",
            "."
        ],
        "preceding_context_tokens": [
            [
                "In",
                "addition",
                "to",
                "feeling",
                "foolish",
                ",",
                "Ulquiorra",
                "felt",
                "stupid",
                "."
            ],
            [
                "How",
                "could",
                "he",
                "have",
                "forgotten",
                "that",
                "he",
                "had",
                "told",
                "Neliel",
                "to",
                "give",
                "some",
                "excuse",
                "to",
                "Grimmjow",
                "should",
                "he",
                "ever",
                "call",
                "so",
                "that",
                "he",
                "did",
                "not",
                "have",
                "to",
                "deal",
                "with",
                "him",
                "?"
            ],
            [
                "Ulquiorra",
                "ought",
                "to",
                "have",
                "the",
                "word",
                "``",
                "Stupid",
                "''",
                "stamped",
                "across",
                "his",
                "forehead",
                ".",
                "''"
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "in",
                "addition",
                "to",
                "feel",
                "foolish",
                ",",
                "Ulquiorra",
                "feel",
                "stupid",
                "."
            ],
            [
                "how",
                "could",
                "he",
                "have",
                "forget",
                "that",
                "he",
                "have",
                "tell",
                "Neliel",
                "to",
                "give",
                "some",
                "excuse",
                "to",
                "Grimmjow",
                "should",
                "he",
                "ever",
                "call",
                "so",
                "that",
                "he",
                "do",
                "not",
                "have",
                "to",
                "deal",
                "with",
                "he",
                "?"
            ],
            [
                "Ulquiorra",
                "ought",
                "to",
                "have",
                "the",
                "word",
                "``",
                "stupid",
                "''",
                "stamp",
                "across",
                "he",
                "forehead",
                ".",
                "''"
            ]
        ],
        "label": "Surprise"
    },
    {
        "body_part_token_idx": 7,
        "sentence_id": "9136d546-ea32-3392-ad03-ad661300f3a6",
        "tokens": [
            "Until",
            "pain",
            "counterpoints",
            "the",
            "throb",
            "in",
            "her",
            "heart",
            "."
        ],
        "lemmatized_tokens": [
            "until",
            "pain",
            "counterpoint",
            "the",
            "throb",
            "in",
            "she",
            "heart",
            "."
        ],
        "preceding_context_tokens": [
            [
                "I",
                "just",
                "wanted",
                "to",
                "be",
                "near",
                "you.",
                "The",
                "last",
                "is",
                "a",
                "confession",
                ",",
                "and",
                "it",
                "'s",
                "the",
                "scariest",
                "thing",
                "she",
                "'s",
                "ever",
                "admitted",
                "."
            ],
            [
                "Her",
                "vision",
                "tunnels",
                ",",
                "the",
                "room",
                "expanding",
                ",",
                "corridor",
                "opening",
                "up",
                "into",
                "a",
                "sharp",
                "and",
                "distant",
                "spur",
                "."
            ],
            [
                "She",
                "thinks",
                "about",
                "running",
                ",",
                "sprinting",
                "until",
                "her",
                "muscles",
                "burn",
                ",",
                "until",
                "the",
                "acid",
                "makes",
                "her",
                "weak",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "I",
                "just",
                "want",
                "to",
                "be",
                "near",
                "you.",
                "the",
                "last",
                "be",
                "a",
                "confession",
                ",",
                "and",
                "it",
                "be",
                "the",
                "scariest",
                "thing",
                "she",
                "be",
                "ever",
                "admit",
                "."
            ],
            [
                "she",
                "vision",
                "tunnel",
                ",",
                "the",
                "room",
                "expand",
                ",",
                "corridor",
                "opening",
                "up",
                "into",
                "a",
                "sharp",
                "and",
                "distant",
                "spur",
                "."
            ],
            [
                "she",
                "think",
                "about",
                "running",
                ",",
                "sprinting",
                "until",
                "she",
                "muscle",
                "burn",
                ",",
                "until",
                "the",
                "acid",
                "make",
                "she",
                "weak",
                "."
            ]
        ],
        "label": "Fear"
    },
    {
        "body_part_token_idx": 14,
        "sentence_id": "b8b5de99-ec60-332c-ace5-eb1d0a1320fa",
        "tokens": [
            "You",
            "and",
            "I",
            "should",
            "follow",
            "her",
            "and",
            "keep",
            "an",
            "eye",
            "out.",
            "Koga",
            "hunched",
            "his",
            "shoulders",
            "and",
            "followed",
            "Kikyo.Inuyasha",
            "stayed",
            "near",
            "the",
            "wagon",
            "and",
            "looked",
            "northerly",
            "towards",
            "the",
            "plains",
            "."
        ],
        "lemmatized_tokens": [
            "you",
            "and",
            "I",
            "should",
            "follow",
            "she",
            "and",
            "keep",
            "a",
            "eye",
            "out.",
            "Koga",
            "hunch",
            "he",
            "shoulder",
            "and",
            "follow",
            "Kikyo.Inuyasha",
            "stay",
            "near",
            "the",
            "wagon",
            "and",
            "look",
            "northerly",
            "towards",
            "the",
            "plain",
            "."
        ],
        "preceding_context_tokens": [
            [
                "Let",
                "her",
                "be",
                ",",
                "Koga",
                "."
            ],
            [
                "It",
                "'s",
                "actually",
                "a",
                "good",
                "idea",
                "to",
                "gather",
                "medicinal",
                "plants",
                "."
            ],
            [
                "They",
                "may",
                "come",
                "in",
                "handy",
                "as",
                "we",
                "move",
                "through",
                "the",
                "mountains",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "let",
                "she",
                "be",
                ",",
                "Koga",
                "."
            ],
            [
                "it",
                "be",
                "actually",
                "a",
                "good",
                "idea",
                "to",
                "gather",
                "medicinal",
                "plant",
                "."
            ],
            [
                "they",
                "may",
                "come",
                "in",
                "handy",
                "as",
                "we",
                "move",
                "through",
                "the",
                "mountain",
                "."
            ]
        ],
        "label": "Anger"
    },
    {
        "body_part_token_idx": 10,
        "sentence_id": "cf8bbca0-cf0b-35d9-b088-8b78447cceb1",
        "tokens": [
            "He",
            "tried",
            "to",
            "stop",
            "part",
            "way",
            "but",
            "she",
            "shook",
            "her",
            "head",
            "."
        ],
        "lemmatized_tokens": [
            "he",
            "try",
            "to",
            "stop",
            "part",
            "way",
            "but",
            "she",
            "shake",
            "she",
            "head",
            "."
        ],
        "preceding_context_tokens": [
            [
                "Will",
                "was",
                "silent",
                "and",
                "still",
                "for",
                "a",
                "moment",
                "."
            ],
            [
                "James",
                "spoke",
                "finally",
                ",",
                "drawing",
                "his",
                "legs",
                "up",
                "to",
                "his",
                "chest",
                "closer",
                "."
            ],
            [
                "D",
                "-",
                "don",
                "'",
                "t",
                "stop.",
                "*",
                "*",
                "*",
                "She",
                "cried",
                "out",
                "in",
                "pain",
                "at",
                "first",
                ",",
                "though",
                "Jack",
                "tried",
                "to",
                "be",
                "gentle",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "will",
                "be",
                "silent",
                "and",
                "still",
                "for",
                "a",
                "moment",
                "."
            ],
            [
                "James",
                "speak",
                "finally",
                ",",
                "draw",
                "he",
                "leg",
                "up",
                "to",
                "he",
                "chest",
                "closer",
                "."
            ],
            [
                "d",
                "-",
                "don",
                "'",
                "t",
                "stop.",
                "*",
                "*",
                "*",
                "she",
                "cry",
                "out",
                "in",
                "pain",
                "at",
                "first",
                ",",
                "though",
                "Jack",
                "try",
                "to",
                "be",
                "gentle",
                "."
            ]
        ],
        "label": "Fear"
    },
    {
        "body_part_token_idx": 1,
        "sentence_id": "80d6108e-181c-3eb6-b198-71743d1bb4c1",
        "tokens": [
            "His",
            "cheeks",
            "were",
            "burning",
            "only",
            "from",
            "the",
            "slightest",
            "thought",
            "about",
            "what",
            "he",
            "saw",
            "today",
            "."
        ],
        "lemmatized_tokens": [
            "he",
            "cheek",
            "be",
            "burn",
            "only",
            "from",
            "the",
            "slightest",
            "thought",
            "about",
            "what",
            "he",
            "see",
            "today",
            "."
        ],
        "preceding_context_tokens": [
            [
                "He",
                "would",
                "pay",
                "twice",
                "and",
                "he",
                "did",
                "n't",
                "want",
                "to",
                "waste",
                "money",
                "for",
                "SUCH",
                "things.He",
                "watched",
                "Morinaga",
                "as",
                "he",
                "walked",
                "cheerfully",
                "to",
                "their",
                "destination",
                "."
            ],
            [
                "Souichi",
                "had",
                "called",
                "Kanako",
                "earlier",
                "to",
                "tell",
                "her",
                "that",
                "he",
                "would",
                "spend",
                "the",
                "night",
                "at",
                "Morinaga",
                "'s",
                "place",
                ",",
                "but",
                "he",
                "was",
                "now",
                "having",
                "serious",
                "doubts",
                "."
            ],
            [
                "He",
                "was",
                "scared",
                "of",
                "what",
                "was",
                "awaiting",
                "him",
                "when",
                "they",
                "came",
                "to",
                "their",
                "destination",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "he",
                "would",
                "pay",
                "twice",
                "and",
                "he",
                "do",
                "not",
                "want",
                "to",
                "waste",
                "money",
                "for",
                "SUCH",
                "things.He",
                "watch",
                "Morinaga",
                "as",
                "he",
                "walk",
                "cheerfully",
                "to",
                "they",
                "destination",
                "."
            ],
            [
                "Souichi",
                "have",
                "call",
                "Kanako",
                "earlier",
                "to",
                "tell",
                "she",
                "that",
                "he",
                "would",
                "spend",
                "the",
                "night",
                "at",
                "Morinaga",
                "'s",
                "place",
                ",",
                "but",
                "he",
                "be",
                "now",
                "have",
                "serious",
                "doubt",
                "."
            ],
            [
                "he",
                "be",
                "scared",
                "of",
                "what",
                "be",
                "await",
                "he",
                "when",
                "they",
                "come",
                "to",
                "they",
                "destination",
                "."
            ]
        ],
        "label": "Fear"
    },
    {
        "body_part_token_idx": 14,
        "sentence_id": "d07dca12-64a8-30db-8ba7-70d9fa30b6bd",
        "tokens": [
            "Finding",
            "her",
            "boring",
            ",",
            "Ridic",
            "leaned",
            "back",
            "in",
            "the",
            "wire",
            "seat",
            "and",
            "crossed",
            "his",
            "arms",
            "lightly",
            "while",
            "his",
            "right",
            "hand",
            "pushed",
            "the",
            "laminated",
            "menu",
            "away.",
            "Coca",
            "-",
            "Cola",
            ",",
            "he",
            "ordered",
            "."
        ],
        "lemmatized_tokens": [
            "find",
            "she",
            "boring",
            ",",
            "ridic",
            "lean",
            "back",
            "in",
            "the",
            "wire",
            "seat",
            "and",
            "cross",
            "he",
            "arm",
            "lightly",
            "while",
            "he",
            "right",
            "hand",
            "push",
            "the",
            "laminate",
            "menu",
            "away.",
            "Coca",
            "-",
            "Cola",
            ",",
            "he",
            "order",
            "."
        ],
        "preceding_context_tokens": [
            [
                "The",
                "man",
                "rolled",
                "his",
                "eyes",
                "behind",
                "his",
                "glasses.",
                "Hi",
                ",",
                "she",
                "said",
                "through",
                "an",
                "airy",
                "tone",
                "."
            ],
            [
                "I",
                "'m",
                "Trish",
                "."
            ],
            [
                "What",
                "can",
                "I",
                "get",
                "for",
                "you?",
                "As",
                "she",
                "spoke",
                "he",
                "noticed",
                "that",
                "she",
                "moved",
                "her",
                "head",
                ",",
                "like",
                "trying",
                "to",
                "find",
                "the",
                "perfect",
                "angle",
                "to",
                "look",
                "at",
                "him",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "the",
                "man",
                "roll",
                "he",
                "eye",
                "behind",
                "he",
                "glasses.",
                "hi",
                ",",
                "she",
                "say",
                "through",
                "a",
                "airy",
                "tone",
                "."
            ],
            [
                "I",
                "be",
                "Trish",
                "."
            ],
            [
                "what",
                "can",
                "I",
                "get",
                "for",
                "you?",
                "as",
                "she",
                "speak",
                "he",
                "notice",
                "that",
                "she",
                "move",
                "she",
                "head",
                ",",
                "like",
                "try",
                "to",
                "find",
                "the",
                "perfect",
                "angle",
                "to",
                "look",
                "at",
                "he",
                "."
            ]
        ],
        "label": "Disgust"
    },
    {
        "body_part_token_idx": 7,
        "sentence_id": "d81f1462-683d-3694-bb5d-cd676966def6",
        "tokens": [
            "To",
            "top",
            "it",
            "all",
            "off",
            ",",
            "my",
            "back",
            "started",
            "to",
            "sieze",
            "up",
            ",",
            "possibly",
            "due",
            "to",
            "compensation",
            "habits",
            "and",
            "stress",
            "worrying",
            "about",
            "the",
            "issue",
            "."
        ],
        "lemmatized_tokens": [
            "to",
            "top",
            "it",
            "all",
            "off",
            ",",
            "my",
            "back",
            "start",
            "to",
            "sieze",
            "up",
            ",",
            "possibly",
            "due",
            "to",
            "compensation",
            "habit",
            "and",
            "stress",
            "worry",
            "about",
            "the",
            "issue",
            "."
        ],
        "preceding_context_tokens": [
            [
                "We",
                "were",
                "driving",
                "to",
                "Niagara",
                "and",
                "had",
                "been",
                "on",
                "the",
                "road",
                "for",
                "a",
                "few",
                "hours",
                "when",
                "I",
                "started",
                "to",
                "feel",
                "pain",
                "shooting",
                "down",
                "my",
                "left",
                "hip",
                "."
            ],
            [
                "It",
                "HURT",
                "."
            ],
            [
                "Every",
                "time",
                "from",
                "then",
                "on",
                "that",
                "I",
                "had",
                "to",
                "remain",
                "seated",
                "in",
                "the",
                "same",
                "position",
                "for",
                "more",
                "than",
                "an",
                "hour",
                "or",
                "so",
                ",",
                "I",
                "ran",
                "the",
                "risk",
                "of",
                "pain",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "we",
                "be",
                "drive",
                "to",
                "Niagara",
                "and",
                "have",
                "be",
                "on",
                "the",
                "road",
                "for",
                "a",
                "few",
                "hour",
                "when",
                "I",
                "start",
                "to",
                "feel",
                "pain",
                "shoot",
                "down",
                "my",
                "left",
                "hip",
                "."
            ],
            [
                "it",
                "HURT",
                "."
            ],
            [
                "every",
                "time",
                "from",
                "then",
                "on",
                "that",
                "I",
                "have",
                "to",
                "remain",
                "seat",
                "in",
                "the",
                "same",
                "position",
                "for",
                "more",
                "than",
                "a",
                "hour",
                "or",
                "so",
                ",",
                "I",
                "run",
                "the",
                "risk",
                "of",
                "pain",
                "."
            ]
        ],
        "label": "Fear"
    },
    {
        "body_part_token_idx": 17,
        "sentence_id": "574e7d0b-f952-3453-81bd-38b95bcdbcee",
        "tokens": [
            "Staring",
            "down",
            "at",
            "the",
            "device",
            ",",
            "I",
            "felt",
            "this",
            "cold",
            "chill",
            "start",
            "at",
            "the",
            "base",
            "of",
            "my",
            "neck",
            "and",
            "spread",
            "throughout",
            "my",
            "body",
            "."
        ],
        "lemmatized_tokens": [
            "stare",
            "down",
            "at",
            "the",
            "device",
            ",",
            "I",
            "feel",
            "this",
            "cold",
            "chill",
            "start",
            "at",
            "the",
            "base",
            "of",
            "my",
            "neck",
            "and",
            "spread",
            "throughout",
            "my",
            "body",
            "."
        ],
        "preceding_context_tokens": [
            [
                "So",
                "much",
                "for",
                "Exercise",
                "2",
                "."
            ],
            [
                "How",
                "`",
                "bout",
                "1",
                "?"
            ],
            [
                "Borrowing",
                "the",
                "sentence",
                "from",
                "Caleb",
                "Carr",
                "'s",
                "The",
                "Italian",
                "Secretary",
                ":",
                "Looking",
                "down",
                ",",
                "both",
                "my",
                "friend",
                "and",
                "I",
                "saw",
                "the",
                "ominous",
                "form",
                "of",
                "a",
                "small",
                "homemade",
                "bomb",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "so",
                "much",
                "for",
                "Exercise",
                "2",
                "."
            ],
            [
                "how",
                "`",
                "bout",
                "1",
                "?"
            ],
            [
                "borrow",
                "the",
                "sentence",
                "from",
                "Caleb",
                "Carr",
                "'s",
                "the",
                "italian",
                "Secretary",
                ":",
                "look",
                "down",
                ",",
                "both",
                "my",
                "friend",
                "and",
                "I",
                "see",
                "the",
                "ominous",
                "form",
                "of",
                "a",
                "small",
                "homemade",
                "bomb",
                "."
            ]
        ],
        "label": "Fear"
    },
    {
        "body_part_token_idx": 5,
        "sentence_id": "16badb65-acd1-38df-9e7f-9b704bfa212e",
        "tokens": [
            "It",
            "brings",
            "tears",
            "to",
            "my",
            "eyes",
            "just",
            "thinking",
            "about",
            "it",
            "."
        ],
        "lemmatized_tokens": [
            "it",
            "bring",
            "tear",
            "to",
            "my",
            "eye",
            "just",
            "think",
            "about",
            "it",
            "."
        ],
        "preceding_context_tokens": [
            [
                "the",
                "feeling",
                "of",
                "his",
                "heart",
                "beating",
                "on",
                "mine",
                ",",
                "his",
                "breath",
                "on",
                "my",
                "skin",
                "and",
                "his",
                "little",
                "hands",
                "gently",
                "holding",
                "on",
                "to",
                "me",
                "."
            ],
            [
                "I",
                "rubbed",
                "his",
                "back",
                "and",
                "head",
                "and",
                "thought",
                "i",
                "never",
                "wanted",
                "that",
                "moment",
                "to",
                "end",
                "."
            ],
            [
                "This",
                "was",
                "exactly",
                "where",
                "i",
                "needed",
                "to",
                "be",
                "at",
                "that",
                "moment",
                "-",
                "no",
                "place",
                "to",
                "go",
                ",",
                "nothing",
                "else",
                "to",
                "think",
                "about",
                ",",
                "nothing",
                "else",
                "to",
                "do",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "the",
                "feeling",
                "of",
                "he",
                "heart",
                "beat",
                "on",
                "mine",
                ",",
                "he",
                "breath",
                "on",
                "my",
                "skin",
                "and",
                "he",
                "little",
                "hand",
                "gently",
                "hold",
                "on",
                "to",
                "I",
                "."
            ],
            [
                "I",
                "rub",
                "he",
                "back",
                "and",
                "head",
                "and",
                "think",
                "i",
                "never",
                "want",
                "that",
                "moment",
                "to",
                "end",
                "."
            ],
            [
                "this",
                "be",
                "exactly",
                "where",
                "i",
                "need",
                "to",
                "be",
                "at",
                "that",
                "moment",
                "-",
                "no",
                "place",
                "to",
                "go",
                ",",
                "nothing",
                "else",
                "to",
                "think",
                "about",
                ",",
                "nothing",
                "else",
                "to",
                "do",
                "."
            ]
        ],
        "label": "Joy"
    },
    {
        "body_part_token_idx": 9,
        "sentence_id": "dbeb36c7-1931-3aaa-9e58-13c67fef5f6f",
        "tokens": [
            "I",
            "went",
            "so",
            "crazy",
            ",",
            "that",
            "I",
            "trashed",
            "my",
            "wrists",
            "and",
            "bled",
            "to",
            "the",
            "point",
            "of",
            "fainting",
            "."
        ],
        "lemmatized_tokens": [
            "I",
            "go",
            "so",
            "crazy",
            ",",
            "that",
            "I",
            "trash",
            "my",
            "wrist",
            "and",
            "bleed",
            "to",
            "the",
            "point",
            "of",
            "faint",
            "."
        ],
        "preceding_context_tokens": [
            [
                "I",
                "'m",
                "always",
                "crying",
                "during",
                "a",
                "thunderstorm",
                ",",
                "regardless",
                "who",
                "I",
                "'m",
                "with",
                "."
            ],
            [
                "I",
                "'m",
                "usually",
                "with",
                "Jake",
                ",",
                "but",
                "when",
                "he",
                "'s",
                "not",
                "there",
                ",",
                "I",
                "go",
                "crazy",
                "."
            ],
            [
                "Just",
                "like",
                "I",
                "did",
                "a",
                "couple",
                "weeks",
                "ago",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "I",
                "be",
                "always",
                "cry",
                "during",
                "a",
                "thunderstorm",
                ",",
                "regardless",
                "who",
                "I",
                "be",
                "with",
                "."
            ],
            [
                "I",
                "be",
                "usually",
                "with",
                "Jake",
                ",",
                "but",
                "when",
                "he",
                "be",
                "not",
                "there",
                ",",
                "I",
                "go",
                "crazy",
                "."
            ],
            [
                "just",
                "like",
                "I",
                "do",
                "a",
                "couple",
                "week",
                "ago",
                "."
            ]
        ],
        "label": "Fear"
    },
    {
        "body_part_token_idx": 14,
        "sentence_id": "b43ca07d-c6fd-3286-b5af-228a9b4bec6f",
        "tokens": [
            "I",
            "grieved",
            "for",
            "you.",
            "I",
            "saw",
            "a",
            "faint",
            "shadow",
            "of",
            "guilt",
            "pass",
            "over",
            "his",
            "eyes",
            "."
        ],
        "lemmatized_tokens": [
            "I",
            "grieve",
            "for",
            "you.",
            "I",
            "see",
            "a",
            "faint",
            "shadow",
            "of",
            "guilt",
            "pass",
            "over",
            "he",
            "eye",
            "."
        ],
        "preceding_context_tokens": [
            [
                "We",
                "were",
                "relaxed",
                "and",
                "I",
                "was",
                "encircled",
                "in",
                "his",
                "arms",
                "with",
                "my",
                "head",
                "on",
                "his",
                "shoulder",
                "."
            ],
            [
                "It",
                "was",
                "while",
                "you",
                "were",
                "gone",
                ",",
                "I",
                "began",
                "."
            ],
            [
                "I",
                "looked",
                "up",
                "at",
                "him",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "we",
                "be",
                "relaxed",
                "and",
                "I",
                "be",
                "encircle",
                "in",
                "he",
                "arm",
                "with",
                "my",
                "head",
                "on",
                "he",
                "shoulder",
                "."
            ],
            [
                "it",
                "be",
                "while",
                "you",
                "be",
                "go",
                ",",
                "I",
                "begin",
                "."
            ],
            [
                "I",
                "look",
                "up",
                "at",
                "he",
                "."
            ]
        ],
        "label": "Sadness"
    },
    {
        "body_part_token_idx": 5,
        "sentence_id": "8c0fcd75-28cb-3779-84a0-39a976cda171",
        "tokens": [
            "The",
            "clipboard",
            "shook",
            "in",
            "my",
            "hands",
            "."
        ],
        "lemmatized_tokens": [
            "the",
            "clipboard",
            "shake",
            "in",
            "my",
            "hand",
            "."
        ],
        "preceding_context_tokens": [
            [
                "Without",
                "a",
                "word",
                "to",
                "me",
                ",",
                "and",
                "only",
                "a",
                "half",
                "a",
                "moment",
                "later",
                ",",
                "Pia",
                "went",
                "out",
                "the",
                "door",
                "."
            ],
            [
                "My",
                "heart",
                "thumped",
                "as",
                "I",
                "found",
                "myself",
                "alone",
                "in",
                "the",
                "Orange",
                "Julius",
                "with",
                "no",
                "idea",
                "as",
                "to",
                "what",
                "to",
                "do",
                "in",
                "the",
                "event",
                "of",
                "receiving",
                "a",
                "customer",
                "."
            ],
            [
                "I",
                "became",
                "incensed",
                "with",
                "anger",
                "and",
                "stood",
                "stock",
                "still",
                "in",
                "front",
                "of",
                "the",
                "storage",
                "room",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "without",
                "a",
                "word",
                "to",
                "I",
                ",",
                "and",
                "only",
                "a",
                "half",
                "a",
                "moment",
                "later",
                ",",
                "Pia",
                "go",
                "out",
                "the",
                "door",
                "."
            ],
            [
                "my",
                "heart",
                "thump",
                "as",
                "I",
                "find",
                "myself",
                "alone",
                "in",
                "the",
                "Orange",
                "Julius",
                "with",
                "no",
                "idea",
                "as",
                "to",
                "what",
                "to",
                "do",
                "in",
                "the",
                "event",
                "of",
                "receive",
                "a",
                "customer",
                "."
            ],
            [
                "I",
                "become",
                "incensed",
                "with",
                "anger",
                "and",
                "stand",
                "stock",
                "still",
                "in",
                "front",
                "of",
                "the",
                "storage",
                "room",
                "."
            ]
        ],
        "label": "Anger"
    },
    {
        "body_part_token_idx": 20,
        "sentence_id": "40b182f4-1faf-359a-9a54-732078b6b156",
        "tokens": [
            "``",
            "Do",
            "n't",
            "laugh",
            "at",
            "your",
            "father",
            ",",
            "''",
            "he",
            "chided",
            "automatically",
            "mid-sentence",
            ",",
            "to",
            "which",
            "Amunet",
            "only",
            "rolled",
            "her",
            "eyes",
            ",",
            "''",
            "$",
            "The",
            "last",
            "two",
            "centuries",
            "notwithstanding",
            ",",
            "''",
            "he",
            "continued",
            "grimly",
            "and",
            "Amunet",
            "stopped",
            ",",
            "sobering",
            "quickly",
            ",",
            "``",
            "so",
            "we",
            "both",
            "decided",
            "it",
            "was",
            "best",
            "to",
            "delay",
            "until",
            "the",
            "bulk",
            "of",
            "it",
            "was",
            "over",
            ",",
            "as",
            "did",
            "Tekhne",
            "and",
            "Perturabo",
            ".",
            "''"
        ],
        "lemmatized_tokens": [
            "``",
            "do",
            "not",
            "laugh",
            "at",
            "you",
            "father",
            ",",
            "''",
            "he",
            "chide",
            "automatically",
            "mid-sentence",
            ",",
            "to",
            "which",
            "Amunet",
            "only",
            "roll",
            "she",
            "eye",
            ",",
            "''",
            "$",
            "the",
            "last",
            "two",
            "century",
            "notwithstanding",
            ",",
            "''",
            "he",
            "continue",
            "grimly",
            "and",
            "Amunet",
            "stop",
            ",",
            "sobering",
            "quickly",
            ",",
            "``",
            "so",
            "we",
            "both",
            "decide",
            "it",
            "be",
            "best",
            "to",
            "delay",
            "until",
            "the",
            "bulk",
            "of",
            "it",
            "be",
            "over",
            ",",
            "as",
            "do",
            "Tekhne",
            "and",
            "Perturabo",
            ".",
            "''"
        ],
        "preceding_context_tokens": [
            [
                "Fulgrim",
                "blinked",
                "and",
                "gathered",
                "himself",
                ",",
                "``",
                "I",
                ",",
                "ah",
                ",",
                "did",
                "n't",
                "expect",
                "you",
                "and",
                "Ira",
                "to",
                "have",
                "children",
                "?",
                "''"
            ],
            [
                "he",
                "offered",
                "."
            ],
            [
                "Magnus",
                "coughed",
                "sheepishly",
                ",",
                "``",
                "Ira",
                "and",
                "I",
                "did",
                "take",
                "a",
                "while",
                "to",
                "settle",
                "down",
                ",",
                "''",
                "while",
                "Amunet",
                "sniggered",
                "in",
                "the",
                "background",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "Fulgrim",
                "blink",
                "and",
                "gather",
                "himself",
                ",",
                "``",
                "I",
                ",",
                "ah",
                ",",
                "do",
                "not",
                "expect",
                "you",
                "and",
                "Ira",
                "to",
                "have",
                "child",
                "?",
                "''"
            ],
            [
                "he",
                "offer",
                "."
            ],
            [
                "Magnus",
                "cough",
                "sheepishly",
                ",",
                "``",
                "Ira",
                "and",
                "I",
                "do",
                "take",
                "a",
                "while",
                "to",
                "settle",
                "down",
                ",",
                "''",
                "while",
                "Amunet",
                "snigger",
                "in",
                "the",
                "background",
                "."
            ]
        ],
        "label": "Disgust"
    },
    {
        "body_part_token_idx": 13,
        "sentence_id": "20ccab26-fbd0-3195-88b6-00d88eaf987d",
        "tokens": [
            "With",
            "the",
            "ear",
            "muffs",
            "on",
            "he",
            "could",
            "feel",
            "his",
            "blood",
            "beat",
            "at",
            "his",
            "temples",
            "."
        ],
        "lemmatized_tokens": [
            "with",
            "the",
            "ear",
            "muff",
            "on",
            "he",
            "could",
            "feel",
            "he",
            "blood",
            "beat",
            "at",
            "he",
            "temple",
            "."
        ],
        "preceding_context_tokens": [
            [
                "Not",
                "quite",
                "under",
                "control",
                "."
            ],
            [
                "Flack",
                "swallowed",
                "in",
                "a",
                "lungful",
                "of",
                "air",
                ",",
                "imagining",
                "his",
                "heart",
                "and",
                "lungs",
                "stilling",
                "under",
                "his",
                "command",
                "."
            ],
            [
                "He",
                "bit",
                "his",
                "lip",
                "and",
                "loaded",
                "a",
                "second",
                "clip",
                "into",
                "the",
                "magazine",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "not",
                "quite",
                "under",
                "control",
                "."
            ],
            [
                "flack",
                "swallow",
                "in",
                "a",
                "lungful",
                "of",
                "air",
                ",",
                "imagine",
                "he",
                "heart",
                "and",
                "lung",
                "still",
                "under",
                "he",
                "command",
                "."
            ],
            [
                "he",
                "bite",
                "he",
                "lip",
                "and",
                "load",
                "a",
                "second",
                "clip",
                "into",
                "the",
                "magazine",
                "."
            ]
        ],
        "label": "Fear"
    },
    {
        "body_part_token_idx": 34,
        "sentence_id": "6f0773b6-4ca0-38c3-8018-67fba2bbdaf2",
        "tokens": [
            "She",
            "recognizes",
            "the",
            "tube",
            "and",
            "allows",
            "me",
            "to",
            "put",
            "it",
            "in",
            "her",
            "mouth",
            "and",
            "rub",
            "her",
            "gums",
            ",",
            "before",
            "she",
            "just",
            "tried",
            "to",
            "grab",
            "my",
            "hand",
            "and",
            "swat",
            "it",
            "away",
            ",",
            "or",
            "pursed",
            "her",
            "lips",
            "and",
            "refused",
            "to",
            "let",
            "it",
            "in.CrawlingWe",
            "'ve",
            "progressed",
            "vastly",
            "in",
            "this",
            "department",
            "."
        ],
        "lemmatized_tokens": [
            "she",
            "recognize",
            "the",
            "tube",
            "and",
            "allow",
            "I",
            "to",
            "put",
            "it",
            "in",
            "she",
            "mouth",
            "and",
            "rub",
            "she",
            "gum",
            ",",
            "before",
            "she",
            "just",
            "try",
            "to",
            "grab",
            "my",
            "hand",
            "and",
            "swat",
            "it",
            "away",
            ",",
            "or",
            "purse",
            "she",
            "lip",
            "and",
            "refuse",
            "to",
            "let",
            "it",
            "in.crawlingwe",
            "have",
            "progress",
            "vastly",
            "in",
            "this",
            "department",
            "."
        ],
        "preceding_context_tokens": [
            [
                "One",
                "is",
                "just",
                "about",
                "through",
                "the",
                "gums",
                "and",
                "the",
                "other",
                "is",
                "just",
                "partially",
                "through",
                "."
            ],
            [
                "Hopefully",
                "once",
                "it",
                "'s",
                "through",
                "the",
                "biting",
                "will",
                "lessen",
                "."
            ],
            [
                "We",
                "'re",
                "doing",
                "the",
                "numbing",
                "stuff",
                "when",
                "she",
                "'s",
                "really",
                "miserable",
                "and",
                "she",
                "now",
                "knows",
                "what",
                "it",
                "'s",
                "for",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "one",
                "be",
                "just",
                "about",
                "through",
                "the",
                "gum",
                "and",
                "the",
                "other",
                "be",
                "just",
                "partially",
                "through",
                "."
            ],
            [
                "hopefully",
                "once",
                "it",
                "be",
                "through",
                "the",
                "biting",
                "will",
                "lessen",
                "."
            ],
            [
                "we",
                "be",
                "do",
                "the",
                "numb",
                "stuff",
                "when",
                "she",
                "be",
                "really",
                "miserable",
                "and",
                "she",
                "now",
                "know",
                "what",
                "it",
                "be",
                "for",
                "."
            ]
        ],
        "label": "Disgust"
    },
    {
        "body_part_token_idx": 7,
        "sentence_id": "4b798d65-0ee5-31d6-bfe6-0fcea6c09eeb",
        "tokens": [
            "I",
            "just",
            "smiled",
            "at",
            "him",
            "and",
            "his",
            "cheeks",
            "tinged",
            "pink",
            "."
        ],
        "lemmatized_tokens": [
            "I",
            "just",
            "smile",
            "at",
            "he",
            "and",
            "he",
            "cheek",
            "tinge",
            "pink",
            "."
        ],
        "preceding_context_tokens": [
            [
                "He",
                "nodded",
                "."
            ],
            [
                "We",
                "were",
                "about",
                "to",
                "walk",
                "out",
                "the",
                "door",
                ",",
                "but",
                "Jonghyun",
                "stopped",
                "us",
                "and",
                "said",
                ",",
                "``",
                "I",
                "'ll",
                "take",
                "you",
                "home",
                "."
            ],
            [
                "It",
                "'s",
                "really",
                "cold",
                "out",
                "tonight",
                ",",
                "but",
                "you",
                "two",
                "are",
                "not",
                "sitting",
                "in",
                "my",
                "back",
                "seat",
                "together",
                ".",
                "''"
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "he",
                "nod",
                "."
            ],
            [
                "we",
                "be",
                "about",
                "to",
                "walk",
                "out",
                "the",
                "door",
                ",",
                "but",
                "Jonghyun",
                "stop",
                "we",
                "and",
                "say",
                ",",
                "``",
                "I",
                "will",
                "take",
                "you",
                "home",
                "."
            ],
            [
                "it",
                "be",
                "really",
                "cold",
                "out",
                "tonight",
                ",",
                "but",
                "you",
                "two",
                "be",
                "not",
                "sit",
                "in",
                "my",
                "back",
                "seat",
                "together",
                ".",
                "''"
            ]
        ],
        "label": "Fear"
    },
    {
        "body_part_token_idx": 17,
        "sentence_id": "045caf50-e7c8-3271-8973-65f778385eaa",
        "tokens": [
            "But",
            "let",
            "me",
            "just",
            "make",
            "it",
            "simple",
            ",",
            "just",
            "so",
            "to",
            "keep",
            "my",
            "head",
            "calm",
            "and",
            "my",
            "heart",
            "stop",
            "racing",
            "and",
            "my",
            "hands",
            "stop",
            "shaking",
            "and",
            "my",
            "mouth",
            "stop",
            "smiling",
            "and",
            "my",
            "cheek",
            "stop",
            "blushing",
            "."
        ],
        "lemmatized_tokens": [
            "but",
            "let",
            "I",
            "just",
            "make",
            "it",
            "simple",
            ",",
            "just",
            "so",
            "to",
            "keep",
            "my",
            "head",
            "calm",
            "and",
            "my",
            "heart",
            "stop",
            "race",
            "and",
            "my",
            "hand",
            "stop",
            "shake",
            "and",
            "my",
            "mouth",
            "stop",
            "smile",
            "and",
            "my",
            "cheek",
            "stop",
            "blush",
            "."
        ],
        "preceding_context_tokens": [
            [
                "Must",
                "I",
                "tell",
                "the",
                "story",
                "?"
            ],
            [
                "Of",
                "what",
                "happen",
                "to",
                "me",
                "tonight",
                ",",
                "must",
                "I",
                "tell",
                "?"
            ],
            [
                "I",
                "prefer",
                "to",
                "keep",
                "it",
                "lock",
                "in",
                "my",
                "chest",
                ",",
                "as",
                "telling",
                "it",
                "would",
                "open",
                "up",
                "a",
                "whole",
                "different",
                "story",
                "that",
                "relates",
                ",",
                "thus",
                "exposing",
                "things",
                "that",
                "I",
                "wish",
                "not",
                "to",
                "expose",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "must",
                "I",
                "tell",
                "the",
                "story",
                "?"
            ],
            [
                "of",
                "what",
                "happen",
                "to",
                "I",
                "tonight",
                ",",
                "must",
                "I",
                "tell",
                "?"
            ],
            [
                "I",
                "prefer",
                "to",
                "keep",
                "it",
                "lock",
                "in",
                "my",
                "chest",
                ",",
                "as",
                "tell",
                "it",
                "would",
                "open",
                "up",
                "a",
                "whole",
                "different",
                "story",
                "that",
                "relate",
                ",",
                "thus",
                "expose",
                "thing",
                "that",
                "I",
                "wish",
                "not",
                "to",
                "expose",
                "."
            ]
        ],
        "label": "Fear"
    },
    {
        "body_part_token_idx": 22,
        "sentence_id": "045caf50-e7c8-3271-8973-65f778385eaa",
        "tokens": [
            "But",
            "let",
            "me",
            "just",
            "make",
            "it",
            "simple",
            ",",
            "just",
            "so",
            "to",
            "keep",
            "my",
            "head",
            "calm",
            "and",
            "my",
            "heart",
            "stop",
            "racing",
            "and",
            "my",
            "hands",
            "stop",
            "shaking",
            "and",
            "my",
            "mouth",
            "stop",
            "smiling",
            "and",
            "my",
            "cheek",
            "stop",
            "blushing",
            "."
        ],
        "lemmatized_tokens": [
            "but",
            "let",
            "I",
            "just",
            "make",
            "it",
            "simple",
            ",",
            "just",
            "so",
            "to",
            "keep",
            "my",
            "head",
            "calm",
            "and",
            "my",
            "heart",
            "stop",
            "race",
            "and",
            "my",
            "hand",
            "stop",
            "shake",
            "and",
            "my",
            "mouth",
            "stop",
            "smile",
            "and",
            "my",
            "cheek",
            "stop",
            "blush",
            "."
        ],
        "preceding_context_tokens": [
            [
                "Must",
                "I",
                "tell",
                "the",
                "story",
                "?"
            ],
            [
                "Of",
                "what",
                "happen",
                "to",
                "me",
                "tonight",
                ",",
                "must",
                "I",
                "tell",
                "?"
            ],
            [
                "I",
                "prefer",
                "to",
                "keep",
                "it",
                "lock",
                "in",
                "my",
                "chest",
                ",",
                "as",
                "telling",
                "it",
                "would",
                "open",
                "up",
                "a",
                "whole",
                "different",
                "story",
                "that",
                "relates",
                ",",
                "thus",
                "exposing",
                "things",
                "that",
                "I",
                "wish",
                "not",
                "to",
                "expose",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "must",
                "I",
                "tell",
                "the",
                "story",
                "?"
            ],
            [
                "of",
                "what",
                "happen",
                "to",
                "I",
                "tonight",
                ",",
                "must",
                "I",
                "tell",
                "?"
            ],
            [
                "I",
                "prefer",
                "to",
                "keep",
                "it",
                "lock",
                "in",
                "my",
                "chest",
                ",",
                "as",
                "tell",
                "it",
                "would",
                "open",
                "up",
                "a",
                "whole",
                "different",
                "story",
                "that",
                "relate",
                ",",
                "thus",
                "expose",
                "thing",
                "that",
                "I",
                "wish",
                "not",
                "to",
                "expose",
                "."
            ]
        ],
        "label": "Fear"
    },
    {
        "body_part_token_idx": 27,
        "sentence_id": "045caf50-e7c8-3271-8973-65f778385eaa",
        "tokens": [
            "But",
            "let",
            "me",
            "just",
            "make",
            "it",
            "simple",
            ",",
            "just",
            "so",
            "to",
            "keep",
            "my",
            "head",
            "calm",
            "and",
            "my",
            "heart",
            "stop",
            "racing",
            "and",
            "my",
            "hands",
            "stop",
            "shaking",
            "and",
            "my",
            "mouth",
            "stop",
            "smiling",
            "and",
            "my",
            "cheek",
            "stop",
            "blushing",
            "."
        ],
        "lemmatized_tokens": [
            "but",
            "let",
            "I",
            "just",
            "make",
            "it",
            "simple",
            ",",
            "just",
            "so",
            "to",
            "keep",
            "my",
            "head",
            "calm",
            "and",
            "my",
            "heart",
            "stop",
            "race",
            "and",
            "my",
            "hand",
            "stop",
            "shake",
            "and",
            "my",
            "mouth",
            "stop",
            "smile",
            "and",
            "my",
            "cheek",
            "stop",
            "blush",
            "."
        ],
        "preceding_context_tokens": [
            [
                "Must",
                "I",
                "tell",
                "the",
                "story",
                "?"
            ],
            [
                "Of",
                "what",
                "happen",
                "to",
                "me",
                "tonight",
                ",",
                "must",
                "I",
                "tell",
                "?"
            ],
            [
                "I",
                "prefer",
                "to",
                "keep",
                "it",
                "lock",
                "in",
                "my",
                "chest",
                ",",
                "as",
                "telling",
                "it",
                "would",
                "open",
                "up",
                "a",
                "whole",
                "different",
                "story",
                "that",
                "relates",
                ",",
                "thus",
                "exposing",
                "things",
                "that",
                "I",
                "wish",
                "not",
                "to",
                "expose",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "must",
                "I",
                "tell",
                "the",
                "story",
                "?"
            ],
            [
                "of",
                "what",
                "happen",
                "to",
                "I",
                "tonight",
                ",",
                "must",
                "I",
                "tell",
                "?"
            ],
            [
                "I",
                "prefer",
                "to",
                "keep",
                "it",
                "lock",
                "in",
                "my",
                "chest",
                ",",
                "as",
                "tell",
                "it",
                "would",
                "open",
                "up",
                "a",
                "whole",
                "different",
                "story",
                "that",
                "relate",
                ",",
                "thus",
                "expose",
                "thing",
                "that",
                "I",
                "wish",
                "not",
                "to",
                "expose",
                "."
            ]
        ],
        "label": "Fear"
    },
    {
        "body_part_token_idx": 32,
        "sentence_id": "045caf50-e7c8-3271-8973-65f778385eaa",
        "tokens": [
            "But",
            "let",
            "me",
            "just",
            "make",
            "it",
            "simple",
            ",",
            "just",
            "so",
            "to",
            "keep",
            "my",
            "head",
            "calm",
            "and",
            "my",
            "heart",
            "stop",
            "racing",
            "and",
            "my",
            "hands",
            "stop",
            "shaking",
            "and",
            "my",
            "mouth",
            "stop",
            "smiling",
            "and",
            "my",
            "cheek",
            "stop",
            "blushing",
            "."
        ],
        "lemmatized_tokens": [
            "but",
            "let",
            "I",
            "just",
            "make",
            "it",
            "simple",
            ",",
            "just",
            "so",
            "to",
            "keep",
            "my",
            "head",
            "calm",
            "and",
            "my",
            "heart",
            "stop",
            "race",
            "and",
            "my",
            "hand",
            "stop",
            "shake",
            "and",
            "my",
            "mouth",
            "stop",
            "smile",
            "and",
            "my",
            "cheek",
            "stop",
            "blush",
            "."
        ],
        "preceding_context_tokens": [
            [
                "Must",
                "I",
                "tell",
                "the",
                "story",
                "?"
            ],
            [
                "Of",
                "what",
                "happen",
                "to",
                "me",
                "tonight",
                ",",
                "must",
                "I",
                "tell",
                "?"
            ],
            [
                "I",
                "prefer",
                "to",
                "keep",
                "it",
                "lock",
                "in",
                "my",
                "chest",
                ",",
                "as",
                "telling",
                "it",
                "would",
                "open",
                "up",
                "a",
                "whole",
                "different",
                "story",
                "that",
                "relates",
                ",",
                "thus",
                "exposing",
                "things",
                "that",
                "I",
                "wish",
                "not",
                "to",
                "expose",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "must",
                "I",
                "tell",
                "the",
                "story",
                "?"
            ],
            [
                "of",
                "what",
                "happen",
                "to",
                "I",
                "tonight",
                ",",
                "must",
                "I",
                "tell",
                "?"
            ],
            [
                "I",
                "prefer",
                "to",
                "keep",
                "it",
                "lock",
                "in",
                "my",
                "chest",
                ",",
                "as",
                "tell",
                "it",
                "would",
                "open",
                "up",
                "a",
                "whole",
                "different",
                "story",
                "that",
                "relate",
                ",",
                "thus",
                "expose",
                "thing",
                "that",
                "I",
                "wish",
                "not",
                "to",
                "expose",
                "."
            ]
        ],
        "label": "Fear"
    },
    {
        "body_part_token_idx": 5,
        "sentence_id": "3e4a2688-82ff-358a-8a1c-9f4d581ecd6a",
        "tokens": [
            "Joanna",
            "stopped",
            "fighting",
            ",",
            "her",
            "throat",
            "tight",
            "."
        ],
        "lemmatized_tokens": [
            "Joanna",
            "stop",
            "fight",
            ",",
            "she",
            "throat",
            "tight",
            "."
        ],
        "preceding_context_tokens": [
            [
                "Whirling",
                "around",
                ",",
                "Joanna",
                "tried",
                "to",
                "pull",
                "away",
                "."
            ],
            [
                "``",
                "It",
                "'s",
                "not",
                "like",
                "I",
                "keep",
                "a",
                "calendar",
                "--",
                "''",
                "``",
                "Twenty",
                "-",
                "five",
                "years",
                "have",
                "passed",
                "on",
                "Earth",
                ".",
                "''"
            ],
            [
                "His",
                "voice",
                "was",
                "just",
                "as",
                "low",
                "as",
                "Joanna",
                "remembered",
                ",",
                "and",
                "he",
                "had",
                "n't",
                "changed",
                "at",
                "all",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "whirl",
                "around",
                ",",
                "Joanna",
                "try",
                "to",
                "pull",
                "away",
                "."
            ],
            [
                "``",
                "it",
                "be",
                "not",
                "like",
                "I",
                "keep",
                "a",
                "calendar",
                "--",
                "''",
                "``",
                "twenty",
                "-",
                "five",
                "year",
                "have",
                "pass",
                "on",
                "Earth",
                ".",
                "''"
            ],
            [
                "he",
                "voice",
                "be",
                "just",
                "as",
                "low",
                "as",
                "Joanna",
                "remember",
                ",",
                "and",
                "he",
                "have",
                "not",
                "change",
                "at",
                "all",
                "."
            ]
        ],
        "label": "Sadness"
    },
    {
        "body_part_token_idx": 8,
        "sentence_id": "486a477b-196f-3017-9d4d-fbdff473da22",
        "tokens": [
            "She",
            "could",
            "see",
            "the",
            "worried",
            "look",
            "in",
            "his",
            "eye",
            "and",
            "could",
            "understand",
            "why",
            "."
        ],
        "lemmatized_tokens": [
            "she",
            "could",
            "see",
            "the",
            "worried",
            "look",
            "in",
            "he",
            "eye",
            "and",
            "could",
            "understand",
            "why",
            "."
        ],
        "preceding_context_tokens": [
            [
                "Placing",
                "the",
                "paper",
                "in",
                "her",
                "pocket",
                "again",
                "and",
                "handing",
                "Eric",
                "the",
                "his",
                "license",
                "and",
                "registration",
                "back",
                "Stacy",
                "turns",
                "on",
                "her",
                "heels",
                "and",
                "makes",
                "her",
                "way",
                "back",
                "to",
                "the",
                "cop",
                "again",
                "once",
                "more",
                "."
            ],
            [
                "Getting",
                "in",
                "writing",
                "a",
                "few",
                "things",
                "down",
                "and",
                "entering",
                "both",
                "tickets",
                "into",
                "a",
                "computer",
                "before",
                "pulling",
                "away",
                "and",
                "continuing",
                "her",
                "road",
                "patrol",
                "."
            ],
            [
                "Once",
                "Rick",
                "was",
                "gone",
                "again",
                "Katie",
                "turns",
                "back",
                "to",
                "Jason",
                "trying",
                "to",
                "give",
                "him",
                "a",
                "reassured",
                "smile",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "place",
                "the",
                "paper",
                "in",
                "she",
                "pocket",
                "again",
                "and",
                "hand",
                "Eric",
                "the",
                "he",
                "license",
                "and",
                "registration",
                "back",
                "Stacy",
                "turn",
                "on",
                "she",
                "heel",
                "and",
                "make",
                "she",
                "way",
                "back",
                "to",
                "the",
                "cop",
                "again",
                "once",
                "more",
                "."
            ],
            [
                "get",
                "in",
                "write",
                "a",
                "few",
                "thing",
                "down",
                "and",
                "enter",
                "both",
                "ticket",
                "into",
                "a",
                "computer",
                "before",
                "pull",
                "away",
                "and",
                "continue",
                "she",
                "road",
                "patrol",
                "."
            ],
            [
                "once",
                "Rick",
                "be",
                "go",
                "again",
                "Katie",
                "turn",
                "back",
                "to",
                "Jason",
                "try",
                "to",
                "give",
                "he",
                "a",
                "reassured",
                "smile",
                "."
            ]
        ],
        "label": "Fear"
    },
    {
        "body_part_token_idx": 3,
        "sentence_id": "89a3415f-004a-3e15-ac56-74d3f424215a",
        "tokens": [
            "I",
            "shook",
            "my",
            "head",
            "."
        ],
        "lemmatized_tokens": [
            "I",
            "shake",
            "my",
            "head",
            "."
        ],
        "preceding_context_tokens": [
            [
                "I",
                "looked",
                "at",
                "him",
                "in",
                "the",
                "rear",
                "view",
                "mirror",
                "."
            ],
            [
                "``",
                "What",
                "?",
                "''"
            ],
            [
                "he",
                "asked",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "I",
                "look",
                "at",
                "he",
                "in",
                "the",
                "rear",
                "view",
                "mirror",
                "."
            ],
            [
                "``",
                "what",
                "?",
                "''"
            ],
            [
                "he",
                "ask",
                "."
            ]
        ],
        "label": "Fear"
    },
    {
        "body_part_token_idx": 1,
        "sentence_id": "50d3cc02-3688-382c-a283-42b0afc17a14",
        "tokens": [
            "My",
            "hand",
            "seemed",
            "to",
            "tremble",
            "more",
            "as",
            "I",
            "took",
            "the",
            "frail",
            "hand",
            "offered",
            "to",
            "me",
            ",",
            "feeling",
            "the",
            "protruding",
            "veins",
            "under",
            "my",
            "thumb",
            "."
        ],
        "lemmatized_tokens": [
            "my",
            "hand",
            "seem",
            "to",
            "tremble",
            "more",
            "as",
            "I",
            "take",
            "the",
            "frail",
            "hand",
            "offer",
            "to",
            "I",
            ",",
            "feel",
            "the",
            "protrude",
            "vein",
            "under",
            "my",
            "thumb",
            "."
        ],
        "preceding_context_tokens": [
            [
                "Sometimes",
                ",",
                "I",
                "would",
                "just",
                "let",
                "her",
                ",",
                "but",
                "you",
                "see",
                ",",
                "Emma",
                "had",
                "the",
                "tendancy",
                "to",
                "stretch",
                "the",
                "truth",
                "and",
                "make",
                "me",
                "sound",
                "more",
                "uptight",
                "than",
                "I",
                "really",
                "was",
                "and",
                "I",
                "would",
                "have",
                "to",
                "-",
                "er",
                "correct",
                "her",
                ",",
                "in",
                "which",
                "case",
                "that",
                "smile",
                "would",
                "widen",
                "."
            ],
            [
                "I",
                "noticed",
                "as",
                "we",
                "stared",
                "at",
                "eachother",
                "then",
                "that",
                "the",
                "light",
                "was",
                "dim",
                ",",
                "and",
                "I",
                "knew",
                "something",
                "was",
                "wrong",
                "."
            ],
            [
                "She",
                "lay",
                "on",
                "the",
                "stiff",
                "arm",
                "long",
                "enough",
                "to",
                "reach",
                "for",
                "me",
                "as",
                "if",
                "she",
                "felt",
                "it",
                "too",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "sometimes",
                ",",
                "I",
                "would",
                "just",
                "let",
                "she",
                ",",
                "but",
                "you",
                "see",
                ",",
                "Emma",
                "have",
                "the",
                "tendancy",
                "to",
                "stretch",
                "the",
                "truth",
                "and",
                "make",
                "I",
                "sound",
                "more",
                "uptight",
                "than",
                "I",
                "really",
                "be",
                "and",
                "I",
                "would",
                "have",
                "to",
                "-",
                "er",
                "correct",
                "she",
                ",",
                "in",
                "which",
                "case",
                "that",
                "smile",
                "would",
                "widen",
                "."
            ],
            [
                "I",
                "notice",
                "as",
                "we",
                "stare",
                "at",
                "eachother",
                "then",
                "that",
                "the",
                "light",
                "be",
                "dim",
                ",",
                "and",
                "I",
                "know",
                "something",
                "be",
                "wrong",
                "."
            ],
            [
                "she",
                "lay",
                "on",
                "the",
                "stiff",
                "arm",
                "long",
                "enough",
                "to",
                "reach",
                "for",
                "I",
                "as",
                "if",
                "she",
                "feel",
                "it",
                "too",
                "."
            ]
        ],
        "label": "Fear"
    },
    {
        "body_part_token_idx": 22,
        "sentence_id": "50d3cc02-3688-382c-a283-42b0afc17a14",
        "tokens": [
            "My",
            "hand",
            "seemed",
            "to",
            "tremble",
            "more",
            "as",
            "I",
            "took",
            "the",
            "frail",
            "hand",
            "offered",
            "to",
            "me",
            ",",
            "feeling",
            "the",
            "protruding",
            "veins",
            "under",
            "my",
            "thumb",
            "."
        ],
        "lemmatized_tokens": [
            "my",
            "hand",
            "seem",
            "to",
            "tremble",
            "more",
            "as",
            "I",
            "take",
            "the",
            "frail",
            "hand",
            "offer",
            "to",
            "I",
            ",",
            "feel",
            "the",
            "protrude",
            "vein",
            "under",
            "my",
            "thumb",
            "."
        ],
        "preceding_context_tokens": [
            [
                "Sometimes",
                ",",
                "I",
                "would",
                "just",
                "let",
                "her",
                ",",
                "but",
                "you",
                "see",
                ",",
                "Emma",
                "had",
                "the",
                "tendancy",
                "to",
                "stretch",
                "the",
                "truth",
                "and",
                "make",
                "me",
                "sound",
                "more",
                "uptight",
                "than",
                "I",
                "really",
                "was",
                "and",
                "I",
                "would",
                "have",
                "to",
                "-",
                "er",
                "correct",
                "her",
                ",",
                "in",
                "which",
                "case",
                "that",
                "smile",
                "would",
                "widen",
                "."
            ],
            [
                "I",
                "noticed",
                "as",
                "we",
                "stared",
                "at",
                "eachother",
                "then",
                "that",
                "the",
                "light",
                "was",
                "dim",
                ",",
                "and",
                "I",
                "knew",
                "something",
                "was",
                "wrong",
                "."
            ],
            [
                "She",
                "lay",
                "on",
                "the",
                "stiff",
                "arm",
                "long",
                "enough",
                "to",
                "reach",
                "for",
                "me",
                "as",
                "if",
                "she",
                "felt",
                "it",
                "too",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "sometimes",
                ",",
                "I",
                "would",
                "just",
                "let",
                "she",
                ",",
                "but",
                "you",
                "see",
                ",",
                "Emma",
                "have",
                "the",
                "tendancy",
                "to",
                "stretch",
                "the",
                "truth",
                "and",
                "make",
                "I",
                "sound",
                "more",
                "uptight",
                "than",
                "I",
                "really",
                "be",
                "and",
                "I",
                "would",
                "have",
                "to",
                "-",
                "er",
                "correct",
                "she",
                ",",
                "in",
                "which",
                "case",
                "that",
                "smile",
                "would",
                "widen",
                "."
            ],
            [
                "I",
                "notice",
                "as",
                "we",
                "stare",
                "at",
                "eachother",
                "then",
                "that",
                "the",
                "light",
                "be",
                "dim",
                ",",
                "and",
                "I",
                "know",
                "something",
                "be",
                "wrong",
                "."
            ],
            [
                "she",
                "lay",
                "on",
                "the",
                "stiff",
                "arm",
                "long",
                "enough",
                "to",
                "reach",
                "for",
                "I",
                "as",
                "if",
                "she",
                "feel",
                "it",
                "too",
                "."
            ]
        ],
        "label": "Fear"
    },
    {
        "body_part_token_idx": 20,
        "sentence_id": "fac10a87-1e2c-307d-bea5-41c5cfdee09b",
        "tokens": [
            "-",
            "Harry",
            "is",
            "in",
            "the",
            "bathroom",
            ",",
            "shaking",
            "uncontrollably",
            ",",
            "tears",
            "of",
            "frustration",
            ",",
            "confusion",
            "and",
            "sadness",
            "cascading",
            "down",
            "his",
            "cheeks",
            "as",
            "he",
            "sits",
            "on",
            "the",
            "cold",
            "tiled",
            "floor",
            ",",
            "back",
            "against",
            "the",
            "bath",
            "and",
            "head",
            "resting",
            "on",
            "his",
            "bent",
            "knees",
            ",",
            "hands",
            "curled",
            "over",
            "his",
            "head",
            "and",
            "fisted",
            "in",
            "his",
            "hair",
            "."
        ],
        "lemmatized_tokens": [
            "-",
            "Harry",
            "be",
            "in",
            "the",
            "bathroom",
            ",",
            "shake",
            "uncontrollably",
            ",",
            "tear",
            "of",
            "frustration",
            ",",
            "confusion",
            "and",
            "sadness",
            "cascade",
            "down",
            "he",
            "cheek",
            "as",
            "he",
            "sit",
            "on",
            "the",
            "cold",
            "tile",
            "floor",
            ",",
            "back",
            "against",
            "the",
            "bath",
            "and",
            "head",
            "rest",
            "on",
            "he",
            "bent",
            "knee",
            ",",
            "hand",
            "curl",
            "over",
            "he",
            "head",
            "and",
            "fisted",
            "in",
            "he",
            "hair",
            "."
        ],
        "preceding_context_tokens": [
            [
                "It",
                "takes",
                "Zayn",
                "only",
                "a",
                "second",
                "after",
                "stepping",
                "into",
                "the",
                "room",
                "to",
                "realise",
                "what",
                "must",
                "have",
                "happened",
                "."
            ],
            [
                "He",
                "locks",
                "eyes",
                "with",
                "Liam",
                "before",
                "he",
                "walks",
                "through",
                "the",
                "room",
                "and",
                "out",
                "the",
                "front",
                "door",
                "."
            ],
            [
                "He",
                "knows",
                "Louis",
                "will",
                "be",
                "ok",
                "with",
                "Liam",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "it",
                "take",
                "Zayn",
                "only",
                "a",
                "second",
                "after",
                "step",
                "into",
                "the",
                "room",
                "to",
                "realise",
                "what",
                "must",
                "have",
                "happen",
                "."
            ],
            [
                "he",
                "lock",
                "eye",
                "with",
                "Liam",
                "before",
                "he",
                "walk",
                "through",
                "the",
                "room",
                "and",
                "out",
                "the",
                "front",
                "door",
                "."
            ],
            [
                "he",
                "know",
                "Louis",
                "will",
                "be",
                "ok",
                "with",
                "Liam",
                "."
            ]
        ],
        "label": "Sadness"
    },
    {
        "body_part_token_idx": 46,
        "sentence_id": "fac10a87-1e2c-307d-bea5-41c5cfdee09b",
        "tokens": [
            "-",
            "Harry",
            "is",
            "in",
            "the",
            "bathroom",
            ",",
            "shaking",
            "uncontrollably",
            ",",
            "tears",
            "of",
            "frustration",
            ",",
            "confusion",
            "and",
            "sadness",
            "cascading",
            "down",
            "his",
            "cheeks",
            "as",
            "he",
            "sits",
            "on",
            "the",
            "cold",
            "tiled",
            "floor",
            ",",
            "back",
            "against",
            "the",
            "bath",
            "and",
            "head",
            "resting",
            "on",
            "his",
            "bent",
            "knees",
            ",",
            "hands",
            "curled",
            "over",
            "his",
            "head",
            "and",
            "fisted",
            "in",
            "his",
            "hair",
            "."
        ],
        "lemmatized_tokens": [
            "-",
            "Harry",
            "be",
            "in",
            "the",
            "bathroom",
            ",",
            "shake",
            "uncontrollably",
            ",",
            "tear",
            "of",
            "frustration",
            ",",
            "confusion",
            "and",
            "sadness",
            "cascade",
            "down",
            "he",
            "cheek",
            "as",
            "he",
            "sit",
            "on",
            "the",
            "cold",
            "tile",
            "floor",
            ",",
            "back",
            "against",
            "the",
            "bath",
            "and",
            "head",
            "rest",
            "on",
            "he",
            "bent",
            "knee",
            ",",
            "hand",
            "curl",
            "over",
            "he",
            "head",
            "and",
            "fisted",
            "in",
            "he",
            "hair",
            "."
        ],
        "preceding_context_tokens": [
            [
                "It",
                "takes",
                "Zayn",
                "only",
                "a",
                "second",
                "after",
                "stepping",
                "into",
                "the",
                "room",
                "to",
                "realise",
                "what",
                "must",
                "have",
                "happened",
                "."
            ],
            [
                "He",
                "locks",
                "eyes",
                "with",
                "Liam",
                "before",
                "he",
                "walks",
                "through",
                "the",
                "room",
                "and",
                "out",
                "the",
                "front",
                "door",
                "."
            ],
            [
                "He",
                "knows",
                "Louis",
                "will",
                "be",
                "ok",
                "with",
                "Liam",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "it",
                "take",
                "Zayn",
                "only",
                "a",
                "second",
                "after",
                "step",
                "into",
                "the",
                "room",
                "to",
                "realise",
                "what",
                "must",
                "have",
                "happen",
                "."
            ],
            [
                "he",
                "lock",
                "eye",
                "with",
                "Liam",
                "before",
                "he",
                "walk",
                "through",
                "the",
                "room",
                "and",
                "out",
                "the",
                "front",
                "door",
                "."
            ],
            [
                "he",
                "know",
                "Louis",
                "will",
                "be",
                "ok",
                "with",
                "Liam",
                "."
            ]
        ],
        "label": "Sadness"
    },
    {
        "body_part_token_idx": 3,
        "sentence_id": "f57dfbcd-ee11-3089-8cdc-e0d873950412",
        "tokens": [
            "She",
            "opened",
            "her",
            "eyes",
            ",",
            "smiling",
            "."
        ],
        "lemmatized_tokens": [
            "she",
            "open",
            "she",
            "eye",
            ",",
            "smile",
            "."
        ],
        "preceding_context_tokens": [
            [
                "There",
                "were",
                "patches",
                "of",
                "dead",
                "grass",
                ",",
                "and",
                "areas",
                "with",
                "no",
                "grass",
                "at",
                "all",
                "."
            ],
            [
                "She",
                "chewed",
                "the",
                "inside",
                "of",
                "her",
                "cheek",
                "and",
                "closed",
                "her",
                "eyes",
                ",",
                "breathing",
                "in",
                "and",
                "out",
                "slowly",
                "."
            ],
            [
                "Suddenly",
                ",",
                "the",
                "areas",
                "that",
                "were",
                "missing",
                "grass",
                ",",
                "appeared",
                "and",
                "the",
                "rest",
                "turned",
                "a",
                "natural",
                "beautiful",
                "green",
                "color",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "there",
                "be",
                "patch",
                "of",
                "dead",
                "grass",
                ",",
                "and",
                "area",
                "with",
                "no",
                "grass",
                "at",
                "all",
                "."
            ],
            [
                "she",
                "chew",
                "the",
                "inside",
                "of",
                "she",
                "cheek",
                "and",
                "close",
                "she",
                "eye",
                ",",
                "breathe",
                "in",
                "and",
                "out",
                "slowly",
                "."
            ],
            [
                "suddenly",
                ",",
                "the",
                "area",
                "that",
                "be",
                "miss",
                "grass",
                ",",
                "appear",
                "and",
                "the",
                "rest",
                "turn",
                "a",
                "natural",
                "beautiful",
                "green",
                "color",
                "."
            ]
        ],
        "label": "Joy"
    },
    {
        "body_part_token_idx": 12,
        "sentence_id": "44f6d5e8-bbbe-338e-90dc-38adbdb69c9c",
        "tokens": [
            "As",
            "I",
            "looked",
            "up",
            "I",
            "could",
            "see",
            ",",
            "the",
            "sadness",
            "drown",
            "her",
            "eyes",
            "."
        ],
        "lemmatized_tokens": [
            "as",
            "I",
            "look",
            "up",
            "I",
            "could",
            "see",
            ",",
            "the",
            "sadness",
            "drown",
            "she",
            "eye",
            "."
        ],
        "preceding_context_tokens": [
            [
                "Silence",
                "suffocated",
                "the",
                "air",
                "."
            ],
            [
                "Words",
                "were",
                "held",
                "captive",
                "behind",
                "our",
                "lips",
                "."
            ],
            [
                "She",
                "forcefully",
                "put",
                "her",
                "hand",
                "on",
                "my",
                "shoulder",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "silence",
                "suffocate",
                "the",
                "air",
                "."
            ],
            [
                "word",
                "be",
                "hold",
                "captive",
                "behind",
                "we",
                "lip",
                "."
            ],
            [
                "she",
                "forcefully",
                "put",
                "she",
                "hand",
                "on",
                "my",
                "shoulder",
                "."
            ]
        ],
        "label": "Sadness"
    },
    {
        "body_part_token_idx": 6,
        "sentence_id": "4ef214bb-14c3-39e9-a4c5-4a7e74c15156",
        "tokens": [
            "``",
            "Fleur",
            "smiled",
            "and",
            "narrowed",
            "her",
            "eyes",
            ",",
            "also",
            "raising",
            "an",
            "eyebrow",
            "at",
            "her",
            "."
        ],
        "lemmatized_tokens": [
            "``",
            "Fleur",
            "smile",
            "and",
            "narrow",
            "she",
            "eye",
            ",",
            "also",
            "raise",
            "a",
            "eyebrow",
            "at",
            "she",
            "."
        ],
        "preceding_context_tokens": [
            [
                "Hermione",
                "raised",
                "her",
                "eyebrow",
                "at",
                "Fleur",
                "when",
                "she",
                "did",
                "n't",
                "appear",
                "to",
                "be",
                "catching",
                "on",
                "."
            ],
            [
                "``",
                "What",
                "'s",
                "wrong",
                ",",
                "Fleur",
                "?"
            ],
            [
                "Two",
                "left",
                "feet",
                "?"
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "Hermione",
                "raise",
                "she",
                "eyebrow",
                "at",
                "Fleur",
                "when",
                "she",
                "do",
                "not",
                "appear",
                "to",
                "be",
                "catch",
                "on",
                "."
            ],
            [
                "``",
                "what",
                "be",
                "wrong",
                ",",
                "Fleur",
                "?"
            ],
            [
                "two",
                "left",
                "foot",
                "?"
            ]
        ],
        "label": "Joy"
    },
    {
        "body_part_token_idx": 18,
        "sentence_id": "222cb81d-59a9-3a09-8887-7d5b8fb9ba07",
        "tokens": [
            "There",
            "was",
            "nothing",
            "I",
            "could",
            "do",
            ",",
            "all",
            "things",
            "were",
            "over",
            "Tears",
            "were",
            "starting",
            "to",
            "flow",
            "from",
            "my",
            "eyes",
            "."
        ],
        "lemmatized_tokens": [
            "there",
            "be",
            "nothing",
            "I",
            "could",
            "do",
            ",",
            "all",
            "thing",
            "be",
            "over",
            "tear",
            "be",
            "start",
            "to",
            "flow",
            "from",
            "my",
            "eye",
            "."
        ],
        "preceding_context_tokens": [
            [
                "She",
                "got",
                "married",
                "Raj",
                "!!!"
            ],
            [
                "and",
                "she",
                "cut",
                "the",
                "call",
                "I",
                "felt",
                "the",
                "world",
                "around",
                "me",
                "shatter",
                ",",
                "my",
                "heart",
                "became",
                "heavy",
                "."
            ],
            [
                "At",
                "that",
                "moment",
                "I",
                "wished",
                "the",
                "ground",
                "beneath",
                "me",
                "to",
                "devour",
                "me",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "she",
                "get",
                "married",
                "Raj",
                "!!!"
            ],
            [
                "and",
                "she",
                "cut",
                "the",
                "call",
                "I",
                "feel",
                "the",
                "world",
                "around",
                "I",
                "shatter",
                ",",
                "my",
                "heart",
                "become",
                "heavy",
                "."
            ],
            [
                "at",
                "that",
                "moment",
                "I",
                "wish",
                "the",
                "ground",
                "beneath",
                "I",
                "to",
                "devour",
                "I",
                "."
            ]
        ],
        "label": "Sadness"
    },
    {
        "body_part_token_idx": 13,
        "sentence_id": "95d82ea7-5723-3eed-bf44-62716dfa6961",
        "tokens": [
            "When",
            "the",
            "smile",
            "started",
            "to",
            "grow",
            "and",
            "her",
            "bottom",
            "lip",
            "trembled",
            ",",
            "her",
            "fingers",
            "went",
            "over",
            "her",
            "mouth",
            ",",
            "catching",
            "a",
            "gasp",
            "as",
            "the",
            "build",
            "up",
            "of",
            "emotion",
            "brought",
            "tears",
            "to",
            "her",
            "eyes",
            "."
        ],
        "lemmatized_tokens": [
            "when",
            "the",
            "smile",
            "start",
            "to",
            "grow",
            "and",
            "she",
            "bottom",
            "lip",
            "tremble",
            ",",
            "she",
            "finger",
            "go",
            "over",
            "she",
            "mouth",
            ",",
            "catch",
            "a",
            "gasp",
            "as",
            "the",
            "build",
            "up",
            "of",
            "emotion",
            "bring",
            "tear",
            "to",
            "she",
            "eye",
            "."
        ],
        "preceding_context_tokens": [
            [
                "For",
                "lack",
                "of",
                "an",
                "honest",
                "project",
                ",",
                "Tyrol",
                "had",
                "constructed",
                "the",
                "wooden",
                "support",
                "it",
                "stretched",
                "over",
                ",",
                "and",
                "the",
                "simple",
                "varnished",
                "frame",
                "that",
                "would",
                "later",
                "go",
                "around",
                "it",
                ",",
                "in",
                "just",
                "under",
                "an",
                "hour",
                "."
            ],
            [
                "He",
                "smiled",
                "as",
                "he",
                "handed",
                "her",
                "the",
                "new",
                "blank",
                "canvas",
                "."
            ],
            [
                "Even",
                "though",
                "she",
                "never",
                "told",
                "him",
                "what",
                "it",
                "was",
                "for",
                ",",
                "he",
                "seemed",
                "to",
                "know",
                "it",
                "would",
                "be",
                "a",
                "gift",
                "and",
                "he",
                "looked",
                "touched",
                "that",
                "he",
                "was",
                "a",
                "part",
                "of",
                "making",
                "someone",
                "happy.That",
                "someone",
                "'s",
                "eyes",
                "were",
                "shining",
                ",",
                "and",
                "a",
                "soft",
                "breath",
                "passed",
                "slowly",
                "through",
                "parted",
                "lips",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "for",
                "lack",
                "of",
                "a",
                "honest",
                "project",
                ",",
                "Tyrol",
                "have",
                "construct",
                "the",
                "wooden",
                "support",
                "it",
                "stretch",
                "over",
                ",",
                "and",
                "the",
                "simple",
                "varnish",
                "frame",
                "that",
                "would",
                "later",
                "go",
                "around",
                "it",
                ",",
                "in",
                "just",
                "under",
                "a",
                "hour",
                "."
            ],
            [
                "he",
                "smile",
                "as",
                "he",
                "hand",
                "she",
                "the",
                "new",
                "blank",
                "canvas",
                "."
            ],
            [
                "even",
                "though",
                "she",
                "never",
                "tell",
                "he",
                "what",
                "it",
                "be",
                "for",
                ",",
                "he",
                "seem",
                "to",
                "know",
                "it",
                "would",
                "be",
                "a",
                "gift",
                "and",
                "he",
                "look",
                "touch",
                "that",
                "he",
                "be",
                "a",
                "part",
                "of",
                "make",
                "someone",
                "happy.that",
                "someone",
                "'s",
                "eye",
                "be",
                "shine",
                ",",
                "and",
                "a",
                "soft",
                "breath",
                "pass",
                "slowly",
                "through",
                "part",
                "lip",
                "."
            ]
        ],
        "label": "Joy"
    },
    {
        "body_part_token_idx": 17,
        "sentence_id": "95d82ea7-5723-3eed-bf44-62716dfa6961",
        "tokens": [
            "When",
            "the",
            "smile",
            "started",
            "to",
            "grow",
            "and",
            "her",
            "bottom",
            "lip",
            "trembled",
            ",",
            "her",
            "fingers",
            "went",
            "over",
            "her",
            "mouth",
            ",",
            "catching",
            "a",
            "gasp",
            "as",
            "the",
            "build",
            "up",
            "of",
            "emotion",
            "brought",
            "tears",
            "to",
            "her",
            "eyes",
            "."
        ],
        "lemmatized_tokens": [
            "when",
            "the",
            "smile",
            "start",
            "to",
            "grow",
            "and",
            "she",
            "bottom",
            "lip",
            "tremble",
            ",",
            "she",
            "finger",
            "go",
            "over",
            "she",
            "mouth",
            ",",
            "catch",
            "a",
            "gasp",
            "as",
            "the",
            "build",
            "up",
            "of",
            "emotion",
            "bring",
            "tear",
            "to",
            "she",
            "eye",
            "."
        ],
        "preceding_context_tokens": [
            [
                "For",
                "lack",
                "of",
                "an",
                "honest",
                "project",
                ",",
                "Tyrol",
                "had",
                "constructed",
                "the",
                "wooden",
                "support",
                "it",
                "stretched",
                "over",
                ",",
                "and",
                "the",
                "simple",
                "varnished",
                "frame",
                "that",
                "would",
                "later",
                "go",
                "around",
                "it",
                ",",
                "in",
                "just",
                "under",
                "an",
                "hour",
                "."
            ],
            [
                "He",
                "smiled",
                "as",
                "he",
                "handed",
                "her",
                "the",
                "new",
                "blank",
                "canvas",
                "."
            ],
            [
                "Even",
                "though",
                "she",
                "never",
                "told",
                "him",
                "what",
                "it",
                "was",
                "for",
                ",",
                "he",
                "seemed",
                "to",
                "know",
                "it",
                "would",
                "be",
                "a",
                "gift",
                "and",
                "he",
                "looked",
                "touched",
                "that",
                "he",
                "was",
                "a",
                "part",
                "of",
                "making",
                "someone",
                "happy.That",
                "someone",
                "'s",
                "eyes",
                "were",
                "shining",
                ",",
                "and",
                "a",
                "soft",
                "breath",
                "passed",
                "slowly",
                "through",
                "parted",
                "lips",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "for",
                "lack",
                "of",
                "a",
                "honest",
                "project",
                ",",
                "Tyrol",
                "have",
                "construct",
                "the",
                "wooden",
                "support",
                "it",
                "stretch",
                "over",
                ",",
                "and",
                "the",
                "simple",
                "varnish",
                "frame",
                "that",
                "would",
                "later",
                "go",
                "around",
                "it",
                ",",
                "in",
                "just",
                "under",
                "a",
                "hour",
                "."
            ],
            [
                "he",
                "smile",
                "as",
                "he",
                "hand",
                "she",
                "the",
                "new",
                "blank",
                "canvas",
                "."
            ],
            [
                "even",
                "though",
                "she",
                "never",
                "tell",
                "he",
                "what",
                "it",
                "be",
                "for",
                ",",
                "he",
                "seem",
                "to",
                "know",
                "it",
                "would",
                "be",
                "a",
                "gift",
                "and",
                "he",
                "look",
                "touch",
                "that",
                "he",
                "be",
                "a",
                "part",
                "of",
                "make",
                "someone",
                "happy.that",
                "someone",
                "'s",
                "eye",
                "be",
                "shine",
                ",",
                "and",
                "a",
                "soft",
                "breath",
                "pass",
                "slowly",
                "through",
                "part",
                "lip",
                "."
            ]
        ],
        "label": "Joy"
    },
    {
        "body_part_token_idx": 32,
        "sentence_id": "95d82ea7-5723-3eed-bf44-62716dfa6961",
        "tokens": [
            "When",
            "the",
            "smile",
            "started",
            "to",
            "grow",
            "and",
            "her",
            "bottom",
            "lip",
            "trembled",
            ",",
            "her",
            "fingers",
            "went",
            "over",
            "her",
            "mouth",
            ",",
            "catching",
            "a",
            "gasp",
            "as",
            "the",
            "build",
            "up",
            "of",
            "emotion",
            "brought",
            "tears",
            "to",
            "her",
            "eyes",
            "."
        ],
        "lemmatized_tokens": [
            "when",
            "the",
            "smile",
            "start",
            "to",
            "grow",
            "and",
            "she",
            "bottom",
            "lip",
            "tremble",
            ",",
            "she",
            "finger",
            "go",
            "over",
            "she",
            "mouth",
            ",",
            "catch",
            "a",
            "gasp",
            "as",
            "the",
            "build",
            "up",
            "of",
            "emotion",
            "bring",
            "tear",
            "to",
            "she",
            "eye",
            "."
        ],
        "preceding_context_tokens": [
            [
                "For",
                "lack",
                "of",
                "an",
                "honest",
                "project",
                ",",
                "Tyrol",
                "had",
                "constructed",
                "the",
                "wooden",
                "support",
                "it",
                "stretched",
                "over",
                ",",
                "and",
                "the",
                "simple",
                "varnished",
                "frame",
                "that",
                "would",
                "later",
                "go",
                "around",
                "it",
                ",",
                "in",
                "just",
                "under",
                "an",
                "hour",
                "."
            ],
            [
                "He",
                "smiled",
                "as",
                "he",
                "handed",
                "her",
                "the",
                "new",
                "blank",
                "canvas",
                "."
            ],
            [
                "Even",
                "though",
                "she",
                "never",
                "told",
                "him",
                "what",
                "it",
                "was",
                "for",
                ",",
                "he",
                "seemed",
                "to",
                "know",
                "it",
                "would",
                "be",
                "a",
                "gift",
                "and",
                "he",
                "looked",
                "touched",
                "that",
                "he",
                "was",
                "a",
                "part",
                "of",
                "making",
                "someone",
                "happy.That",
                "someone",
                "'s",
                "eyes",
                "were",
                "shining",
                ",",
                "and",
                "a",
                "soft",
                "breath",
                "passed",
                "slowly",
                "through",
                "parted",
                "lips",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "for",
                "lack",
                "of",
                "a",
                "honest",
                "project",
                ",",
                "Tyrol",
                "have",
                "construct",
                "the",
                "wooden",
                "support",
                "it",
                "stretch",
                "over",
                ",",
                "and",
                "the",
                "simple",
                "varnish",
                "frame",
                "that",
                "would",
                "later",
                "go",
                "around",
                "it",
                ",",
                "in",
                "just",
                "under",
                "a",
                "hour",
                "."
            ],
            [
                "he",
                "smile",
                "as",
                "he",
                "hand",
                "she",
                "the",
                "new",
                "blank",
                "canvas",
                "."
            ],
            [
                "even",
                "though",
                "she",
                "never",
                "tell",
                "he",
                "what",
                "it",
                "be",
                "for",
                ",",
                "he",
                "seem",
                "to",
                "know",
                "it",
                "would",
                "be",
                "a",
                "gift",
                "and",
                "he",
                "look",
                "touch",
                "that",
                "he",
                "be",
                "a",
                "part",
                "of",
                "make",
                "someone",
                "happy.that",
                "someone",
                "'s",
                "eye",
                "be",
                "shine",
                ",",
                "and",
                "a",
                "soft",
                "breath",
                "pass",
                "slowly",
                "through",
                "part",
                "lip",
                "."
            ]
        ],
        "label": "Joy"
    },
    {
        "body_part_token_idx": 10,
        "sentence_id": "2cee5d7b-b724-318b-a89b-5bbf509c149f",
        "tokens": [
            "He",
            "collapsed",
            "next",
            "to",
            "the",
            "worthless",
            "box",
            ",",
            "placed",
            "his",
            "face",
            "in",
            "his",
            "weathered",
            "hands",
            ",",
            "tears",
            "slowly",
            "peeking",
            "out",
            "from",
            "the",
            "spaces",
            "between",
            "his",
            "fingers",
            "."
        ],
        "lemmatized_tokens": [
            "he",
            "collapse",
            "next",
            "to",
            "the",
            "worthless",
            "box",
            ",",
            "place",
            "he",
            "face",
            "in",
            "he",
            "weathered",
            "hand",
            ",",
            "tear",
            "slowly",
            "peek",
            "out",
            "from",
            "the",
            "space",
            "between",
            "he",
            "finger",
            "."
        ],
        "preceding_context_tokens": [
            [
                "It",
                "dripped",
                "off",
                "the",
                "petals",
                "of",
                "the",
                "violets",
                ",",
                "meeting",
                "the",
                "green",
                "of",
                "the",
                "grass",
                "in",
                "a",
                "brief",
                "and",
                "awkward",
                "clashing",
                "of",
                "colors",
                "before",
                "the",
                "soil",
                "drank",
                "it",
                "up",
                "forever",
                "."
            ],
            [
                "The",
                "lavender",
                ",",
                "smelling",
                "the",
                "change",
                "in",
                "the",
                "air",
                ",",
                "followed",
                "suit",
                "."
            ],
            [
                "A",
                "humble",
                "fruit",
                "seller",
                ",",
                "already",
                "distraught",
                "over",
                "losing",
                "customers",
                "to",
                "faceless",
                "corporate",
                "nothings",
                ",",
                "opened",
                "a",
                "crate",
                "of",
                "grapes",
                "to",
                "find",
                "them",
                "all",
                "black",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "it",
                "drip",
                "off",
                "the",
                "petal",
                "of",
                "the",
                "violet",
                ",",
                "meet",
                "the",
                "green",
                "of",
                "the",
                "grass",
                "in",
                "a",
                "brief",
                "and",
                "awkward",
                "clash",
                "of",
                "color",
                "before",
                "the",
                "soil",
                "drink",
                "it",
                "up",
                "forever",
                "."
            ],
            [
                "the",
                "lavender",
                ",",
                "smell",
                "the",
                "change",
                "in",
                "the",
                "air",
                ",",
                "follow",
                "suit",
                "."
            ],
            [
                "a",
                "humble",
                "fruit",
                "seller",
                ",",
                "already",
                "distraught",
                "over",
                "lose",
                "customer",
                "to",
                "faceless",
                "corporate",
                "nothing",
                ",",
                "open",
                "a",
                "crate",
                "of",
                "grape",
                "to",
                "find",
                "they",
                "all",
                "black",
                "."
            ]
        ],
        "label": "Sadness"
    },
    {
        "body_part_token_idx": 25,
        "sentence_id": "2cee5d7b-b724-318b-a89b-5bbf509c149f",
        "tokens": [
            "He",
            "collapsed",
            "next",
            "to",
            "the",
            "worthless",
            "box",
            ",",
            "placed",
            "his",
            "face",
            "in",
            "his",
            "weathered",
            "hands",
            ",",
            "tears",
            "slowly",
            "peeking",
            "out",
            "from",
            "the",
            "spaces",
            "between",
            "his",
            "fingers",
            "."
        ],
        "lemmatized_tokens": [
            "he",
            "collapse",
            "next",
            "to",
            "the",
            "worthless",
            "box",
            ",",
            "place",
            "he",
            "face",
            "in",
            "he",
            "weathered",
            "hand",
            ",",
            "tear",
            "slowly",
            "peek",
            "out",
            "from",
            "the",
            "space",
            "between",
            "he",
            "finger",
            "."
        ],
        "preceding_context_tokens": [
            [
                "It",
                "dripped",
                "off",
                "the",
                "petals",
                "of",
                "the",
                "violets",
                ",",
                "meeting",
                "the",
                "green",
                "of",
                "the",
                "grass",
                "in",
                "a",
                "brief",
                "and",
                "awkward",
                "clashing",
                "of",
                "colors",
                "before",
                "the",
                "soil",
                "drank",
                "it",
                "up",
                "forever",
                "."
            ],
            [
                "The",
                "lavender",
                ",",
                "smelling",
                "the",
                "change",
                "in",
                "the",
                "air",
                ",",
                "followed",
                "suit",
                "."
            ],
            [
                "A",
                "humble",
                "fruit",
                "seller",
                ",",
                "already",
                "distraught",
                "over",
                "losing",
                "customers",
                "to",
                "faceless",
                "corporate",
                "nothings",
                ",",
                "opened",
                "a",
                "crate",
                "of",
                "grapes",
                "to",
                "find",
                "them",
                "all",
                "black",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "it",
                "drip",
                "off",
                "the",
                "petal",
                "of",
                "the",
                "violet",
                ",",
                "meet",
                "the",
                "green",
                "of",
                "the",
                "grass",
                "in",
                "a",
                "brief",
                "and",
                "awkward",
                "clash",
                "of",
                "color",
                "before",
                "the",
                "soil",
                "drink",
                "it",
                "up",
                "forever",
                "."
            ],
            [
                "the",
                "lavender",
                ",",
                "smell",
                "the",
                "change",
                "in",
                "the",
                "air",
                ",",
                "follow",
                "suit",
                "."
            ],
            [
                "a",
                "humble",
                "fruit",
                "seller",
                ",",
                "already",
                "distraught",
                "over",
                "lose",
                "customer",
                "to",
                "faceless",
                "corporate",
                "nothing",
                ",",
                "open",
                "a",
                "crate",
                "of",
                "grape",
                "to",
                "find",
                "they",
                "all",
                "black",
                "."
            ]
        ],
        "label": "Sadness"
    },
    {
        "body_part_token_idx": 13,
        "sentence_id": "1fac83e5-772f-3fa8-b28e-0888189f7116",
        "tokens": [
            "In",
            "my",
            "brain",
            ",",
            "I",
            "knew",
            "it",
            "'s",
            "nothing",
            "serious",
            ",",
            "but",
            "my",
            "eyes",
            "darted",
            "away",
            "while",
            "my",
            "hands",
            "looked",
            "for",
            "something",
            "to",
            "occupy",
            "automatically",
            "."
        ],
        "lemmatized_tokens": [
            "in",
            "my",
            "brain",
            ",",
            "I",
            "know",
            "it",
            "be",
            "nothing",
            "serious",
            ",",
            "but",
            "my",
            "eye",
            "dart",
            "away",
            "while",
            "my",
            "hand",
            "look",
            "for",
            "something",
            "to",
            "occupy",
            "automatically",
            "."
        ],
        "preceding_context_tokens": [
            [
                "What",
                "kind",
                "of",
                "dream",
                "?",
                "''"
            ],
            [
                "I",
                "asked",
                "."
            ],
            [
                "Ever",
                "since",
                "yesterday",
                ",",
                "I",
                "could",
                "n't",
                "bring",
                "myself",
                "to",
                "make",
                "eye",
                "contact",
                "with",
                "Jaejoong",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "what",
                "kind",
                "of",
                "dream",
                "?",
                "''"
            ],
            [
                "I",
                "ask",
                "."
            ],
            [
                "ever",
                "since",
                "yesterday",
                ",",
                "I",
                "could",
                "not",
                "bring",
                "myself",
                "to",
                "make",
                "eye",
                "contact",
                "with",
                "Jaejoong",
                "."
            ]
        ],
        "label": "Fear"
    },
    {
        "body_part_token_idx": 18,
        "sentence_id": "1fac83e5-772f-3fa8-b28e-0888189f7116",
        "tokens": [
            "In",
            "my",
            "brain",
            ",",
            "I",
            "knew",
            "it",
            "'s",
            "nothing",
            "serious",
            ",",
            "but",
            "my",
            "eyes",
            "darted",
            "away",
            "while",
            "my",
            "hands",
            "looked",
            "for",
            "something",
            "to",
            "occupy",
            "automatically",
            "."
        ],
        "lemmatized_tokens": [
            "in",
            "my",
            "brain",
            ",",
            "I",
            "know",
            "it",
            "be",
            "nothing",
            "serious",
            ",",
            "but",
            "my",
            "eye",
            "dart",
            "away",
            "while",
            "my",
            "hand",
            "look",
            "for",
            "something",
            "to",
            "occupy",
            "automatically",
            "."
        ],
        "preceding_context_tokens": [
            [
                "What",
                "kind",
                "of",
                "dream",
                "?",
                "''"
            ],
            [
                "I",
                "asked",
                "."
            ],
            [
                "Ever",
                "since",
                "yesterday",
                ",",
                "I",
                "could",
                "n't",
                "bring",
                "myself",
                "to",
                "make",
                "eye",
                "contact",
                "with",
                "Jaejoong",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "what",
                "kind",
                "of",
                "dream",
                "?",
                "''"
            ],
            [
                "I",
                "ask",
                "."
            ],
            [
                "ever",
                "since",
                "yesterday",
                ",",
                "I",
                "could",
                "not",
                "bring",
                "myself",
                "to",
                "make",
                "eye",
                "contact",
                "with",
                "Jaejoong",
                "."
            ]
        ],
        "label": "Fear"
    },
    {
        "body_part_token_idx": 27,
        "sentence_id": "a346ea13-5bbf-3cbe-89a3-25f6163cde52",
        "tokens": [
            "I",
            "never",
            "cease",
            "to",
            "enjoy",
            "the",
            "look",
            "on",
            "my",
            "son",
            "'s",
            "face",
            "as",
            "he",
            "comes",
            "downstairs",
            ",",
            "still",
            "half",
            "asleep",
            ",",
            "with",
            "a",
            "victorious",
            "smile",
            "on",
            "his",
            "face",
            "knowing",
            "that",
            "it",
            "is",
            "another",
            "`",
            "no",
            "school",
            "'",
            "day",
            "."
        ],
        "lemmatized_tokens": [
            "I",
            "never",
            "cease",
            "to",
            "enjoy",
            "the",
            "look",
            "on",
            "my",
            "son",
            "'s",
            "face",
            "as",
            "he",
            "come",
            "downstairs",
            ",",
            "still",
            "half",
            "asleep",
            ",",
            "with",
            "a",
            "victorious",
            "smile",
            "on",
            "he",
            "face",
            "know",
            "that",
            "it",
            "be",
            "another",
            "`",
            "no",
            "school",
            "'",
            "day",
            "."
        ],
        "preceding_context_tokens": [
            [
                "Its",
                "yet",
                "another",
                "day",
                "of",
                "snow",
                "storm",
                "."
            ],
            [
                "Schools",
                "and",
                "offices",
                "are",
                "closed",
                ",",
                "snow",
                "plowers",
                "are",
                "out",
                "on",
                "the",
                "roads",
                ",",
                "flights",
                "are",
                "canceled",
                ",",
                "and",
                "another",
                "frenzy",
                "on",
                "the",
                "news",
                "as",
                "if",
                "the",
                "world",
                "is",
                "coming",
                "to",
                "an",
                "end",
                "!"
            ],
            [
                "But",
                "underneath",
                "the",
                "whole",
                "drama",
                ",",
                "people",
                "living",
                "here",
                "in",
                "US",
                ",",
                "celebrate",
                "such",
                "snow",
                "storms",
                "more",
                "than",
                "anything",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "its",
                "yet",
                "another",
                "day",
                "of",
                "snow",
                "storm",
                "."
            ],
            [
                "school",
                "and",
                "office",
                "be",
                "close",
                ",",
                "snow",
                "plower",
                "be",
                "out",
                "on",
                "the",
                "road",
                ",",
                "flight",
                "be",
                "cancel",
                ",",
                "and",
                "another",
                "frenzy",
                "on",
                "the",
                "news",
                "as",
                "if",
                "the",
                "world",
                "be",
                "come",
                "to",
                "a",
                "end",
                "!"
            ],
            [
                "but",
                "underneath",
                "the",
                "whole",
                "drama",
                ",",
                "people",
                "live",
                "here",
                "in",
                "US",
                ",",
                "celebrate",
                "such",
                "snow",
                "storm",
                "more",
                "than",
                "anything",
                "."
            ]
        ],
        "label": "Joy"
    },
    {
        "body_part_token_idx": 4,
        "sentence_id": "5573dd7c-e768-3a92-bfac-b9649fe050b4",
        "tokens": [
            "``",
            "I",
            "rolled",
            "my",
            "eyes",
            "to",
            "the",
            "heavens",
            "."
        ],
        "lemmatized_tokens": [
            "``",
            "I",
            "roll",
            "my",
            "eye",
            "to",
            "the",
            "heaven",
            "."
        ],
        "preceding_context_tokens": [
            [
                "``",
                "Jesus",
                "Christ",
                "."
            ],
            [
                "Typically",
                ",",
                "your",
                "father",
                "has",
                "already",
                "taken",
                "your",
                "side",
                "."
            ],
            [
                "I",
                "told",
                "him",
                "though",
                ",",
                "if",
                "he",
                "only",
                "knew",
                "what",
                "you",
                "were",
                "really",
                "like",
                ",",
                "he",
                "would",
                "n't",
                "be",
                "thinking",
                "like",
                "that",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "``",
                "Jesus",
                "Christ",
                "."
            ],
            [
                "typically",
                ",",
                "you",
                "father",
                "have",
                "already",
                "take",
                "you",
                "side",
                "."
            ],
            [
                "I",
                "tell",
                "he",
                "though",
                ",",
                "if",
                "he",
                "only",
                "know",
                "what",
                "you",
                "be",
                "really",
                "like",
                ",",
                "he",
                "would",
                "not",
                "be",
                "think",
                "like",
                "that",
                "."
            ]
        ],
        "label": "Disgust"
    },
    {
        "body_part_token_idx": 7,
        "sentence_id": "643f6cb1-211b-3b44-8c17-9fa4b49933db",
        "tokens": [
            "The",
            "expression",
            "so",
            "familiar",
            "He",
            "rolled",
            "his",
            "eyes",
            "."
        ],
        "lemmatized_tokens": [
            "the",
            "expression",
            "so",
            "familiar",
            "he",
            "roll",
            "he",
            "eye",
            "."
        ],
        "preceding_context_tokens": [
            [
                "Her",
                "eyes",
                "darted",
                "again",
                "the",
                "older",
                "man",
                ",",
                "Logan",
                ",",
                "now",
                "spluttering",
                "in",
                "apoplectic",
                "rage",
                "."
            ],
            [
                "So",
                "did",
                "Alec",
                "'s",
                "."
            ],
            [
                "She",
                "looked",
                "back",
                "at",
                "the",
                "transgenic",
                "at",
                "her",
                "side",
                "in",
                "time",
                "to",
                "catch",
                "him",
                "rolling",
                "his",
                "eyes",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "she",
                "eye",
                "dart",
                "again",
                "the",
                "older",
                "man",
                ",",
                "Logan",
                ",",
                "now",
                "splutter",
                "in",
                "apoplectic",
                "rage",
                "."
            ],
            [
                "so",
                "do",
                "Alec",
                "'s",
                "."
            ],
            [
                "she",
                "look",
                "back",
                "at",
                "the",
                "transgenic",
                "at",
                "she",
                "side",
                "in",
                "time",
                "to",
                "catch",
                "he",
                "roll",
                "he",
                "eye",
                "."
            ]
        ],
        "label": "Disgust"
    },
    {
        "body_part_token_idx": 10,
        "sentence_id": "303cb3ee-022f-31ad-aada-2390d1cd2ac7",
        "tokens": [
            "At",
            "sight",
            "of",
            "her",
            ",",
            "the",
            "girl",
            "threw",
            "back",
            "her",
            "head",
            "and",
            "screamed",
            "."
        ],
        "lemmatized_tokens": [
            "at",
            "sight",
            "of",
            "she",
            ",",
            "the",
            "girl",
            "throw",
            "back",
            "she",
            "head",
            "and",
            "scream",
            "."
        ],
        "preceding_context_tokens": [
            [
                "But",
                "now",
                "the",
                "wailing",
                "did",
                "not",
                "stop",
                "."
            ],
            [
                "It",
                "was",
                "growing",
                "to",
                "a",
                "strength",
                "that",
                "could",
                "have",
                "shook",
                "the",
                "very",
                "earth",
                "."
            ],
            [
                "The",
                "girl",
                "gazed",
                "down",
                "the",
                "line",
                "and",
                "saw",
                "a",
                "woman",
                "approaching",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "but",
                "now",
                "the",
                "wail",
                "do",
                "not",
                "stop",
                "."
            ],
            [
                "it",
                "be",
                "grow",
                "to",
                "a",
                "strength",
                "that",
                "could",
                "have",
                "shake",
                "the",
                "very",
                "earth",
                "."
            ],
            [
                "the",
                "girl",
                "gaze",
                "down",
                "the",
                "line",
                "and",
                "see",
                "a",
                "woman",
                "approach",
                "."
            ]
        ],
        "label": "Fear"
    },
    {
        "body_part_token_idx": 1,
        "sentence_id": "03eb7bc7-3a39-362a-8860-b558536331c4",
        "tokens": [
            "My",
            "fingers",
            "are",
            "crossed",
            "!"
        ],
        "lemmatized_tokens": [
            "my",
            "finger",
            "be",
            "cross",
            "!"
        ],
        "preceding_context_tokens": [
            [
                "It",
                "is",
                "so",
                "frustrating",
                "!"
            ],
            [
                "And",
                "we",
                "are",
                "so",
                "tired",
                "!!!"
            ],
            [
                "Maybe",
                "all",
                "the",
                "running",
                "he",
                "did",
                "today",
                "will",
                "help",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "it",
                "be",
                "so",
                "frustrating",
                "!"
            ],
            [
                "and",
                "we",
                "be",
                "so",
                "tired",
                "!!!"
            ],
            [
                "maybe",
                "all",
                "the",
                "running",
                "he",
                "do",
                "today",
                "will",
                "help",
                "."
            ]
        ],
        "label": "Anger"
    },
    {
        "body_part_token_idx": 13,
        "sentence_id": "6058f820-c464-35be-89e2-720e9e7d5d87",
        "tokens": [
            "Natalie",
            "felt",
            "herself",
            "freeze",
            "for",
            "a",
            "moment",
            "as",
            "a",
            "sensation",
            "spread",
            "from",
            "her",
            "stomach",
            "and",
            "out",
            "through",
            "the",
            "rest",
            "of",
            "her",
            "body",
            "quickly",
            ",",
            "like",
            "a",
            "high",
            "pitched",
            "note",
            "that",
            "fluttered",
            "on",
            "giant",
            "wings",
            "."
        ],
        "lemmatized_tokens": [
            "Natalie",
            "feel",
            "herself",
            "freeze",
            "for",
            "a",
            "moment",
            "as",
            "a",
            "sensation",
            "spread",
            "from",
            "she",
            "stomach",
            "and",
            "out",
            "through",
            "the",
            "rest",
            "of",
            "she",
            "body",
            "quickly",
            ",",
            "like",
            "a",
            "high",
            "pitch",
            "note",
            "that",
            "flutter",
            "on",
            "giant",
            "wing",
            "."
        ],
        "preceding_context_tokens": [
            [
                "I",
                "would",
                "n't",
                "be",
                "willing",
                "to",
                "force",
                "him",
                "into",
                "doing",
                "what",
                "he",
                "does",
                "n't",
                "want",
                "to",
                "do",
                "just",
                "because",
                "we",
                "may",
                "think",
                "its",
                "best",
                "for",
                "him",
                "."
            ],
            [
                "Maybe",
                "its",
                "not",
                "...",
                "maybe",
                "he",
                "just",
                "wants",
                "it",
                "to",
                "be",
                "you",
                "and",
                "me",
                "...",
                "I",
                "do",
                "n't",
                "know",
                ".",
                "''"
            ],
            [
                "He",
                "then",
                "opened",
                "his",
                "eyes",
                "again",
                "an",
                "wrapped",
                "a",
                "heavy",
                "arm",
                "around",
                "Natalie",
                "'s",
                "waist",
                ",",
                "then",
                "held",
                "her",
                "snugly",
                "before",
                "he",
                "said",
                ",",
                "``",
                "But",
                "for",
                "now",
                "...",
                "let",
                "me",
                "just",
                "...",
                "worry",
                "about",
                "you",
                "and",
                "how",
                "much",
                "I",
                "need",
                "you",
                ".",
                "''"
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "I",
                "would",
                "not",
                "be",
                "willing",
                "to",
                "force",
                "he",
                "into",
                "do",
                "what",
                "he",
                "do",
                "not",
                "want",
                "to",
                "do",
                "just",
                "because",
                "we",
                "may",
                "think",
                "its",
                "best",
                "for",
                "he",
                "."
            ],
            [
                "maybe",
                "its",
                "not",
                "...",
                "maybe",
                "he",
                "just",
                "want",
                "it",
                "to",
                "be",
                "you",
                "and",
                "I",
                "...",
                "I",
                "do",
                "not",
                "know",
                ".",
                "''"
            ],
            [
                "he",
                "then",
                "open",
                "he",
                "eye",
                "again",
                "a",
                "wrap",
                "a",
                "heavy",
                "arm",
                "around",
                "Natalie",
                "'s",
                "waist",
                ",",
                "then",
                "hold",
                "she",
                "snugly",
                "before",
                "he",
                "say",
                ",",
                "``",
                "but",
                "for",
                "now",
                "...",
                "let",
                "I",
                "just",
                "...",
                "worry",
                "about",
                "you",
                "and",
                "how",
                "much",
                "I",
                "need",
                "you",
                ".",
                "''"
            ]
        ],
        "label": "Joy"
    },
    {
        "body_part_token_idx": 1,
        "sentence_id": "2028626d-e178-3479-8ba9-84c53f9f834d",
        "tokens": [
            "My",
            "face",
            "was",
            "one",
            "big",
            "smile",
            "as",
            "I",
            "passed",
            "him",
            ",",
            "locking",
            "eyes",
            "for",
            "the",
            "breifest",
            "of",
            "moments",
            ".",
            "''"
        ],
        "lemmatized_tokens": [
            "my",
            "face",
            "be",
            "one",
            "big",
            "smile",
            "as",
            "I",
            "pass",
            "he",
            ",",
            "lock",
            "eye",
            "for",
            "the",
            "breifest",
            "of",
            "moment",
            ".",
            "''"
        ],
        "preceding_context_tokens": [
            [
                "Our",
                "eyes",
                "met",
                "as",
                "I",
                "was",
                "in",
                "between",
                "turns",
                "."
            ],
            [
                "He",
                "had",
                "a",
                "great",
                "big",
                "smile",
                "on",
                "his",
                "face",
                ",",
                "perhaps",
                "in",
                "response",
                "to",
                "the",
                "one",
                "on",
                "my",
                "face",
                ",",
                "though",
                "I",
                "was",
                "unaware",
                "of",
                "smiling",
                "at",
                "that",
                "moment",
                "."
            ],
            [
                "But",
                "upon",
                "seeing",
                "him",
                ",",
                "it",
                "was",
                "as",
                "if",
                "I",
                "suddenly",
                "landed",
                "back",
                "in",
                "my",
                "body",
                "only",
                "to",
                "be",
                "flodded",
                "with",
                "a",
                "huge",
                "rush",
                "of",
                "exploding",
                ",",
                "unbelieveable",
                "joy",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "we",
                "eye",
                "meet",
                "as",
                "I",
                "be",
                "in",
                "between",
                "turn",
                "."
            ],
            [
                "he",
                "have",
                "a",
                "great",
                "big",
                "smile",
                "on",
                "he",
                "face",
                ",",
                "perhaps",
                "in",
                "response",
                "to",
                "the",
                "one",
                "on",
                "my",
                "face",
                ",",
                "though",
                "I",
                "be",
                "unaware",
                "of",
                "smile",
                "at",
                "that",
                "moment",
                "."
            ],
            [
                "but",
                "upon",
                "see",
                "he",
                ",",
                "it",
                "be",
                "as",
                "if",
                "I",
                "suddenly",
                "land",
                "back",
                "in",
                "my",
                "body",
                "only",
                "to",
                "be",
                "flodd",
                "with",
                "a",
                "huge",
                "rush",
                "of",
                "explode",
                ",",
                "unbelieveable",
                "joy",
                "."
            ]
        ],
        "label": "Joy"
    },
    {
        "body_part_token_idx": 11,
        "sentence_id": "f7781e02-cfc6-3baa-816d-dadafbc3eb8f",
        "tokens": [
            "I",
            "arrived",
            "at",
            "Penny",
            "'s",
            "doorstep",
            ",",
            "tears",
            "streaming",
            "down",
            "my",
            "face",
            "."
        ],
        "lemmatized_tokens": [
            "I",
            "arrive",
            "at",
            "penny",
            "'s",
            "doorstep",
            ",",
            "tear",
            "stream",
            "down",
            "my",
            "face",
            "."
        ],
        "preceding_context_tokens": [
            [
                "I",
                "was",
                "so",
                "hurt",
                "by",
                "them",
                ",",
                "I",
                "ran",
                "to",
                "my",
                "only",
                "true",
                "friend",
                "."
            ],
            [
                "Sure",
                "I",
                "started",
                "out",
                "hanging",
                "out",
                "with",
                "her",
                "just",
                "because",
                "of",
                "Captain",
                "Hammer",
                ",",
                "but",
                "things",
                "changed",
                "."
            ],
            [
                "I",
                "changed",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "I",
                "be",
                "so",
                "hurt",
                "by",
                "they",
                ",",
                "I",
                "run",
                "to",
                "my",
                "only",
                "true",
                "friend",
                "."
            ],
            [
                "sure",
                "I",
                "start",
                "out",
                "hang",
                "out",
                "with",
                "she",
                "just",
                "because",
                "of",
                "Captain",
                "Hammer",
                ",",
                "but",
                "thing",
                "change",
                "."
            ],
            [
                "I",
                "change",
                "."
            ]
        ],
        "label": "Sadness"
    },
    {
        "body_part_token_idx": 3,
        "sentence_id": "15ed0682-db68-3c61-8172-dbee50a79e5f",
        "tokens": [
            "Onew",
            "bit",
            "his",
            "lip",
            "."
        ],
        "lemmatized_tokens": [
            "Onew",
            "bite",
            "he",
            "lip",
            "."
        ],
        "preceding_context_tokens": [
            [
                "Yes",
                ",",
                "he",
                "remembered",
                "everything",
                "."
            ],
            [
                "``",
                "So",
                "...",
                "what",
                "do",
                "we",
                "do",
                "now",
                "?",
                "''"
            ],
            [
                "Key",
                "shuffled",
                "around",
                ",",
                "finding",
                "his",
                "boxers",
                "and",
                "tank",
                "and",
                "slipping",
                "into",
                "them",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "yes",
                ",",
                "he",
                "remember",
                "everything",
                "."
            ],
            [
                "``",
                "so",
                "...",
                "what",
                "do",
                "we",
                "do",
                "now",
                "?",
                "''"
            ],
            [
                "key",
                "shuffle",
                "around",
                ",",
                "find",
                "he",
                "boxer",
                "and",
                "tank",
                "and",
                "slip",
                "into",
                "they",
                "."
            ]
        ],
        "label": "Fear"
    },
    {
        "body_part_token_idx": 10,
        "sentence_id": "475562ab-87a7-3b84-90d4-789128161f73",
        "tokens": [
            "She",
            "focused",
            "her",
            "attention",
            "on",
            "her",
            "burger",
            "and",
            "crossed",
            "her",
            "ankles",
            "beneath",
            "the",
            "cafe",
            "table",
            ",",
            "turning",
            "slightly",
            "away",
            "from",
            "me",
            "in",
            "the",
            "classic",
            "``",
            "shut",
            "up",
            "and",
            "leave",
            "me",
            "alone",
            "''",
            "Lucy",
            "pose",
            "."
        ],
        "lemmatized_tokens": [
            "she",
            "focus",
            "she",
            "attention",
            "on",
            "she",
            "burger",
            "and",
            "cross",
            "she",
            "ankle",
            "beneath",
            "the",
            "cafe",
            "table",
            ",",
            "turn",
            "slightly",
            "away",
            "from",
            "I",
            "in",
            "the",
            "classic",
            "``",
            "shut",
            "up",
            "and",
            "leave",
            "I",
            "alone",
            "''",
            "Lucy",
            "pose",
            "."
        ],
        "preceding_context_tokens": [
            [
                "It",
                "was",
                "just",
                "another",
                "sign",
                "that",
                "things",
                "were",
                "Wrong",
                "with",
                "a",
                "capital",
                "``",
                "W",
                "''",
                "and",
                "Lucy",
                "could",
                "n't",
                "ignore",
                "them",
                "anymore",
                "."
            ],
            [
                "``",
                "Sorry",
                ",",
                "''",
                "I",
                "muttered",
                "."
            ],
            [
                "``",
                "Whatever",
                ".",
                "''"
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "it",
                "be",
                "just",
                "another",
                "sign",
                "that",
                "thing",
                "be",
                "wrong",
                "with",
                "a",
                "capital",
                "``",
                "W",
                "''",
                "and",
                "Lucy",
                "could",
                "not",
                "ignore",
                "they",
                "anymore",
                "."
            ],
            [
                "``",
                "sorry",
                ",",
                "''",
                "I",
                "mutter",
                "."
            ],
            [
                "``",
                "whatever",
                ".",
                "''"
            ]
        ],
        "label": "Anger"
    },
    {
        "body_part_token_idx": 1,
        "sentence_id": "fe7013a2-5e15-3346-8b2b-58d0d5cbd74a",
        "tokens": [
            "My",
            "head",
            "pounded",
            "and",
            "my",
            "lips",
            "were",
            "chalky",
            ";",
            "that",
            "was",
            "a",
            "good",
            "sign",
            "."
        ],
        "lemmatized_tokens": [
            "my",
            "head",
            "pound",
            "and",
            "my",
            "lip",
            "be",
            "chalky",
            ";",
            "that",
            "be",
            "a",
            "good",
            "sign",
            "."
        ],
        "preceding_context_tokens": [
            [
                "His",
                "face",
                "was",
                "pale",
                "with",
                "sunken",
                "black",
                "eyes",
                "hidden",
                "far",
                "behind",
                "his",
                "cheek",
                "bones",
                "."
            ],
            [
                "Veins",
                "ran",
                "along",
                "either",
                "side",
                "of",
                "his",
                "forehead",
                "."
            ],
            [
                "I",
                "stared",
                "back",
                "at",
                "that",
                "face",
                "with",
                "the",
                "weight",
                "of",
                "the",
                "world",
                "on",
                "my",
                "shoulders",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "he",
                "face",
                "be",
                "pale",
                "with",
                "sink",
                "black",
                "eye",
                "hide",
                "far",
                "behind",
                "he",
                "cheek",
                "bone",
                "."
            ],
            [
                "vein",
                "run",
                "along",
                "either",
                "side",
                "of",
                "he",
                "forehead",
                "."
            ],
            [
                "I",
                "stare",
                "back",
                "at",
                "that",
                "face",
                "with",
                "the",
                "weight",
                "of",
                "the",
                "world",
                "on",
                "my",
                "shoulder",
                "."
            ]
        ],
        "label": "Fear"
    },
    {
        "body_part_token_idx": 5,
        "sentence_id": "fe7013a2-5e15-3346-8b2b-58d0d5cbd74a",
        "tokens": [
            "My",
            "head",
            "pounded",
            "and",
            "my",
            "lips",
            "were",
            "chalky",
            ";",
            "that",
            "was",
            "a",
            "good",
            "sign",
            "."
        ],
        "lemmatized_tokens": [
            "my",
            "head",
            "pound",
            "and",
            "my",
            "lip",
            "be",
            "chalky",
            ";",
            "that",
            "be",
            "a",
            "good",
            "sign",
            "."
        ],
        "preceding_context_tokens": [
            [
                "His",
                "face",
                "was",
                "pale",
                "with",
                "sunken",
                "black",
                "eyes",
                "hidden",
                "far",
                "behind",
                "his",
                "cheek",
                "bones",
                "."
            ],
            [
                "Veins",
                "ran",
                "along",
                "either",
                "side",
                "of",
                "his",
                "forehead",
                "."
            ],
            [
                "I",
                "stared",
                "back",
                "at",
                "that",
                "face",
                "with",
                "the",
                "weight",
                "of",
                "the",
                "world",
                "on",
                "my",
                "shoulders",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "he",
                "face",
                "be",
                "pale",
                "with",
                "sink",
                "black",
                "eye",
                "hide",
                "far",
                "behind",
                "he",
                "cheek",
                "bone",
                "."
            ],
            [
                "vein",
                "run",
                "along",
                "either",
                "side",
                "of",
                "he",
                "forehead",
                "."
            ],
            [
                "I",
                "stare",
                "back",
                "at",
                "that",
                "face",
                "with",
                "the",
                "weight",
                "of",
                "the",
                "world",
                "on",
                "my",
                "shoulder",
                "."
            ]
        ],
        "label": "Fear"
    },
    {
        "body_part_token_idx": 7,
        "sentence_id": "d0e8ac3a-de74-34be-abbb-f2a4da46f7f9",
        "tokens": [
            "He",
            "smiled",
            "and",
            "seemed",
            "to",
            "shake",
            "his",
            "head",
            "."
        ],
        "lemmatized_tokens": [
            "he",
            "smile",
            "and",
            "seem",
            "to",
            "shake",
            "he",
            "head",
            "."
        ],
        "preceding_context_tokens": [
            [
                "If",
                "you",
                "need",
                "an",
                "extra",
                "grandfather",
                ",",
                "he",
                "said",
                ",",
                "directly",
                "to",
                "baby",
                "."
            ],
            [
                "I",
                "'ll",
                "do",
                "it",
                "for",
                "free",
                "."
            ],
            [
                "Baby",
                "had",
                "no",
                "idea",
                "what",
                "to",
                "make",
                "of",
                "this",
                "offer",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "if",
                "you",
                "need",
                "a",
                "extra",
                "grandfather",
                ",",
                "he",
                "say",
                ",",
                "directly",
                "to",
                "baby",
                "."
            ],
            [
                "I",
                "will",
                "do",
                "it",
                "for",
                "free",
                "."
            ],
            [
                "Baby",
                "have",
                "no",
                "idea",
                "what",
                "to",
                "make",
                "of",
                "this",
                "offer",
                "."
            ]
        ],
        "label": "Joy"
    },
    {
        "body_part_token_idx": 13,
        "sentence_id": "53445af6-962e-3cb1-ade4-bb310cc5528e",
        "tokens": [
            "When",
            "he",
            "turns",
            "and",
            "looks",
            "at",
            "her",
            "she",
            "has",
            "a",
            "smile",
            "on",
            "her",
            "face",
            "."
        ],
        "lemmatized_tokens": [
            "when",
            "he",
            "turn",
            "and",
            "look",
            "at",
            "she",
            "she",
            "have",
            "a",
            "smile",
            "on",
            "she",
            "face",
            "."
        ],
        "preceding_context_tokens": [
            [
                "When",
                "he",
                "turned",
                "around",
                "she",
                "had",
                "a",
                "slight",
                "grin",
                "on",
                "her",
                "face",
                ",",
                "so",
                "he",
                "said",
                ",",
                "``",
                "Oh",
                ",",
                "you",
                "think",
                "that",
                "'s",
                "funny",
                "?"
            ],
            [
                "Watch",
                "this",
                ".",
                "''"
            ],
            [
                "He",
                "gets",
                "a",
                "baseball",
                "bat",
                "out",
                "of",
                "his",
                "truck",
                "and",
                "breaks",
                "every",
                "window",
                "in",
                "her",
                "car",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "when",
                "he",
                "turn",
                "around",
                "she",
                "have",
                "a",
                "slight",
                "grin",
                "on",
                "she",
                "face",
                ",",
                "so",
                "he",
                "say",
                ",",
                "``",
                "oh",
                ",",
                "you",
                "think",
                "that",
                "be",
                "funny",
                "?"
            ],
            [
                "watch",
                "this",
                ".",
                "''"
            ],
            [
                "he",
                "get",
                "a",
                "baseball",
                "bat",
                "out",
                "of",
                "he",
                "truck",
                "and",
                "break",
                "every",
                "window",
                "in",
                "she",
                "car",
                "."
            ]
        ],
        "label": "Joy"
    },
    {
        "body_part_token_idx": 2,
        "sentence_id": "15c800ee-c4b1-375c-a89b-97311cf87af4",
        "tokens": [
            "Immediately",
            "my",
            "throat",
            "tightens",
            "."
        ],
        "lemmatized_tokens": [
            "immediately",
            "my",
            "throat",
            "tighten",
            "."
        ],
        "preceding_context_tokens": [
            [
                "I",
                "'m",
                "not",
                "."
            ],
            [
                "You",
                "'re",
                "not",
                "."
            ],
            [
                "He",
                "came",
                "home",
                "this",
                "morning",
                "and",
                "as",
                "I",
                "'m",
                "sitting",
                "at",
                "the",
                "dining",
                "room",
                "table",
                "checking",
                "my",
                "e-mail",
                ",",
                "he",
                "sits",
                "down",
                "and",
                "tells",
                "me",
                "he",
                "is",
                "going",
                "to",
                "need",
                "my",
                "social",
                ",",
                "and",
                "all",
                "my",
                "names",
                "I",
                "'ve",
                "had",
                "in",
                "my",
                "life",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "I",
                "be",
                "not",
                "."
            ],
            [
                "you",
                "be",
                "not",
                "."
            ],
            [
                "he",
                "come",
                "home",
                "this",
                "morning",
                "and",
                "as",
                "I",
                "be",
                "sit",
                "at",
                "the",
                "dining",
                "room",
                "table",
                "check",
                "my",
                "e-mail",
                ",",
                "he",
                "sit",
                "down",
                "and",
                "tell",
                "I",
                "he",
                "be",
                "go",
                "to",
                "need",
                "my",
                "social",
                ",",
                "and",
                "all",
                "my",
                "name",
                "I",
                "have",
                "have",
                "in",
                "my",
                "life",
                "."
            ]
        ],
        "label": "Fear"
    },
    {
        "body_part_token_idx": 9,
        "sentence_id": "5f06993a-e7c2-3481-b039-74de688fe364",
        "tokens": [
            "As",
            "my",
            "eyes",
            "followed",
            "all",
            "of",
            "the",
            "commotion",
            "my",
            "heart",
            "started",
            "beating",
            "in",
            "triple",
            "time",
            "."
        ],
        "lemmatized_tokens": [
            "as",
            "my",
            "eye",
            "follow",
            "all",
            "of",
            "the",
            "commotion",
            "my",
            "heart",
            "start",
            "beat",
            "in",
            "triple",
            "time",
            "."
        ],
        "preceding_context_tokens": [
            [
                "The",
                "kids",
                "had",
                "a",
                "special",
                "treat",
                "on",
                "Thursday",
                "."
            ],
            [
                "Daddy",
                "came",
                "to",
                "watch",
                "Shealyn",
                "and",
                "Carter",
                "swim",
                "on",
                "his",
                "lunch",
                "hour",
                "and",
                "got",
                "to",
                "see",
                "Miss",
                "P.",
                "go",
                "off",
                "the",
                "diving",
                "board",
                "!"
            ],
            [
                "So",
                ",",
                "Clark",
                ",",
                "Payton",
                "and",
                "I",
                "are",
                "watching",
                "Shealyn",
                "and",
                "Carter",
                "finish",
                "up",
                "their",
                "lessons",
                "when",
                "all",
                "of",
                "a",
                "sudden",
                "EVERY",
                "life",
                "guard",
                "in",
                "the",
                "building",
                "-LRB-",
                "with",
                "the",
                "exception",
                "of",
                "the",
                "one",
                "guarding",
                "the",
                "shallow",
                "pool",
                ")",
                "went",
                "running",
                "to",
                "the",
                "deep",
                "end",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "the",
                "kid",
                "have",
                "a",
                "special",
                "treat",
                "on",
                "Thursday",
                "."
            ],
            [
                "daddy",
                "come",
                "to",
                "watch",
                "Shealyn",
                "and",
                "Carter",
                "swim",
                "on",
                "he",
                "lunch",
                "hour",
                "and",
                "get",
                "to",
                "see",
                "Miss",
                "P.",
                "go",
                "off",
                "the",
                "diving",
                "board",
                "!"
            ],
            [
                "so",
                ",",
                "Clark",
                ",",
                "Payton",
                "and",
                "I",
                "be",
                "watch",
                "Shealyn",
                "and",
                "Carter",
                "finish",
                "up",
                "they",
                "lesson",
                "when",
                "all",
                "of",
                "a",
                "sudden",
                "every",
                "life",
                "guard",
                "in",
                "the",
                "building",
                "-lrb-_VBZ",
                "with",
                "the",
                "exception",
                "of",
                "the",
                "one",
                "guard",
                "the",
                "shallow",
                "pool",
                ")",
                "go",
                "run",
                "to",
                "the",
                "deep",
                "end",
                "."
            ]
        ],
        "label": "Fear"
    },
    {
        "body_part_token_idx": 9,
        "sentence_id": "bc13a250-0507-3ab2-8964-d7e4dc199dfc",
        "tokens": [
            "Even",
            "as",
            "I",
            "sit",
            "here",
            "and",
            "type",
            ",",
            "my",
            "eyes",
            "are",
            "welling",
            "up",
            "with",
            "tears",
            "."
        ],
        "lemmatized_tokens": [
            "even",
            "as",
            "I",
            "sit",
            "here",
            "and",
            "type",
            ",",
            "my",
            "eye",
            "be",
            "well",
            "up",
            "with",
            "tear",
            "."
        ],
        "preceding_context_tokens": [
            [
                "I",
                "'m",
                "thankful",
                "that",
                "in",
                "the",
                "past",
                "few",
                "months",
                ",",
                "we",
                "were",
                "able",
                "to",
                "spend",
                "some",
                "sweet",
                "time",
                "with",
                "her",
                "."
            ],
            [
                "She",
                "continued",
                "to",
                "display",
                "her",
                "Jack",
                "Benny",
                "sense",
                "of",
                "wit",
                "and",
                "humor",
                "until",
                "the",
                "last",
                "week",
                "of",
                "her",
                "life",
                "``",
                "you",
                "had",
                "to",
                "be",
                "on",
                "the",
                "ball",
                "to",
                "keep",
                "up",
                "with",
                "that",
                "lady",
                "!"
            ],
            [
                "She",
                "was",
                "a",
                "real",
                "treasure.Not",
                "so",
                "easy",
                "to",
                "reconcile",
                "is",
                "the",
                "death",
                "of",
                "my",
                "Uncle",
                "Sammy",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "I",
                "be",
                "thankful",
                "that",
                "in",
                "the",
                "past",
                "few",
                "month",
                ",",
                "we",
                "be",
                "able",
                "to",
                "spend",
                "some",
                "sweet",
                "time",
                "with",
                "she",
                "."
            ],
            [
                "she",
                "continue",
                "to",
                "display",
                "she",
                "Jack",
                "Benny",
                "sense",
                "of",
                "wit",
                "and",
                "humor",
                "until",
                "the",
                "last",
                "week",
                "of",
                "she",
                "life",
                "``",
                "you",
                "have",
                "to",
                "be",
                "on",
                "the",
                "ball",
                "to",
                "keep",
                "up",
                "with",
                "that",
                "lady",
                "!"
            ],
            [
                "she",
                "be",
                "a",
                "real",
                "treasure.not",
                "so",
                "easy",
                "to",
                "reconcile",
                "be",
                "the",
                "death",
                "of",
                "my",
                "Uncle",
                "Sammy",
                "."
            ]
        ],
        "label": "Sadness"
    },
    {
        "body_part_token_idx": 11,
        "sentence_id": "4387024c-90b9-3051-a861-735bcad97c6d",
        "tokens": [
            "Jackie",
            "looked",
            "at",
            "me",
            "with",
            "nothing",
            "less",
            "than",
            "adoration",
            "in",
            "her",
            "eyes",
            "."
        ],
        "lemmatized_tokens": [
            "Jackie",
            "look",
            "at",
            "I",
            "with",
            "nothing",
            "less",
            "than",
            "adoration",
            "in",
            "she",
            "eye",
            "."
        ],
        "preceding_context_tokens": [
            [
                "We",
                "did",
                "this",
                "for",
                "about",
                "an",
                "hour",
                ",",
                "and",
                "finally",
                "Elyse",
                "'s",
                "front",
                "door",
                "opened",
                "."
            ],
            [
                "Her",
                "mom",
                "'s",
                "friend",
                "and",
                "daughter",
                "made",
                "their",
                "exit",
                "right",
                "on",
                "cue",
                ",",
                "and",
                "before",
                "their",
                "car",
                "was",
                "out",
                "of",
                "sight",
                ",",
                "Elyse",
                "walked",
                "up",
                "to",
                "us",
                "."
            ],
            [
                "Can",
                "I",
                "play?",
                "she",
                "asked",
                "with",
                "a",
                "bright",
                "smile",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "we",
                "do",
                "this",
                "for",
                "about",
                "a",
                "hour",
                ",",
                "and",
                "finally",
                "Elyse",
                "'s",
                "front",
                "door",
                "open",
                "."
            ],
            [
                "she",
                "mom",
                "'s",
                "friend",
                "and",
                "daughter",
                "make",
                "they",
                "exit",
                "right",
                "on",
                "cue",
                ",",
                "and",
                "before",
                "they",
                "car",
                "be",
                "out",
                "of",
                "sight",
                ",",
                "Elyse",
                "walk",
                "up",
                "to",
                "we",
                "."
            ],
            [
                "can",
                "I",
                "play?",
                "she",
                "ask",
                "with",
                "a",
                "bright",
                "smile",
                "."
            ]
        ],
        "label": "Joy"
    },
    {
        "body_part_token_idx": 24,
        "sentence_id": "84ba6dc3-6609-3dff-af7b-6b31f6bc3614",
        "tokens": [
            "And",
            "though",
            "she",
            "lingers",
            "as",
            "he",
            "talks",
            "to",
            "Aimee",
            "about",
            "his",
            "dancing",
            "skills",
            ",",
            "she",
            "remains",
            "silent",
            ",",
            "mostly",
            ",",
            "standing",
            "nearby",
            "with",
            "her",
            "arms",
            "lightly",
            "crossed",
            "over",
            "her",
            "chest.Aimee",
            "watches",
            "the",
            "dance",
            "movements",
            "with",
            "a",
            "professional",
            "'s",
            "eyes",
            ",",
            "dispassionately",
            ",",
            "her",
            "green",
            "eyes",
            "narrowed",
            "."
        ],
        "lemmatized_tokens": [
            "and",
            "though",
            "she",
            "linger",
            "as",
            "he",
            "talk",
            "to",
            "Aimee",
            "about",
            "he",
            "dancing",
            "skill",
            ",",
            "she",
            "remain",
            "silent",
            ",",
            "mostly",
            ",",
            "stand",
            "nearby",
            "with",
            "she",
            "arm",
            "lightly",
            "cross",
            "over",
            "she",
            "chest.aimee",
            "watch",
            "the",
            "dance",
            "movement",
            "with",
            "a",
            "professional",
            "'s",
            "eye",
            ",",
            "dispassionately",
            ",",
            "she",
            "green",
            "eye",
            "narrow",
            "."
        ],
        "preceding_context_tokens": [
            [
                "When",
                "he",
                "'s",
                "done",
                ",",
                "she",
                "eyes",
                "her",
                "hand",
                "a",
                "bit",
                "and",
                "returns",
                "a",
                "brief",
                "assessment",
                "."
            ],
            [
                "``",
                "Its",
                "fine",
                ".",
                "''"
            ],
            [
                "Her",
                "snappish",
                "mood",
                "seeming",
                "to",
                "have",
                "faded",
                "some",
                "at",
                "least",
                ",",
                "if",
                "not",
                "gone",
                "so",
                "far",
                "as",
                "reversing",
                "entirely",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "when",
                "he",
                "be",
                "do",
                ",",
                "she",
                "eye",
                "she",
                "hand",
                "a",
                "bit",
                "and",
                "return",
                "a",
                "brief",
                "assessment",
                "."
            ],
            [
                "``",
                "its",
                "fine",
                ".",
                "''"
            ],
            [
                "she",
                "snappish",
                "mood",
                "seem",
                "to",
                "have",
                "fade",
                "some",
                "at",
                "least",
                ",",
                "if",
                "not",
                "go",
                "so",
                "far",
                "as",
                "reverse",
                "entirely",
                "."
            ]
        ],
        "label": "Disgust"
    },
    {
        "body_part_token_idx": 1,
        "sentence_id": "e16f92ad-401e-33c0-bb65-a38c0050af2b",
        "tokens": [
            "Her",
            "eyes",
            "lit",
            "up",
            "at",
            "the",
            "thought",
            "of",
            "all",
            "the",
            "things",
            "she",
            "wanted",
            "to",
            "know",
            "."
        ],
        "lemmatized_tokens": [
            "she",
            "eye",
            "light",
            "up",
            "at",
            "the",
            "thought",
            "of",
            "all",
            "the",
            "thing",
            "she",
            "want",
            "to",
            "know",
            "."
        ],
        "preceding_context_tokens": [
            [
                "``",
                "Yeah",
                ",",
                "I",
                "do",
                "."
            ],
            [
                "Because",
                "if",
                "you",
                "do",
                "n't",
                "you",
                "are",
                "going",
                "to",
                "miss",
                "all",
                "the",
                "gossip",
                "I",
                "have",
                "to",
                "tell",
                "you",
                ".",
                "''"
            ],
            [
                "He",
                "replied",
                "grinning",
                "down",
                "at",
                "her",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "``",
                "yeah",
                ",",
                "I",
                "do",
                "."
            ],
            [
                "because",
                "if",
                "you",
                "do",
                "not",
                "you",
                "be",
                "go",
                "to",
                "miss",
                "all",
                "the",
                "gossip",
                "I",
                "have",
                "to",
                "tell",
                "you",
                ".",
                "''"
            ],
            [
                "he",
                "reply",
                "grin",
                "down",
                "at",
                "she",
                "."
            ]
        ],
        "label": "Surprise"
    },
    {
        "body_part_token_idx": 12,
        "sentence_id": "2afb1651-4cdb-3a6f-a6aa-aae8dc340a5b",
        "tokens": [
            "Out",
            "of",
            "the",
            "corner",
            "of",
            "his",
            "eyes",
            "he",
            "saw",
            "Angel",
            "shaking",
            "his",
            "head",
            "with",
            "his",
            "eyes",
            "closed",
            ",",
            "a",
            "look",
            "of",
            "annoyance",
            "clear",
            "on",
            "his",
            "face",
            "."
        ],
        "lemmatized_tokens": [
            "out",
            "of",
            "the",
            "corner",
            "of",
            "he",
            "eye",
            "he",
            "see",
            "Angel",
            "shake",
            "he",
            "head",
            "with",
            "he",
            "eye",
            "close",
            ",",
            "a",
            "look",
            "of",
            "annoyance",
            "clear",
            "on",
            "he",
            "face",
            "."
        ],
        "preceding_context_tokens": [
            [
                "he",
                "asked",
                "completely",
                "taken",
                "back",
                "."
            ],
            [
                "Feeling",
                "his",
                "anger",
                "start",
                "to",
                "rise",
                "Jack",
                "lifted",
                "his",
                "chin",
                "and",
                "shrugged",
                "Ya",
                "it",
                "'s",
                "not",
                "that",
                "big",
                "a",
                "deal",
                ",",
                "it",
                "'s",
                "stupid",
                "anyway.",
                "He",
                "said",
                "and",
                "watched",
                "Bobby",
                "'s",
                "mouth",
                "drop",
                "open",
                "in",
                "shock",
                "."
            ],
            [
                "Jack",
                "did",
                "n't",
                "understand",
                "why",
                "he",
                "felt",
                "this",
                "small",
                "satisfaction",
                "that",
                "he",
                "got",
                "from",
                "the",
                "reaction",
                "that",
                "Bobby",
                "had",
                "but",
                "he",
                "felt",
                "himself",
                "smirk",
                "lightly",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "he",
                "ask",
                "completely",
                "take",
                "back",
                "."
            ],
            [
                "feel",
                "he",
                "anger",
                "start",
                "to",
                "rise",
                "Jack",
                "lift",
                "he",
                "chin",
                "and",
                "shrug",
                "Ya",
                "it",
                "be",
                "not",
                "that",
                "big",
                "a",
                "deal",
                ",",
                "it",
                "be",
                "stupid",
                "anyway.",
                "he",
                "say",
                "and",
                "watch",
                "Bobby",
                "'s",
                "mouth",
                "drop",
                "open",
                "in",
                "shock",
                "."
            ],
            [
                "Jack",
                "do",
                "not",
                "understand",
                "why",
                "he",
                "feel",
                "this",
                "small",
                "satisfaction",
                "that",
                "he",
                "get",
                "from",
                "the",
                "reaction",
                "that",
                "Bobby",
                "have",
                "but",
                "he",
                "feel",
                "himself",
                "smirk",
                "lightly",
                "."
            ]
        ],
        "label": "Disgust"
    },
    {
        "body_part_token_idx": 15,
        "sentence_id": "2afb1651-4cdb-3a6f-a6aa-aae8dc340a5b",
        "tokens": [
            "Out",
            "of",
            "the",
            "corner",
            "of",
            "his",
            "eyes",
            "he",
            "saw",
            "Angel",
            "shaking",
            "his",
            "head",
            "with",
            "his",
            "eyes",
            "closed",
            ",",
            "a",
            "look",
            "of",
            "annoyance",
            "clear",
            "on",
            "his",
            "face",
            "."
        ],
        "lemmatized_tokens": [
            "out",
            "of",
            "the",
            "corner",
            "of",
            "he",
            "eye",
            "he",
            "see",
            "Angel",
            "shake",
            "he",
            "head",
            "with",
            "he",
            "eye",
            "close",
            ",",
            "a",
            "look",
            "of",
            "annoyance",
            "clear",
            "on",
            "he",
            "face",
            "."
        ],
        "preceding_context_tokens": [
            [
                "he",
                "asked",
                "completely",
                "taken",
                "back",
                "."
            ],
            [
                "Feeling",
                "his",
                "anger",
                "start",
                "to",
                "rise",
                "Jack",
                "lifted",
                "his",
                "chin",
                "and",
                "shrugged",
                "Ya",
                "it",
                "'s",
                "not",
                "that",
                "big",
                "a",
                "deal",
                ",",
                "it",
                "'s",
                "stupid",
                "anyway.",
                "He",
                "said",
                "and",
                "watched",
                "Bobby",
                "'s",
                "mouth",
                "drop",
                "open",
                "in",
                "shock",
                "."
            ],
            [
                "Jack",
                "did",
                "n't",
                "understand",
                "why",
                "he",
                "felt",
                "this",
                "small",
                "satisfaction",
                "that",
                "he",
                "got",
                "from",
                "the",
                "reaction",
                "that",
                "Bobby",
                "had",
                "but",
                "he",
                "felt",
                "himself",
                "smirk",
                "lightly",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "he",
                "ask",
                "completely",
                "take",
                "back",
                "."
            ],
            [
                "feel",
                "he",
                "anger",
                "start",
                "to",
                "rise",
                "Jack",
                "lift",
                "he",
                "chin",
                "and",
                "shrug",
                "Ya",
                "it",
                "be",
                "not",
                "that",
                "big",
                "a",
                "deal",
                ",",
                "it",
                "be",
                "stupid",
                "anyway.",
                "he",
                "say",
                "and",
                "watch",
                "Bobby",
                "'s",
                "mouth",
                "drop",
                "open",
                "in",
                "shock",
                "."
            ],
            [
                "Jack",
                "do",
                "not",
                "understand",
                "why",
                "he",
                "feel",
                "this",
                "small",
                "satisfaction",
                "that",
                "he",
                "get",
                "from",
                "the",
                "reaction",
                "that",
                "Bobby",
                "have",
                "but",
                "he",
                "feel",
                "himself",
                "smirk",
                "lightly",
                "."
            ]
        ],
        "label": "Disgust"
    },
    {
        "body_part_token_idx": 25,
        "sentence_id": "2afb1651-4cdb-3a6f-a6aa-aae8dc340a5b",
        "tokens": [
            "Out",
            "of",
            "the",
            "corner",
            "of",
            "his",
            "eyes",
            "he",
            "saw",
            "Angel",
            "shaking",
            "his",
            "head",
            "with",
            "his",
            "eyes",
            "closed",
            ",",
            "a",
            "look",
            "of",
            "annoyance",
            "clear",
            "on",
            "his",
            "face",
            "."
        ],
        "lemmatized_tokens": [
            "out",
            "of",
            "the",
            "corner",
            "of",
            "he",
            "eye",
            "he",
            "see",
            "Angel",
            "shake",
            "he",
            "head",
            "with",
            "he",
            "eye",
            "close",
            ",",
            "a",
            "look",
            "of",
            "annoyance",
            "clear",
            "on",
            "he",
            "face",
            "."
        ],
        "preceding_context_tokens": [
            [
                "he",
                "asked",
                "completely",
                "taken",
                "back",
                "."
            ],
            [
                "Feeling",
                "his",
                "anger",
                "start",
                "to",
                "rise",
                "Jack",
                "lifted",
                "his",
                "chin",
                "and",
                "shrugged",
                "Ya",
                "it",
                "'s",
                "not",
                "that",
                "big",
                "a",
                "deal",
                ",",
                "it",
                "'s",
                "stupid",
                "anyway.",
                "He",
                "said",
                "and",
                "watched",
                "Bobby",
                "'s",
                "mouth",
                "drop",
                "open",
                "in",
                "shock",
                "."
            ],
            [
                "Jack",
                "did",
                "n't",
                "understand",
                "why",
                "he",
                "felt",
                "this",
                "small",
                "satisfaction",
                "that",
                "he",
                "got",
                "from",
                "the",
                "reaction",
                "that",
                "Bobby",
                "had",
                "but",
                "he",
                "felt",
                "himself",
                "smirk",
                "lightly",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "he",
                "ask",
                "completely",
                "take",
                "back",
                "."
            ],
            [
                "feel",
                "he",
                "anger",
                "start",
                "to",
                "rise",
                "Jack",
                "lift",
                "he",
                "chin",
                "and",
                "shrug",
                "Ya",
                "it",
                "be",
                "not",
                "that",
                "big",
                "a",
                "deal",
                ",",
                "it",
                "be",
                "stupid",
                "anyway.",
                "he",
                "say",
                "and",
                "watch",
                "Bobby",
                "'s",
                "mouth",
                "drop",
                "open",
                "in",
                "shock",
                "."
            ],
            [
                "Jack",
                "do",
                "not",
                "understand",
                "why",
                "he",
                "feel",
                "this",
                "small",
                "satisfaction",
                "that",
                "he",
                "get",
                "from",
                "the",
                "reaction",
                "that",
                "Bobby",
                "have",
                "but",
                "he",
                "feel",
                "himself",
                "smirk",
                "lightly",
                "."
            ]
        ],
        "label": "Disgust"
    },
    {
        "body_part_token_idx": 7,
        "sentence_id": "38c656be-c10f-3883-9874-efe81433ca43",
        "tokens": [
            "Jihwan",
            "had",
            "a",
            "dumbfounded",
            "look",
            "oh",
            "his",
            "face",
            "as",
            "Injoon",
            "stopped",
            "in",
            "front",
            "of",
            "him",
            ",",
            "completely",
            "oblivious",
            "to",
            "his",
            "surrounding",
            "with",
            "the",
            "smile",
            "still",
            "on",
            "his",
            "face",
            "."
        ],
        "lemmatized_tokens": [
            "Jihwan",
            "have",
            "a",
            "dumbfounded",
            "look",
            "oh",
            "he",
            "face",
            "as",
            "Injoon",
            "stop",
            "in",
            "front",
            "of",
            "he",
            ",",
            "completely",
            "oblivious",
            "to",
            "he",
            "surround",
            "with",
            "the",
            "smile",
            "still",
            "on",
            "he",
            "face",
            "."
        ],
        "preceding_context_tokens": [
            [
                "The",
                "boy",
                "was",
                "no",
                "longer",
                "soot",
                "covered",
                "and",
                "he",
                "changed",
                "clothes",
                ",",
                "he",
                "looked",
                "more",
                "normal",
                "then",
                "when",
                "Jihwan",
                "first",
                "saw",
                "him",
                "."
            ],
            [
                "His",
                "dark",
                "brown",
                "hair",
                "was",
                "slightly",
                "faded",
                "and",
                "messy",
                ",",
                "his",
                "bangs",
                "pushed",
                "to",
                "the",
                "side",
                "so",
                "they",
                "stayed",
                "out",
                "of",
                "his",
                "face",
                ";",
                "a",
                "giant",
                "smile",
                "spread",
                "across",
                "his",
                "face",
                "."
            ],
            [
                "Jihwan",
                "'s",
                "eyes",
                "kept",
                "switching",
                "between",
                "Hyunchul",
                "as",
                "he",
                "fought",
                "with",
                "the",
                "cat",
                "and",
                "Injoon",
                "as",
                "he",
                "happily",
                "passed",
                "Hyunchul",
                "and",
                "the",
                "cat",
                "and",
                "skipped",
                "towards",
                "him",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "the",
                "boy",
                "be",
                "no",
                "longer",
                "soot",
                "cover",
                "and",
                "he",
                "change",
                "clothes",
                ",",
                "he",
                "look",
                "more",
                "normal",
                "then",
                "when",
                "Jihwan",
                "first",
                "see",
                "he",
                "."
            ],
            [
                "he",
                "dark",
                "brown",
                "hair",
                "be",
                "slightly",
                "fade",
                "and",
                "messy",
                ",",
                "he",
                "bang",
                "push",
                "to",
                "the",
                "side",
                "so",
                "they",
                "stay",
                "out",
                "of",
                "he",
                "face",
                ";",
                "a",
                "giant",
                "smile",
                "spread",
                "across",
                "he",
                "face",
                "."
            ],
            [
                "Jihwan",
                "'s",
                "eye",
                "keep",
                "switch",
                "between",
                "Hyunchul",
                "as",
                "he",
                "fight",
                "with",
                "the",
                "cat",
                "and",
                "Injoon",
                "as",
                "he",
                "happily",
                "pass",
                "Hyunchul",
                "and",
                "the",
                "cat",
                "and",
                "skip",
                "towards",
                "he",
                "."
            ]
        ],
        "label": "Joy"
    },
    {
        "body_part_token_idx": 27,
        "sentence_id": "38c656be-c10f-3883-9874-efe81433ca43",
        "tokens": [
            "Jihwan",
            "had",
            "a",
            "dumbfounded",
            "look",
            "oh",
            "his",
            "face",
            "as",
            "Injoon",
            "stopped",
            "in",
            "front",
            "of",
            "him",
            ",",
            "completely",
            "oblivious",
            "to",
            "his",
            "surrounding",
            "with",
            "the",
            "smile",
            "still",
            "on",
            "his",
            "face",
            "."
        ],
        "lemmatized_tokens": [
            "Jihwan",
            "have",
            "a",
            "dumbfounded",
            "look",
            "oh",
            "he",
            "face",
            "as",
            "Injoon",
            "stop",
            "in",
            "front",
            "of",
            "he",
            ",",
            "completely",
            "oblivious",
            "to",
            "he",
            "surround",
            "with",
            "the",
            "smile",
            "still",
            "on",
            "he",
            "face",
            "."
        ],
        "preceding_context_tokens": [
            [
                "The",
                "boy",
                "was",
                "no",
                "longer",
                "soot",
                "covered",
                "and",
                "he",
                "changed",
                "clothes",
                ",",
                "he",
                "looked",
                "more",
                "normal",
                "then",
                "when",
                "Jihwan",
                "first",
                "saw",
                "him",
                "."
            ],
            [
                "His",
                "dark",
                "brown",
                "hair",
                "was",
                "slightly",
                "faded",
                "and",
                "messy",
                ",",
                "his",
                "bangs",
                "pushed",
                "to",
                "the",
                "side",
                "so",
                "they",
                "stayed",
                "out",
                "of",
                "his",
                "face",
                ";",
                "a",
                "giant",
                "smile",
                "spread",
                "across",
                "his",
                "face",
                "."
            ],
            [
                "Jihwan",
                "'s",
                "eyes",
                "kept",
                "switching",
                "between",
                "Hyunchul",
                "as",
                "he",
                "fought",
                "with",
                "the",
                "cat",
                "and",
                "Injoon",
                "as",
                "he",
                "happily",
                "passed",
                "Hyunchul",
                "and",
                "the",
                "cat",
                "and",
                "skipped",
                "towards",
                "him",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "the",
                "boy",
                "be",
                "no",
                "longer",
                "soot",
                "cover",
                "and",
                "he",
                "change",
                "clothes",
                ",",
                "he",
                "look",
                "more",
                "normal",
                "then",
                "when",
                "Jihwan",
                "first",
                "see",
                "he",
                "."
            ],
            [
                "he",
                "dark",
                "brown",
                "hair",
                "be",
                "slightly",
                "fade",
                "and",
                "messy",
                ",",
                "he",
                "bang",
                "push",
                "to",
                "the",
                "side",
                "so",
                "they",
                "stay",
                "out",
                "of",
                "he",
                "face",
                ";",
                "a",
                "giant",
                "smile",
                "spread",
                "across",
                "he",
                "face",
                "."
            ],
            [
                "Jihwan",
                "'s",
                "eye",
                "keep",
                "switch",
                "between",
                "Hyunchul",
                "as",
                "he",
                "fight",
                "with",
                "the",
                "cat",
                "and",
                "Injoon",
                "as",
                "he",
                "happily",
                "pass",
                "Hyunchul",
                "and",
                "the",
                "cat",
                "and",
                "skip",
                "towards",
                "he",
                "."
            ]
        ],
        "label": "Joy"
    },
    {
        "body_part_token_idx": 3,
        "sentence_id": "66b8c9c2-45b6-3369-bb8a-85bfdedee92c",
        "tokens": [
            "He",
            "tapped",
            "his",
            "foot",
            "against",
            "the",
            "wall",
            "and",
            "smiled",
            "awkwardly",
            "at",
            "a",
            "few",
            "of",
            "the",
            "girls",
            "that",
            "walked",
            "by",
            "."
        ],
        "lemmatized_tokens": [
            "he",
            "tap",
            "he",
            "foot",
            "against",
            "the",
            "wall",
            "and",
            "smile",
            "awkwardly",
            "at",
            "a",
            "few",
            "of",
            "the",
            "girl",
            "that",
            "walk",
            "by",
            "."
        ],
        "preceding_context_tokens": [
            [
                "He",
                "let",
                "out",
                "a",
                "huff",
                "when",
                "he",
                "put",
                "down",
                "the",
                "clothes",
                "in",
                "the",
                "dressing",
                "room",
                "."
            ],
            [
                "``",
                "So",
                ",",
                "try",
                "on",
                "one",
                "pair",
                "of",
                "the",
                "jeans",
                "and",
                "a",
                "shirt",
                "or",
                "something",
                ",",
                "I",
                "'ll",
                "be",
                "right",
                "here",
                ".",
                "''"
            ],
            [
                "Nick",
                "said",
                "standing",
                "outside",
                "the",
                "room",
                "and",
                "leaning",
                "against",
                "the",
                "wall",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "he",
                "let",
                "out",
                "a",
                "huff",
                "when",
                "he",
                "put",
                "down",
                "the",
                "clothes",
                "in",
                "the",
                "dressing",
                "room",
                "."
            ],
            [
                "``",
                "so",
                ",",
                "try",
                "on",
                "one",
                "pair",
                "of",
                "the",
                "jeans",
                "and",
                "a",
                "shirt",
                "or",
                "something",
                ",",
                "I",
                "will",
                "be",
                "right",
                "here",
                ".",
                "''"
            ],
            [
                "Nick",
                "say",
                "stand",
                "outside",
                "the",
                "room",
                "and",
                "lean",
                "against",
                "the",
                "wall",
                "."
            ]
        ],
        "label": "Joy"
    },
    {
        "body_part_token_idx": 4,
        "sentence_id": "cdcf47bb-c2db-39ab-bddd-bede817709a8",
        "tokens": [
            "I",
            "breathed",
            "with",
            "my",
            "mouth",
            "open",
            ",",
            "my",
            "eyes",
            "wide",
            "like",
            "those",
            "of",
            "a",
            "mad",
            "cow",
            ",",
            "my",
            "heart",
            "pounding",
            "and",
            "my",
            "head",
            "spinning",
            "towards",
            "each",
            "sound",
            "like",
            "a",
            "scene",
            "from",
            "the",
            "Exorcist",
            "."
        ],
        "lemmatized_tokens": [
            "I",
            "breathe",
            "with",
            "my",
            "mouth",
            "open",
            ",",
            "my",
            "eye",
            "wide",
            "like",
            "those",
            "of",
            "a",
            "mad",
            "cow",
            ",",
            "my",
            "heart",
            "pound",
            "and",
            "my",
            "head",
            "spin",
            "towards",
            "each",
            "sound",
            "like",
            "a",
            "scene",
            "from",
            "the",
            "Exorcist",
            "."
        ],
        "preceding_context_tokens": [
            [
                "Then",
                "there",
                "was",
                "the",
                "low",
                "rumble",
                "that",
                "had",
                "me",
                "darting",
                "to",
                "my",
                "right",
                "in",
                "the",
                "certain",
                "knowledge",
                "that",
                "it",
                "was",
                "the",
                "empty",
                "-",
                "stomach",
                "of",
                "a",
                "cantankerous",
                "elephant",
                "."
            ],
            [
                "Next",
                "came",
                "the",
                "almost",
                "silent",
                "hiss",
                "of",
                "something",
                "blood",
                "-",
                "thirsty",
                "and",
                "nasty",
                "sighing",
                "to",
                "my",
                "left",
                "."
            ],
            [
                "This",
                "was",
                "promptly",
                "followed",
                "by",
                "another",
                "brush",
                "against",
                "the",
                "back",
                "flaps",
                ";",
                "a",
                "whisper",
                "that",
                "could",
                "have",
                "been",
                "the",
                "wind",
                "but",
                "was",
                "almost",
                "certainly",
                "a",
                "leopard",
                "and",
                "the",
                "sharp",
                "meow",
                "-",
                "like",
                "snarl",
                "of",
                "a",
                "clearly",
                "small",
                "but",
                "patently",
                "lethal",
                "wild",
                "cat",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "then",
                "there",
                "be",
                "the",
                "low",
                "rumble",
                "that",
                "have",
                "I",
                "dart",
                "to",
                "my",
                "right",
                "in",
                "the",
                "certain",
                "knowledge",
                "that",
                "it",
                "be",
                "the",
                "empty",
                "-",
                "stomach",
                "of",
                "a",
                "cantankerous",
                "elephant",
                "."
            ],
            [
                "Next",
                "come",
                "the",
                "almost",
                "silent",
                "hiss",
                "of",
                "something",
                "blood",
                "-",
                "thirsty",
                "and",
                "nasty",
                "sighing",
                "to",
                "my",
                "left",
                "."
            ],
            [
                "this",
                "be",
                "promptly",
                "follow",
                "by",
                "another",
                "brush",
                "against",
                "the",
                "back",
                "flap",
                ";",
                "a",
                "whisper",
                "that",
                "could",
                "have",
                "be",
                "the",
                "wind",
                "but",
                "be",
                "almost",
                "certainly",
                "a",
                "leopard",
                "and",
                "the",
                "sharp",
                "meow",
                "-",
                "like",
                "snarl",
                "of",
                "a",
                "clearly",
                "small",
                "but",
                "patently",
                "lethal",
                "wild",
                "cat",
                "."
            ]
        ],
        "label": "Fear"
    },
    {
        "body_part_token_idx": 8,
        "sentence_id": "cdcf47bb-c2db-39ab-bddd-bede817709a8",
        "tokens": [
            "I",
            "breathed",
            "with",
            "my",
            "mouth",
            "open",
            ",",
            "my",
            "eyes",
            "wide",
            "like",
            "those",
            "of",
            "a",
            "mad",
            "cow",
            ",",
            "my",
            "heart",
            "pounding",
            "and",
            "my",
            "head",
            "spinning",
            "towards",
            "each",
            "sound",
            "like",
            "a",
            "scene",
            "from",
            "the",
            "Exorcist",
            "."
        ],
        "lemmatized_tokens": [
            "I",
            "breathe",
            "with",
            "my",
            "mouth",
            "open",
            ",",
            "my",
            "eye",
            "wide",
            "like",
            "those",
            "of",
            "a",
            "mad",
            "cow",
            ",",
            "my",
            "heart",
            "pound",
            "and",
            "my",
            "head",
            "spin",
            "towards",
            "each",
            "sound",
            "like",
            "a",
            "scene",
            "from",
            "the",
            "Exorcist",
            "."
        ],
        "preceding_context_tokens": [
            [
                "Then",
                "there",
                "was",
                "the",
                "low",
                "rumble",
                "that",
                "had",
                "me",
                "darting",
                "to",
                "my",
                "right",
                "in",
                "the",
                "certain",
                "knowledge",
                "that",
                "it",
                "was",
                "the",
                "empty",
                "-",
                "stomach",
                "of",
                "a",
                "cantankerous",
                "elephant",
                "."
            ],
            [
                "Next",
                "came",
                "the",
                "almost",
                "silent",
                "hiss",
                "of",
                "something",
                "blood",
                "-",
                "thirsty",
                "and",
                "nasty",
                "sighing",
                "to",
                "my",
                "left",
                "."
            ],
            [
                "This",
                "was",
                "promptly",
                "followed",
                "by",
                "another",
                "brush",
                "against",
                "the",
                "back",
                "flaps",
                ";",
                "a",
                "whisper",
                "that",
                "could",
                "have",
                "been",
                "the",
                "wind",
                "but",
                "was",
                "almost",
                "certainly",
                "a",
                "leopard",
                "and",
                "the",
                "sharp",
                "meow",
                "-",
                "like",
                "snarl",
                "of",
                "a",
                "clearly",
                "small",
                "but",
                "patently",
                "lethal",
                "wild",
                "cat",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "then",
                "there",
                "be",
                "the",
                "low",
                "rumble",
                "that",
                "have",
                "I",
                "dart",
                "to",
                "my",
                "right",
                "in",
                "the",
                "certain",
                "knowledge",
                "that",
                "it",
                "be",
                "the",
                "empty",
                "-",
                "stomach",
                "of",
                "a",
                "cantankerous",
                "elephant",
                "."
            ],
            [
                "Next",
                "come",
                "the",
                "almost",
                "silent",
                "hiss",
                "of",
                "something",
                "blood",
                "-",
                "thirsty",
                "and",
                "nasty",
                "sighing",
                "to",
                "my",
                "left",
                "."
            ],
            [
                "this",
                "be",
                "promptly",
                "follow",
                "by",
                "another",
                "brush",
                "against",
                "the",
                "back",
                "flap",
                ";",
                "a",
                "whisper",
                "that",
                "could",
                "have",
                "be",
                "the",
                "wind",
                "but",
                "be",
                "almost",
                "certainly",
                "a",
                "leopard",
                "and",
                "the",
                "sharp",
                "meow",
                "-",
                "like",
                "snarl",
                "of",
                "a",
                "clearly",
                "small",
                "but",
                "patently",
                "lethal",
                "wild",
                "cat",
                "."
            ]
        ],
        "label": "Fear"
    },
    {
        "body_part_token_idx": 18,
        "sentence_id": "cdcf47bb-c2db-39ab-bddd-bede817709a8",
        "tokens": [
            "I",
            "breathed",
            "with",
            "my",
            "mouth",
            "open",
            ",",
            "my",
            "eyes",
            "wide",
            "like",
            "those",
            "of",
            "a",
            "mad",
            "cow",
            ",",
            "my",
            "heart",
            "pounding",
            "and",
            "my",
            "head",
            "spinning",
            "towards",
            "each",
            "sound",
            "like",
            "a",
            "scene",
            "from",
            "the",
            "Exorcist",
            "."
        ],
        "lemmatized_tokens": [
            "I",
            "breathe",
            "with",
            "my",
            "mouth",
            "open",
            ",",
            "my",
            "eye",
            "wide",
            "like",
            "those",
            "of",
            "a",
            "mad",
            "cow",
            ",",
            "my",
            "heart",
            "pound",
            "and",
            "my",
            "head",
            "spin",
            "towards",
            "each",
            "sound",
            "like",
            "a",
            "scene",
            "from",
            "the",
            "Exorcist",
            "."
        ],
        "preceding_context_tokens": [
            [
                "Then",
                "there",
                "was",
                "the",
                "low",
                "rumble",
                "that",
                "had",
                "me",
                "darting",
                "to",
                "my",
                "right",
                "in",
                "the",
                "certain",
                "knowledge",
                "that",
                "it",
                "was",
                "the",
                "empty",
                "-",
                "stomach",
                "of",
                "a",
                "cantankerous",
                "elephant",
                "."
            ],
            [
                "Next",
                "came",
                "the",
                "almost",
                "silent",
                "hiss",
                "of",
                "something",
                "blood",
                "-",
                "thirsty",
                "and",
                "nasty",
                "sighing",
                "to",
                "my",
                "left",
                "."
            ],
            [
                "This",
                "was",
                "promptly",
                "followed",
                "by",
                "another",
                "brush",
                "against",
                "the",
                "back",
                "flaps",
                ";",
                "a",
                "whisper",
                "that",
                "could",
                "have",
                "been",
                "the",
                "wind",
                "but",
                "was",
                "almost",
                "certainly",
                "a",
                "leopard",
                "and",
                "the",
                "sharp",
                "meow",
                "-",
                "like",
                "snarl",
                "of",
                "a",
                "clearly",
                "small",
                "but",
                "patently",
                "lethal",
                "wild",
                "cat",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "then",
                "there",
                "be",
                "the",
                "low",
                "rumble",
                "that",
                "have",
                "I",
                "dart",
                "to",
                "my",
                "right",
                "in",
                "the",
                "certain",
                "knowledge",
                "that",
                "it",
                "be",
                "the",
                "empty",
                "-",
                "stomach",
                "of",
                "a",
                "cantankerous",
                "elephant",
                "."
            ],
            [
                "Next",
                "come",
                "the",
                "almost",
                "silent",
                "hiss",
                "of",
                "something",
                "blood",
                "-",
                "thirsty",
                "and",
                "nasty",
                "sighing",
                "to",
                "my",
                "left",
                "."
            ],
            [
                "this",
                "be",
                "promptly",
                "follow",
                "by",
                "another",
                "brush",
                "against",
                "the",
                "back",
                "flap",
                ";",
                "a",
                "whisper",
                "that",
                "could",
                "have",
                "be",
                "the",
                "wind",
                "but",
                "be",
                "almost",
                "certainly",
                "a",
                "leopard",
                "and",
                "the",
                "sharp",
                "meow",
                "-",
                "like",
                "snarl",
                "of",
                "a",
                "clearly",
                "small",
                "but",
                "patently",
                "lethal",
                "wild",
                "cat",
                "."
            ]
        ],
        "label": "Fear"
    },
    {
        "body_part_token_idx": 22,
        "sentence_id": "cdcf47bb-c2db-39ab-bddd-bede817709a8",
        "tokens": [
            "I",
            "breathed",
            "with",
            "my",
            "mouth",
            "open",
            ",",
            "my",
            "eyes",
            "wide",
            "like",
            "those",
            "of",
            "a",
            "mad",
            "cow",
            ",",
            "my",
            "heart",
            "pounding",
            "and",
            "my",
            "head",
            "spinning",
            "towards",
            "each",
            "sound",
            "like",
            "a",
            "scene",
            "from",
            "the",
            "Exorcist",
            "."
        ],
        "lemmatized_tokens": [
            "I",
            "breathe",
            "with",
            "my",
            "mouth",
            "open",
            ",",
            "my",
            "eye",
            "wide",
            "like",
            "those",
            "of",
            "a",
            "mad",
            "cow",
            ",",
            "my",
            "heart",
            "pound",
            "and",
            "my",
            "head",
            "spin",
            "towards",
            "each",
            "sound",
            "like",
            "a",
            "scene",
            "from",
            "the",
            "Exorcist",
            "."
        ],
        "preceding_context_tokens": [
            [
                "Then",
                "there",
                "was",
                "the",
                "low",
                "rumble",
                "that",
                "had",
                "me",
                "darting",
                "to",
                "my",
                "right",
                "in",
                "the",
                "certain",
                "knowledge",
                "that",
                "it",
                "was",
                "the",
                "empty",
                "-",
                "stomach",
                "of",
                "a",
                "cantankerous",
                "elephant",
                "."
            ],
            [
                "Next",
                "came",
                "the",
                "almost",
                "silent",
                "hiss",
                "of",
                "something",
                "blood",
                "-",
                "thirsty",
                "and",
                "nasty",
                "sighing",
                "to",
                "my",
                "left",
                "."
            ],
            [
                "This",
                "was",
                "promptly",
                "followed",
                "by",
                "another",
                "brush",
                "against",
                "the",
                "back",
                "flaps",
                ";",
                "a",
                "whisper",
                "that",
                "could",
                "have",
                "been",
                "the",
                "wind",
                "but",
                "was",
                "almost",
                "certainly",
                "a",
                "leopard",
                "and",
                "the",
                "sharp",
                "meow",
                "-",
                "like",
                "snarl",
                "of",
                "a",
                "clearly",
                "small",
                "but",
                "patently",
                "lethal",
                "wild",
                "cat",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "then",
                "there",
                "be",
                "the",
                "low",
                "rumble",
                "that",
                "have",
                "I",
                "dart",
                "to",
                "my",
                "right",
                "in",
                "the",
                "certain",
                "knowledge",
                "that",
                "it",
                "be",
                "the",
                "empty",
                "-",
                "stomach",
                "of",
                "a",
                "cantankerous",
                "elephant",
                "."
            ],
            [
                "Next",
                "come",
                "the",
                "almost",
                "silent",
                "hiss",
                "of",
                "something",
                "blood",
                "-",
                "thirsty",
                "and",
                "nasty",
                "sighing",
                "to",
                "my",
                "left",
                "."
            ],
            [
                "this",
                "be",
                "promptly",
                "follow",
                "by",
                "another",
                "brush",
                "against",
                "the",
                "back",
                "flap",
                ";",
                "a",
                "whisper",
                "that",
                "could",
                "have",
                "be",
                "the",
                "wind",
                "but",
                "be",
                "almost",
                "certainly",
                "a",
                "leopard",
                "and",
                "the",
                "sharp",
                "meow",
                "-",
                "like",
                "snarl",
                "of",
                "a",
                "clearly",
                "small",
                "but",
                "patently",
                "lethal",
                "wild",
                "cat",
                "."
            ]
        ],
        "label": "Fear"
    },
    {
        "body_part_token_idx": 9,
        "sentence_id": "ab05b3cc-979b-3801-a9c2-21cec5ed1fbb",
        "tokens": [
            "I",
            "had",
            "to",
            "listen",
            "closely",
            ",",
            "to",
            "close",
            "my",
            "eyes",
            ",",
            "to",
            "feel",
            "it",
            "filling",
            "my",
            "head",
            "."
        ],
        "lemmatized_tokens": [
            "I",
            "have",
            "to",
            "listen",
            "closely",
            ",",
            "to",
            "close",
            "my",
            "eye",
            ",",
            "to",
            "feel",
            "it",
            "fill",
            "my",
            "head",
            "."
        ],
        "preceding_context_tokens": [
            [
                "The",
                "first",
                "seconds",
                "announce",
                "a",
                "great",
                "song",
                ",",
                "and",
                "the",
                "vocals",
                "are",
                "filled",
                "with",
                "feelings",
                "of",
                "loneliness",
                "and",
                "anguish",
                ",",
                "in",
                "my",
                "opinion",
                "."
            ],
            [
                "It",
                "sounded",
                "like",
                "Muse",
                "meets",
                "Radiohead",
                "at",
                "first",
                "...",
                "but",
                "neither",
                "Muse",
                "nor",
                "Radiohead",
                "have",
                "touched",
                "me",
                "so",
                "deeply",
                "as",
                "Sleepy",
                "."
            ],
            [
                "ab",
                "has",
                ",",
                "with",
                "just",
                "THAT",
                "song",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "the",
                "first",
                "seconds",
                "announce",
                "a",
                "great",
                "song",
                ",",
                "and",
                "the",
                "vocal",
                "be",
                "fill",
                "with",
                "feeling",
                "of",
                "loneliness",
                "and",
                "anguish",
                ",",
                "in",
                "my",
                "opinion",
                "."
            ],
            [
                "it",
                "sound",
                "like",
                "Muse",
                "meet",
                "Radiohead",
                "at",
                "first",
                "...",
                "but",
                "neither",
                "Muse",
                "nor",
                "Radiohead",
                "have",
                "touch",
                "I",
                "so",
                "deeply",
                "as",
                "sleepy",
                "."
            ],
            [
                "ab",
                "have",
                ",",
                "with",
                "just",
                "that",
                "song",
                "."
            ]
        ],
        "label": "Sadness"
    },
    {
        "body_part_token_idx": 3,
        "sentence_id": "98ea00c7-1bf5-3158-b060-f5e7e78a99b1",
        "tokens": [
            "She",
            "spread",
            "her",
            "lips",
            "and",
            "gave",
            "her",
            "parents",
            "the",
            "hugest",
            "smile",
            "she",
            "could",
            "manage",
            "``",
            "Gosh",
            ",",
            "the",
            "traffic",
            "here",
            "is",
            "worst",
            "than",
            "it",
            "is",
            "in",
            "Jersey",
            ",",
            "''",
            "said",
            "Josselyn",
            "from",
            "the",
            "passenger",
            "'s",
            "seat",
            "of",
            "her",
            "mom",
            "'s",
            "Jeep",
            "Liberty",
            "."
        ],
        "lemmatized_tokens": [
            "she",
            "spread",
            "she",
            "lip",
            "and",
            "give",
            "she",
            "parent",
            "the",
            "hugest",
            "smile",
            "she",
            "could",
            "manage",
            "``",
            "gosh",
            ",",
            "the",
            "traffic",
            "here",
            "be",
            "worst",
            "than",
            "it",
            "be",
            "in",
            "Jersey",
            ",",
            "''",
            "say",
            "Josselyn",
            "from",
            "the",
            "passenger",
            "'s",
            "seat",
            "of",
            "she",
            "mom",
            "'s",
            "Jeep",
            "Liberty",
            "."
        ],
        "preceding_context_tokens": [
            [
                "``",
                "You",
                "have",
                "an",
                "interview",
                "with",
                "a",
                "representative",
                "from",
                "the",
                "Alvin",
                "Ailey",
                "School",
                "Friday",
                "afternoon",
                "."
            ],
            [
                "We",
                "'ll",
                "leave",
                "early",
                "and",
                "maybe",
                "you",
                "can",
                "bring",
                "a",
                "friend",
                "since",
                "we",
                "'ll",
                "be",
                "spending",
                "the",
                "weekend",
                "up",
                "there",
                ".",
                "''"
            ],
            [
                "Josselyn",
                "stood",
                "glued",
                "in",
                "her",
                "tracks",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "``",
                "you",
                "have",
                "a",
                "interview",
                "with",
                "a",
                "representative",
                "from",
                "the",
                "Alvin",
                "Ailey",
                "School",
                "Friday",
                "afternoon",
                "."
            ],
            [
                "we",
                "will",
                "leave",
                "early",
                "and",
                "maybe",
                "you",
                "can",
                "bring",
                "a",
                "friend",
                "since",
                "we",
                "will",
                "be",
                "spend",
                "the",
                "weekend",
                "up",
                "there",
                ".",
                "''"
            ],
            [
                "Josselyn",
                "stand",
                "glue",
                "in",
                "she",
                "track",
                "."
            ]
        ],
        "label": "Joy"
    },
    {
        "body_part_token_idx": 17,
        "sentence_id": "f1582d2e-ed25-320e-be34-04745e29b39d",
        "tokens": [
            "``",
            "We",
            "'re",
            "not",
            "staying",
            ",",
            "''",
            "Snape",
            "said",
            ",",
            "adjusting",
            "his",
            "scarf",
            "more",
            "tightly",
            "around",
            "his",
            "neck",
            ",",
            "and",
            "not",
            "just",
            "because",
            "of",
            "the",
            "chill",
            "December",
            "air",
            "."
        ],
        "lemmatized_tokens": [
            "``",
            "we",
            "be",
            "not",
            "stay",
            ",",
            "''",
            "Snape",
            "say",
            ",",
            "adjust",
            "he",
            "scarf",
            "more",
            "tightly",
            "around",
            "he",
            "neck",
            ",",
            "and",
            "not",
            "just",
            "because",
            "of",
            "the",
            "chill",
            "December",
            "air",
            "."
        ],
        "preceding_context_tokens": [
            [
                "I",
                "Found",
                "It",
                "in",
                "You",
                "''",
                "-LRB-",
                "sorry",
                "about",
                "the",
                "horses",
                ",",
                "I",
                "could",
                "n't",
                "find",
                "a",
                "better",
                "video",
                "...",
                "it",
                "was",
                "either",
                "this",
                "or",
                "someone",
                "'s",
                "kids",
                "!",
                ")"
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "I",
                "find",
                "it",
                "in",
                "you",
                "''",
                "-lrb-",
                "sorry",
                "about",
                "the",
                "horse",
                ",",
                "I",
                "could",
                "not",
                "find",
                "a",
                "better",
                "video",
                "...",
                "it",
                "be",
                "either",
                "this",
                "or",
                "someone",
                "'s",
                "kid",
                "!",
                ")"
            ]
        ],
        "label": "Disgust"
    },
    {
        "body_part_token_idx": 1,
        "sentence_id": "44bf9ff3-27d8-3620-bed5-e64896c08667",
        "tokens": [
            "My",
            "cheeks",
            "more",
            "red",
            "than",
            "before",
            "."
        ],
        "lemmatized_tokens": [
            "my",
            "cheek",
            "more",
            "red",
            "than",
            "before",
            "."
        ],
        "preceding_context_tokens": [
            [
                "``",
                "Yah",
                ",",
                "you",
                "are",
                "the",
                "most",
                "beautiful",
                "man",
                "I",
                "ever",
                "seen",
                "."
            ],
            [
                "And",
                "I",
                "did",
                "n't",
                "see",
                "a",
                "girl",
                "as",
                "beautiful",
                "as",
                "you",
                ".",
                "''"
            ],
            [
                "She",
                "blurted",
                "out",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "``",
                "Yah",
                ",",
                "you",
                "be",
                "the",
                "most",
                "beautiful",
                "man",
                "I",
                "ever",
                "see",
                "."
            ],
            [
                "and",
                "I",
                "do",
                "not",
                "see",
                "a",
                "girl",
                "as",
                "beautiful",
                "as",
                "you",
                ".",
                "''"
            ],
            [
                "she",
                "blurt",
                "out",
                "."
            ]
        ],
        "label": "Joy"
    },
    {
        "body_part_token_idx": 7,
        "sentence_id": "ff646bf6-561a-365c-b916-3b0c39f4920d",
        "tokens": [
            "It",
            "felt",
            "like",
            "someone",
            "was",
            "squeezing",
            "my",
            "heart",
            "."
        ],
        "lemmatized_tokens": [
            "it",
            "feel",
            "like",
            "someone",
            "be",
            "squeeze",
            "my",
            "heart",
            "."
        ],
        "preceding_context_tokens": [
            [
                "About",
                "two",
                "days",
                "later",
                ",",
                "at",
                "work",
                ",",
                "I",
                "had",
                "some",
                "strange",
                "chest",
                "pains",
                "."
            ],
            [
                "I",
                "took",
                "myself",
                "to",
                "health",
                "services",
                ",",
                "but",
                "I",
                "was",
                "n't",
                "having",
                "a",
                "heart",
                "attack",
                "."
            ],
            [
                "I",
                "think",
                "it",
                "must",
                "have",
                "been",
                "an",
                "anxiety",
                "attack",
                "for",
                "some",
                "reason",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "about",
                "two",
                "day",
                "later",
                ",",
                "at",
                "work",
                ",",
                "I",
                "have",
                "some",
                "strange",
                "chest",
                "pain",
                "."
            ],
            [
                "I",
                "take",
                "myself",
                "to",
                "health",
                "service",
                ",",
                "but",
                "I",
                "be",
                "not",
                "have",
                "a",
                "heart",
                "attack",
                "."
            ],
            [
                "I",
                "think",
                "it",
                "must",
                "have",
                "be",
                "a",
                "anxiety",
                "attack",
                "for",
                "some",
                "reason",
                "."
            ]
        ],
        "label": "Fear"
    },
    {
        "body_part_token_idx": 13,
        "sentence_id": "c1a3ea15-08a2-3d00-899c-7883857af592",
        "tokens": [
            "'",
            "By",
            "now",
            ",",
            "a",
            "small",
            "intense",
            "knot",
            "of",
            "hatred",
            "swelling",
            "in",
            "my",
            "stomach",
            "."
        ],
        "lemmatized_tokens": [
            "'",
            "by",
            "now",
            ",",
            "a",
            "small",
            "intense",
            "knot",
            "of",
            "hatred",
            "swell",
            "in",
            "my",
            "stomach",
            "."
        ],
        "preceding_context_tokens": [
            [
                "Mother",
                "stormed",
                "into",
                "my",
                "room",
                ",",
                "opening",
                "blinds",
                ",",
                "pulling",
                "back",
                "covers",
                ",",
                "crashing",
                ",",
                "banging",
                ",",
                "`",
                "GET",
                "UP",
                "!!!"
            ],
            [
                "ITS",
                "ALMOST",
                "1PM",
                "!!!"
            ],
            [
                "You",
                "need",
                "to",
                "be",
                "awake",
                "before",
                "I",
                "leave",
                "!"
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "Mother",
                "storm",
                "into",
                "my",
                "room",
                ",",
                "open",
                "blind",
                ",",
                "pull",
                "back",
                "cover",
                ",",
                "crash",
                ",",
                "bang",
                ",",
                "`",
                "get",
                "up",
                "!!!"
            ],
            [
                "ITS",
                "almost",
                "1pm",
                "!!!"
            ],
            [
                "you",
                "need",
                "to",
                "be",
                "awake",
                "before",
                "I",
                "leave",
                "!"
            ]
        ],
        "label": "Anger"
    },
    {
        "body_part_token_idx": 14,
        "sentence_id": "6089c364-8c3c-3a67-9779-3944d3da4c5a",
        "tokens": [
            "Cat",
            "looked",
            "up",
            "at",
            "her",
            "with",
            "disgust",
            "-LRB-",
            "which",
            "looked",
            "rather",
            "funny",
            "with",
            "his",
            "tongue",
            "out",
            ")",
            ",",
            "and",
            "quickened",
            "his",
            "pace",
            "."
        ],
        "lemmatized_tokens": [
            "cat",
            "look",
            "up",
            "at",
            "she",
            "with",
            "disgust",
            "-lrb-",
            "which",
            "look",
            "rather",
            "funny",
            "with",
            "he",
            "tongue",
            "out",
            ")",
            ",",
            "and",
            "quicken",
            "he",
            "pace",
            "."
        ],
        "preceding_context_tokens": [
            [
                "Are",
                "we",
                "very",
                "far",
                "from",
                "the",
                "oasis",
                "?"
            ],
            [
                "He",
                "shook",
                "his",
                "head",
                "."
            ],
            [
                "Would",
                "you",
                "like",
                "to",
                "ride",
                "on",
                "my",
                "shoulders",
                "?"
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "be",
                "we",
                "very",
                "far",
                "from",
                "the",
                "oasis",
                "?"
            ],
            [
                "he",
                "shake",
                "he",
                "head",
                "."
            ],
            [
                "would",
                "you",
                "like",
                "to",
                "ride",
                "on",
                "my",
                "shoulder",
                "?"
            ]
        ],
        "label": "Disgust"
    },
    {
        "body_part_token_idx": 1,
        "sentence_id": "0c8135d4-1341-3d2a-9eef-0c2eb2e02495",
        "tokens": [
            "His",
            "head",
            "spun",
            ",",
            "clogged",
            "with",
            "a",
            "confusing",
            "swirl",
            "of",
            "thoughts",
            "and",
            "emotions",
            "."
        ],
        "lemmatized_tokens": [
            "he",
            "head",
            "spin",
            ",",
            "clog",
            "with",
            "a",
            "confusing",
            "swirl",
            "of",
            "thought",
            "and",
            "emotion",
            "."
        ],
        "preceding_context_tokens": [
            [
                "So",
                "infuriating",
                "!"
            ],
            [
                "And",
                "and",
                "stop",
                "/",
                "doing",
                "that",
                "/",
                "!"
            ],
            [
                "Barely",
                "keeping",
                "from",
                "exploding",
                ",",
                "Neku",
                "gestured",
                "jerkily",
                "and",
                "vaguely",
                "at",
                "nothing",
                "in",
                "particular",
                ",",
                "the",
                "culmination",
                "of",
                "the",
                "day",
                "'s",
                "frustration",
                "and",
                "humiliation",
                "having",
                "robbed",
                "him",
                "of",
                "his",
                "usual",
                "wit",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "so",
                "infuriating",
                "!"
            ],
            [
                "and",
                "and",
                "stop",
                "/",
                "do",
                "that",
                "/",
                "!"
            ],
            [
                "barely",
                "keep",
                "from",
                "explode",
                ",",
                "Neku",
                "gesture",
                "jerkily",
                "and",
                "vaguely",
                "at",
                "nothing",
                "in",
                "particular",
                ",",
                "the",
                "culmination",
                "of",
                "the",
                "day",
                "'s",
                "frustration",
                "and",
                "humiliation",
                "have",
                "rob",
                "he",
                "of",
                "he",
                "usual",
                "wit",
                "."
            ]
        ],
        "label": "Anger"
    },
    {
        "body_part_token_idx": 8,
        "sentence_id": "3dcdc520-09e8-3f3f-9247-074fc9a8a8fc",
        "tokens": [
            "She",
            "took",
            "a",
            "step",
            "back",
            ",",
            "shaking",
            "her",
            "head",
            "."
        ],
        "lemmatized_tokens": [
            "she",
            "take",
            "a",
            "step",
            "back",
            ",",
            "shake",
            "she",
            "head",
            "."
        ],
        "preceding_context_tokens": [
            [
                "I",
                "told",
                "you",
                "things",
                "."
            ],
            [
                "God",
                ",",
                "Coop",
                ",",
                "you",
                "were",
                "using",
                "my",
                "thoughts",
                "against",
                "me",
                "."
            ],
            [
                "How",
                "could",
                "you",
                "do",
                "that?",
                "Ashlee",
                ",",
                "he",
                "stood",
                "up",
                "as",
                "well",
                "and",
                "walked",
                "toward",
                "her",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "I",
                "tell",
                "you",
                "thing",
                "."
            ],
            [
                "God",
                ",",
                "Coop",
                ",",
                "you",
                "be",
                "use",
                "my",
                "thought",
                "against",
                "I",
                "."
            ],
            [
                "how",
                "could",
                "you",
                "do",
                "that?",
                "Ashlee",
                ",",
                "he",
                "stand",
                "up",
                "as",
                "well",
                "and",
                "walk",
                "toward",
                "she",
                "."
            ]
        ],
        "label": "Fear"
    },
    {
        "body_part_token_idx": 64,
        "sentence_id": "d5c4d1f7-3d21-38fd-93b0-3e086a1e9681",
        "tokens": [
            "The",
            "next",
            "morning",
            "Ricardo",
            "and",
            "I",
            "went",
            "to",
            "Huallychoca",
            "where",
            "I",
            "had",
            "worked",
            "with",
            "all",
            "the",
            "other",
            "kids",
            ",",
            "as",
            "we",
            "entered",
            "the",
            "grounds",
            "of",
            "the",
            "centre",
            ",",
            "a",
            "few",
            "of",
            "the",
            "kids",
            "were",
            "playing",
            "on",
            "the",
            "grass",
            "and",
            "my",
            "little",
            "amigo",
            "Sabrina",
            "came",
            "running",
            "over",
            "shouting",
            "``",
            "proffy",
            ",",
            "proffy",
            "''",
            "...",
            "again",
            ",",
            "tears",
            "in",
            "the",
            "eyes",
            "and",
            "a",
            "lump",
            "in",
            "my",
            "throat",
            "."
        ],
        "lemmatized_tokens": [
            "the",
            "next",
            "morning",
            "Ricardo",
            "and",
            "I",
            "go",
            "to",
            "Huallychoca",
            "where",
            "I",
            "have",
            "work",
            "with",
            "all",
            "the",
            "other",
            "kid",
            ",",
            "as",
            "we",
            "enter",
            "the",
            "grounds",
            "of",
            "the",
            "centre",
            ",",
            "a",
            "few",
            "of",
            "the",
            "kid",
            "be",
            "play",
            "on",
            "the",
            "grass",
            "and",
            "my",
            "little",
            "amigo",
            "Sabrina",
            "come",
            "run",
            "over",
            "shout",
            "``",
            "proffy",
            ",",
            "proffy",
            "''",
            "...",
            "again",
            ",",
            "tear",
            "in",
            "the",
            "eye",
            "and",
            "a",
            "lump",
            "in",
            "my",
            "throat",
            "."
        ],
        "preceding_context_tokens": [
            [
                "He",
                "is",
                "a",
                "very",
                "bright",
                ",",
                "caring",
                "and",
                "lovely",
                "boy",
                "."
            ],
            [
                "I",
                "wanted",
                "to",
                "spend",
                "as",
                "much",
                "time",
                "as",
                "I",
                "could",
                "with",
                "him",
                "while",
                "I",
                "was",
                "here",
                "so",
                "I",
                "arranged",
                "to",
                "visit",
                "his",
                "father",
                "the",
                "next",
                "day",
                "and",
                "Ricardo",
                "&",
                "I",
                "thought",
                "it",
                "would",
                "be",
                "great",
                "to",
                "have",
                "a",
                "day",
                "out",
                "on",
                "Saturday",
                "...",
                "so",
                "Pisac",
                "it",
                "was",
                "and",
                "Cain",
                "just",
                "couldnt",
                "stop",
                "smiling",
                "."
            ],
            [
                "We",
                "went",
                "for",
                "a",
                "coke",
                "and",
                "a",
                "chat",
                "then",
                "I",
                "walked",
                "him",
                "to",
                "his",
                "English",
                "class",
                ",",
                "arranging",
                "to",
                "meet",
                "the",
                "next",
                "day",
                "and",
                "saying",
                "our",
                "goodbyes",
                "...",
                "its",
                "a",
                "great",
                "feeling",
                "when",
                "someone",
                "smiles",
                "so",
                "much",
                "just",
                "because",
                "your",
                "there",
                "...",
                "and",
                "I",
                "had",
                "the",
                "same",
                "feeling",
                "too",
                "!"
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "he",
                "be",
                "a",
                "very",
                "bright",
                ",",
                "caring",
                "and",
                "lovely",
                "boy",
                "."
            ],
            [
                "I",
                "want",
                "to",
                "spend",
                "as",
                "much",
                "time",
                "as",
                "I",
                "could",
                "with",
                "he",
                "while",
                "I",
                "be",
                "here",
                "so",
                "I",
                "arrange",
                "to",
                "visit",
                "he",
                "father",
                "the",
                "next",
                "day",
                "and",
                "Ricardo",
                "&",
                "I",
                "think",
                "it",
                "would",
                "be",
                "great",
                "to",
                "have",
                "a",
                "day",
                "out",
                "on",
                "Saturday",
                "...",
                "so",
                "Pisac",
                "it",
                "be",
                "and",
                "Cain",
                "just",
                "couldnt",
                "stop",
                "smile",
                "."
            ],
            [
                "we",
                "go",
                "for",
                "a",
                "coke",
                "and",
                "a",
                "chat",
                "then",
                "I",
                "walk",
                "he",
                "to",
                "he",
                "english",
                "class",
                ",",
                "arrange",
                "to",
                "meet",
                "the",
                "next",
                "day",
                "and",
                "say",
                "we",
                "goodbye",
                "...",
                "its",
                "a",
                "great",
                "feeling",
                "when",
                "someone",
                "smile",
                "so",
                "much",
                "just",
                "because",
                "you",
                "there",
                "...",
                "and",
                "I",
                "have",
                "the",
                "same",
                "feeling",
                "too",
                "!"
            ]
        ],
        "label": "Sadness"
    },
    {
        "body_part_token_idx": 60,
        "sentence_id": "3e101a8d-ae00-3d37-9513-93598893353b",
        "tokens": [
            "Max",
            ",",
            "from",
            "working",
            "outside",
            ",",
            "was",
            "already",
            "warmed",
            "up",
            "-",
            "so",
            "he",
            "shed",
            "his",
            "coat",
            ",",
            "hung",
            "it",
            "on",
            "a",
            "wooden",
            "knob",
            "beside",
            "the",
            "door",
            "with",
            "a",
            "rubber",
            "mat",
            "below",
            "to",
            "catch",
            "the",
            "melting",
            "snow",
            ",",
            "and",
            "sat",
            "down",
            "on",
            "a",
            "hard",
            "wooden",
            "bench",
            "to",
            "take",
            "off",
            "his",
            "boats.She",
            "looked",
            "over",
            "at",
            "him",
            "then",
            ",",
            "a",
            "flash",
            "in",
            "her",
            "eyes",
            "."
        ],
        "lemmatized_tokens": [
            "Max",
            ",",
            "from",
            "work",
            "outside",
            ",",
            "be",
            "already",
            "warm",
            "up",
            "-",
            "so",
            "he",
            "shed",
            "he",
            "coat",
            ",",
            "hang",
            "it",
            "on",
            "a",
            "wooden",
            "knob",
            "beside",
            "the",
            "door",
            "with",
            "a",
            "rubber",
            "mat",
            "below",
            "to",
            "catch",
            "the",
            "melting",
            "snow",
            ",",
            "and",
            "sit",
            "down",
            "on",
            "a",
            "hard",
            "wooden",
            "bench",
            "to",
            "take",
            "off",
            "he",
            "boats.she",
            "look",
            "over",
            "at",
            "he",
            "then",
            ",",
            "a",
            "flash",
            "in",
            "she",
            "eye",
            "."
        ],
        "preceding_context_tokens": [
            [
                "That",
                "gave",
                "him",
                "plenty",
                "of",
                "time",
                "to",
                "clear",
                "the",
                "path",
                "to",
                "the",
                "door",
                ",",
                "carry",
                "in",
                "all",
                "their",
                "gear",
                "and",
                "food",
                ",",
                "and",
                "check",
                "on",
                "the",
                "cabin",
                "itself",
                "from",
                "the",
                "outside",
                "."
            ],
            [
                "Once",
                "he",
                "was",
                "satisfied",
                "with",
                "the",
                "perimeter",
                "and",
                "the",
                "security",
                "of",
                "the",
                "place",
                ",",
                "Max",
                "checked",
                "the",
                "car",
                "one",
                "last",
                "time",
                "for",
                "anything",
                "that",
                "might",
                "freeze",
                ",",
                "locked",
                "it",
                ",",
                "and",
                "then",
                "went",
                "into",
                "the",
                "cabin.She",
                "was",
                "working",
                "on",
                "some",
                "tea",
                "as",
                "he",
                "opened",
                "the",
                "door",
                "and",
                "stamped",
                "the",
                "snow",
                "off",
                "his",
                "boots",
                "."
            ],
            [
                "She",
                "'d",
                "taken",
                "off",
                "her",
                "heavy",
                "jacket",
                "but",
                "added",
                "another",
                "sweater",
                "with",
                "a",
                "high",
                "collar",
                "to",
                "keep",
                "warm",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "that",
                "give",
                "he",
                "plenty",
                "of",
                "time",
                "to",
                "clear",
                "the",
                "path",
                "to",
                "the",
                "door",
                ",",
                "carry",
                "in",
                "all",
                "they",
                "gear",
                "and",
                "food",
                ",",
                "and",
                "check",
                "on",
                "the",
                "cabin",
                "itself",
                "from",
                "the",
                "outside",
                "."
            ],
            [
                "once",
                "he",
                "be",
                "satisfied",
                "with",
                "the",
                "perimeter",
                "and",
                "the",
                "security",
                "of",
                "the",
                "place",
                ",",
                "Max",
                "check",
                "the",
                "car",
                "one",
                "last",
                "time",
                "for",
                "anything",
                "that",
                "might",
                "freeze",
                ",",
                "lock",
                "it",
                ",",
                "and",
                "then",
                "go",
                "into",
                "the",
                "cabin.she",
                "be",
                "work",
                "on",
                "some",
                "tea",
                "as",
                "he",
                "open",
                "the",
                "door",
                "and",
                "stamp",
                "the",
                "snow",
                "off",
                "he",
                "boot",
                "."
            ],
            [
                "she",
                "would",
                "take",
                "off",
                "she",
                "heavy",
                "jacket",
                "but",
                "add",
                "another",
                "sweater",
                "with",
                "a",
                "high",
                "collar",
                "to",
                "keep",
                "warm",
                "."
            ]
        ],
        "label": "Surprise"
    },
    {
        "body_part_token_idx": 7,
        "sentence_id": "a1e89818-24c5-3281-8295-6456e9fdc29a",
        "tokens": [
            "``",
            "That",
            "pretty",
            "blush",
            "played",
            "across",
            "his",
            "cheeks",
            ",",
            "and",
            "Bond",
            "held",
            "out",
            "an",
            "arm",
            "dramatically",
            ",",
            "leading",
            "him",
            "to",
            "the",
            "lift",
            "."
        ],
        "lemmatized_tokens": [
            "``",
            "that",
            "pretty",
            "blush",
            "play",
            "across",
            "he",
            "cheek",
            ",",
            "and",
            "Bond",
            "hold",
            "out",
            "a",
            "arm",
            "dramatically",
            ",",
            "lead",
            "he",
            "to",
            "the",
            "lift",
            "."
        ],
        "preceding_context_tokens": [
            [
                "He",
                "'d",
                "been",
                "right",
                "about",
                "the",
                "cut",
                "``",
                "it",
                "was",
                "flattering",
                ",",
                "elegant",
                ",",
                "perfect",
                "."
            ],
            [
                "The",
                "man",
                "was",
                "made",
                "for",
                "a",
                "dinner",
                "jacket",
                ",",
                "made",
                "for",
                "such",
                "style",
                ",",
                "and",
                "what",
                "could",
                "he",
                "possibly",
                "say",
                "to",
                "acknowledge",
                "the",
                "perfect",
                "marriage",
                "of",
                "clothes",
                "and",
                "man",
                "?"
            ],
            [
                "``",
                "Beautiful",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "he",
                "have",
                "be",
                "right",
                "about",
                "the",
                "cut",
                "``",
                "it",
                "be",
                "flattering",
                ",",
                "elegant",
                ",",
                "perfect",
                "."
            ],
            [
                "the",
                "man",
                "be",
                "make",
                "for",
                "a",
                "dinner",
                "jacket",
                ",",
                "make",
                "for",
                "such",
                "style",
                ",",
                "and",
                "what",
                "could",
                "he",
                "possibly",
                "say",
                "to",
                "acknowledge",
                "the",
                "perfect",
                "marriage",
                "of",
                "clothes",
                "and",
                "man",
                "?"
            ],
            [
                "``",
                "beautiful",
                "."
            ]
        ],
        "label": "Joy"
    },
    {
        "body_part_token_idx": 10,
        "sentence_id": "e8d24178-d1b4-3c6d-b9af-aad5c077b3be",
        "tokens": [
            "And",
            "a",
            "silly",
            "kid",
            "making",
            "a",
            "snow",
            "angel",
            "with",
            "her",
            "tongue",
            "sticking",
            "out",
            "."
        ],
        "lemmatized_tokens": [
            "and",
            "a",
            "silly",
            "kid",
            "make",
            "a",
            "snow",
            "angel",
            "with",
            "she",
            "tongue",
            "stick",
            "out",
            "."
        ],
        "preceding_context_tokens": [
            [
                "What",
                "is",
                "this",
                "stuff",
                "?"
            ],
            [
                "One",
                "of",
                "our",
                "backyard",
                "trees",
                "enveloped",
                "in",
                "white",
                "."
            ],
            [
                "A",
                "cute",
                "kid",
                "enjoying",
                "it",
                "all",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "what",
                "be",
                "this",
                "stuff",
                "?"
            ],
            [
                "one",
                "of",
                "we",
                "backyard",
                "tree",
                "envelop",
                "in",
                "white",
                "."
            ],
            [
                "a",
                "cute",
                "kid",
                "enjoy",
                "it",
                "all",
                "."
            ]
        ],
        "label": "Joy"
    },
    {
        "body_part_token_idx": 3,
        "sentence_id": "5ce062ae-3555-36f7-8752-32759e2ff16f",
        "tokens": [
            "Kurt",
            "rolled",
            "his",
            "eyes",
            "."
        ],
        "lemmatized_tokens": [
            "Kurt",
            "roll",
            "he",
            "eye",
            "."
        ],
        "preceding_context_tokens": [
            [
                "``",
                "Yes",
                "!"
            ],
            [
                "I",
                "get",
                "the",
                "whole",
                "celebration",
                "thing",
                ",",
                "really",
                ",",
                "but",
                "it",
                "will",
                "be",
                "just",
                "the",
                "slightest",
                "bit",
                "suspicious",
                "when",
                "all",
                "of",
                "Dalton",
                "wakes",
                "up",
                "hung",
                "over",
                "tomorrow",
                "."
            ],
            [
                "Now",
                ",",
                "get",
                "rid",
                "of",
                "it",
                ".",
                "''"
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "``",
                "yes",
                "!"
            ],
            [
                "I",
                "get",
                "the",
                "whole",
                "celebration",
                "thing",
                ",",
                "really",
                ",",
                "but",
                "it",
                "will",
                "be",
                "just",
                "the",
                "slightest",
                "bit",
                "suspicious",
                "when",
                "all",
                "of",
                "Dalton",
                "wake",
                "up",
                "hang",
                "over",
                "tomorrow",
                "."
            ],
            [
                "now",
                ",",
                "get",
                "rid",
                "of",
                "it",
                ".",
                "''"
            ]
        ],
        "label": "Disgust"
    },
    {
        "body_part_token_idx": 2,
        "sentence_id": "3e109f27-3150-34dc-bde2-a5bc38222aa9",
        "tokens": [
            "With",
            "my",
            "heart",
            "in",
            "my",
            "throat",
            ",",
            "my",
            "voice",
            "thick",
            "with",
            "emotion",
            "said",
            ",",
            "``",
            "OH",
            "!"
        ],
        "lemmatized_tokens": [
            "with",
            "my",
            "heart",
            "in",
            "my",
            "throat",
            ",",
            "my",
            "voice",
            "thick",
            "with",
            "emotion",
            "say",
            ",",
            "``",
            "OH",
            "!"
        ],
        "preceding_context_tokens": [
            [
                "``",
                "THAT",
                "'S",
                "MY",
                "PURSE",
                "!",
                "''"
            ],
            [
                "the",
                "woman",
                "standing",
                "next",
                "to",
                "the",
                "CSM",
                "cried",
                "as",
                "her",
                "anguished",
                "eyes",
                "fell",
                "on",
                "the",
                "black",
                "purse",
                "I",
                "was",
                "clutching",
                "my",
                "right",
                "hand",
                "."
            ],
            [
                "My",
                "eyes",
                "went",
                "from",
                "the",
                "shocked",
                "and",
                "surprised",
                "look",
                "of",
                "the",
                "CSM",
                "to",
                "the",
                "lady",
                "and",
                ",",
                "in",
                "milliseconds",
                "the",
                "center",
                "of",
                "my",
                "chest",
                "was",
                "bombarded",
                "with",
                "such",
                "intense",
                "relief",
                "and",
                "joy",
                ",",
                "tears",
                "pooled",
                "in",
                "my",
                "eyes",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "``",
                "that",
                "be",
                "my",
                "purse",
                "!",
                "''"
            ],
            [
                "the",
                "woman",
                "stand",
                "next",
                "to",
                "the",
                "CSM",
                "cry",
                "as",
                "she",
                "anguished",
                "eye",
                "fall",
                "on",
                "the",
                "black",
                "purse",
                "I",
                "be",
                "clutch",
                "my",
                "right",
                "hand",
                "."
            ],
            [
                "my",
                "eye",
                "go",
                "from",
                "the",
                "shocked",
                "and",
                "surprised",
                "look",
                "of",
                "the",
                "CSM",
                "to",
                "the",
                "lady",
                "and",
                ",",
                "in",
                "millisecond",
                "the",
                "center",
                "of",
                "my",
                "chest",
                "be",
                "bombard",
                "with",
                "such",
                "intense",
                "relief",
                "and",
                "joy",
                ",",
                "tear",
                "pool",
                "in",
                "my",
                "eye",
                "."
            ]
        ],
        "label": "Joy"
    },
    {
        "body_part_token_idx": 5,
        "sentence_id": "3e109f27-3150-34dc-bde2-a5bc38222aa9",
        "tokens": [
            "With",
            "my",
            "heart",
            "in",
            "my",
            "throat",
            ",",
            "my",
            "voice",
            "thick",
            "with",
            "emotion",
            "said",
            ",",
            "``",
            "OH",
            "!"
        ],
        "lemmatized_tokens": [
            "with",
            "my",
            "heart",
            "in",
            "my",
            "throat",
            ",",
            "my",
            "voice",
            "thick",
            "with",
            "emotion",
            "say",
            ",",
            "``",
            "OH",
            "!"
        ],
        "preceding_context_tokens": [
            [
                "``",
                "THAT",
                "'S",
                "MY",
                "PURSE",
                "!",
                "''"
            ],
            [
                "the",
                "woman",
                "standing",
                "next",
                "to",
                "the",
                "CSM",
                "cried",
                "as",
                "her",
                "anguished",
                "eyes",
                "fell",
                "on",
                "the",
                "black",
                "purse",
                "I",
                "was",
                "clutching",
                "my",
                "right",
                "hand",
                "."
            ],
            [
                "My",
                "eyes",
                "went",
                "from",
                "the",
                "shocked",
                "and",
                "surprised",
                "look",
                "of",
                "the",
                "CSM",
                "to",
                "the",
                "lady",
                "and",
                ",",
                "in",
                "milliseconds",
                "the",
                "center",
                "of",
                "my",
                "chest",
                "was",
                "bombarded",
                "with",
                "such",
                "intense",
                "relief",
                "and",
                "joy",
                ",",
                "tears",
                "pooled",
                "in",
                "my",
                "eyes",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "``",
                "that",
                "be",
                "my",
                "purse",
                "!",
                "''"
            ],
            [
                "the",
                "woman",
                "stand",
                "next",
                "to",
                "the",
                "CSM",
                "cry",
                "as",
                "she",
                "anguished",
                "eye",
                "fall",
                "on",
                "the",
                "black",
                "purse",
                "I",
                "be",
                "clutch",
                "my",
                "right",
                "hand",
                "."
            ],
            [
                "my",
                "eye",
                "go",
                "from",
                "the",
                "shocked",
                "and",
                "surprised",
                "look",
                "of",
                "the",
                "CSM",
                "to",
                "the",
                "lady",
                "and",
                ",",
                "in",
                "millisecond",
                "the",
                "center",
                "of",
                "my",
                "chest",
                "be",
                "bombard",
                "with",
                "such",
                "intense",
                "relief",
                "and",
                "joy",
                ",",
                "tear",
                "pool",
                "in",
                "my",
                "eye",
                "."
            ]
        ],
        "label": "Joy"
    },
    {
        "body_part_token_idx": 8,
        "sentence_id": "528cf248-e7d8-3163-bb06-12066e6fdafa",
        "tokens": [
            "He",
            "looked",
            "around",
            "the",
            "warehouse",
            "and",
            "cleared",
            "his",
            "throat",
            "again",
            "as",
            "he",
            "leaned",
            "forward",
            "."
        ],
        "lemmatized_tokens": [
            "he",
            "look",
            "around",
            "the",
            "warehouse",
            "and",
            "clear",
            "he",
            "throat",
            "again",
            "as",
            "he",
            "lean",
            "forward",
            "."
        ],
        "preceding_context_tokens": [
            [
                "The",
                "grin",
                "on",
                "his",
                "face",
                "about",
                "made",
                "me",
                "melt",
                "outta",
                "my",
                "chair",
                "."
            ],
            [
                "``",
                "I",
                "know",
                "what",
                "you",
                "mean",
                "."
            ],
            [
                "I",
                "get",
                "hot",
                "too",
                ".",
                "''"
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "the",
                "grin",
                "on",
                "he",
                "face",
                "about",
                "make",
                "I",
                "melt",
                "outta",
                "my",
                "chair",
                "."
            ],
            [
                "``",
                "I",
                "know",
                "what",
                "you",
                "mean",
                "."
            ],
            [
                "I",
                "get",
                "hot",
                "too",
                ".",
                "''"
            ]
        ],
        "label": "Joy"
    },
    {
        "body_part_token_idx": 33,
        "sentence_id": "13481c34-4db1-38b1-b1b0-a1a19a55f146",
        "tokens": [
            "Security",
            "and",
            "I",
            "managed",
            "to",
            "get",
            "shots",
            "in",
            "and",
            "they",
            "ended",
            "up",
            "running",
            "their",
            "car",
            "into",
            "a",
            "tree.",
            "A",
            "chuckle",
            "slipped",
            "out",
            "of",
            "me",
            "of",
            "its",
            "own",
            "volition",
            ",",
            "and",
            "I",
            "clapped",
            "my",
            "hand",
            "over",
            "my",
            "mouth",
            "in",
            "chagrin",
            "."
        ],
        "lemmatized_tokens": [
            "security",
            "and",
            "I",
            "manage",
            "to",
            "get",
            "shot",
            "in",
            "and",
            "they",
            "end",
            "up",
            "run",
            "they",
            "car",
            "into",
            "a",
            "tree.",
            "a",
            "chuckle",
            "slip",
            "out",
            "of",
            "I",
            "of",
            "its",
            "own",
            "volition",
            ",",
            "and",
            "I",
            "clap",
            "my",
            "hand",
            "over",
            "my",
            "mouth",
            "in",
            "chagrin",
            "."
        ],
        "preceding_context_tokens": [
            [
                "It",
                "was",
                "a",
                "shoddy",
                "assassination",
                "attempt",
                "."
            ],
            [
                "They",
                "were",
                "driving",
                "by",
                ",",
                "hoping",
                "to",
                "get",
                "a",
                "clean",
                "shot",
                "at",
                "me",
                "as",
                "I",
                "got",
                "out",
                "of",
                "the",
                "car",
                "."
            ],
            [
                "They",
                "missed",
                "the",
                "vital",
                "stuff",
                "but",
                "got",
                "my",
                "kneecap",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "it",
                "be",
                "a",
                "shoddy",
                "assassination",
                "attempt",
                "."
            ],
            [
                "they",
                "be",
                "drive",
                "by",
                ",",
                "hope",
                "to",
                "get",
                "a",
                "clean",
                "shot",
                "at",
                "I",
                "as",
                "I",
                "get",
                "out",
                "of",
                "the",
                "car",
                "."
            ],
            [
                "they",
                "miss",
                "the",
                "vital",
                "stuff",
                "but",
                "get",
                "my",
                "kneecap",
                "."
            ]
        ],
        "label": "Fear"
    },
    {
        "body_part_token_idx": 36,
        "sentence_id": "13481c34-4db1-38b1-b1b0-a1a19a55f146",
        "tokens": [
            "Security",
            "and",
            "I",
            "managed",
            "to",
            "get",
            "shots",
            "in",
            "and",
            "they",
            "ended",
            "up",
            "running",
            "their",
            "car",
            "into",
            "a",
            "tree.",
            "A",
            "chuckle",
            "slipped",
            "out",
            "of",
            "me",
            "of",
            "its",
            "own",
            "volition",
            ",",
            "and",
            "I",
            "clapped",
            "my",
            "hand",
            "over",
            "my",
            "mouth",
            "in",
            "chagrin",
            "."
        ],
        "lemmatized_tokens": [
            "security",
            "and",
            "I",
            "manage",
            "to",
            "get",
            "shot",
            "in",
            "and",
            "they",
            "end",
            "up",
            "run",
            "they",
            "car",
            "into",
            "a",
            "tree.",
            "a",
            "chuckle",
            "slip",
            "out",
            "of",
            "I",
            "of",
            "its",
            "own",
            "volition",
            ",",
            "and",
            "I",
            "clap",
            "my",
            "hand",
            "over",
            "my",
            "mouth",
            "in",
            "chagrin",
            "."
        ],
        "preceding_context_tokens": [
            [
                "It",
                "was",
                "a",
                "shoddy",
                "assassination",
                "attempt",
                "."
            ],
            [
                "They",
                "were",
                "driving",
                "by",
                ",",
                "hoping",
                "to",
                "get",
                "a",
                "clean",
                "shot",
                "at",
                "me",
                "as",
                "I",
                "got",
                "out",
                "of",
                "the",
                "car",
                "."
            ],
            [
                "They",
                "missed",
                "the",
                "vital",
                "stuff",
                "but",
                "got",
                "my",
                "kneecap",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "it",
                "be",
                "a",
                "shoddy",
                "assassination",
                "attempt",
                "."
            ],
            [
                "they",
                "be",
                "drive",
                "by",
                ",",
                "hope",
                "to",
                "get",
                "a",
                "clean",
                "shot",
                "at",
                "I",
                "as",
                "I",
                "get",
                "out",
                "of",
                "the",
                "car",
                "."
            ],
            [
                "they",
                "miss",
                "the",
                "vital",
                "stuff",
                "but",
                "get",
                "my",
                "kneecap",
                "."
            ]
        ],
        "label": "Fear"
    },
    {
        "body_part_token_idx": 4,
        "sentence_id": "c50ac24c-f209-3b6f-9f17-c7ee8de7b2ea",
        "tokens": [
            "So",
            "why",
            "did",
            "his",
            "eyes",
            "light",
            "up",
            "just",
            "a",
            "little",
            "when",
            "he",
            "heard",
            "that",
            "knock",
            "on",
            "the",
            "door",
            "?"
        ],
        "lemmatized_tokens": [
            "so",
            "why",
            "do",
            "he",
            "eye",
            "light",
            "up",
            "just",
            "a",
            "little",
            "when",
            "he",
            "hear",
            "that",
            "knock",
            "on",
            "the",
            "door",
            "?"
        ],
        "preceding_context_tokens": [
            [
                "He",
                "was",
                "a",
                "man",
                "of",
                "leisure",
                "and",
                "it",
                "suited",
                "him",
                "fine",
                "."
            ],
            [
                "Maybe",
                "he",
                "'d",
                "go",
                "out",
                "a",
                "little",
                "later",
                "and",
                "do",
                "a",
                "sweep",
                ",",
                "see",
                "if",
                "any",
                "hapless",
                "creature",
                "of",
                "the",
                "night",
                "might",
                "be",
                "itching",
                "for",
                "a",
                "beheading",
                "."
            ],
            [
                "Yeah",
                ",",
                "unlife",
                "was",
                "good",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "he",
                "be",
                "a",
                "man",
                "of",
                "leisure",
                "and",
                "it",
                "suit",
                "he",
                "fine",
                "."
            ],
            [
                "maybe",
                "he",
                "would",
                "go",
                "out",
                "a",
                "little",
                "later",
                "and",
                "do",
                "a",
                "sweep",
                ",",
                "see",
                "if",
                "any",
                "hapless",
                "creature",
                "of",
                "the",
                "night",
                "might",
                "be",
                "itching",
                "for",
                "a",
                "beheading",
                "."
            ],
            [
                "yeah",
                ",",
                "unlife",
                "be",
                "good",
                "."
            ]
        ],
        "label": "Joy"
    },
    {
        "body_part_token_idx": 9,
        "sentence_id": "0de2f306-4b3e-31fd-b632-846541909a34",
        "tokens": [
            "A",
            "loud",
            "sob",
            "raced",
            "up",
            "the",
            "back",
            "of",
            "her",
            "throat",
            ",",
            "choking",
            "her",
            ",",
            "and",
            "her",
            "knees",
            "buckled",
            "."
        ],
        "lemmatized_tokens": [
            "a",
            "loud",
            "sob",
            "race",
            "up",
            "the",
            "back",
            "of",
            "she",
            "throat",
            ",",
            "choke",
            "she",
            ",",
            "and",
            "she",
            "knee",
            "buckle",
            "."
        ],
        "preceding_context_tokens": [
            [
                "``",
                "I",
                "'ll",
                "never",
                "let",
                "anyone",
                "hurt",
                "you",
                "again",
                "."
            ],
            [
                "I",
                "promise",
                ".",
                "''"
            ],
            [
                "She",
                "started",
                "to",
                "shake",
                "her",
                "head",
                ",",
                "to",
                "deny",
                "it",
                "all",
                "yet",
                "again",
                ",",
                "but",
                "something",
                "inside",
                "her",
                "broke",
                ",",
                "some",
                "wall",
                "came",
                "tumbling",
                "down",
                ",",
                "and",
                "she",
                "was",
                "left",
                "standing",
                "in",
                "the",
                "ruins",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "``",
                "I",
                "will",
                "never",
                "let",
                "anyone",
                "hurt",
                "you",
                "again",
                "."
            ],
            [
                "I",
                "promise",
                ".",
                "''"
            ],
            [
                "she",
                "start",
                "to",
                "shake",
                "she",
                "head",
                ",",
                "to",
                "deny",
                "it",
                "all",
                "yet",
                "again",
                ",",
                "but",
                "something",
                "inside",
                "she",
                "break",
                ",",
                "some",
                "wall",
                "come",
                "tumble",
                "down",
                ",",
                "and",
                "she",
                "be",
                "leave",
                "stand",
                "in",
                "the",
                "ruin",
                "."
            ]
        ],
        "label": "Sadness"
    },
    {
        "body_part_token_idx": 16,
        "sentence_id": "0de2f306-4b3e-31fd-b632-846541909a34",
        "tokens": [
            "A",
            "loud",
            "sob",
            "raced",
            "up",
            "the",
            "back",
            "of",
            "her",
            "throat",
            ",",
            "choking",
            "her",
            ",",
            "and",
            "her",
            "knees",
            "buckled",
            "."
        ],
        "lemmatized_tokens": [
            "a",
            "loud",
            "sob",
            "race",
            "up",
            "the",
            "back",
            "of",
            "she",
            "throat",
            ",",
            "choke",
            "she",
            ",",
            "and",
            "she",
            "knee",
            "buckle",
            "."
        ],
        "preceding_context_tokens": [
            [
                "``",
                "I",
                "'ll",
                "never",
                "let",
                "anyone",
                "hurt",
                "you",
                "again",
                "."
            ],
            [
                "I",
                "promise",
                ".",
                "''"
            ],
            [
                "She",
                "started",
                "to",
                "shake",
                "her",
                "head",
                ",",
                "to",
                "deny",
                "it",
                "all",
                "yet",
                "again",
                ",",
                "but",
                "something",
                "inside",
                "her",
                "broke",
                ",",
                "some",
                "wall",
                "came",
                "tumbling",
                "down",
                ",",
                "and",
                "she",
                "was",
                "left",
                "standing",
                "in",
                "the",
                "ruins",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "``",
                "I",
                "will",
                "never",
                "let",
                "anyone",
                "hurt",
                "you",
                "again",
                "."
            ],
            [
                "I",
                "promise",
                ".",
                "''"
            ],
            [
                "she",
                "start",
                "to",
                "shake",
                "she",
                "head",
                ",",
                "to",
                "deny",
                "it",
                "all",
                "yet",
                "again",
                ",",
                "but",
                "something",
                "inside",
                "she",
                "break",
                ",",
                "some",
                "wall",
                "come",
                "tumble",
                "down",
                ",",
                "and",
                "she",
                "be",
                "leave",
                "stand",
                "in",
                "the",
                "ruin",
                "."
            ]
        ],
        "label": "Sadness"
    },
    {
        "body_part_token_idx": 16,
        "sentence_id": "a5ed16ad-d32f-3b10-abdf-ab2d48d8a419",
        "tokens": [
            "One",
            "evening",
            ",",
            "long",
            "ago",
            ",",
            "she",
            "had",
            "awoken",
            "into",
            "darkness",
            ",",
            "chills",
            "creeping",
            "up",
            "her",
            "spine",
            "."
        ],
        "lemmatized_tokens": [
            "one",
            "evening",
            ",",
            "long",
            "ago",
            ",",
            "she",
            "have",
            "awake",
            "into",
            "darkness",
            ",",
            "chill",
            "creep",
            "up",
            "she",
            "spine",
            "."
        ],
        "preceding_context_tokens": [
            [
                "He",
                "never",
                "once",
                "reached",
                "out",
                "his",
                "arms",
                "to",
                "be",
                "comforted",
                "."
            ],
            [
                "His",
                "mind",
                "did",
                "not",
                "quake",
                "at",
                "such",
                "things",
                "as",
                "roller",
                "coasters",
                ",",
                "or",
                "Frankenstein",
                "'s",
                "monsters",
                ",",
                "or",
                "ghoulies",
                "or",
                "ghosties",
                "or",
                "things",
                "that",
                "go",
                "bump",
                "in",
                "the",
                "night.But",
                "though",
                "he",
                "feared",
                "nothing",
                ",",
                "the",
                "dreams",
                "still",
                "plagued",
                "him",
                ",",
                "and",
                "though",
                "he",
                "never",
                "went",
                "to",
                "his",
                "mother",
                ",",
                "still",
                "she",
                "heard",
                "his",
                "faint",
                "whimpers",
                "and",
                "went",
                "to",
                "him",
                "."
            ],
            [
                "Daniel",
                "rarely",
                "woke",
                "up",
                "when",
                "she",
                "stroked",
                "the",
                "black",
                "curls",
                "away",
                "from",
                "his",
                "damp",
                "forehead",
                "and",
                "softly",
                "murmured",
                "words",
                "of",
                "comfort",
                ",",
                "but",
                "always",
                "he",
                "calmed",
                ",",
                "and",
                "the",
                "worry",
                "smoothed",
                "itself",
                "from",
                "his",
                "face.She",
                "was",
                "not",
                "really",
                "his",
                "mother",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "he",
                "never",
                "once",
                "reach",
                "out",
                "he",
                "arm",
                "to",
                "be",
                "comfort",
                "."
            ],
            [
                "he",
                "mind",
                "do",
                "not",
                "quake",
                "at",
                "such",
                "thing",
                "as",
                "roller",
                "coaster",
                ",",
                "or",
                "Frankenstein",
                "'s",
                "monster",
                ",",
                "or",
                "ghouly",
                "or",
                "ghosty",
                "or",
                "thing",
                "that",
                "go",
                "bump",
                "in",
                "the",
                "night.but",
                "though",
                "he",
                "fear",
                "nothing",
                ",",
                "the",
                "dream",
                "still",
                "plague",
                "he",
                ",",
                "and",
                "though",
                "he",
                "never",
                "go",
                "to",
                "he",
                "mother",
                ",",
                "still",
                "she",
                "hear",
                "he",
                "faint",
                "whimper",
                "and",
                "go",
                "to",
                "he",
                "."
            ],
            [
                "Daniel",
                "rarely",
                "wake",
                "up",
                "when",
                "she",
                "stroke",
                "the",
                "black",
                "curl",
                "away",
                "from",
                "he",
                "damp",
                "forehead",
                "and",
                "softly",
                "murmur",
                "word",
                "of",
                "comfort",
                ",",
                "but",
                "always",
                "he",
                "calm",
                ",",
                "and",
                "the",
                "worry",
                "smooth",
                "itself",
                "from",
                "he",
                "face.she",
                "be",
                "not",
                "really",
                "he",
                "mother",
                "."
            ]
        ],
        "label": "Fear"
    },
    {
        "body_part_token_idx": 8,
        "sentence_id": "31c9bd51-396a-3da7-b526-0add732c16ad",
        "tokens": [
            ",",
            "''",
            "he",
            "said",
            "s'mores",
            "all",
            "over",
            "his",
            "face",
            "."
        ],
        "lemmatized_tokens": [
            ",",
            "''",
            "he",
            "say",
            "s'more",
            "all",
            "over",
            "he",
            "face",
            "."
        ],
        "preceding_context_tokens": [
            [
                "``",
                "I",
                "let",
                "nobody",
                "nap",
                "him",
                "."
            ],
            [
                "``",
                "By",
                "the",
                "time",
                "Maggie",
                "and",
                "Rich",
                "got",
                "home",
                "he",
                "was",
                "almost",
                "his",
                "old",
                "self",
                "."
            ],
            [
                "``",
                "Gramma",
                "we",
                "going",
                "to",
                "have",
                "a",
                "baby",
                "?"
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "``",
                "I",
                "let",
                "nobody",
                "nap",
                "he",
                "."
            ],
            [
                "``",
                "by",
                "the",
                "time",
                "Maggie",
                "and",
                "Rich",
                "get",
                "home",
                "he",
                "be",
                "almost",
                "he",
                "old",
                "self",
                "."
            ],
            [
                "``",
                "Gramma",
                "we",
                "go",
                "to",
                "have",
                "a",
                "baby",
                "?"
            ]
        ],
        "label": "Joy"
    },
    {
        "body_part_token_idx": 19,
        "sentence_id": "baa6ac9d-5920-3df6-89c2-2186e43f4ea9",
        "tokens": [
            "He",
            "was",
            "clearly",
            "in",
            "so",
            "much",
            "pain",
            "he",
            "did",
            "n't",
            "even",
            "notice",
            "that",
            "Davey",
            "was",
            "sitting",
            "there.Ray",
            "bit",
            "his",
            "lip",
            "."
        ],
        "lemmatized_tokens": [
            "he",
            "be",
            "clearly",
            "in",
            "so",
            "much",
            "pain",
            "he",
            "do",
            "not",
            "even",
            "notice",
            "that",
            "Davey",
            "be",
            "sit",
            "there.Ray",
            "bite",
            "he",
            "lip",
            "."
        ],
        "preceding_context_tokens": [
            [
                "Possibly",
                "multiple",
                "Mpreg",
                ",",
                "really",
                ",",
                "but",
                "the",
                "concept",
                "is",
                "kinda",
                "coolWould",
                "You",
                "Kill",
                "Me",
                "In",
                "My",
                "SleepDavey",
                "walked",
                "into",
                "his",
                "parents",
                "room",
                "and",
                "found",
                "Ray",
                "sitting",
                "on",
                "a",
                "stool",
                "beside",
                "the",
                "bed",
                ",",
                "stroking",
                "Bob",
                "'s",
                "face",
                "as",
                "Sisky",
                "wiped",
                "away",
                "a",
                "lot",
                "of",
                "blood",
                "."
            ],
            [
                "Davey",
                "felt",
                "slightly",
                "queasy",
                ",",
                "but",
                "kneeled",
                "down",
                "beside",
                "his",
                "father",
                "."
            ],
            [
                "Hey",
                "Papi",
                ",",
                "what",
                "'s",
                "going",
                "on?",
                "he",
                "asked",
                ",",
                "taking",
                "Bob",
                "'s",
                "hand",
                "as",
                "he",
                "looked",
                "at",
                "his",
                "dad",
                "in",
                "concern",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "possibly",
                "multiple",
                "Mpreg",
                ",",
                "really",
                ",",
                "but",
                "the",
                "concept",
                "be",
                "kinda",
                "coolwould",
                "you",
                "kill",
                "I",
                "in",
                "my",
                "SleepDavey",
                "walk",
                "into",
                "he",
                "parent",
                "room",
                "and",
                "find",
                "Ray",
                "sit",
                "on",
                "a",
                "stool",
                "beside",
                "the",
                "bed",
                ",",
                "stroke",
                "Bob",
                "'s",
                "face",
                "as",
                "Sisky",
                "wipe",
                "away",
                "a",
                "lot",
                "of",
                "blood",
                "."
            ],
            [
                "Davey",
                "feel",
                "slightly",
                "queasy",
                ",",
                "but",
                "kneel",
                "down",
                "beside",
                "he",
                "father",
                "."
            ],
            [
                "hey",
                "Papi",
                ",",
                "what",
                "be",
                "go",
                "on?",
                "he",
                "ask",
                ",",
                "take",
                "Bob",
                "'s",
                "hand",
                "as",
                "he",
                "look",
                "at",
                "he",
                "dad",
                "in",
                "concern",
                "."
            ]
        ],
        "label": "Sadness"
    },
    {
        "body_part_token_idx": 5,
        "sentence_id": "a8848c71-b502-31ae-8fb5-48371793a1a7",
        "tokens": [
            "so",
            "hard",
            ",",
            "till",
            "my",
            "eyes",
            "burned",
            "."
        ],
        "lemmatized_tokens": [
            "so",
            "hard",
            ",",
            "till",
            "my",
            "eye",
            "burn",
            "."
        ],
        "preceding_context_tokens": [
            [
                "forever",
                "."
            ],
            [
                "without",
                "a",
                "word",
                "."
            ],
            [
                "that",
                "night",
                ",",
                "i",
                "cry",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "forever",
                "."
            ],
            [
                "without",
                "a",
                "word",
                "."
            ],
            [
                "that",
                "night",
                ",",
                "i",
                "cry",
                "."
            ]
        ],
        "label": "Sadness"
    },
    {
        "body_part_token_idx": 5,
        "sentence_id": "c96e24a8-6d44-3073-ae95-bd408a6f7711",
        "tokens": [
            "I",
            "'m",
            "really",
            "scratching",
            "my",
            "head",
            "here",
            "folks",
            "!"
        ],
        "lemmatized_tokens": [
            "I",
            "be",
            "really",
            "scratch",
            "my",
            "head",
            "here",
            "folk",
            "!"
        ],
        "preceding_context_tokens": [
            [
                "The",
                "white",
                "British",
                "population",
                "went",
                "down",
                "by",
                "70,400",
                "over",
                "the",
                "year",
                "through",
                "emigration",
                "."
            ],
            [
                "And",
                "the",
                "white",
                "Irish",
                "population",
                "fell",
                "by",
                "4,600",
                "because",
                "of",
                "emigration",
                ",",
                "bringing",
                "the",
                "total",
                "decline",
                "in",
                "the",
                "existing",
                "white",
                "population",
                "to",
                "75,000",
                "."
            ],
            [
                "MK",
                "-",
                "One",
                "of",
                "life",
                "'s",
                "great",
                "mysteries",
                "folks",
                ",",
                "do",
                "you",
                "know",
                "why",
                "so",
                "many",
                "are",
                "leaving",
                "?"
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "the",
                "white",
                "british",
                "population",
                "go",
                "down",
                "by",
                "70,400",
                "over",
                "the",
                "year",
                "through",
                "emigration",
                "."
            ],
            [
                "and",
                "the",
                "white",
                "irish",
                "population",
                "fall",
                "by",
                "4,600",
                "because",
                "of",
                "emigration",
                ",",
                "bring",
                "the",
                "total",
                "decline",
                "in",
                "the",
                "exist",
                "white",
                "population",
                "to",
                "75,000",
                "."
            ],
            [
                "MK",
                "-",
                "One",
                "of",
                "life",
                "'s",
                "great",
                "mystery",
                "folk",
                ",",
                "do",
                "you",
                "know",
                "why",
                "so",
                "many",
                "be",
                "leave",
                "?"
            ]
        ],
        "label": "Surprise"
    },
    {
        "body_part_token_idx": 13,
        "sentence_id": "b4864281-fbc9-3053-8c18-011fb33498c2",
        "tokens": [
            "When",
            "Hibari",
            "shoved",
            "the",
            "tonfa",
            "closer",
            "to",
            "his",
            "face",
            ",",
            "Mukuro",
            "raised",
            "his",
            "hands",
            "in",
            "defeat",
            ",",
            "taking",
            "a",
            "step",
            "back",
            "lest",
            "he",
            "lose",
            "an",
            "eye",
            "."
        ],
        "lemmatized_tokens": [
            "when",
            "Hibari",
            "shove",
            "the",
            "tonfa",
            "closer",
            "to",
            "he",
            "face",
            ",",
            "Mukuro",
            "raise",
            "he",
            "hand",
            "in",
            "defeat",
            ",",
            "take",
            "a",
            "step",
            "back",
            "lest",
            "he",
            "lose",
            "a",
            "eye",
            "."
        ],
        "preceding_context_tokens": [
            [
                "``",
                "You",
                "'ll",
                "bite",
                "me",
                "?",
                "''"
            ],
            [
                "Mukuro",
                "repeated",
                "Hibari",
                "'s",
                "words",
                ",",
                "looking",
                "amused",
                "."
            ],
            [
                "``",
                "Actually",
                ",",
                "I",
                "might",
                "like",
                "that",
                ",",
                "''",
                "he",
                "said",
                "suggestively",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "``",
                "you",
                "will",
                "bite",
                "I",
                "?",
                "''"
            ],
            [
                "Mukuro",
                "repeat",
                "Hibari",
                "'s",
                "word",
                ",",
                "look",
                "amused",
                "."
            ],
            [
                "``",
                "actually",
                ",",
                "I",
                "might",
                "like",
                "that",
                ",",
                "''",
                "he",
                "say",
                "suggestively",
                "."
            ]
        ],
        "label": "Fear"
    },
    {
        "body_part_token_idx": 24,
        "sentence_id": "5b0c4e4c-2dcb-3d98-a2fb-b5c6d2203afe",
        "tokens": [
            "I",
            "saw",
            "one",
            "woman",
            "say",
            "something",
            "angrily",
            "to",
            "her",
            "friends",
            ",",
            "and",
            "then",
            "throw",
            "her",
            "cane",
            "over",
            "the",
            "top",
            "with",
            "a",
            "look",
            "on",
            "her",
            "face",
            "like",
            "she",
            "did",
            "n't",
            "care",
            "what",
            "happened",
            ",",
            "she",
            "was",
            "climbing",
            "the",
            "thing",
            "."
        ],
        "lemmatized_tokens": [
            "I",
            "see",
            "one",
            "woman",
            "say",
            "something",
            "angrily",
            "to",
            "she",
            "friend",
            ",",
            "and",
            "then",
            "throw",
            "she",
            "cane",
            "over",
            "the",
            "top",
            "with",
            "a",
            "look",
            "on",
            "she",
            "face",
            "like",
            "she",
            "do",
            "not",
            "care",
            "what",
            "happen",
            ",",
            "she",
            "be",
            "climb",
            "the",
            "thing",
            "."
        ],
        "preceding_context_tokens": [
            [
                "At",
                "this",
                "point",
                "you",
                "'re",
                "either",
                "sitting",
                "on",
                "rows",
                "of",
                "wooden",
                "benches",
                ",",
                "or",
                "sitting",
                "on",
                "a",
                "stone",
                "wall",
                "just",
                "before",
                "the",
                "covered",
                "area",
                "with",
                "the",
                "benches",
                "-LRB-",
                "as",
                "I",
                "was",
                ")",
                "in",
                "rows",
                "of",
                "metal",
                "gates",
                "."
            ],
            [
                "It",
                "was",
                "strangely",
                "reminiscent",
                "of",
                "waiting",
                "to",
                "get",
                "on",
                "the",
                "Indiana",
                "Jones",
                "Adventure",
                "ride",
                "at",
                "Disneyland",
                "when",
                "it",
                "first",
                "came",
                "out",
                "-LRB-",
                "and",
                "before",
                "they",
                "invented",
                "that",
                "FastPass",
                "thing",
                ")",
                "."
            ],
            [
                "By",
                "my",
                "estimate",
                "there",
                "were",
                "200",
                "of",
                "us",
                "in",
                "line",
                ",",
                "and",
                "there",
                "were",
                "women",
                "who",
                "showed",
                "up",
                "around",
                "1:30",
                "p.m.",
                ",",
                "and",
                "were",
                "so",
                "distressed",
                "that",
                "the",
                "queue",
                "was",
                "filled",
                "for",
                "the",
                "afternoon",
                ",",
                "that",
                "they",
                "started",
                "trying",
                "to",
                "scale",
                "the",
                "gates",
                "!"
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "at",
                "this",
                "point",
                "you",
                "be",
                "either",
                "sit",
                "on",
                "row",
                "of",
                "wooden",
                "bench",
                ",",
                "or",
                "sit",
                "on",
                "a",
                "stone",
                "wall",
                "just",
                "before",
                "the",
                "covered",
                "area",
                "with",
                "the",
                "bench",
                "-lrb-_VBP",
                "as",
                "I",
                "be",
                ")",
                "in",
                "row",
                "of",
                "metal",
                "gate",
                "."
            ],
            [
                "it",
                "be",
                "strangely",
                "reminiscent",
                "of",
                "wait",
                "to",
                "get",
                "on",
                "the",
                "Indiana",
                "Jones",
                "adventure",
                "ride",
                "at",
                "Disneyland",
                "when",
                "it",
                "first",
                "come",
                "out",
                "-LRB-",
                "and",
                "before",
                "they",
                "invent",
                "that",
                "FastPass",
                "thing",
                ")",
                "."
            ],
            [
                "by",
                "my",
                "estimate",
                "there",
                "be",
                "200",
                "of",
                "we",
                "in",
                "line",
                ",",
                "and",
                "there",
                "be",
                "woman",
                "who",
                "show",
                "up",
                "around",
                "1:30",
                "p.m.",
                ",",
                "and",
                "be",
                "so",
                "distressed",
                "that",
                "the",
                "queue",
                "be",
                "fill",
                "for",
                "the",
                "afternoon",
                ",",
                "that",
                "they",
                "start",
                "try",
                "to",
                "scale",
                "the",
                "gate",
                "!"
            ]
        ],
        "label": "Anger"
    },
    {
        "body_part_token_idx": 16,
        "sentence_id": "836ee1f7-d17c-329e-a5a6-449d333ad1e6",
        "tokens": [
            "The",
            "more",
            "engrossed",
            "he",
            "became",
            "in",
            "these",
            "thoughts",
            ",",
            "the",
            "more",
            "the",
            "sweat",
            "poured",
            "off",
            "his",
            "face",
            "."
        ],
        "lemmatized_tokens": [
            "the",
            "more",
            "engross",
            "he",
            "become",
            "in",
            "these",
            "thought",
            ",",
            "the",
            "more",
            "the",
            "sweat",
            "pour",
            "off",
            "he",
            "face",
            "."
        ],
        "preceding_context_tokens": [
            [
                "Live",
                "with",
                "a",
                "wife",
                "!"
            ],
            [
                "It",
                "was",
                "just",
                "inconceivable",
                "!"
            ],
            [
                "He",
                "would",
                "never",
                "be",
                "alone",
                "in",
                "his",
                "room",
                "any",
                "more",
                ",",
                "because",
                "there",
                "would",
                "always",
                "be",
                "two",
                "of",
                "them",
                ",",
                "together",
                ",",
                "everywhere",
                "!"
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "live",
                "with",
                "a",
                "wife",
                "!"
            ],
            [
                "it",
                "be",
                "just",
                "inconceivable",
                "!"
            ],
            [
                "he",
                "would",
                "never",
                "be",
                "alone",
                "in",
                "he",
                "room",
                "any",
                "more",
                ",",
                "because",
                "there",
                "would",
                "always",
                "be",
                "two",
                "of",
                "they",
                ",",
                "together",
                ",",
                "everywhere",
                "!"
            ]
        ],
        "label": "Fear"
    },
    {
        "body_part_token_idx": 8,
        "sentence_id": "8c1c1f55-0abd-3069-adfa-6338ed23335c",
        "tokens": [
            "As",
            "we",
            "hung",
            "up",
            "the",
            "phone",
            ",",
            "my",
            "eyes",
            "were",
            "even",
            "wider",
            "than",
            "before",
            "-",
            "and",
            "Joe",
            "was",
            "too",
            "."
        ],
        "lemmatized_tokens": [
            "as",
            "we",
            "hang",
            "up",
            "the",
            "phone",
            ",",
            "my",
            "eye",
            "be",
            "even",
            "wider",
            "than",
            "before",
            "-",
            "and",
            "Joe",
            "be",
            "too",
            "."
        ],
        "preceding_context_tokens": [
            [
                "Can",
                "I",
                "call",
                "you",
                "back",
                "?"
            ],
            [
                "Me",
                ":",
                "Sure",
                "!"
            ],
            [
                "Sure",
                "!!"
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "can",
                "I",
                "call",
                "you",
                "back",
                "?"
            ],
            [
                "I",
                ":",
                "sure",
                "!"
            ],
            [
                "sure",
                "!!"
            ]
        ],
        "label": "Surprise"
    },
    {
        "body_part_token_idx": 20,
        "sentence_id": "59c5f861-1500-3aa1-8504-710b9e854441",
        "tokens": [
            "Hankyung",
            "followed",
            "the",
            "tall",
            "man",
            "down",
            "the",
            "rest",
            "of",
            "the",
            "hallways",
            ",",
            "a",
            "tingle",
            "of",
            "anxious",
            "excitement",
            "running",
            "through",
            "his",
            "lungs",
            "with",
            "every",
            "breath",
            "."
        ],
        "lemmatized_tokens": [
            "Hankyung",
            "follow",
            "the",
            "tall",
            "man",
            "down",
            "the",
            "rest",
            "of",
            "the",
            "hallway",
            ",",
            "a",
            "tingle",
            "of",
            "anxious",
            "excitement",
            "run",
            "through",
            "he",
            "lung",
            "with",
            "every",
            "breath",
            "."
        ],
        "preceding_context_tokens": [
            [
                "The",
                "host",
                "paused",
                ",",
                "seeming",
                "to",
                "consider",
                "his",
                "options",
                "."
            ],
            [
                "Finally",
                "he",
                "spoke",
                ":",
                "``",
                "I",
                "'ll",
                "go",
                "see",
                "if",
                "he",
                "'s",
                "free",
                "."
            ],
            [
                "Please",
                "be",
                "seated",
                "in",
                "the",
                "lobby",
                ";",
                "follow",
                "me",
                ".",
                "''"
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "the",
                "host",
                "pause",
                ",",
                "seem",
                "to",
                "consider",
                "he",
                "option",
                "."
            ],
            [
                "finally",
                "he",
                "speak",
                ":",
                "``",
                "I",
                "will",
                "go",
                "see",
                "if",
                "he",
                "be",
                "free",
                "."
            ],
            [
                "please",
                "be",
                "seat",
                "in",
                "the",
                "lobby",
                ";",
                "follow",
                "I",
                ".",
                "''"
            ]
        ],
        "label": "Surprise"
    },
    {
        "body_part_token_idx": 17,
        "sentence_id": "eafbd8d2-07d2-394e-95dd-55dedbef5bb8",
        "tokens": [
            "Mary",
            "returns",
            "the",
            "smile",
            ",",
            "somewhat",
            "self",
            "-",
            "conscious",
            "of",
            "how",
            "foolish",
            "she",
            "must",
            "look",
            "with",
            "her",
            "mouth",
            "agape",
            ",",
            "fingers",
            "dragging",
            "over",
            "the",
            "body",
            "of",
            "this",
            "accomplishment.John",
            "slides",
            "into",
            "the",
            "car",
            ",",
            "turns",
            "it",
            "on",
            ",",
            "and",
            "Mary",
            "feels",
            "the",
            "vibrations",
            "through",
            "her",
            "feet",
            "."
        ],
        "lemmatized_tokens": [
            "Mary",
            "return",
            "the",
            "smile",
            ",",
            "somewhat",
            "self",
            "-",
            "conscious",
            "of",
            "how",
            "foolish",
            "she",
            "must",
            "look",
            "with",
            "she",
            "mouth",
            "agape",
            ",",
            "finger",
            "drag",
            "over",
            "the",
            "body",
            "of",
            "this",
            "accomplishment.john",
            "slide",
            "into",
            "the",
            "car",
            ",",
            "turn",
            "it",
            "on",
            ",",
            "and",
            "Mary",
            "feel",
            "the",
            "vibration",
            "through",
            "she",
            "foot",
            "."
        ],
        "preceding_context_tokens": [
            [
                "She",
                "walks",
                "over",
                "to",
                "the",
                "car",
                ",",
                "runs",
                "a",
                "hand",
                "down",
                "its",
                "side",
                "."
            ],
            [
                "The",
                "metal",
                "is",
                "satiny",
                ",",
                "it",
                "sends",
                "tingles",
                "into",
                "her",
                "fingertips",
                "."
            ],
            [
                "John",
                "is",
                "standing",
                "at",
                "the",
                "driver",
                "'s",
                "side",
                "door",
                ",",
                "smiling",
                "over",
                "the",
                "roof",
                "at",
                "Mary",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "she",
                "walk",
                "over",
                "to",
                "the",
                "car",
                ",",
                "run",
                "a",
                "hand",
                "down",
                "its",
                "side",
                "."
            ],
            [
                "the",
                "metal",
                "be",
                "satiny",
                ",",
                "it",
                "send",
                "tingle",
                "into",
                "she",
                "fingertip",
                "."
            ],
            [
                "John",
                "be",
                "stand",
                "at",
                "the",
                "driver",
                "'s",
                "side",
                "door",
                ",",
                "smile",
                "over",
                "the",
                "roof",
                "at",
                "Mary",
                "."
            ]
        ],
        "label": "Surprise"
    },
    {
        "body_part_token_idx": 20,
        "sentence_id": "7f66edc9-1584-3899-b66c-57679c5f1c66",
        "tokens": [
            "He",
            "stared",
            "at",
            "his",
            "computer",
            "figure",
            "flying",
            "over",
            "the",
            "treetops",
            "aboard",
            "a",
            "flying",
            "dragon",
            ",",
            "a",
            "gentle",
            "smile",
            "on",
            "his",
            "face",
            "."
        ],
        "lemmatized_tokens": [
            "he",
            "stare",
            "at",
            "he",
            "computer",
            "figure",
            "fly",
            "over",
            "the",
            "treetop",
            "aboard",
            "a",
            "fly",
            "dragon",
            ",",
            "a",
            "gentle",
            "smile",
            "on",
            "he",
            "face",
            "."
        ],
        "preceding_context_tokens": [
            [
                "He",
                "turned",
                "back",
                "to",
                "the",
                "computer",
                "screen",
                "and",
                "murmured",
                "a",
                "series",
                "of",
                "cusses",
                "."
            ],
            [
                "After",
                "an",
                "arduous",
                "thirty",
                "second",
                "digital",
                "walk",
                "back",
                ",",
                "he",
                "resumed",
                "his",
                "slaying",
                "of",
                "the",
                "innocent",
                "creatures",
                "of",
                "the",
                "computer",
                "world",
                ".",
                "''"
            ],
            [
                "...",
                "Such",
                "beautiful",
                "creatures",
                ",",
                "''",
                "he",
                "murmured",
                "to",
                "himself",
                "at",
                "one",
                "point",
                "in",
                "the",
                "evening",
                ",",
                "leaning",
                "forward",
                "on",
                "his",
                "palm",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "he",
                "turn",
                "back",
                "to",
                "the",
                "computer",
                "screen",
                "and",
                "murmur",
                "a",
                "series",
                "of",
                "cuss",
                "."
            ],
            [
                "after",
                "a",
                "arduous",
                "thirty",
                "second",
                "digital",
                "walk",
                "back",
                ",",
                "he",
                "resume",
                "he",
                "slaying",
                "of",
                "the",
                "innocent",
                "creature",
                "of",
                "the",
                "computer",
                "world",
                ".",
                "''"
            ],
            [
                "...",
                "such",
                "beautiful",
                "creature",
                ",",
                "''",
                "he",
                "murmur",
                "to",
                "himself",
                "at",
                "one",
                "point",
                "in",
                "the",
                "evening",
                ",",
                "lean",
                "forward",
                "on",
                "he",
                "palm",
                "."
            ]
        ],
        "label": "Joy"
    },
    {
        "body_part_token_idx": 4,
        "sentence_id": "9e821186-8f06-39ca-abf4-d267d4f18824",
        "tokens": [
            "I",
            "fell",
            "to",
            "my",
            "knees",
            ",",
            "my",
            "body",
            "shaking",
            "with",
            "the",
            "sorrow",
            "I",
            "held",
            "in",
            "me",
            "since",
            "I",
            "woke",
            "up",
            "."
        ],
        "lemmatized_tokens": [
            "I",
            "fall",
            "to",
            "my",
            "knee",
            ",",
            "my",
            "body",
            "shake",
            "with",
            "the",
            "sorrow",
            "I",
            "hold",
            "in",
            "I",
            "since",
            "I",
            "wake",
            "up",
            "."
        ],
        "preceding_context_tokens": [
            [
                "I",
                "was",
                "afraid",
                "."
            ],
            [
                "``",
                "I",
                "will",
                "not",
                "harm",
                "you",
                "."
            ],
            [
                "``",
                "I",
                "started",
                "to",
                "cry",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "I",
                "be",
                "afraid",
                "."
            ],
            [
                "``",
                "I",
                "will",
                "not",
                "harm",
                "you",
                "."
            ],
            [
                "``",
                "I",
                "start",
                "to",
                "cry",
                "."
            ]
        ],
        "label": "Sadness"
    },
    {
        "body_part_token_idx": 8,
        "sentence_id": "422326ad-b1a6-3f88-8973-a0bad343f552",
        "tokens": [
            "Screaming",
            "with",
            "all",
            "his",
            "worth",
            "he",
            "slammed",
            "his",
            "fists",
            "to",
            "the",
            "ground",
            ",",
            "cursing",
            "the",
            "heavens",
            "and",
            "himself",
            "for",
            "his",
            "pride",
            "and",
            "what",
            "was",
            "left",
            "of",
            "it",
            "."
        ],
        "lemmatized_tokens": [
            "scream",
            "with",
            "all",
            "he",
            "worth",
            "he",
            "slam",
            "he",
            "fist",
            "to",
            "the",
            "ground",
            ",",
            "curse",
            "the",
            "heaven",
            "and",
            "himself",
            "for",
            "he",
            "pride",
            "and",
            "what",
            "be",
            "leave",
            "of",
            "it",
            "."
        ],
        "preceding_context_tokens": [
            [
                "Shuuhei",
                "pulled",
                "back",
                "and",
                "was",
                "bracing",
                "himself",
                "for",
                "impact",
                "when",
                "all",
                "he",
                "felt",
                "was",
                "air",
                "and",
                "his",
                "shoulder",
                "slammed",
                "into",
                "the",
                "ground",
                "making",
                "him",
                "tumble",
                "to",
                "a",
                "stop",
                "a",
                "few",
                "feet",
                "away",
                "."
            ],
            [
                "He",
                "made",
                "no",
                "move",
                "to",
                "get",
                "up",
                "from",
                "his",
                "position",
                "on",
                "the",
                "ground",
                ",",
                "too",
                "upset",
                "and",
                "angry",
                "to",
                "do",
                "anything",
                "."
            ],
            [
                "His",
                "body",
                "was",
                "shaking",
                "due",
                "to",
                "suppressed",
                "emotions",
                "and",
                "heartache",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "Shuuhei",
                "pull",
                "back",
                "and",
                "be",
                "brace",
                "himself",
                "for",
                "impact",
                "when",
                "all",
                "he",
                "feel",
                "be",
                "air",
                "and",
                "he",
                "shoulder",
                "slam",
                "into",
                "the",
                "ground",
                "make",
                "he",
                "tumble",
                "to",
                "a",
                "stop",
                "a",
                "few",
                "foot",
                "away",
                "."
            ],
            [
                "he",
                "make",
                "no",
                "move",
                "to",
                "get",
                "up",
                "from",
                "he",
                "position",
                "on",
                "the",
                "ground",
                ",",
                "too",
                "upset",
                "and",
                "angry",
                "to",
                "do",
                "anything",
                "."
            ],
            [
                "he",
                "body",
                "be",
                "shake",
                "due",
                "to",
                "suppress",
                "emotion",
                "and",
                "heartache",
                "."
            ]
        ],
        "label": "Anger"
    },
    {
        "body_part_token_idx": 9,
        "sentence_id": "7d726f3d-99aa-3435-b333-ca0c8d963f97",
        "tokens": [
            "The",
            "word",
            "`",
            "Rose",
            "'",
            "made",
            "her",
            "shake",
            "her",
            "head",
            "and",
            "stare",
            "at",
            "the",
            "flower",
            "more",
            "before",
            "turning",
            "and",
            "walking",
            "down",
            "towards",
            "the",
            "door",
            "."
        ],
        "lemmatized_tokens": [
            "the",
            "word",
            "`",
            "Rose",
            "'",
            "make",
            "she",
            "shake",
            "she",
            "head",
            "and",
            "stare",
            "at",
            "the",
            "flower",
            "more",
            "before",
            "turn",
            "and",
            "walk",
            "down",
            "towards",
            "the",
            "door",
            "."
        ],
        "preceding_context_tokens": [
            [
                "There",
                "was",
                "nothing",
                "in",
                "the",
                "room",
                "--",
                "it",
                "was",
                "a",
                "big",
                "room",
                "with",
                "white",
                "columns",
                "and",
                "white",
                "walls",
                ",",
                "floor",
                "tiles",
                ",",
                "and",
                "decorations",
                "."
            ],
            [
                "The",
                "latter",
                "of",
                "the",
                "objects",
                "made",
                "the",
                "blonde",
                "'s",
                "eyes",
                "widen",
                "and",
                "approach",
                "the",
                "closest",
                "ornament",
                "."
            ],
            [
                "It",
                "was",
                "a",
                "flower",
                ",",
                "carved",
                "out",
                "of",
                "stone",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "there",
                "be",
                "nothing",
                "in",
                "the",
                "room",
                "--",
                "it",
                "be",
                "a",
                "big",
                "room",
                "with",
                "white",
                "column",
                "and",
                "white",
                "wall",
                ",",
                "floor",
                "tile",
                ",",
                "and",
                "decoration",
                "."
            ],
            [
                "the",
                "latter",
                "of",
                "the",
                "object",
                "make",
                "the",
                "blonde",
                "'s",
                "eye",
                "widen",
                "and",
                "approach",
                "the",
                "closest",
                "ornament",
                "."
            ],
            [
                "it",
                "be",
                "a",
                "flower",
                ",",
                "carve",
                "out",
                "of",
                "stone",
                "."
            ]
        ],
        "label": "Surprise"
    },
    {
        "body_part_token_idx": 11,
        "sentence_id": "8d3ba848-3eb4-31d8-a753-f3545e2558fa",
        "tokens": [
            "All",
            "the",
            "nicks",
            "and",
            "scrapes",
            "stood",
            "out",
            "proudly",
            ",",
            "making",
            "his",
            "heart",
            "ache",
            "for",
            "days",
            "of",
            "old",
            "."
        ],
        "lemmatized_tokens": [
            "all",
            "the",
            "nick",
            "and",
            "scrape",
            "stand",
            "out",
            "proudly",
            ",",
            "make",
            "he",
            "heart",
            "ache",
            "for",
            "day",
            "of",
            "old",
            "."
        ],
        "preceding_context_tokens": [
            [
                "There",
                "are",
                "a",
                "few",
                "hours",
                "until",
                "the",
                "meeting",
                "."
            ],
            [
                "I",
                "suggest",
                "you",
                "make",
                "as",
                "much",
                "use",
                "of",
                "them",
                "as",
                "possible.",
                "Frank",
                "opened",
                "up",
                "the",
                "box",
                "hesitantly",
                ",",
                "already",
                "knowing",
                "what",
                "lay",
                "inside",
                "."
            ],
            [
                "His",
                "kama",
                "were",
                "in",
                "the",
                "same",
                "condition",
                "as",
                "he",
                "left",
                "them",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "there",
                "be",
                "a",
                "few",
                "hour",
                "until",
                "the",
                "meeting",
                "."
            ],
            [
                "I",
                "suggest",
                "you",
                "make",
                "as",
                "much",
                "use",
                "of",
                "they",
                "as",
                "possible.",
                "Frank",
                "open",
                "up",
                "the",
                "box",
                "hesitantly",
                ",",
                "already",
                "know",
                "what",
                "lay",
                "inside",
                "."
            ],
            [
                "he",
                "kama",
                "be",
                "in",
                "the",
                "same",
                "condition",
                "as",
                "he",
                "leave",
                "they",
                "."
            ]
        ],
        "label": "Sadness"
    },
    {
        "body_part_token_idx": 10,
        "sentence_id": "c1c489e6-34f9-3013-8ba6-2ccef801cf99",
        "tokens": [
            "Chase",
            "feels",
            "the",
            "dread",
            "mount",
            "in",
            "the",
            "pit",
            "of",
            "his",
            "stomach",
            "as",
            "House",
            "'s",
            "gaze",
            "becomes",
            "curious",
            "."
        ],
        "lemmatized_tokens": [
            "Chase",
            "feel",
            "the",
            "dread",
            "mount",
            "in",
            "the",
            "pit",
            "of",
            "he",
            "stomach",
            "as",
            "House",
            "'s",
            "gaze",
            "become",
            "curious",
            "."
        ],
        "preceding_context_tokens": [
            [
                "House",
                ",",
                "look",
                "at",
                "me",
                "."
            ],
            [
                "Please.",
                "Scowling",
                ",",
                "House",
                "drops",
                "the",
                "remote",
                "and",
                "turns",
                "to",
                "face",
                "him.Chase",
                "knows",
                "that",
                "he",
                "has",
                "all",
                "of",
                "five",
                "seconds",
                "to",
                "make",
                "his",
                "case",
                "for",
                "why",
                "he",
                "'s",
                "more",
                "interesting",
                "than",
                "the",
                "television",
                "and",
                "he",
                "speaks",
                "before",
                "he",
                "can",
                "think",
                "about",
                "what",
                "to",
                "say",
                "."
            ],
            [
                "Your",
                "father",
                "''",
                "he",
                "wanted",
                "me",
                "to",
                "tell",
                "you",
                "that",
                "That",
                "your",
                "House",
                "'s",
                "eyebrow",
                "raises",
                ",",
                "and",
                "Chase",
                "knows",
                "that",
                "four",
                "of",
                "his",
                "five",
                "seconds",
                "have",
                "gone.",
                "Your",
                "mother",
                ",",
                "he",
                "blurts",
                "out",
                ",",
                "and",
                "suddenly",
                "House",
                "is",
                "n't",
                "timing",
                "him",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "House",
                ",",
                "look",
                "at",
                "I",
                "."
            ],
            [
                "Please.",
                "Scowling",
                ",",
                "House",
                "drop",
                "the",
                "remote",
                "and",
                "turn",
                "to",
                "face",
                "him.chase",
                "know",
                "that",
                "he",
                "have",
                "all",
                "of",
                "five",
                "seconds",
                "to",
                "make",
                "he",
                "case",
                "for",
                "why",
                "he",
                "be",
                "more",
                "interesting",
                "than",
                "the",
                "television",
                "and",
                "he",
                "speak",
                "before",
                "he",
                "can",
                "think",
                "about",
                "what",
                "to",
                "say",
                "."
            ],
            [
                "you",
                "father",
                "''",
                "he",
                "want",
                "I",
                "to",
                "tell",
                "you",
                "that",
                "that",
                "you",
                "House",
                "'s",
                "eyebrow",
                "raise",
                ",",
                "and",
                "Chase",
                "know",
                "that",
                "four",
                "of",
                "he",
                "five",
                "seconds",
                "have",
                "gone.",
                "you",
                "mother",
                ",",
                "he",
                "blurt",
                "out",
                ",",
                "and",
                "suddenly",
                "House",
                "be",
                "not",
                "time",
                "he",
                "."
            ]
        ],
        "label": "Fear"
    },
    {
        "body_part_token_idx": 5,
        "sentence_id": "26d2d7ce-a677-3d6f-8d72-103679d1ebd2",
        "tokens": [
            "Thanks.",
            "YoungBae",
            "nervously",
            "cleared",
            "his",
            "throat",
            "then",
            "forced",
            "himself",
            "to",
            "smile",
            "."
        ],
        "lemmatized_tokens": [
            "Thanks.",
            "YoungBae",
            "nervously",
            "clear",
            "he",
            "throat",
            "then",
            "force",
            "himself",
            "to",
            "smile",
            "."
        ],
        "preceding_context_tokens": [
            [
                "Because",
                "I",
                "can",
                "...",
                "No",
                "."
            ],
            [
                "Really",
                "."
            ],
            [
                "I",
                "'m",
                "fine",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "because",
                "I",
                "can",
                "...",
                "no",
                "."
            ],
            [
                "really",
                "."
            ],
            [
                "I",
                "be",
                "fine",
                "."
            ]
        ],
        "label": "Fear"
    },
    {
        "body_part_token_idx": 14,
        "sentence_id": "f57b1d8b-14cc-37c6-b11f-a5eb6e376ec5",
        "tokens": [
            "I",
            "was",
            "in",
            "pain",
            ",",
            "still",
            "I",
            "felt",
            "a",
            "grin",
            "stretch",
            "itself",
            "on",
            "my",
            "face",
            "."
        ],
        "lemmatized_tokens": [
            "I",
            "be",
            "in",
            "pain",
            ",",
            "still",
            "I",
            "feel",
            "a",
            "grin",
            "stretch",
            "itself",
            "on",
            "my",
            "face",
            "."
        ],
        "preceding_context_tokens": [
            [
                "The",
                "flowers",
                "were",
                "burning",
                "."
            ],
            [
                "My",
                "face",
                ",",
                "I",
                "knew",
                ",",
                "would",
                "never",
                "be",
                "the",
                "same",
                "."
            ],
            [
                "And",
                "through",
                "the",
                "flames",
                ",",
                "I",
                "saw",
                "her",
                "walking",
                "away",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "the",
                "flower",
                "be",
                "burn",
                "."
            ],
            [
                "my",
                "face",
                ",",
                "I",
                "know",
                ",",
                "would",
                "never",
                "be",
                "the",
                "same",
                "."
            ],
            [
                "and",
                "through",
                "the",
                "flame",
                ",",
                "I",
                "see",
                "she",
                "walk",
                "away",
                "."
            ]
        ],
        "label": "Joy"
    },
    {
        "body_part_token_idx": 3,
        "sentence_id": "61bb41ab-47b9-370b-b08d-777e362e552b",
        "tokens": [
            "I",
            "felt",
            "my",
            "heart",
            "stop",
            "beating",
            "I",
            "do",
            "n't",
            "even",
            "remember",
            "what",
            "I",
            "said",
            "All",
            "I",
            "feel",
            "is",
            "a",
            "flutter",
            "in",
            "my",
            "stomach",
            "Hopefully",
            "we",
            "can",
            "speak",
            "banmal",
            "to",
            "each",
            "other",
            "even",
            "though",
            "it",
            "'s",
            "still",
            "awkward",
            "and",
            "unfamiliar",
            "instead",
            "of",
            "saying",
            "`",
            "thank",
            "you",
            "'",
            "talk",
            "to",
            "me",
            "in",
            "a",
            "friendlier",
            "way",
            "you",
            "walk",
            "towards",
            "me",
            "slowly",
            ",",
            "step",
            "by",
            "step",
            "now",
            "look",
            "at",
            "my",
            "two",
            "eyes",
            "and",
            "tell",
            "me",
            "``",
            "Do",
            "n't",
            "you",
            "listen",
            "to",
            "the",
            "lyrics",
            "?"
        ],
        "lemmatized_tokens": [
            "I",
            "feel",
            "my",
            "heart",
            "stop",
            "beat",
            "I",
            "do",
            "not",
            "even",
            "remember",
            "what",
            "I",
            "say",
            "all",
            "I",
            "feel",
            "be",
            "a",
            "flutter",
            "in",
            "my",
            "stomach",
            "hopefully",
            "we",
            "can",
            "speak",
            "banmal",
            "to",
            "each",
            "other",
            "even",
            "though",
            "it",
            "be",
            "still",
            "awkward",
            "and",
            "unfamiliar",
            "instead",
            "of",
            "say",
            "`",
            "thank",
            "you",
            "'",
            "talk",
            "to",
            "I",
            "in",
            "a",
            "friendlier",
            "way",
            "you",
            "walk",
            "towards",
            "I",
            "slowly",
            ",",
            "step",
            "by",
            "step",
            "now",
            "look",
            "at",
            "my",
            "two",
            "eye",
            "and",
            "tell",
            "I",
            "``",
            "do",
            "not",
            "you",
            "listen",
            "to",
            "the",
            "lyric",
            "?"
        ],
        "preceding_context_tokens": [
            [
                "I",
                "think",
                "it",
                "'s",
                "the",
                "same",
                "song",
                "."
            ],
            [
                "You",
                "showed",
                "me",
                "his",
                "part",
                "and",
                "this",
                "is",
                "the",
                "same",
                "song",
                ".",
                "''"
            ],
            [
                "Unnie",
                "asked",
                "then",
                "the",
                "second",
                "verse",
                "came",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "I",
                "think",
                "it",
                "be",
                "the",
                "same",
                "song",
                "."
            ],
            [
                "you",
                "show",
                "I",
                "he",
                "part",
                "and",
                "this",
                "be",
                "the",
                "same",
                "song",
                ".",
                "''"
            ],
            [
                "Unnie",
                "ask",
                "then",
                "the",
                "second",
                "verse",
                "come",
                "."
            ]
        ],
        "label": "Fear"
    },
    {
        "body_part_token_idx": 3,
        "sentence_id": "284d89f0-5e5c-3833-b796-2503e1e79dde",
        "tokens": [
            "He",
            "shook",
            "his",
            "head",
            "and",
            "pulled",
            "Jaejoong",
            "'s",
            "hands",
            "away",
            "."
        ],
        "lemmatized_tokens": [
            "he",
            "shake",
            "he",
            "head",
            "and",
            "pull",
            "Jaejoong",
            "'s",
            "hand",
            "away",
            "."
        ],
        "preceding_context_tokens": [
            [
                "He",
                "'s",
                "so",
                "nice",
                "to",
                "me",
                "but",
                "I",
                "always",
                "hurting",
                "him",
                "$",
                "Jaejoong",
                "cupped",
                "Yunho",
                "'s",
                "face",
                "with",
                "a",
                "concern",
                "looked",
                "."
            ],
            [
                "``",
                "Yunho",
                "-",
                "ah",
                ",",
                "what",
                "'s",
                "wrong",
                "?",
                "''"
            ],
            [
                "the",
                "vampire",
                "could",
                "n't",
                "control",
                "his",
                "tears",
                "from",
                "flowing",
                "down",
                "and",
                "he",
                "was",
                "ashamed",
                "of",
                "himself",
                "for",
                "being",
                "a",
                "jerk",
                "weak",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "he",
                "be",
                "so",
                "nice",
                "to",
                "I",
                "but",
                "I",
                "always",
                "hurt",
                "he",
                "$",
                "jaejoong",
                "cup",
                "Yunho",
                "'s",
                "face",
                "with",
                "a",
                "concern",
                "look",
                "."
            ],
            [
                "``",
                "Yunho",
                "-",
                "ah",
                ",",
                "what",
                "be",
                "wrong",
                "?",
                "''"
            ],
            [
                "the",
                "vampire",
                "could",
                "not",
                "control",
                "he",
                "tear",
                "from",
                "flow",
                "down",
                "and",
                "he",
                "be",
                "ashamed",
                "of",
                "himself",
                "for",
                "be",
                "a",
                "jerk",
                "weak",
                "."
            ]
        ],
        "label": "Sadness"
    },
    {
        "body_part_token_idx": 9,
        "sentence_id": "5212f8b4-b279-3aa7-983f-47f6006b7fd8",
        "tokens": [
            "He",
            "sat",
            "there",
            ",",
            "feeling",
            "almost",
            "sick",
            "to",
            "his",
            "stomach",
            "as",
            "he",
            "remembered",
            "the",
            "name",
            "."
        ],
        "lemmatized_tokens": [
            "he",
            "sit",
            "there",
            ",",
            "feel",
            "almost",
            "sick",
            "to",
            "he",
            "stomach",
            "as",
            "he",
            "remember",
            "the",
            "name",
            "."
        ],
        "preceding_context_tokens": [
            [
                "He",
                "felt",
                "so",
                "dizzy",
                "and",
                "light",
                "headed",
                "as",
                "the",
                "manager",
                "turned",
                "to",
                "face",
                "Jinki",
                "and",
                "spoke",
                "to",
                "him",
                ",",
                "``",
                "Jinki",
                ",",
                "you",
                "'re",
                "going",
                "to",
                "be",
                "the",
                "leader",
                "of",
                "our",
                "new",
                "group",
                "."
            ],
            [
                "We",
                "'ve",
                "decided",
                "to",
                "give",
                "you",
                "the",
                "stage",
                "name",
                "Onyu",
                ",",
                "but",
                "we",
                "'ll",
                "spell",
                "it",
                "O",
                "N",
                "E",
                "W.",
                "''",
                "The",
                "manager",
                "spelled",
                "it",
                "out",
                ",",
                "but",
                "it",
                "went",
                "over",
                "Jinki",
                "'s",
                "head",
                ",",
                "his",
                "brain",
                "had",
                "paused",
                "on",
                "the",
                "name",
                "itself",
                "."
            ],
            [
                "He",
                "found",
                "himself",
                "repeating",
                "``",
                "Onyu",
                "''",
                "over",
                "and",
                "over",
                "in",
                "his",
                "head",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "he",
                "feel",
                "so",
                "dizzy",
                "and",
                "light",
                "head",
                "as",
                "the",
                "manager",
                "turn",
                "to",
                "face",
                "Jinki",
                "and",
                "speak",
                "to",
                "he",
                ",",
                "``",
                "Jinki",
                ",",
                "you",
                "be",
                "go",
                "to",
                "be",
                "the",
                "leader",
                "of",
                "we",
                "new",
                "group",
                "."
            ],
            [
                "we",
                "have",
                "decide",
                "to",
                "give",
                "you",
                "the",
                "stage",
                "name",
                "Onyu",
                ",",
                "but",
                "we",
                "will",
                "spell",
                "it",
                "o",
                "n",
                "e",
                "W.",
                "''",
                "the",
                "manager",
                "spell",
                "it",
                "out",
                ",",
                "but",
                "it",
                "go",
                "over",
                "Jinki",
                "'s",
                "head",
                ",",
                "he",
                "brain",
                "have",
                "pause",
                "on",
                "the",
                "name",
                "itself",
                "."
            ],
            [
                "he",
                "find",
                "himself",
                "repeat",
                "``",
                "Onyu",
                "''",
                "over",
                "and",
                "over",
                "in",
                "he",
                "head",
                "."
            ]
        ],
        "label": "Disgust"
    },
    {
        "body_part_token_idx": 5,
        "sentence_id": "8af953e6-3582-389a-a671-fbf9229c2f93",
        "tokens": [
            "The",
            "Doctor",
            "was",
            "shaking",
            "his",
            "head",
            ",",
            "his",
            "dark",
            "eyes",
            "serious",
            "."
        ],
        "lemmatized_tokens": [
            "the",
            "Doctor",
            "be",
            "shake",
            "he",
            "head",
            ",",
            "he",
            "dark",
            "eye",
            "serious",
            "."
        ],
        "preceding_context_tokens": [
            [
                "Jethro",
                "silently",
                "cursed",
                "the",
                "Master",
                "with",
                "every",
                "step",
                ",",
                "wishing",
                "that",
                "it",
                "was",
                "possible",
                "to",
                "destroy",
                "the",
                "bastard",
                "with",
                "his",
                "thoughts",
                "."
            ],
            [
                "``",
                "Do",
                "n't",
                "think",
                "like",
                "that",
                ",",
                "Jethro",
                ".",
                "''"
            ],
            [
                "The",
                "Doctor",
                "'s",
                "voice",
                "cut",
                "into",
                "his",
                "thoughts",
                ",",
                "and",
                "his",
                "head",
                "jerked",
                "towards",
                "the",
                "man",
                "beside",
                "him",
                ",",
                "his",
                "eyes",
                "wide",
                "with",
                "surprise",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "Jethro",
                "silently",
                "curse",
                "the",
                "Master",
                "with",
                "every",
                "step",
                ",",
                "wish",
                "that",
                "it",
                "be",
                "possible",
                "to",
                "destroy",
                "the",
                "bastard",
                "with",
                "he",
                "thought",
                "."
            ],
            [
                "``",
                "do",
                "not",
                "think",
                "like",
                "that",
                ",",
                "Jethro",
                ".",
                "''"
            ],
            [
                "the",
                "Doctor",
                "'s",
                "voice",
                "cut",
                "into",
                "he",
                "thought",
                ",",
                "and",
                "he",
                "head",
                "jerk",
                "towards",
                "the",
                "man",
                "beside",
                "he",
                ",",
                "he",
                "eye",
                "wide",
                "with",
                "surprise",
                "."
            ]
        ],
        "label": "Disgust"
    },
    {
        "body_part_token_idx": 5,
        "sentence_id": "d166bc8b-9ca4-3185-9bfd-6f10339551f7",
        "tokens": [
            "Thrashing",
            "he",
            "clutched",
            "at",
            "his",
            "head",
            "as",
            "his",
            "skull",
            "throbbed",
            "with",
            "the",
            "amount",
            "of",
            "data",
            "it",
            "was",
            "trying",
            "to",
            "process",
            "."
        ],
        "lemmatized_tokens": [
            "thrash",
            "he",
            "clutch",
            "at",
            "he",
            "head",
            "as",
            "he",
            "skull",
            "throb",
            "with",
            "the",
            "amount",
            "of",
            "datum",
            "it",
            "be",
            "try",
            "to",
            "process",
            "."
        ],
        "preceding_context_tokens": [
            [
                "He",
                "remembered",
                "Cain",
                "'s",
                "icy",
                "expression",
                "very",
                "well",
                "indeed.Jerking",
                "hard",
                "a",
                "tidal",
                "wave",
                "of",
                "memories",
                "rolled",
                "over",
                "him",
                "as",
                "this",
                "one",
                "acknowledgement",
                "opened",
                "the",
                "floodgate",
                "to",
                "his",
                "past",
                "."
            ],
            [
                "He",
                "was",
                "n't",
                "entirely",
                "sure",
                "if",
                "he",
                "shouted",
                "but",
                "he",
                "had",
                "somehow",
                "alerted",
                "everyone",
                "in",
                "the",
                "room",
                "that",
                "he",
                "was",
                "awake",
                "and",
                "was",
                "not",
                "like",
                "he",
                "had",
                "been",
                "."
            ],
            [
                "When",
                "he",
                "had",
                "been",
                "searching",
                "on",
                "and",
                "off",
                "for",
                "his",
                "missing",
                "brain",
                "he",
                "had",
                "n't",
                "thought",
                "it",
                "would",
                "hurt",
                "quiet",
                "so",
                "badly",
                "when",
                "he",
                "got",
                "what",
                "he",
                "wanted",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "he",
                "remember",
                "Cain",
                "'s",
                "icy",
                "expression",
                "very",
                "well",
                "indeed.jerking",
                "hard",
                "a",
                "tidal",
                "wave",
                "of",
                "memory",
                "roll",
                "over",
                "he",
                "as",
                "this",
                "one",
                "acknowledgement",
                "open",
                "the",
                "floodgate",
                "to",
                "he",
                "past",
                "."
            ],
            [
                "he",
                "be",
                "not",
                "entirely",
                "sure",
                "if",
                "he",
                "shout",
                "but",
                "he",
                "have",
                "somehow",
                "alert",
                "everyone",
                "in",
                "the",
                "room",
                "that",
                "he",
                "be",
                "awake",
                "and",
                "be",
                "not",
                "like",
                "he",
                "have",
                "be",
                "."
            ],
            [
                "when",
                "he",
                "have",
                "be",
                "search",
                "on",
                "and",
                "off",
                "for",
                "he",
                "missing",
                "brain",
                "he",
                "have",
                "not",
                "think",
                "it",
                "would",
                "hurt",
                "quiet",
                "so",
                "badly",
                "when",
                "he",
                "get",
                "what",
                "he",
                "want",
                "."
            ]
        ],
        "label": "Surprise"
    },
    {
        "body_part_token_idx": 5,
        "sentence_id": "40660421-021f-3204-bd4d-7bca79a67790",
        "tokens": [
            "I",
            "ask",
            "quickly",
            ",",
            "my",
            "heart",
            "starting",
            "to",
            "race",
            "."
        ],
        "lemmatized_tokens": [
            "I",
            "ask",
            "quickly",
            ",",
            "my",
            "heart",
            "start",
            "to",
            "race",
            "."
        ],
        "preceding_context_tokens": [
            [
                "She",
                "says",
                ",",
                "and",
                "it",
                "'s",
                "now",
                "that",
                "I",
                "hear",
                "the",
                "panic",
                "in",
                "her",
                "voice",
                "even",
                "though",
                "I",
                "can",
                "tell",
                "she",
                "'s",
                "trying",
                "to",
                "hide",
                "it",
                "."
            ],
            [
                "``",
                "What",
                ",",
                "is",
                "something",
                "wrong",
                "?"
            ],
            [
                "Is",
                "she",
                "okay",
                "?",
                "''"
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "she",
                "say",
                ",",
                "and",
                "it",
                "be",
                "now",
                "that",
                "I",
                "hear",
                "the",
                "panic",
                "in",
                "she",
                "voice",
                "even",
                "though",
                "I",
                "can",
                "tell",
                "she",
                "be",
                "try",
                "to",
                "hide",
                "it",
                "."
            ],
            [
                "``",
                "what",
                ",",
                "be",
                "something",
                "wrong",
                "?"
            ],
            [
                "be",
                "she",
                "okay",
                "?",
                "''"
            ]
        ],
        "label": "Fear"
    },
    {
        "body_part_token_idx": 7,
        "sentence_id": "55c63ce1-de99-3248-96c2-8cfde1b7ee92",
        "tokens": [
            "The",
            "disappointment",
            "had",
            "been",
            "all",
            "over",
            "his",
            "face",
            "when",
            "Sheldon",
            "came",
            "clean",
            "about",
            "his",
            "relationship",
            ",",
            "making",
            "Sheldon",
            "feel",
            "like",
            "a",
            "child",
            "being",
            "shamed",
            "by",
            "his",
            "parents",
            "."
        ],
        "lemmatized_tokens": [
            "the",
            "disappointment",
            "have",
            "be",
            "all",
            "over",
            "he",
            "face",
            "when",
            "Sheldon",
            "come",
            "clean",
            "about",
            "he",
            "relationship",
            ",",
            "make",
            "Sheldon",
            "feel",
            "like",
            "a",
            "child",
            "be",
            "shame",
            "by",
            "he",
            "parent",
            "."
        ],
        "preceding_context_tokens": [
            [
                "While",
                "he",
                "warmed",
                "up",
                ",",
                "Sheldon",
                "'s",
                "thoughts",
                "turned",
                "to",
                "Monica",
                ",",
                "the",
                "woman",
                "he",
                "had",
                "met",
                "while",
                "she",
                "had",
                "been",
                "under",
                "investigation",
                "for",
                "murder",
                "."
            ],
            [
                "The",
                "evidence",
                "eventually",
                "pointed",
                "out",
                "the",
                "real",
                "killer",
                ",",
                "but",
                "Sheldon",
                "'s",
                "involvement",
                "with",
                "her",
                "had",
                "drawn",
                "some",
                "fire",
                "from",
                "his",
                "teammates",
                ",",
                "especially",
                "Mac",
                "."
            ],
            [
                "Mac",
                "had",
                "been",
                "firmly",
                "against",
                "Sheldon",
                "'s",
                "relationship",
                "with",
                "Monica",
                ",",
                "particularly",
                "since",
                "she",
                "had",
                "been",
                "a",
                "suspect",
                "in",
                "a",
                "murder",
                "investigation",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "while",
                "he",
                "warm",
                "up",
                ",",
                "Sheldon",
                "'s",
                "thought",
                "turn",
                "to",
                "Monica",
                ",",
                "the",
                "woman",
                "he",
                "have",
                "meet",
                "while",
                "she",
                "have",
                "be",
                "under",
                "investigation",
                "for",
                "murder",
                "."
            ],
            [
                "the",
                "evidence",
                "eventually",
                "point",
                "out",
                "the",
                "real",
                "killer",
                ",",
                "but",
                "Sheldon",
                "'s",
                "involvement",
                "with",
                "she",
                "have",
                "draw",
                "some",
                "fire",
                "from",
                "he",
                "teammate",
                ",",
                "especially",
                "Mac",
                "."
            ],
            [
                "Mac",
                "have",
                "be",
                "firmly",
                "against",
                "Sheldon",
                "'s",
                "relationship",
                "with",
                "Monica",
                ",",
                "particularly",
                "since",
                "she",
                "have",
                "be",
                "a",
                "suspect",
                "in",
                "a",
                "murder",
                "investigation",
                "."
            ]
        ],
        "label": "Disgust"
    },
    {
        "body_part_token_idx": 14,
        "sentence_id": "fdc16fdd-e433-37c8-92fb-ac72c7869f01",
        "tokens": [
            "``",
            "I",
            "do",
            "n't",
            "know",
            ",",
            "''",
            "she",
            "snapped.He",
            "pinched",
            "the",
            "bridge",
            "of",
            "his",
            "nose",
            "."
        ],
        "lemmatized_tokens": [
            "``",
            "I",
            "do",
            "not",
            "know",
            ",",
            "''",
            "she",
            "snapped.He",
            "pinch",
            "the",
            "bridge",
            "of",
            "he",
            "nose",
            "."
        ],
        "preceding_context_tokens": [
            [
                "Daphne",
                "crouched",
                "down",
                "and",
                "moved",
                "in",
                "a",
                "bit",
                "of",
                "a",
                "zigzag",
                "pattern",
                "trying",
                "to",
                "get",
                "at",
                "him",
                "."
            ],
            [
                "It",
                "did",
                "not",
                "do",
                "her",
                "much",
                "good",
                "."
            ],
            [
                "``",
                "What",
                "was",
                "that",
                "?",
                "''"
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "Daphne",
                "crouch",
                "down",
                "and",
                "move",
                "in",
                "a",
                "bit",
                "of",
                "a",
                "zigzag",
                "pattern",
                "try",
                "to",
                "get",
                "at",
                "he",
                "."
            ],
            [
                "it",
                "do",
                "not",
                "do",
                "she",
                "much",
                "good",
                "."
            ],
            [
                "``",
                "what",
                "be",
                "that",
                "?",
                "''"
            ]
        ],
        "label": "Anger"
    },
    {
        "body_part_token_idx": 6,
        "sentence_id": "7bc1eb08-a524-3657-a822-29f2ccfde4c3",
        "tokens": [
            "Changmin",
            "blushed",
            "as",
            "he",
            "shook",
            "his",
            "head",
            "indicating",
            "a",
            "shy",
            "no",
            "."
        ],
        "lemmatized_tokens": [
            "Changmin",
            "blush",
            "as",
            "he",
            "shake",
            "he",
            "head",
            "indicate",
            "a",
            "shy",
            "no",
            "."
        ],
        "preceding_context_tokens": [
            [
                "He",
                "bit",
                "onto",
                "his",
                "lips",
                "as",
                "his",
                "member",
                "leaked",
                "of",
                "white",
                "juices",
                "."
            ],
            [
                "``",
                "You",
                "really",
                "want",
                "me",
                "to",
                "get",
                "off",
                "?",
                "''"
            ],
            [
                "I",
                "teased",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "he",
                "bite",
                "onto",
                "he",
                "lip",
                "as",
                "he",
                "member",
                "leak",
                "of",
                "white",
                "juice",
                "."
            ],
            [
                "``",
                "you",
                "really",
                "want",
                "I",
                "to",
                "get",
                "off",
                "?",
                "''"
            ],
            [
                "I",
                "tease",
                "."
            ]
        ],
        "label": "Fear"
    },
    {
        "body_part_token_idx": 13,
        "sentence_id": "eb3a51bf-a732-3207-8253-2611a4b84aa8",
        "tokens": [
            "Her",
            "voice",
            "was",
            "serious",
            ",",
            "but",
            "there",
            "were",
            "glints",
            "of",
            "laughter",
            "in",
            "her",
            "eyes",
            "."
        ],
        "lemmatized_tokens": [
            "she",
            "voice",
            "be",
            "serious",
            ",",
            "but",
            "there",
            "be",
            "glint",
            "of",
            "laughter",
            "in",
            "she",
            "eye",
            "."
        ],
        "preceding_context_tokens": [
            [
                "Then",
                "she",
                "cast",
                "a",
                "glance",
                "back",
                "at",
                "Steve",
                "."
            ],
            [
                "``",
                "You",
                "arm",
                "a",
                "goddess",
                "of",
                "liberty",
                "with",
                "a",
                "book",
                "and",
                "a",
                "torch",
                ",",
                "''",
                "she",
                "said",
                "."
            ],
            [
                "``",
                "Not",
                "very",
                "effective",
                "weaponry",
                "for",
                "a",
                "warrior",
                "of",
                "freedom",
                ".",
                "''"
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "then",
                "she",
                "cast",
                "a",
                "glance",
                "back",
                "at",
                "Steve",
                "."
            ],
            [
                "``",
                "you",
                "arm",
                "a",
                "goddess",
                "of",
                "liberty",
                "with",
                "a",
                "book",
                "and",
                "a",
                "torch",
                ",",
                "''",
                "she",
                "say",
                "."
            ],
            [
                "``",
                "not",
                "very",
                "effective",
                "weaponry",
                "for",
                "a",
                "warrior",
                "of",
                "freedom",
                ".",
                "''"
            ]
        ],
        "label": "Joy"
    },
    {
        "body_part_token_idx": 1,
        "sentence_id": "70954b21-6d8f-3c10-9a31-fac0d6d338ca",
        "tokens": [
            "My",
            "stomach",
            "still",
            "hurts",
            "."
        ],
        "lemmatized_tokens": [
            "my",
            "stomach",
            "still",
            "hurt",
            "."
        ],
        "preceding_context_tokens": [
            [
                "I",
                "mean",
                "that",
                "whole",
                "jinx",
                "dust",
                "up",
                "thing",
                "you",
                "wrote",
                "about",
                "recently",
                "?"
            ],
            [
                "I",
                "laughed",
                "so",
                "hard",
                "I",
                "peed",
                "myself",
                "a",
                "little",
                "."
            ],
            [
                "And",
                "the",
                "Stevie",
                "Wonder",
                "send",
                "up",
                "?!"
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "I",
                "mean",
                "that",
                "whole",
                "jinx",
                "dust",
                "up",
                "thing",
                "you",
                "write",
                "about",
                "recently",
                "?"
            ],
            [
                "I",
                "laugh",
                "so",
                "hard",
                "I",
                "pee",
                "myself",
                "a",
                "little",
                "."
            ],
            [
                "and",
                "the",
                "Stevie",
                "Wonder",
                "send",
                "up",
                "?!"
            ]
        ],
        "label": "Joy"
    },
    {
        "body_part_token_idx": 5,
        "sentence_id": "e75ae447-b8ad-30c9-af75-f726a53afb5f",
        "tokens": [
            "Daisy",
            "groaned",
            "and",
            "dropped",
            "her",
            "head",
            "onto",
            "the",
            "table",
            "."
        ],
        "lemmatized_tokens": [
            "Daisy",
            "groan",
            "and",
            "drop",
            "she",
            "head",
            "onto",
            "the",
            "table",
            "."
        ],
        "preceding_context_tokens": [
            [
                "She",
                "really",
                "did",
                "n't",
                "know",
                "if",
                "Kevin",
                "was",
                "lying",
                "."
            ],
            [
                "Could",
                "she",
                "be",
                "projecting",
                "all",
                "her",
                "other",
                "failed",
                "relationships",
                "on",
                "him",
                "?"
            ],
            [
                "Could",
                "he",
                "really",
                "just",
                "be",
                "a",
                "nice",
                "guy",
                "that",
                "likes",
                "her",
                "for",
                "her",
                "?"
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "she",
                "really",
                "do",
                "not",
                "know",
                "if",
                "Kevin",
                "be",
                "lie",
                "."
            ],
            [
                "could",
                "she",
                "be",
                "project",
                "all",
                "she",
                "other",
                "fail",
                "relationship",
                "on",
                "he",
                "?"
            ],
            [
                "could",
                "he",
                "really",
                "just",
                "be",
                "a",
                "nice",
                "guy",
                "that",
                "like",
                "she",
                "for",
                "she",
                "?"
            ]
        ],
        "label": "Sadness"
    },
    {
        "body_part_token_idx": 28,
        "sentence_id": "1277e51c-d62b-3a8a-9cf8-b21b1253c470",
        "tokens": [
            "She",
            "danced",
            "just",
            "as",
            "well",
            ",",
            "looking",
            "more",
            "alert",
            "and",
            "there",
            "than",
            "before",
            ",",
            "and",
            "her",
            "eyes",
            "occasionally",
            "locked",
            "onto",
            "him",
            "with",
            "a",
            "small",
            "accompanying",
            "smile",
            "on",
            "her",
            "lips",
            "."
        ],
        "lemmatized_tokens": [
            "she",
            "dance",
            "just",
            "as",
            "well",
            ",",
            "look",
            "more",
            "alert",
            "and",
            "there",
            "than",
            "before",
            ",",
            "and",
            "she",
            "eye",
            "occasionally",
            "lock",
            "onto",
            "he",
            "with",
            "a",
            "small",
            "accompany",
            "smile",
            "on",
            "she",
            "lip",
            "."
        ],
        "preceding_context_tokens": [
            [
                "The",
                "second",
                "time",
                "he",
                "arrived",
                ",",
                "she",
                "was",
                "dancing",
                "near",
                "the",
                "open",
                "markets",
                "in",
                "a",
                "new",
                "brown",
                "cottoned",
                "dress",
                ",",
                "animal",
                "dirty",
                "as",
                "they",
                "were",
                "prone",
                "to",
                "be",
                "but",
                "combed",
                "and",
                "cut",
                ",",
                "and",
                "her",
                "tambourine",
                "rang",
                "louder",
                "and",
                "more",
                "steady",
                "with",
                "the",
                "new",
                "shiny",
                "silver",
                "discs",
                "adorning",
                "the",
                "sides",
                "."
            ],
            [
                "A",
                "small",
                "hat",
                "held",
                "a",
                "modest",
                "collection",
                "of",
                "coins",
                "inside",
                ",",
                "but",
                "she",
                "still",
                "did",
                "not",
                "bother",
                "to",
                "stop",
                "any",
                "of",
                "the",
                "street",
                "children",
                "that",
                "crept",
                "through",
                "the",
                "crowd",
                "and",
                "snatched",
                "a",
                "few",
                "for",
                "themselves",
                "."
            ],
            [
                "He",
                "watched",
                "with",
                "the",
                "crowd",
                "that",
                "had",
                "gathered",
                ",",
                "again",
                "donning",
                "the",
                "clothing",
                "of",
                "this",
                "World",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "the",
                "second",
                "time",
                "he",
                "arrive",
                ",",
                "she",
                "be",
                "dance",
                "near",
                "the",
                "open",
                "market",
                "in",
                "a",
                "new",
                "brown",
                "cotton",
                "dress",
                ",",
                "animal",
                "dirty",
                "as",
                "they",
                "be",
                "prone",
                "to",
                "be",
                "but",
                "comb",
                "and",
                "cut",
                ",",
                "and",
                "she",
                "tambourine",
                "ring",
                "louder",
                "and",
                "more",
                "steady",
                "with",
                "the",
                "new",
                "shiny",
                "silver",
                "disc",
                "adorn",
                "the",
                "side",
                "."
            ],
            [
                "a",
                "small",
                "hat",
                "hold",
                "a",
                "modest",
                "collection",
                "of",
                "coin",
                "inside",
                ",",
                "but",
                "she",
                "still",
                "do",
                "not",
                "bother",
                "to",
                "stop",
                "any",
                "of",
                "the",
                "street",
                "child",
                "that",
                "creep",
                "through",
                "the",
                "crowd",
                "and",
                "snatch",
                "a",
                "few",
                "for",
                "themselves",
                "."
            ],
            [
                "he",
                "watch",
                "with",
                "the",
                "crowd",
                "that",
                "have",
                "gather",
                ",",
                "again",
                "don",
                "the",
                "clothing",
                "of",
                "this",
                "world",
                "."
            ]
        ],
        "label": "Joy"
    },
    {
        "body_part_token_idx": 16,
        "sentence_id": "002ba9d7-9210-3f85-8dc4-1cf90c7a4ed2",
        "tokens": [
            "Lucien",
            "stayed",
            "quiet",
            "about",
            "it",
            ",",
            "although",
            "I",
            "could",
            "see",
            "a",
            "bit",
            "of",
            "worry",
            "in",
            "his",
            "eyes",
            "."
        ],
        "lemmatized_tokens": [
            "Lucien",
            "stay",
            "quiet",
            "about",
            "it",
            ",",
            "although",
            "I",
            "could",
            "see",
            "a",
            "bit",
            "of",
            "worry",
            "in",
            "he",
            "eye",
            "."
        ],
        "preceding_context_tokens": [
            [
                "The",
                "morning",
                "was",
                "spent",
                "arranging",
                "deliveries",
                "of",
                "sandwiches",
                "and",
                "coffee",
                "from",
                "the",
                "cafe",
                "'",
                ",",
                "mead",
                "from",
                "Verdi",
                ",",
                "pastires",
                "from",
                "Edmund",
                "of",
                "course",
                ",",
                "and",
                "one",
                "of",
                "the",
                "local",
                "farmers",
                "dropped",
                "off",
                "an",
                "order",
                "of",
                "fruits",
                "and",
                "vegetables",
                "for",
                "me",
                "."
            ],
            [
                "Then",
                "between",
                "customers",
                ",",
                "I",
                "baked",
                "scones",
                "and",
                "cut",
                "up",
                "the",
                "veggies",
                "and",
                "fruits",
                "for",
                "trays",
                "while",
                "Lucien",
                "was",
                "sent",
                "to",
                "work",
                "setting",
                "up",
                "tables",
                "and",
                "chairs.Finally",
                ",",
                "after",
                "the",
                "last",
                "customer",
                "was",
                "sent",
                "on",
                "their",
                "way",
                ",",
                "and",
                "I",
                "was",
                "somewhat",
                "sure",
                "the",
                "kitchen",
                "was",
                "ready",
                "and",
                "stocked",
                ",",
                "I",
                "went",
                "up",
                "stairs",
                ",",
                "showered",
                ",",
                "threw",
                "on",
                "a",
                "pair",
                "of",
                "jeans",
                "that",
                "hung",
                "a",
                "bit",
                "low",
                "on",
                "the",
                "hips",
                ",",
                "a",
                "soft",
                "beige",
                "top",
                "that",
                "showed",
                "off",
                "the",
                "middrift",
                "and",
                "an",
                "old",
                "pair",
                "of",
                "boots",
                "."
            ],
            [
                "I",
                "had",
                "been",
                "negligent",
                "too",
                "long",
                "in",
                "my",
                "promise",
                "to",
                "Jamie",
                "and",
                "it",
                "'s",
                "time",
                "to",
                "head",
                "out",
                "there",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "the",
                "morning",
                "be",
                "spend",
                "arrange",
                "delivery",
                "of",
                "sandwich",
                "and",
                "coffee",
                "from",
                "the",
                "cafe",
                "'",
                ",",
                "mead",
                "from",
                "Verdi",
                ",",
                "pastire",
                "from",
                "Edmund",
                "of",
                "course",
                ",",
                "and",
                "one",
                "of",
                "the",
                "local",
                "farmer",
                "drop",
                "off",
                "a",
                "order",
                "of",
                "fruit",
                "and",
                "vegetable",
                "for",
                "I",
                "."
            ],
            [
                "then",
                "between",
                "customer",
                ",",
                "I",
                "bake",
                "scone",
                "and",
                "cut",
                "up",
                "the",
                "veggy",
                "and",
                "fruit",
                "for",
                "tray",
                "while",
                "Lucien",
                "be",
                "send",
                "to",
                "work",
                "set",
                "up",
                "table",
                "and",
                "chairs.finally",
                ",",
                "after",
                "the",
                "last",
                "customer",
                "be",
                "send",
                "on",
                "they",
                "way",
                ",",
                "and",
                "I",
                "be",
                "somewhat",
                "sure",
                "the",
                "kitchen",
                "be",
                "ready",
                "and",
                "stock",
                ",",
                "I",
                "go",
                "up",
                "stair",
                ",",
                "shower",
                ",",
                "throw",
                "on",
                "a",
                "pair",
                "of",
                "jeans",
                "that",
                "hang",
                "a",
                "bit",
                "low",
                "on",
                "the",
                "hip",
                ",",
                "a",
                "soft",
                "beige",
                "top",
                "that",
                "show",
                "off",
                "the",
                "middrift",
                "and",
                "a",
                "old",
                "pair",
                "of",
                "boot",
                "."
            ],
            [
                "I",
                "have",
                "be",
                "negligent",
                "too",
                "long",
                "in",
                "my",
                "promise",
                "to",
                "Jamie",
                "and",
                "it",
                "be",
                "time",
                "to",
                "head",
                "out",
                "there",
                "."
            ]
        ],
        "label": "Fear"
    },
    {
        "body_part_token_idx": 12,
        "sentence_id": "789e708d-3b80-3d10-b60d-4517ad266eea",
        "tokens": [
            "He",
            "dug",
            "right",
            "in",
            "after",
            "that",
            "...",
            "He",
            "must",
            "have",
            "had",
            "his",
            "eye",
            "on",
            "a",
            "present",
            "all",
            "week",
            "because",
            "he",
            "went",
            "to",
            "the",
            "back",
            "of",
            "the",
            "tree",
            "and",
            "dug",
            "for",
            "a",
            "present",
            "at",
            "the",
            "bottom",
            "-LRB-",
            "it",
            "was",
            "his",
            "Mack",
            "truck",
            "-LRB-",
            "from",
            "Cars",
            ")",
            "from",
            "his",
            "Auntie",
            "Sherri",
            "and",
            "Uncle",
            "Danny",
            ")",
            "!"
        ],
        "lemmatized_tokens": [
            "he",
            "dig",
            "right",
            "in",
            "after",
            "that",
            "...",
            "he",
            "must",
            "have",
            "have",
            "he",
            "eye",
            "on",
            "a",
            "present",
            "all",
            "week",
            "because",
            "he",
            "go",
            "to",
            "the",
            "back",
            "of",
            "the",
            "tree",
            "and",
            "dig",
            "for",
            "a",
            "present",
            "at",
            "the",
            "bottom",
            "-lrb-_VBZ",
            "it",
            "be",
            "he",
            "Mack",
            "truck",
            "-lrb-",
            "from",
            "car",
            ")",
            "from",
            "he",
            "Auntie",
            "Sherri",
            "and",
            "Uncle",
            "Danny",
            ")",
            "!"
        ],
        "preceding_context_tokens": [
            [
                "Grandpa",
                "and",
                "Grandma",
                "must",
                "have",
                "heard",
                "us",
                "because",
                "they",
                "were",
                "heading",
                "up",
                "the",
                "stairs",
                "at",
                "the",
                "same",
                "time",
                "."
            ],
            [
                "Bowman",
                "was",
                "funny",
                "he",
                "just",
                "kind",
                "of",
                "stared",
                "at",
                "the",
                "presents",
                "-LRB-",
                "prolly",
                "because",
                "he",
                "'s",
                "been",
                "told",
                "for",
                "the",
                "last",
                "month",
                "NOT",
                "TO",
                "TOUCH",
                "the",
                "presents",
                "or",
                "ELSE",
                ")",
                "."
            ],
            [
                "Until",
                "I",
                "said",
                ",",
                "``",
                "It",
                "'s",
                "the",
                "day",
                ",",
                "you",
                "can",
                "open",
                "all",
                "your",
                "presents",
                "!",
                "''"
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "Grandpa",
                "and",
                "Grandma",
                "must",
                "have",
                "hear",
                "we",
                "because",
                "they",
                "be",
                "head",
                "up",
                "the",
                "stair",
                "at",
                "the",
                "same",
                "time",
                "."
            ],
            [
                "Bowman",
                "be",
                "funny",
                "he",
                "just",
                "kind",
                "of",
                "stare",
                "at",
                "the",
                "present",
                "-lrb-",
                "prolly",
                "because",
                "he",
                "be",
                "be",
                "tell",
                "for",
                "the",
                "last",
                "month",
                "not",
                "to",
                "touch",
                "the",
                "present",
                "or",
                "ELSE",
                ")",
                "."
            ],
            [
                "until",
                "I",
                "say",
                ",",
                "``",
                "it",
                "be",
                "the",
                "day",
                ",",
                "you",
                "can",
                "open",
                "all",
                "you",
                "present",
                "!",
                "''"
            ]
        ],
        "label": "Joy"
    },
    {
        "body_part_token_idx": 2,
        "sentence_id": "be57df64-d788-326f-8bb8-4b7dc2470278",
        "tokens": [
            "Kick",
            "my",
            "heels",
            "up",
            "and",
            "shout",
            "."
        ],
        "lemmatized_tokens": [
            "kick",
            "my",
            "heel",
            "up",
            "and",
            "shout",
            "."
        ],
        "preceding_context_tokens": [
            [
                "Since",
                "we",
                "do",
                "n't",
                "smoke",
                "and",
                "it",
                "'s",
                "a",
                "school",
                "building",
                ",",
                "our",
                "phones",
                "had",
                "to",
                "be",
                "the",
                "substitutes",
                "."
            ],
            [
                "Mrs.",
                "A",
                "fails",
                "at",
                "the",
                "art",
                "of",
                "hula",
                "hooping",
                "."
            ],
            [
                "They",
                "make",
                "me",
                "want",
                "to",
                "shout",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "since",
                "we",
                "do",
                "not",
                "smoke",
                "and",
                "it",
                "be",
                "a",
                "school",
                "building",
                ",",
                "we",
                "phone",
                "have",
                "to",
                "be",
                "the",
                "substitute",
                "."
            ],
            [
                "Mrs.",
                "A",
                "fail",
                "at",
                "the",
                "art",
                "of",
                "hula",
                "hooping",
                "."
            ],
            [
                "they",
                "make",
                "I",
                "want",
                "to",
                "shout",
                "."
            ]
        ],
        "label": "Anger"
    },
    {
        "body_part_token_idx": 12,
        "sentence_id": "74bc13ff-5218-3edc-b45c-bc326ee74cd7",
        "tokens": [
            "My",
            "heart",
            "melted",
            "and",
            "the",
            "tears",
            "started",
            "to",
            "well",
            "up",
            "in",
            "my",
            "eyes",
            "straight",
            "away",
            "."
        ],
        "lemmatized_tokens": [
            "my",
            "heart",
            "melt",
            "and",
            "the",
            "tear",
            "start",
            "to",
            "well",
            "up",
            "in",
            "my",
            "eye",
            "straight",
            "away",
            "."
        ],
        "preceding_context_tokens": [
            [
                "Now",
                "I",
                "ca",
                "n't",
                "remember",
                "the",
                "last",
                "time",
                "we",
                "used",
                "it",
                "but",
                "it",
                "was",
                "a",
                "far",
                "while",
                "since",
                "the",
                "camera",
                "had",
                "even",
                "been",
                "out",
                "of",
                "it",
                "'s",
                "case",
                "."
            ],
            [
                "Last",
                "night",
                "after",
                "the",
                "kids",
                "were",
                "in",
                "bed",
                ",",
                "we",
                "rigged",
                "the",
                "camera",
                "up",
                "to",
                "find",
                "out",
                "just",
                "what",
                "was",
                "on",
                "those",
                "tapes",
                "."
            ],
            [
                "When",
                "I",
                "pressed",
                "play",
                ",",
                "Jack",
                "tiny",
                "newborn",
                "face",
                "appeared",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "now",
                "I",
                "can",
                "not",
                "remember",
                "the",
                "last",
                "time",
                "we",
                "use",
                "it",
                "but",
                "it",
                "be",
                "a",
                "far",
                "while",
                "since",
                "the",
                "camera",
                "have",
                "even",
                "be",
                "out",
                "of",
                "it",
                "be",
                "case",
                "."
            ],
            [
                "last",
                "night",
                "after",
                "the",
                "kid",
                "be",
                "in",
                "bed",
                ",",
                "we",
                "rig",
                "the",
                "camera",
                "up",
                "to",
                "find",
                "out",
                "just",
                "what",
                "be",
                "on",
                "those",
                "tape",
                "."
            ],
            [
                "when",
                "I",
                "press",
                "play",
                ",",
                "Jack",
                "tiny",
                "newborn",
                "face",
                "appear",
                "."
            ]
        ],
        "label": "Joy"
    },
    {
        "body_part_token_idx": 10,
        "sentence_id": "0b0b75f9-0de4-3406-bac1-98aa43184fb0",
        "tokens": [
            "Brandon",
            "turned",
            "away",
            "from",
            "his",
            "blue",
            "gaze",
            "and",
            "nodded",
            "his",
            "head",
            "."
        ],
        "lemmatized_tokens": [
            "Brandon",
            "turn",
            "away",
            "from",
            "he",
            "blue",
            "gaze",
            "and",
            "nod",
            "he",
            "head",
            "."
        ],
        "preceding_context_tokens": [
            [
                "he",
                "asked",
                "."
            ],
            [
                "His",
                "older",
                "face",
                "filled",
                "with",
                "concern",
                "."
            ],
            [
                "He",
                "was",
                "getting",
                "sick",
                "of",
                "all",
                "the",
                "concern",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "he",
                "ask",
                "."
            ],
            [
                "he",
                "older",
                "face",
                "fill",
                "with",
                "concern",
                "."
            ],
            [
                "he",
                "be",
                "get",
                "sick",
                "of",
                "all",
                "the",
                "concern",
                "."
            ]
        ],
        "label": "Disgust"
    },
    {
        "body_part_token_idx": 11,
        "sentence_id": "5e7515bd-27e5-3473-a8c4-019ee9ddeb27",
        "tokens": [
            "Brendon",
            "asks",
            ",",
            "a",
            "smile",
            "playing",
            "at",
            "the",
            "corner",
            "of",
            "his",
            "lips",
            ",",
            "and",
            "Ryan",
            "nods",
            "dumbly",
            "."
        ],
        "lemmatized_tokens": [
            "Brendon",
            "ask",
            ",",
            "a",
            "smile",
            "play",
            "at",
            "the",
            "corner",
            "of",
            "he",
            "lip",
            ",",
            "and",
            "Ryan",
            "nod",
            "dumbly",
            "."
        ],
        "preceding_context_tokens": [
            [
                "Brendon",
                "frowns",
                ",",
                "trying",
                "to",
                "recall",
                "what",
                "he",
                "said",
                "to",
                "Shane",
                ",",
                "but",
                "then",
                "his",
                "face",
                "lights",
                "up",
                "with",
                "remembrance",
                "and",
                "he",
                "laughs",
                ",",
                "loud",
                "and",
                "happy",
                "."
            ],
            [
                "It",
                "makes",
                "something",
                "white",
                "hot",
                "pool",
                "in",
                "Ryan",
                "'s",
                "stomach",
                "."
            ],
            [
                "``",
                "The",
                "guy",
                "I",
                "was",
                "talking",
                "about",
                "to",
                "Shane",
                "who",
                "I",
                "'m",
                "completely",
                "infatuated",
                "with",
                "and",
                "has",
                "the",
                "most",
                "beautiful",
                "eyes",
                "and",
                "the",
                "prettiest",
                "face",
                "I",
                "'ve",
                "ever",
                "seen",
                "?",
                "''"
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "Brendon",
                "frown",
                ",",
                "try",
                "to",
                "recall",
                "what",
                "he",
                "say",
                "to",
                "Shane",
                ",",
                "but",
                "then",
                "he",
                "face",
                "light",
                "up",
                "with",
                "remembrance",
                "and",
                "he",
                "laugh",
                ",",
                "loud",
                "and",
                "happy",
                "."
            ],
            [
                "it",
                "make",
                "something",
                "white",
                "hot",
                "pool",
                "in",
                "Ryan",
                "'s",
                "stomach",
                "."
            ],
            [
                "``",
                "the",
                "guy",
                "I",
                "be",
                "talk",
                "about",
                "to",
                "Shane",
                "who",
                "I",
                "be",
                "completely",
                "infatuate",
                "with",
                "and",
                "have",
                "the",
                "most",
                "beautiful",
                "eye",
                "and",
                "the",
                "prettiest",
                "face",
                "I",
                "have",
                "ever",
                "see",
                "?",
                "''"
            ]
        ],
        "label": "Joy"
    },
    {
        "body_part_token_idx": 10,
        "sentence_id": "1dd96a76-24a6-3367-9e09-adb511ecd650",
        "tokens": [
            "Doojoon",
            "could",
            "n't",
            "help",
            "but",
            "laugh",
            "then",
            "and",
            "shook",
            "his",
            "head",
            "."
        ],
        "lemmatized_tokens": [
            "Doojoon",
            "could",
            "not",
            "help",
            "but",
            "laugh",
            "then",
            "and",
            "shake",
            "he",
            "head",
            "."
        ],
        "preceding_context_tokens": [
            [
                "Yoseob",
                "gaped",
                "for",
                "a",
                "moment",
                ",",
                "sputtering",
                "a",
                "little",
                "in",
                "his",
                "aggravated",
                "disbelief",
                "."
            ],
            [
                "``",
                "Tha",
                "-",
                "That",
                "dirty",
                "little",
                "cheat",
                "!",
                "''"
            ],
            [
                "Everyone",
                "knew",
                "that",
                "Dongwoon",
                "was",
                "never",
                "quite",
                "able",
                "to",
                "say",
                "no",
                "to",
                "his",
                "hyungs",
                ",",
                "no",
                "matter",
                "how",
                "much",
                "it",
                "was",
                "probably",
                "better",
                "for",
                "him",
                "if",
                "he",
                "did",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "Yoseob",
                "gape",
                "for",
                "a",
                "moment",
                ",",
                "sputtering",
                "a",
                "little",
                "in",
                "he",
                "aggravated",
                "disbelief",
                "."
            ],
            [
                "``",
                "tha",
                "-",
                "that",
                "dirty",
                "little",
                "cheat",
                "!",
                "''"
            ],
            [
                "everyone",
                "know",
                "that",
                "Dongwoon",
                "be",
                "never",
                "quite",
                "able",
                "to",
                "say",
                "no",
                "to",
                "he",
                "hyung",
                ",",
                "no",
                "matter",
                "how",
                "much",
                "it",
                "be",
                "probably",
                "better",
                "for",
                "he",
                "if",
                "he",
                "do",
                "."
            ]
        ],
        "label": "Sadness"
    },
    {
        "body_part_token_idx": 19,
        "sentence_id": "71a63c94-700e-3052-a9a3-287a8ca648c2",
        "tokens": [
            "Five",
            "times",
            "in",
            "a",
            "row",
            "she",
            "puts",
            "the",
            "phone",
            "down",
            ",",
            "shoots",
            "us",
            "a",
            "pained",
            "expression",
            "and",
            "shakes",
            "her",
            "head",
            "sharply",
            "."
        ],
        "lemmatized_tokens": [
            "five",
            "time",
            "in",
            "a",
            "row",
            "she",
            "put",
            "the",
            "phone",
            "down",
            ",",
            "shoot",
            "we",
            "a",
            "pained",
            "expression",
            "and",
            "shake",
            "she",
            "head",
            "sharply",
            "."
        ],
        "preceding_context_tokens": [
            [
                "But",
                "I",
                "do",
                "n't",
                "think",
                "there",
                "are",
                "any",
                "holidays",
                "this",
                "week",
                ",",
                "so",
                "you",
                "'ll",
                "be",
                "fine",
                "!",
                "''"
            ],
            [
                ":P",
                "Ah",
                ",",
                "well",
                "...",
                "now",
                "we",
                "know",
                "."
            ],
            [
                "So",
                ",",
                "we",
                "'re",
                "standing",
                "there",
                "with",
                "pleading",
                ",",
                "puppy",
                "dog",
                "eyes",
                "in",
                "front",
                "of",
                "the",
                "clerk",
                "who",
                "is",
                "busily",
                "calling",
                "every",
                "hotel",
                "and",
                "ryokan",
                "in",
                "her",
                "little",
                "book",
                "looking",
                "for",
                "an",
                "available",
                "room",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "but",
                "I",
                "do",
                "not",
                "think",
                "there",
                "be",
                "any",
                "holiday",
                "this",
                "week",
                ",",
                "so",
                "you",
                "will",
                "be",
                "fine",
                "!",
                "''"
            ],
            [
                ":p",
                "ah",
                ",",
                "well",
                "...",
                "now",
                "we",
                "know",
                "."
            ],
            [
                "so",
                ",",
                "we",
                "be",
                "stand",
                "there",
                "with",
                "pleading",
                ",",
                "puppy",
                "dog",
                "eye",
                "in",
                "front",
                "of",
                "the",
                "clerk",
                "who",
                "be",
                "busily",
                "call",
                "every",
                "hotel",
                "and",
                "ryokan",
                "in",
                "she",
                "little",
                "book",
                "look",
                "for",
                "a",
                "available",
                "room",
                "."
            ]
        ],
        "label": "Sadness"
    },
    {
        "body_part_token_idx": 3,
        "sentence_id": "41766ee9-6854-3b38-b867-f07931af5a35",
        "tokens": [
            "Daphne",
            "rolled",
            "her",
            "eyes",
            "."
        ],
        "lemmatized_tokens": [
            "Daphne",
            "roll",
            "she",
            "eye",
            "."
        ],
        "preceding_context_tokens": [
            [
                "``",
                "All",
                "I",
                "did",
                "was",
                "point",
                "out",
                "that",
                "her",
                "father",
                "'s",
                "a",
                "Mudblood",
                "."
            ],
            [
                "It",
                "'s",
                "not",
                "as",
                "if",
                "she",
                "does",
                "n't",
                "already",
                "know",
                "that",
                ".",
                "''"
            ],
            [
                "``",
                "And",
                "she",
                "slapped",
                "you",
                "for",
                "that",
                "?",
                "''"
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "``",
                "all",
                "I",
                "do",
                "be",
                "point",
                "out",
                "that",
                "she",
                "father",
                "'s",
                "a",
                "Mudblood",
                "."
            ],
            [
                "it",
                "be",
                "not",
                "as",
                "if",
                "she",
                "do",
                "not",
                "already",
                "know",
                "that",
                ".",
                "''"
            ],
            [
                "``",
                "and",
                "she",
                "slap",
                "you",
                "for",
                "that",
                "?",
                "''"
            ]
        ],
        "label": "Disgust"
    },
    {
        "body_part_token_idx": 4,
        "sentence_id": "f1330479-334c-38c3-ae53-98693c854c8d",
        "tokens": [
            "I",
            "just",
            "closed",
            "my",
            "eyes",
            ",",
            "swayed",
            ",",
            "and",
            "let",
            "the",
            "song",
            "envelop",
            "me",
            "."
        ],
        "lemmatized_tokens": [
            "I",
            "just",
            "close",
            "my",
            "eye",
            ",",
            "sway",
            ",",
            "and",
            "let",
            "the",
            "song",
            "envelop",
            "I",
            "."
        ],
        "preceding_context_tokens": [
            [
                "No",
                "other",
                "acoustic",
                "shows",
                "that",
                "I",
                "know",
                "of",
                "!!"
            ],
            [
                "OH",
                "yes",
                ",",
                "they",
                "played",
                "my",
                "favs",
                "and",
                "also",
                "some",
                "new",
                "ones",
                "."
            ],
            [
                "My",
                "eyes",
                "clouded",
                "up",
                "when",
                "Peter",
                "began",
                "``",
                "Fault",
                "Line",
                "''",
                ",",
                "but",
                "they",
                "cleared",
                "up",
                "as",
                "soon",
                "as",
                "I",
                "started",
                "singing",
                "along",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "no",
                "other",
                "acoustic",
                "show",
                "that",
                "I",
                "know",
                "of",
                "!!"
            ],
            [
                "OH",
                "yes",
                ",",
                "they",
                "play",
                "my",
                "fav",
                "and",
                "also",
                "some",
                "new",
                "one",
                "."
            ],
            [
                "my",
                "eye",
                "cloud",
                "up",
                "when",
                "Peter",
                "begin",
                "``",
                "Fault",
                "Line",
                "''",
                ",",
                "but",
                "they",
                "clear",
                "up",
                "as",
                "soon",
                "as",
                "I",
                "start",
                "sing",
                "along",
                "."
            ]
        ],
        "label": "Joy"
    },
    {
        "body_part_token_idx": 30,
        "sentence_id": "fd1fef52-8639-33a7-902a-534df606392a",
        "tokens": [
            "I",
            "have",
            "to",
            "admit",
            "that",
            "when",
            "I",
            "started",
            "reading",
            "Terri",
            "'s",
            "raves",
            "for",
            "the",
            "electrolyte",
            "supplement",
            "called",
            "Endurolytes",
            "on",
            "her",
            "Middle",
            "of",
            "the",
            "Pack",
            "Girl",
            "blog",
            "I",
            "sorta",
            "rolled",
            "my",
            "eyes",
            "."
        ],
        "lemmatized_tokens": [
            "I",
            "have",
            "to",
            "admit",
            "that",
            "when",
            "I",
            "start",
            "read",
            "Terri",
            "'s",
            "rave",
            "for",
            "the",
            "electrolyte",
            "supplement",
            "call",
            "Endurolytes",
            "on",
            "she",
            "middle",
            "of",
            "the",
            "Pack",
            "Girl",
            "blog",
            "I",
            "sorta",
            "roll",
            "my",
            "eye",
            "."
        ],
        "preceding_context_tokens": [],
        "preceding_context_lemmatized_tokens": [],
        "label": "Disgust"
    },
    {
        "body_part_token_idx": 8,
        "sentence_id": "ba0db14b-d093-301b-8860-309f6cbc0832",
        "tokens": [
            "She",
            "blushed",
            "and",
            "held",
            "her",
            "binder",
            "across",
            "her",
            "chest",
            "."
        ],
        "lemmatized_tokens": [
            "she",
            "blush",
            "and",
            "hold",
            "she",
            "binder",
            "across",
            "she",
            "chest",
            "."
        ],
        "preceding_context_tokens": [
            [
                "a",
                "quiet",
                "voice",
                "sounded",
                "off",
                "behind",
                "me",
                "."
            ],
            [
                "I",
                "turned",
                "to",
                "see",
                "Katrina",
                ",",
                "a",
                "fellow",
                "Senior",
                "cheerleader",
                "and",
                "a",
                "beautiful",
                "brunette",
                "to",
                "boot",
                "."
            ],
            [
                "``",
                "Hey",
                ",",
                "what",
                "'s",
                "up",
                "?",
                "''"
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "a",
                "quiet",
                "voice",
                "sound",
                "off",
                "behind",
                "I",
                "."
            ],
            [
                "I",
                "turn",
                "to",
                "see",
                "Katrina",
                ",",
                "a",
                "fellow",
                "senior",
                "cheerleader",
                "and",
                "a",
                "beautiful",
                "brunette",
                "to",
                "boot",
                "."
            ],
            [
                "``",
                "hey",
                ",",
                "what",
                "be",
                "up",
                "?",
                "''"
            ]
        ],
        "label": "Surprise"
    },
    {
        "body_part_token_idx": 14,
        "sentence_id": "1679e7f8-fef4-3076-8270-053b9677e65a",
        "tokens": [
            "I",
            "yell",
            "but",
            "I",
            "ca",
            "n't",
            "help",
            "but",
            "feel",
            "a",
            "sharp",
            "stave",
            "in",
            "my",
            "chest",
            "."
        ],
        "lemmatized_tokens": [
            "I",
            "yell",
            "but",
            "I",
            "can",
            "not",
            "help",
            "but",
            "feel",
            "a",
            "sharp",
            "stave",
            "in",
            "my",
            "chest",
            "."
        ],
        "preceding_context_tokens": [
            [
                "Ugh",
                "!!"
            ],
            [
                "This",
                "is",
                "sooo",
                "stupid",
                ",",
                "they",
                "'re",
                "a",
                "million",
                "guys",
                "around",
                ",",
                "why",
                "do",
                "I",
                "need",
                "to",
                "get",
                "with",
                "Reita",
                "!?"
            ],
            [
                "He",
                "'s",
                "a",
                "freaking",
                "Retard",
                "!"
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "ugh",
                "!!"
            ],
            [
                "this",
                "be",
                "sooo",
                "stupid",
                ",",
                "they",
                "be",
                "a",
                "million",
                "guy",
                "around",
                ",",
                "why",
                "do",
                "I",
                "need",
                "to",
                "get",
                "with",
                "Reita",
                "!?"
            ],
            [
                "he",
                "be",
                "a",
                "freak",
                "Retard",
                "!"
            ]
        ],
        "label": "Sadness"
    },
    {
        "body_part_token_idx": 10,
        "sentence_id": "8ffdeca7-0f79-3913-a759-59f1ab901b2c",
        "tokens": [
            "As",
            "his",
            "eyes",
            "skimmed",
            "the",
            "contents",
            "of",
            "the",
            "letter",
            "his",
            "face",
            "became",
            "pale",
            ",",
            "twin",
            "red",
            "splotches",
            "appearing",
            "in",
            "his",
            "cheeks",
            "."
        ],
        "lemmatized_tokens": [
            "as",
            "he",
            "eye",
            "skim",
            "the",
            "contents",
            "of",
            "the",
            "letter",
            "he",
            "face",
            "become",
            "pale",
            ",",
            "twin",
            "red",
            "splotch",
            "appear",
            "in",
            "he",
            "cheek",
            "."
        ],
        "preceding_context_tokens": [
            [
                "The",
                "moment",
                "his",
                "father",
                "came",
                "home",
                "Xander",
                "bounced",
                "up",
                "the",
                "stairs",
                "to",
                "his",
                "room",
                ",",
                "water",
                "droplets",
                "flying",
                "from",
                "his",
                "still",
                "wet",
                "curls",
                ",",
                "grabbing",
                "the",
                "letter",
                "in",
                "damp",
                "hands",
                "as",
                "he",
                "raced",
                "down",
                "the",
                "stairs",
                "to",
                "fulfil",
                "his",
                "task",
                "."
            ],
            [
                "It",
                "seemed",
                "his",
                "father",
                "had",
                "already",
                "had",
                "time",
                "to",
                "stop",
                "off",
                "at",
                "the",
                "pub",
                "after",
                "work",
                ",",
                "the",
                "smell",
                "of",
                "alcohol",
                "nauseatingly",
                "familiar",
                "to",
                "Xander",
                "even",
                "at",
                "the",
                "age",
                "of",
                "seven",
                "."
            ],
            [
                "He",
                "grabbed",
                "the",
                "letter",
                "out",
                "of",
                "Xander",
                "'s",
                "hands",
                "and",
                "tore",
                "the",
                "envelope",
                "open",
                "violently",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "the",
                "moment",
                "he",
                "father",
                "come",
                "home",
                "Xander",
                "bounce",
                "up",
                "the",
                "stair",
                "to",
                "he",
                "room",
                ",",
                "water",
                "droplet",
                "fly",
                "from",
                "he",
                "still",
                "wet",
                "curl",
                ",",
                "grab",
                "the",
                "letter",
                "in",
                "damp",
                "hand",
                "as",
                "he",
                "race",
                "down",
                "the",
                "stair",
                "to",
                "fulfil",
                "he",
                "task",
                "."
            ],
            [
                "it",
                "seem",
                "he",
                "father",
                "have",
                "already",
                "have",
                "time",
                "to",
                "stop",
                "off",
                "at",
                "the",
                "pub",
                "after",
                "work",
                ",",
                "the",
                "smell",
                "of",
                "alcohol",
                "nauseatingly",
                "familiar",
                "to",
                "Xander",
                "even",
                "at",
                "the",
                "age",
                "of",
                "seven",
                "."
            ],
            [
                "he",
                "grab",
                "the",
                "letter",
                "out",
                "of",
                "Xander",
                "'s",
                "hand",
                "and",
                "tear",
                "the",
                "envelope",
                "open",
                "violently",
                "."
            ]
        ],
        "label": "Anger"
    },
    {
        "body_part_token_idx": 20,
        "sentence_id": "8ffdeca7-0f79-3913-a759-59f1ab901b2c",
        "tokens": [
            "As",
            "his",
            "eyes",
            "skimmed",
            "the",
            "contents",
            "of",
            "the",
            "letter",
            "his",
            "face",
            "became",
            "pale",
            ",",
            "twin",
            "red",
            "splotches",
            "appearing",
            "in",
            "his",
            "cheeks",
            "."
        ],
        "lemmatized_tokens": [
            "as",
            "he",
            "eye",
            "skim",
            "the",
            "contents",
            "of",
            "the",
            "letter",
            "he",
            "face",
            "become",
            "pale",
            ",",
            "twin",
            "red",
            "splotch",
            "appear",
            "in",
            "he",
            "cheek",
            "."
        ],
        "preceding_context_tokens": [
            [
                "The",
                "moment",
                "his",
                "father",
                "came",
                "home",
                "Xander",
                "bounced",
                "up",
                "the",
                "stairs",
                "to",
                "his",
                "room",
                ",",
                "water",
                "droplets",
                "flying",
                "from",
                "his",
                "still",
                "wet",
                "curls",
                ",",
                "grabbing",
                "the",
                "letter",
                "in",
                "damp",
                "hands",
                "as",
                "he",
                "raced",
                "down",
                "the",
                "stairs",
                "to",
                "fulfil",
                "his",
                "task",
                "."
            ],
            [
                "It",
                "seemed",
                "his",
                "father",
                "had",
                "already",
                "had",
                "time",
                "to",
                "stop",
                "off",
                "at",
                "the",
                "pub",
                "after",
                "work",
                ",",
                "the",
                "smell",
                "of",
                "alcohol",
                "nauseatingly",
                "familiar",
                "to",
                "Xander",
                "even",
                "at",
                "the",
                "age",
                "of",
                "seven",
                "."
            ],
            [
                "He",
                "grabbed",
                "the",
                "letter",
                "out",
                "of",
                "Xander",
                "'s",
                "hands",
                "and",
                "tore",
                "the",
                "envelope",
                "open",
                "violently",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "the",
                "moment",
                "he",
                "father",
                "come",
                "home",
                "Xander",
                "bounce",
                "up",
                "the",
                "stair",
                "to",
                "he",
                "room",
                ",",
                "water",
                "droplet",
                "fly",
                "from",
                "he",
                "still",
                "wet",
                "curl",
                ",",
                "grab",
                "the",
                "letter",
                "in",
                "damp",
                "hand",
                "as",
                "he",
                "race",
                "down",
                "the",
                "stair",
                "to",
                "fulfil",
                "he",
                "task",
                "."
            ],
            [
                "it",
                "seem",
                "he",
                "father",
                "have",
                "already",
                "have",
                "time",
                "to",
                "stop",
                "off",
                "at",
                "the",
                "pub",
                "after",
                "work",
                ",",
                "the",
                "smell",
                "of",
                "alcohol",
                "nauseatingly",
                "familiar",
                "to",
                "Xander",
                "even",
                "at",
                "the",
                "age",
                "of",
                "seven",
                "."
            ],
            [
                "he",
                "grab",
                "the",
                "letter",
                "out",
                "of",
                "Xander",
                "'s",
                "hand",
                "and",
                "tear",
                "the",
                "envelope",
                "open",
                "violently",
                "."
            ]
        ],
        "label": "Anger"
    },
    {
        "body_part_token_idx": 1,
        "sentence_id": "1bf69561-9e1b-3dc9-bbf2-ce7e115ba5ed",
        "tokens": [
            "My",
            "legs",
            "were",
            "glued",
            "to",
            "the",
            "front",
            "porch",
            "."
        ],
        "lemmatized_tokens": [
            "my",
            "leg",
            "be",
            "glue",
            "to",
            "the",
            "front",
            "porch",
            "."
        ],
        "preceding_context_tokens": [
            [
                "Yeah",
                ",",
                "great",
                "let",
                "'s",
                "let",
                "the",
                "ladies",
                "go",
                "first",
                "that",
                "way",
                "if",
                "they",
                "get",
                "attacked",
                "first",
                ",",
                "the",
                "guy",
                "always",
                "gets",
                "away",
                "!"
            ],
            [
                "I",
                "'m",
                "toast",
                "."
            ],
            [
                "I",
                "could",
                "n't",
                "move",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "yeah",
                ",",
                "great",
                "let",
                "'s",
                "let",
                "the",
                "lady",
                "go",
                "first",
                "that",
                "way",
                "if",
                "they",
                "get",
                "attack",
                "first",
                ",",
                "the",
                "guy",
                "always",
                "get",
                "away",
                "!"
            ],
            [
                "I",
                "be",
                "toast",
                "."
            ],
            [
                "I",
                "could",
                "not",
                "move",
                "."
            ]
        ],
        "label": "Sadness"
    },
    {
        "body_part_token_idx": 24,
        "sentence_id": "1b354e18-0474-3653-a21f-a12058f58547",
        "tokens": [
            "Still",
            "alive",
            ",",
            "Bill?",
            "yeh",
            ",",
            "think",
            "I",
            "lost",
            "feeling",
            "in",
            "my",
            "legs",
            "a",
            "few",
            "hours",
            "ago",
            "though.",
            "He",
            "mumbled",
            "wiping",
            "water",
            "from",
            "his",
            "eyes",
            "."
        ],
        "lemmatized_tokens": [
            "still",
            "alive",
            ",",
            "bill?",
            "yeh",
            ",",
            "think",
            "I",
            "lose",
            "feel",
            "in",
            "my",
            "leg",
            "a",
            "few",
            "hour",
            "ago",
            "though.",
            "he",
            "mumble",
            "wipe",
            "water",
            "from",
            "he",
            "eye",
            "."
        ],
        "preceding_context_tokens": [
            [
                "WET",
                "."
            ],
            [
                "I",
                "shivered",
                ",",
                "those",
                "were",
                "the",
                "only",
                "two",
                "words",
                "that",
                "I",
                "could",
                "think",
                "of",
                "."
            ],
            [
                "Beside",
                "me",
                "Billy",
                "was",
                "n't",
                "doing",
                "much",
                "better",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "wet",
                "."
            ],
            [
                "I",
                "shiver",
                ",",
                "those",
                "be",
                "the",
                "only",
                "two",
                "word",
                "that",
                "I",
                "could",
                "think",
                "of",
                "."
            ],
            [
                "beside",
                "I",
                "Billy",
                "be",
                "not",
                "do",
                "much",
                "better",
                "."
            ]
        ],
        "label": "Sadness"
    },
    {
        "body_part_token_idx": 5,
        "sentence_id": "1bf575f0-7179-3c83-8c0f-0212239fbb96",
        "tokens": [
            "``",
            "Marty",
            "nervously",
            "runs",
            "his",
            "fingers",
            "through",
            "his",
            "hair",
            "before",
            "he",
            "removes",
            "his",
            "glasses",
            "."
        ],
        "lemmatized_tokens": [
            "``",
            "Marty",
            "nervously",
            "run",
            "he",
            "finger",
            "through",
            "he",
            "hair",
            "before",
            "he",
            "remove",
            "he",
            "glass",
            "."
        ],
        "preceding_context_tokens": [
            [
                "``",
                "I",
                "doubt",
                "you",
                "are",
                "that",
                "much",
                "younger",
                "than",
                "me",
                "."
            ],
            [
                "It",
                "wo",
                "n't",
                "make",
                "me",
                "feel",
                "uncomfortable",
                "."
            ],
            [
                "So",
                ",",
                "feel",
                "free",
                "to",
                "tell",
                "me",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "``",
                "I",
                "doubt",
                "you",
                "be",
                "that",
                "much",
                "younger",
                "than",
                "I",
                "."
            ],
            [
                "it",
                "will",
                "not",
                "make",
                "I",
                "feel",
                "uncomfortable",
                "."
            ],
            [
                "so",
                ",",
                "feel",
                "free",
                "to",
                "tell",
                "I",
                "."
            ]
        ],
        "label": "Fear"
    },
    {
        "body_part_token_idx": 1,
        "sentence_id": "1c4083a4-0e1d-33f9-b082-cdd93bb5f0ac",
        "tokens": [
            "His",
            "eyes",
            "narrowed",
            "as",
            "he",
            "reached",
            "the",
            "worn",
            "and",
            "moss",
            "covered",
            "bell",
            "and",
            "saw",
            "the",
            "oak",
            "tree",
            "impressed",
            "on",
            "it",
            "''",
            "damn",
            "."
        ],
        "lemmatized_tokens": [
            "he",
            "eye",
            "narrow",
            "as",
            "he",
            "reach",
            "the",
            "worn",
            "and",
            "moss",
            "cover",
            "bell",
            "and",
            "see",
            "the",
            "oak",
            "tree",
            "impress",
            "on",
            "it",
            "''",
            "damn",
            "."
        ],
        "preceding_context_tokens": [
            [
                "Ava",
                "voice",
                "disturbed",
                "that",
                "silence",
                "and",
                "Sam",
                "turned",
                "toward",
                "her",
                "gratefully",
                "."
            ],
            [
                "She",
                "made",
                "a",
                "motion",
                "with",
                "her",
                "hand",
                "and",
                "his",
                "gaze",
                "followed",
                "the",
                "length",
                "of",
                "her",
                "arm",
                "toward",
                "a",
                "bell",
                "set",
                "up",
                "in",
                "the",
                "center",
                "of",
                "town",
                "."
            ],
            [
                "His",
                "brows",
                "sloped",
                "downward",
                "as",
                "he",
                "made",
                "his",
                "way",
                "forward",
                "and",
                "brought",
                "the",
                "stoker",
                "slightly",
                "in",
                "front",
                "of",
                "his",
                "body",
                "as",
                "he",
                "freed",
                "himself",
                "of",
                "the",
                "cover",
                "of",
                "the",
                "shops",
                "and",
                "stepped",
                "out",
                "into",
                "the",
                "open",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "Ava",
                "voice",
                "disturb",
                "that",
                "silence",
                "and",
                "Sam",
                "turn",
                "toward",
                "she",
                "gratefully",
                "."
            ],
            [
                "she",
                "make",
                "a",
                "motion",
                "with",
                "she",
                "hand",
                "and",
                "he",
                "gaze",
                "follow",
                "the",
                "length",
                "of",
                "she",
                "arm",
                "toward",
                "a",
                "bell",
                "set",
                "up",
                "in",
                "the",
                "center",
                "of",
                "town",
                "."
            ],
            [
                "he",
                "brow",
                "slope",
                "downward",
                "as",
                "he",
                "make",
                "he",
                "way",
                "forward",
                "and",
                "bring",
                "the",
                "stoker",
                "slightly",
                "in",
                "front",
                "of",
                "he",
                "body",
                "as",
                "he",
                "free",
                "himself",
                "of",
                "the",
                "cover",
                "of",
                "the",
                "shop",
                "and",
                "step",
                "out",
                "into",
                "the",
                "open",
                "."
            ]
        ],
        "label": "Surprise"
    },
    {
        "body_part_token_idx": 4,
        "sentence_id": "5802dfcc-5951-31bb-afa8-60f0b94b1547",
        "tokens": [
            "I",
            "yelled",
            ",",
            "my",
            "jaw",
            "hanging",
            "open",
            ",",
            "``",
            "how",
            "do",
            "you",
            "expect",
            "me",
            "to",
            "calm",
            "down",
            "when",
            "my",
            "husband",
            "is",
            "out",
            "in",
            "some",
            "other",
            "godforsaken",
            "country",
            "fighting",
            "a",
            "war",
            "that",
            "is",
            "getting",
            "more",
            "and",
            "more",
            "dangerous",
            "each",
            "day",
            "!"
        ],
        "lemmatized_tokens": [
            "I",
            "yell",
            ",",
            "my",
            "jaw",
            "hang",
            "open",
            ",",
            "``",
            "how",
            "do",
            "you",
            "expect",
            "I",
            "to",
            "calm",
            "down",
            "when",
            "my",
            "husband",
            "be",
            "out",
            "in",
            "some",
            "other",
            "godforsaken",
            "country",
            "fight",
            "a",
            "war",
            "that",
            "be",
            "get",
            "more",
            "and",
            "more",
            "dangerous",
            "each",
            "day",
            "!"
        ],
        "preceding_context_tokens": [
            [
                "I",
                "do",
                "n't",
                "want",
                "you",
                "here",
                "every",
                "day",
                "fussing",
                "around",
                "me",
                "and",
                "checking",
                "up",
                "on",
                "me",
                "."
            ],
            [
                "I",
                "'m",
                "a",
                "grown",
                "woman",
                "!",
                "''"
            ],
            [
                "``",
                "Alice",
                ",",
                "please",
                ",",
                "calm",
                "down",
                "-",
                "''",
                "``",
                "Calm",
                "down",
                "?",
                "''"
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "I",
                "do",
                "not",
                "want",
                "you",
                "here",
                "every",
                "day",
                "fuss",
                "around",
                "I",
                "and",
                "check",
                "up",
                "on",
                "I",
                "."
            ],
            [
                "I",
                "be",
                "a",
                "grow",
                "woman",
                "!",
                "''"
            ],
            [
                "``",
                "Alice",
                ",",
                "please",
                ",",
                "calm",
                "down",
                "-",
                "''",
                "``",
                "calm",
                "down",
                "?",
                "''"
            ]
        ],
        "label": "Anger"
    },
    {
        "body_part_token_idx": 3,
        "sentence_id": "0a373c8a-c03f-3a26-9b29-7cb91165e550",
        "tokens": [
            "He",
            "shook",
            "his",
            "head",
            "and",
            "finished",
            "his",
            "task",
            "."
        ],
        "lemmatized_tokens": [
            "he",
            "shake",
            "he",
            "head",
            "and",
            "finish",
            "he",
            "task",
            "."
        ],
        "preceding_context_tokens": [
            [
                "Sasj",
                "gaped",
                "at",
                "her",
                "."
            ],
            [
                "You",
                "really",
                "are",
                "Rik",
                "'s",
                "daughter",
                "."
            ],
            [
                "Kidnapping",
                "a",
                "Dragon",
                "Blooded",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "Sasj",
                "gape",
                "at",
                "she",
                "."
            ],
            [
                "you",
                "really",
                "be",
                "Rik",
                "'s",
                "daughter",
                "."
            ],
            [
                "kidnap",
                "a",
                "Dragon",
                "Blooded",
                "."
            ]
        ],
        "label": "Disgust"
    },
    {
        "body_part_token_idx": 3,
        "sentence_id": "744b5c8a-ebf1-36bf-b885-b34bbd5f5977",
        "tokens": [
            "I",
            "crossed",
            "my",
            "arms",
            ",",
            "smiled",
            ",",
            "tilted",
            "my",
            "head",
            ",",
            "and",
            "said",
            ",",
            "``",
            "I",
            "thought",
            "you",
            "were",
            "supposed",
            "to",
            "be",
            "in",
            "Austria",
            "?",
            "''"
        ],
        "lemmatized_tokens": [
            "I",
            "cross",
            "my",
            "arm",
            ",",
            "smile",
            ",",
            "tilt",
            "my",
            "head",
            ",",
            "and",
            "say",
            ",",
            "``",
            "I",
            "think",
            "you",
            "be",
            "suppose",
            "to",
            "be",
            "in",
            "Austria",
            "?",
            "''"
        ],
        "preceding_context_tokens": [
            [
                "Then",
                "I",
                "got",
                "closer",
                "and",
                "realized",
                ",",
                "``",
                "Oh",
                "...",
                "no",
                "...",
                "."
            ],
            [
                "WAY",
                "!"
            ],
            [
                "``",
                "We",
                "spied",
                "each",
                "other",
                "and",
                "walked",
                "towards",
                "each",
                "other",
                ",",
                "disbelief",
                "and",
                "happiness",
                "covering",
                "our",
                "faces",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "then",
                "I",
                "get",
                "closer",
                "and",
                "realize",
                ",",
                "``",
                "oh",
                "...",
                "no",
                "...",
                "."
            ],
            [
                "way",
                "!"
            ],
            [
                "``",
                "we",
                "spy",
                "each",
                "other",
                "and",
                "walk",
                "towards",
                "each",
                "other",
                ",",
                "disbelief",
                "and",
                "happiness",
                "cover",
                "we",
                "face",
                "."
            ]
        ],
        "label": "Surprise"
    },
    {
        "body_part_token_idx": 9,
        "sentence_id": "744b5c8a-ebf1-36bf-b885-b34bbd5f5977",
        "tokens": [
            "I",
            "crossed",
            "my",
            "arms",
            ",",
            "smiled",
            ",",
            "tilted",
            "my",
            "head",
            ",",
            "and",
            "said",
            ",",
            "``",
            "I",
            "thought",
            "you",
            "were",
            "supposed",
            "to",
            "be",
            "in",
            "Austria",
            "?",
            "''"
        ],
        "lemmatized_tokens": [
            "I",
            "cross",
            "my",
            "arm",
            ",",
            "smile",
            ",",
            "tilt",
            "my",
            "head",
            ",",
            "and",
            "say",
            ",",
            "``",
            "I",
            "think",
            "you",
            "be",
            "suppose",
            "to",
            "be",
            "in",
            "Austria",
            "?",
            "''"
        ],
        "preceding_context_tokens": [
            [
                "Then",
                "I",
                "got",
                "closer",
                "and",
                "realized",
                ",",
                "``",
                "Oh",
                "...",
                "no",
                "...",
                "."
            ],
            [
                "WAY",
                "!"
            ],
            [
                "``",
                "We",
                "spied",
                "each",
                "other",
                "and",
                "walked",
                "towards",
                "each",
                "other",
                ",",
                "disbelief",
                "and",
                "happiness",
                "covering",
                "our",
                "faces",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "then",
                "I",
                "get",
                "closer",
                "and",
                "realize",
                ",",
                "``",
                "oh",
                "...",
                "no",
                "...",
                "."
            ],
            [
                "way",
                "!"
            ],
            [
                "``",
                "we",
                "spy",
                "each",
                "other",
                "and",
                "walk",
                "towards",
                "each",
                "other",
                ",",
                "disbelief",
                "and",
                "happiness",
                "cover",
                "we",
                "face",
                "."
            ]
        ],
        "label": "Joy"
    },
    {
        "body_part_token_idx": 18,
        "sentence_id": "5d627ea5-8125-3950-b16c-df543621c975",
        "tokens": [
            "I",
            "took",
            "a",
            "deep",
            "breath",
            "as",
            "Papa",
            "gathered",
            "himself",
            "and",
            "went",
            "to",
            "the",
            "master",
            "'s",
            "bedroom",
            ",",
            "his",
            "shoulders",
            "hunched",
            "."
        ],
        "lemmatized_tokens": [
            "I",
            "take",
            "a",
            "deep",
            "breath",
            "as",
            "papa",
            "gather",
            "himself",
            "and",
            "go",
            "to",
            "the",
            "master",
            "'s",
            "bedroom",
            ",",
            "he",
            "shoulder",
            "hunch",
            "."
        ],
        "preceding_context_tokens": [
            [
                "``",
                "You",
                "'re",
                "sleeping",
                "in",
                "my",
                "room",
                ",",
                "''",
                "I",
                "told",
                "him",
                ",",
                "and",
                "he",
                "nodded",
                "."
            ],
            [
                "He",
                "knew",
                "it",
                "."
            ],
            [
                "He",
                "and",
                "I",
                "have",
                "to",
                "talk",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "``",
                "you",
                "be",
                "sleep",
                "in",
                "my",
                "room",
                ",",
                "''",
                "I",
                "tell",
                "he",
                ",",
                "and",
                "he",
                "nod",
                "."
            ],
            [
                "he",
                "know",
                "it",
                "."
            ],
            [
                "he",
                "and",
                "I",
                "have",
                "to",
                "talk",
                "."
            ]
        ],
        "label": "Sadness"
    },
    {
        "body_part_token_idx": 4,
        "sentence_id": "0a4cabd0-bab4-35c1-90df-0aa1d2234e72",
        "tokens": [
            "He",
            "could",
            "feel",
            "his",
            "heart",
            "hurt",
            "so",
            "much",
            ",",
            "but",
            "he",
            "did",
            "n't",
            "wanted",
            "to",
            "show",
            "."
        ],
        "lemmatized_tokens": [
            "he",
            "could",
            "feel",
            "he",
            "heart",
            "hurt",
            "so",
            "much",
            ",",
            "but",
            "he",
            "do",
            "not",
            "want",
            "to",
            "show",
            "."
        ],
        "preceding_context_tokens": [
            [
                "``",
                "This",
                "is",
                "the",
                "worst",
                "thing",
                "it",
                "could",
                "happen",
                "...",
                "''",
                "Yesung",
                "thought",
                ",",
                "but",
                "before",
                "he",
                "could",
                "n't",
                "even",
                "allow",
                "a",
                "tear",
                "to",
                "run",
                "down",
                "his",
                "face",
                ",",
                "he",
                "heard",
                "a",
                "door",
                "open",
                "and",
                "he",
                "knew",
                "he",
                "had",
                "to",
                "leave",
                "Siwon",
                "'s",
                "room",
                "."
            ],
            [
                "He",
                "placed",
                "the",
                "notebook",
                "on",
                "top",
                "of",
                "Siwon",
                "'s",
                "desk",
                "like",
                "it",
                "was",
                "before",
                "and",
                "ran",
                "towards",
                "the",
                "living",
                "room",
                "."
            ],
            [
                "Fortunately",
                "for",
                "him",
                "the",
                "younger",
                "was",
                "n't",
                "there",
                "already",
                "so",
                "he",
                "just",
                "seat",
                "on",
                "the",
                "couch",
                "and",
                "pretended",
                "to",
                "be",
                "asleep",
                ",",
                "just",
                "like",
                "before",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "``",
                "this",
                "be",
                "the",
                "worst",
                "thing",
                "it",
                "could",
                "happen",
                "...",
                "''",
                "Yesung",
                "think",
                ",",
                "but",
                "before",
                "he",
                "could",
                "not",
                "even",
                "allow",
                "a",
                "tear",
                "to",
                "run",
                "down",
                "he",
                "face",
                ",",
                "he",
                "hear",
                "a",
                "door",
                "open",
                "and",
                "he",
                "know",
                "he",
                "have",
                "to",
                "leave",
                "Siwon",
                "'s",
                "room",
                "."
            ],
            [
                "he",
                "place",
                "the",
                "notebook",
                "on",
                "top",
                "of",
                "Siwon",
                "'s",
                "desk",
                "like",
                "it",
                "be",
                "before",
                "and",
                "run",
                "towards",
                "the",
                "living",
                "room",
                "."
            ],
            [
                "fortunately",
                "for",
                "he",
                "the",
                "younger",
                "be",
                "not",
                "there",
                "already",
                "so",
                "he",
                "just",
                "seat",
                "on",
                "the",
                "couch",
                "and",
                "pretend",
                "to",
                "be",
                "asleep",
                ",",
                "just",
                "like",
                "before",
                "."
            ]
        ],
        "label": "Sadness"
    },
    {
        "body_part_token_idx": 4,
        "sentence_id": "c95cabf4-a67a-3760-9f38-07c10c80741a",
        "tokens": [
            "Jaime",
            "holds",
            "up",
            "his",
            "hands",
            "in",
            "surrender",
            ",",
            "eyes",
            "wide",
            "."
        ],
        "lemmatized_tokens": [
            "Jaime",
            "hold",
            "up",
            "he",
            "hand",
            "in",
            "surrender",
            ",",
            "eye",
            "wide",
            "."
        ],
        "preceding_context_tokens": [
            [
                "``",
                "Oh",
                ",",
                "if",
                "I",
                "suffer",
                "you",
                "will",
                "suffer",
                "with",
                "me",
                ",",
                "''",
                "Tony",
                "promises",
                ",",
                "``",
                "We",
                "'ll",
                "play",
                "board",
                "games",
                ".",
                "''",
                "''"
            ],
            [
                "$",
                "that",
                "actually",
                "sounds",
                "like",
                "fun",
                ",",
                "''",
                "Gibbs",
                "shrugs",
                ",",
                "shuffling",
                "to",
                "his",
                "feet",
                "and",
                "hauling",
                "Tony",
                "up",
                "with",
                "him",
                "."
            ],
            [
                "Jaime",
                "and",
                "Tony",
                "look",
                "at",
                "each",
                "other",
                "and",
                "Tony",
                "points",
                "a",
                "finger",
                "at",
                "his",
                "son",
                ",",
                "glaring",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "``",
                "oh",
                ",",
                "if",
                "I",
                "suffer",
                "you",
                "will",
                "suffer",
                "with",
                "I",
                ",",
                "''",
                "Tony",
                "promise",
                ",",
                "``",
                "we",
                "will",
                "play",
                "board",
                "game",
                ".",
                "''",
                "''"
            ],
            [
                "$",
                "that",
                "actually",
                "sound",
                "like",
                "fun",
                ",",
                "''",
                "Gibbs",
                "shrug",
                ",",
                "shuffling",
                "to",
                "he",
                "foot",
                "and",
                "haul",
                "Tony",
                "up",
                "with",
                "he",
                "."
            ],
            [
                "Jaime",
                "and",
                "Tony",
                "look",
                "at",
                "each",
                "other",
                "and",
                "Tony",
                "point",
                "a",
                "finger",
                "at",
                "he",
                "son",
                ",",
                "glaring",
                "."
            ]
        ],
        "label": "Fear"
    },
    {
        "body_part_token_idx": 6,
        "sentence_id": "bd677e93-eec7-30ed-894b-235e9e0782ac",
        "tokens": [
            "I",
            "started",
            "getting",
            "knots",
            "in",
            "my",
            "stomach",
            "because",
            "I",
            "was",
            "extremely",
            "excited",
            ",",
            "yet",
            "completely",
            "terrified",
            ",",
            "because",
            "I",
            "can",
            "hardly",
            "function",
            "like",
            "a",
            "normal",
            "person",
            "in",
            "front",
            "of",
            "Tom",
            "."
        ],
        "lemmatized_tokens": [
            "I",
            "start",
            "get",
            "knot",
            "in",
            "my",
            "stomach",
            "because",
            "I",
            "be",
            "extremely",
            "excited",
            ",",
            "yet",
            "completely",
            "terrified",
            ",",
            "because",
            "I",
            "can",
            "hardly",
            "function",
            "like",
            "a",
            "normal",
            "person",
            "in",
            "front",
            "of",
            "Tom",
            "."
        ],
        "preceding_context_tokens": [
            [
                "The",
                "next",
                "morning",
                ",",
                "we",
                "left",
                "as",
                "soon",
                "as",
                "we",
                "got",
                "up",
                "."
            ],
            [
                "We",
                "drove",
                "to",
                "the",
                "field",
                "where",
                "warped",
                "was",
                "at",
                "and",
                "Trent",
                "and",
                "I",
                "went",
                "and",
                "waited",
                "in",
                "line",
                "while",
                "the",
                "car",
                "was",
                "being",
                "parked",
                "."
            ],
            [
                "We",
                "got",
                "a",
                "schedule",
                "from",
                "this",
                "creeper",
                "and",
                "it",
                "said",
                "there",
                "was",
                "an",
                "ava",
                "signing",
                "at",
                "12:30",
                "at",
                "the",
                "at",
                "&",
                "t",
                "booth",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "the",
                "next",
                "morning",
                ",",
                "we",
                "leave",
                "as",
                "soon",
                "as",
                "we",
                "get",
                "up",
                "."
            ],
            [
                "we",
                "drive",
                "to",
                "the",
                "field",
                "where",
                "warped",
                "be",
                "at",
                "and",
                "Trent",
                "and",
                "I",
                "go",
                "and",
                "wait",
                "in",
                "line",
                "while",
                "the",
                "car",
                "be",
                "be",
                "park",
                "."
            ],
            [
                "we",
                "get",
                "a",
                "schedule",
                "from",
                "this",
                "creeper",
                "and",
                "it",
                "say",
                "there",
                "be",
                "a",
                "ava",
                "signing",
                "at",
                "12:30",
                "at",
                "the",
                "at",
                "&",
                "t",
                "booth",
                "."
            ]
        ],
        "label": "Fear"
    },
    {
        "body_part_token_idx": 5,
        "sentence_id": "3ca92010-1cf8-3891-a942-db40a4fd3859",
        "tokens": [
            "Ok",
            "but",
            "that",
            "time",
            "my",
            "jaw",
            "fell",
            "down",
            "."
        ],
        "lemmatized_tokens": [
            "ok",
            "but",
            "that",
            "time",
            "my",
            "jaw",
            "fall",
            "down",
            "."
        ],
        "preceding_context_tokens": [
            [
                "So",
                "I",
                "gave",
                "him",
                "a",
                "careful",
                "look",
                ",",
                "and",
                "there",
                "was",
                "nothing",
                "in",
                "him",
                "that",
                "would",
                "seem",
                "familiar",
                "."
            ],
            [
                "But",
                "he",
                "goes",
                "again",
                "-",
                "``",
                "You",
                "'re",
                "from",
                "Bialystok",
                ",",
                "right",
                "?"
            ],
            [
                "You",
                "were",
                "a",
                "student",
                "of",
                "37th",
                "Primary",
                "School",
                ",",
                "right",
                "?",
                "''"
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "so",
                "I",
                "give",
                "he",
                "a",
                "careful",
                "look",
                ",",
                "and",
                "there",
                "be",
                "nothing",
                "in",
                "he",
                "that",
                "would",
                "seem",
                "familiar",
                "."
            ],
            [
                "but",
                "he",
                "go",
                "again",
                "-",
                "``",
                "you",
                "be",
                "from",
                "Bialystok",
                ",",
                "right",
                "?"
            ],
            [
                "you",
                "be",
                "a",
                "student",
                "of",
                "37th",
                "primary",
                "school",
                ",",
                "right",
                "?",
                "''"
            ]
        ],
        "label": "Surprise"
    },
    {
        "body_part_token_idx": 7,
        "sentence_id": "ad022703-d12a-3003-848d-1db88370ba94",
        "tokens": [
            "But",
            "for",
            "a",
            "brief",
            "moment",
            ",",
            "my",
            "heart",
            "and",
            "mind",
            "started",
            "racing",
            "."
        ],
        "lemmatized_tokens": [
            "but",
            "for",
            "a",
            "brief",
            "moment",
            ",",
            "my",
            "heart",
            "and",
            "mind",
            "start",
            "race",
            "."
        ],
        "preceding_context_tokens": [
            [
                "I",
                "thought",
                "he",
                "had",
                "a",
                "machete",
                ",",
                "and",
                "apparently",
                "Taylor",
                "did",
                "too",
                ",",
                "and",
                "my",
                "fear",
                "was",
                "cued",
                "more",
                "by",
                "his",
                "surprise",
                "in",
                "the",
                "situation",
                "than",
                "the",
                "situation",
                "itself",
                "."
            ],
            [
                "Taylor",
                "knows",
                "what",
                "'s",
                "up",
                "here",
                ",",
                "so",
                "if",
                "he",
                "reacts",
                ",",
                "that",
                "is",
                "my",
                "cue",
                "to",
                "react",
                "."
            ],
            [
                "It",
                "turned",
                "out",
                "he",
                "was",
                "only",
                "carrying",
                "a",
                "stick",
                ",",
                "and",
                "he",
                "was",
                "only",
                "coming",
                "over",
                "to",
                "say",
                "hi",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "I",
                "think",
                "he",
                "have",
                "a",
                "machete",
                ",",
                "and",
                "apparently",
                "Taylor",
                "do",
                "too",
                ",",
                "and",
                "my",
                "fear",
                "be",
                "cue",
                "more",
                "by",
                "he",
                "surprise",
                "in",
                "the",
                "situation",
                "than",
                "the",
                "situation",
                "itself",
                "."
            ],
            [
                "Taylor",
                "know",
                "what",
                "be",
                "up",
                "here",
                ",",
                "so",
                "if",
                "he",
                "react",
                ",",
                "that",
                "be",
                "my",
                "cue",
                "to",
                "react",
                "."
            ],
            [
                "it",
                "turn",
                "out",
                "he",
                "be",
                "only",
                "carry",
                "a",
                "stick",
                ",",
                "and",
                "he",
                "be",
                "only",
                "come",
                "over",
                "to",
                "say",
                "hi",
                "."
            ]
        ],
        "label": "Fear"
    },
    {
        "body_part_token_idx": 1,
        "sentence_id": "ee2e31ec-86de-3e36-acf1-b82b8fb80aca",
        "tokens": [
            "Her",
            "lips",
            "twitched",
            "into",
            "a",
            "grin",
            ",",
            "the",
            "thefts",
            "did",
            "n't",
            "last",
            "long",
            ",",
            "in",
            "a",
            "day",
            "or",
            "two",
            "the",
            "item",
            "was",
            "found",
            "on",
            "the",
            "owner",
            "'s",
            "front",
            "porch",
            ",",
            "with",
            "a",
            "little",
            "personalized",
            "card",
            "having",
            "a",
            "laugh",
            "at",
            "their",
            "expense.She",
            "wound",
            "her",
            "way",
            "around",
            "to",
            "the",
            "residential",
            "area",
            "and",
            "took",
            "the",
            "back",
            "alleys",
            "to",
            "Windurst",
            "Woods",
            "where",
            "she",
            "proceeded",
            "to",
            "go",
            "place",
            "her",
            "newly",
            "made",
            "food",
            "items",
            "on",
            "sale",
            "while",
            "they",
            "were",
            "hot",
            "and",
            "fresh",
            "."
        ],
        "lemmatized_tokens": [
            "she",
            "lip",
            "twitch",
            "into",
            "a",
            "grin",
            ",",
            "the",
            "theft",
            "do",
            "not",
            "last",
            "long",
            ",",
            "in",
            "a",
            "day",
            "or",
            "two",
            "the",
            "item",
            "be",
            "find",
            "on",
            "the",
            "owner",
            "'s",
            "front",
            "porch",
            ",",
            "with",
            "a",
            "little",
            "personalized",
            "card",
            "have",
            "a",
            "laugh",
            "at",
            "they",
            "expense.she",
            "wind",
            "she",
            "way",
            "around",
            "to",
            "the",
            "residential",
            "area",
            "and",
            "take",
            "the",
            "back",
            "alley",
            "to",
            "Windurst",
            "Woods",
            "where",
            "she",
            "proceed",
            "to",
            "go",
            "place",
            "she",
            "newly",
            "make",
            "food",
            "item",
            "on",
            "sale",
            "while",
            "they",
            "be",
            "hot",
            "and",
            "fresh",
            "."
        ],
        "preceding_context_tokens": [
            [
                "The",
                "young",
                "Mithra",
                "packed",
                "her",
                "belongings",
                "and",
                "the",
                "couple",
                "dozen",
                "kabobs",
                "she",
                "made",
                "into",
                "her",
                "bag",
                ",",
                "then",
                "strode",
                "down",
                "the",
                "walk",
                "way",
                "."
            ],
            [
                "Windurst",
                "was",
                "a",
                "busy",
                "town",
                ",",
                "and",
                "a",
                "big",
                "one",
                "."
            ],
            [
                "Add",
                "that",
                "with",
                "the",
                "mischievous",
                "nature",
                "of",
                "the",
                "Tarutaru",
                "that",
                "founded",
                "the",
                "Federation",
                ",",
                "you",
                "got",
                "the",
                "recipe",
                "for",
                "a",
                "nation",
                "full",
                "of",
                "pranksters",
                "and",
                "theft",
                "reports",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "the",
                "young",
                "Mithra",
                "pack",
                "she",
                "belongings",
                "and",
                "the",
                "couple",
                "dozen",
                "kabob",
                "she",
                "make",
                "into",
                "she",
                "bag",
                ",",
                "then",
                "stride",
                "down",
                "the",
                "walk",
                "way",
                "."
            ],
            [
                "Windurst",
                "be",
                "a",
                "busy",
                "town",
                ",",
                "and",
                "a",
                "big",
                "one",
                "."
            ],
            [
                "add",
                "that",
                "with",
                "the",
                "mischievous",
                "nature",
                "of",
                "the",
                "Tarutaru",
                "that",
                "found",
                "the",
                "Federation",
                ",",
                "you",
                "get",
                "the",
                "recipe",
                "for",
                "a",
                "nation",
                "full",
                "of",
                "prankster",
                "and",
                "theft",
                "report",
                "."
            ]
        ],
        "label": "Joy"
    },
    {
        "body_part_token_idx": 3,
        "sentence_id": "2196db58-89ae-3e84-9e1b-9588baad7a2a",
        "tokens": [
            "Dongwoon",
            "swung",
            "his",
            "shoulders",
            "back",
            "and",
            "forth",
            ",",
            "letting",
            "his",
            "backpack",
            "bounce",
            "up",
            "and",
            "down",
            "."
        ],
        "lemmatized_tokens": [
            "Dongwoon",
            "swing",
            "he",
            "shoulder",
            "back",
            "and",
            "forth",
            ",",
            "let",
            "he",
            "backpack",
            "bounce",
            "up",
            "and",
            "down",
            "."
        ],
        "preceding_context_tokens": [
            [
                "``",
                "serves",
                "you",
                "right",
                "to",
                "not",
                "eat",
                ".",
                "''"
            ],
            [
                "``",
                "Ah",
                "hyung",
                "...",
                "''",
                "Dongwoon",
                "sat",
                "up",
                "apologetically",
                ",",
                "Junhyung",
                "has",
                "been",
                "extra",
                "rough",
                "on",
                "him",
                "lately",
                ",",
                "he",
                "wondered",
                "what",
                "he",
                "might",
                "have",
                "done",
                "to",
                "upset",
                "him",
                "."
            ],
            [
                "-------",
                "It",
                "'s",
                "after",
                "school",
                ",",
                "the",
                "two",
                "were",
                "walking",
                "home",
                "together",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "``",
                "serve",
                "you",
                "right",
                "to",
                "not",
                "eat",
                ".",
                "''"
            ],
            [
                "``",
                "ah",
                "hyung",
                "...",
                "''",
                "Dongwoon",
                "sit",
                "up",
                "apologetically",
                ",",
                "Junhyung",
                "have",
                "be",
                "extra",
                "rough",
                "on",
                "he",
                "lately",
                ",",
                "he",
                "wonder",
                "what",
                "he",
                "might",
                "have",
                "do",
                "to",
                "upset",
                "he",
                "."
            ],
            [
                "-------",
                "it",
                "be",
                "after",
                "school",
                ",",
                "the",
                "two",
                "be",
                "walk",
                "home",
                "together",
                "."
            ]
        ],
        "label": "Joy"
    },
    {
        "body_part_token_idx": 5,
        "sentence_id": "09088089-43af-3752-a703-f05e3e4dddb2",
        "tokens": [
            "put",
            "a",
            "smile",
            "to",
            "my",
            "face",
            "haha",
            "."
        ],
        "lemmatized_tokens": [
            "put",
            "a",
            "smile",
            "to",
            "my",
            "face",
            "haha",
            "."
        ],
        "preceding_context_tokens": [
            [
                "if",
                "you",
                "can",
                "hehe",
                "only",
                "bing",
                "and",
                "babo",
                "."
            ],
            [
                "i",
                "'m",
                "ok",
                "that",
                "you",
                "rebuff",
                "me",
                "today",
                "of",
                "tomorow",
                "anytime",
                "im",
                "good",
                "''",
                "."
            ],
            [
                "ahww",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "if",
                "you",
                "can",
                "hehe",
                "only",
                "bing",
                "and",
                "babo",
                "."
            ],
            [
                "i",
                "be",
                "ok",
                "that",
                "you",
                "rebuff",
                "I",
                "today",
                "of",
                "tomorow",
                "anytime",
                "im",
                "good",
                "''",
                "."
            ],
            [
                "ahww",
                "."
            ]
        ],
        "label": "Joy"
    },
    {
        "body_part_token_idx": 11,
        "sentence_id": "0af18fae-9897-35fc-90e7-a328e6914593",
        "tokens": [
            "A",
            "happy",
            ",",
            "hyped",
            "-",
            "up",
            "grin",
            "was",
            "plastered",
            "on",
            "her",
            "face",
            ",",
            "clearly",
            "not",
            "minding",
            "the",
            "pushes",
            "and",
            "shoves",
            "from",
            "the",
            "others",
            "."
        ],
        "lemmatized_tokens": [
            "a",
            "happy",
            ",",
            "hype",
            "-",
            "up",
            "grin",
            "be",
            "plaster",
            "on",
            "she",
            "face",
            ",",
            "clearly",
            "not",
            "mind",
            "the",
            "push",
            "and",
            "shove",
            "from",
            "the",
            "other",
            "."
        ],
        "preceding_context_tokens": [
            [
                "Sweaty",
                "bodies",
                "crowded",
                "the",
                "standing",
                "VIP",
                "section",
                "in",
                "front",
                "of",
                "the",
                "stage",
                ",",
                "and",
                "the",
                "fans",
                "screamed",
                "their",
                "lungs",
                "out",
                "as",
                "if",
                "there",
                "was",
                "no",
                "tomorrow",
                "."
            ],
            [
                "Blue",
                "lightsticks",
                "lit",
                "up",
                "the",
                "Araneta",
                "Coliseum",
                "like",
                "thousands",
                "of",
                "fireflies",
                "all",
                "lit",
                "up",
                ",",
                "only",
                "for",
                "Super",
                "Junior",
                "."
            ],
            [
                "Eunhee",
                "was",
                "one",
                "of",
                "those",
                "nearest",
                "to",
                "the",
                "stage",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "sweaty",
                "body",
                "crowd",
                "the",
                "stand",
                "vip",
                "section",
                "in",
                "front",
                "of",
                "the",
                "stage",
                ",",
                "and",
                "the",
                "fan",
                "scream",
                "they",
                "lung",
                "out",
                "as",
                "if",
                "there",
                "be",
                "no",
                "tomorrow",
                "."
            ],
            [
                "blue",
                "lightstick",
                "light",
                "up",
                "the",
                "Araneta",
                "Coliseum",
                "like",
                "thousand",
                "of",
                "firefly",
                "all",
                "light",
                "up",
                ",",
                "only",
                "for",
                "Super",
                "Junior",
                "."
            ],
            [
                "Eunhee",
                "be",
                "one",
                "of",
                "those",
                "nearest",
                "to",
                "the",
                "stage",
                "."
            ]
        ],
        "label": "Joy"
    },
    {
        "body_part_token_idx": 7,
        "sentence_id": "e77d9c38-1588-3c24-9379-bfc547e20bc8",
        "tokens": [
            "What",
            "a",
            "relief",
            "it",
            "was",
            "and",
            "my",
            "heart",
            "was",
            "beating",
            "so",
            "fast",
            "."
        ],
        "lemmatized_tokens": [
            "what",
            "a",
            "relief",
            "it",
            "be",
            "and",
            "my",
            "heart",
            "be",
            "beat",
            "so",
            "fast",
            "."
        ],
        "preceding_context_tokens": [
            [
                "I",
                "just",
                "broke",
                "down",
                "and",
                "cried",
                "and",
                "was",
                "so",
                "upset",
                "."
            ],
            [
                "But",
                "...",
                "after",
                "a",
                "few",
                "hours",
                "had",
                "passed",
                ",",
                "he",
                "and",
                "a",
                "lot",
                "of",
                "the",
                "other",
                "workers",
                "managed",
                "to",
                "get",
                "through",
                "somehow",
                "on",
                "the",
                "other",
                "side",
                "to",
                "high",
                "ground",
                "."
            ],
            [
                "Our",
                "street",
                "'s",
                "had",
                "opened",
                "and",
                "water",
                "was",
                "residing",
                ",",
                "so",
                "I",
                "was",
                "able",
                "to",
                "pick",
                "him",
                "up",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "I",
                "just",
                "break",
                "down",
                "and",
                "cry",
                "and",
                "be",
                "so",
                "upset",
                "."
            ],
            [
                "but",
                "...",
                "after",
                "a",
                "few",
                "hour",
                "have",
                "pass",
                ",",
                "he",
                "and",
                "a",
                "lot",
                "of",
                "the",
                "other",
                "worker",
                "manage",
                "to",
                "get",
                "through",
                "somehow",
                "on",
                "the",
                "other",
                "side",
                "to",
                "high",
                "ground",
                "."
            ],
            [
                "we",
                "street",
                "'s",
                "have",
                "open",
                "and",
                "water",
                "be",
                "reside",
                ",",
                "so",
                "I",
                "be",
                "able",
                "to",
                "pick",
                "he",
                "up",
                "."
            ]
        ],
        "label": "Fear"
    },
    {
        "body_part_token_idx": 7,
        "sentence_id": "523d0ac9-0018-3d72-bf87-6ebd3054cee5",
        "tokens": [
            "He",
            "bit",
            "back",
            "the",
            "tears",
            "in",
            "his",
            "eyes",
            "."
        ],
        "lemmatized_tokens": [
            "he",
            "bite",
            "back",
            "the",
            "tear",
            "in",
            "he",
            "eye",
            "."
        ],
        "preceding_context_tokens": [
            [
                "He",
                "looked",
                "from",
                "Ianto",
                "to",
                "the",
                "man",
                "on",
                "the",
                "floor",
                "."
            ],
            [
                "Please",
                "Please",
                ",",
                "Ianto",
                "."
            ],
            [
                "Let",
                "him",
                "go",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "he",
                "look",
                "from",
                "Ianto",
                "to",
                "the",
                "man",
                "on",
                "the",
                "floor",
                "."
            ],
            [
                "please",
                "please",
                ",",
                "Ianto",
                "."
            ],
            [
                "let",
                "he",
                "go",
                "."
            ]
        ],
        "label": "Fear"
    },
    {
        "body_part_token_idx": 11,
        "sentence_id": "b247c245-32be-3d1b-adab-d06478b77761",
        "tokens": [
            "When",
            "I",
            "was",
            "thirteen",
            "I",
            "lay",
            "on",
            "my",
            "bed",
            ",",
            "my",
            "face",
            "shoved",
            "in",
            "a",
            "pillow",
            "with",
            "my",
            "Grandmother",
            "'s",
            "heat",
            "wrap",
            "on",
            "my",
            "lower",
            "back",
            ",",
            "screaming",
            "and",
            "crying",
            "because",
            "Motherly",
            "was",
            "at",
            "work",
            "and",
            "I",
            "could",
            "n't",
            "find",
            "the",
            "pain",
            "killers",
            "."
        ],
        "lemmatized_tokens": [
            "when",
            "I",
            "be",
            "thirteen",
            "I",
            "lay",
            "on",
            "my",
            "bed",
            ",",
            "my",
            "face",
            "shove",
            "in",
            "a",
            "pillow",
            "with",
            "my",
            "grandmother",
            "'s",
            "heat",
            "wrap",
            "on",
            "my",
            "lower",
            "back",
            ",",
            "scream",
            "and",
            "cry",
            "because",
            "Motherly",
            "be",
            "at",
            "work",
            "and",
            "I",
            "could",
            "not",
            "find",
            "the",
            "pain",
            "killer",
            "."
        ],
        "preceding_context_tokens": [
            [
                "She",
                "was",
                "vocal",
                "about",
                "her",
                "distress",
                ",",
                "pain",
                "and",
                "pure",
                "anguish",
                "of",
                "being",
                "a",
                "woman",
                "."
            ],
            [
                "Her",
                "temper",
                "was",
                "lashed",
                "out",
                "in",
                "words",
                "."
            ],
            [
                "Mine",
                "was",
                "quietly",
                "reserved",
                "until",
                "the",
                "final",
                "moment",
                "of",
                "violence",
                "erupted",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "she",
                "be",
                "vocal",
                "about",
                "she",
                "distress",
                ",",
                "pain",
                "and",
                "pure",
                "anguish",
                "of",
                "be",
                "a",
                "woman",
                "."
            ],
            [
                "she",
                "temper",
                "be",
                "lash",
                "out",
                "in",
                "word",
                "."
            ],
            [
                "mine",
                "be",
                "quietly",
                "reserve",
                "until",
                "the",
                "final",
                "moment",
                "of",
                "violence",
                "erupt",
                "."
            ]
        ],
        "label": "Anger"
    },
    {
        "body_part_token_idx": 4,
        "sentence_id": "9f3bfbdb-2d6c-3216-8ac4-3719b437f013",
        "tokens": [
            "Mick",
            "laughed",
            "in",
            "his",
            "throat",
            "."
        ],
        "lemmatized_tokens": [
            "Mick",
            "laugh",
            "in",
            "he",
            "throat",
            "."
        ],
        "preceding_context_tokens": [
            [
                "I",
                "got",
                "so",
                "-",
                "drunk",
                ",",
                "man",
                ",",
                "so",
                "drunk",
                ",",
                "that",
                "I",
                "smashed",
                "a",
                "beer",
                "bottle",
                "over",
                "my",
                "head",
                ",",
                "and",
                "had",
                "to",
                "be",
                "rushed",
                "to",
                "the",
                "hospital",
                ",",
                "in",
                "an",
                "ambulance",
                "."
            ],
            [
                "Man",
                ",",
                "it",
                "took",
                "like",
                "three",
                "hours",
                "to",
                "pick",
                "all",
                "the",
                "little",
                "pieces",
                "of",
                "glass",
                "outta",
                "my",
                "head",
                "."
            ],
            [
                "Ah",
                "man",
                ",",
                "that",
                "was",
                "rough",
                ".",
                "''"
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "I",
                "get",
                "so",
                "-",
                "drunk",
                ",",
                "man",
                ",",
                "so",
                "drunk",
                ",",
                "that",
                "I",
                "smash",
                "a",
                "beer",
                "bottle",
                "over",
                "my",
                "head",
                ",",
                "and",
                "have",
                "to",
                "be",
                "rush",
                "to",
                "the",
                "hospital",
                ",",
                "in",
                "a",
                "ambulance",
                "."
            ],
            [
                "man",
                ",",
                "it",
                "take",
                "like",
                "three",
                "hour",
                "to",
                "pick",
                "all",
                "the",
                "little",
                "piece",
                "of",
                "glass",
                "outta",
                "my",
                "head",
                "."
            ],
            [
                "ah",
                "man",
                ",",
                "that",
                "be",
                "rough",
                ".",
                "''"
            ]
        ],
        "label": "Joy"
    },
    {
        "body_part_token_idx": 20,
        "sentence_id": "801d4a54-7ff2-3e30-a42f-ecd4608cce3b",
        "tokens": [
            "Nearly",
            "morning.",
            "Beside",
            "him",
            ",",
            "Severus",
            "stirred",
            ",",
            "opening",
            "his",
            "eyes",
            "blearily",
            ",",
            "a",
            "ghost",
            "of",
            "a",
            "smile",
            "on",
            "his",
            "lips",
            "as",
            "he",
            "looked",
            "over",
            "at",
            "Remus",
            ",",
            "noting",
            "with",
            "some",
            "satisfaction",
            "the",
            "purple",
            "-",
            "blue",
            "bruises",
            "that",
            "ringed",
            "the",
            "werewolf",
            "'s",
            "neck",
            "."
        ],
        "lemmatized_tokens": [
            "nearly",
            "morning.",
            "beside",
            "he",
            ",",
            "Severus",
            "stir",
            ",",
            "open",
            "he",
            "eye",
            "blearily",
            ",",
            "a",
            "ghost",
            "of",
            "a",
            "smile",
            "on",
            "he",
            "lip",
            "as",
            "he",
            "look",
            "over",
            "at",
            "Remus",
            ",",
            "note",
            "with",
            "some",
            "satisfaction",
            "the",
            "purple",
            "-",
            "blue",
            "bruise",
            "that",
            "ring",
            "the",
            "werewolf",
            "'s",
            "neck",
            "."
        ],
        "preceding_context_tokens": [
            [
                "He",
                "had",
                "been",
                "bled",
                "dry",
                "and",
                "transfused",
                ",",
                "a",
                "new",
                "man",
                "."
            ],
            [
                "Severus",
                "?"
            ],
            [
                "I",
                "'ve",
                "--",
                "it",
                "'s",
                "so",
                "late",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "he",
                "have",
                "be",
                "bleed",
                "dry",
                "and",
                "transfused",
                ",",
                "a",
                "new",
                "man",
                "."
            ],
            [
                "Severus",
                "?"
            ],
            [
                "I",
                "have",
                "--",
                "it",
                "be",
                "so",
                "late",
                "."
            ]
        ],
        "label": "Joy"
    },
    {
        "body_part_token_idx": 3,
        "sentence_id": "b72487d7-e2fa-341d-9f31-bcc332621961",
        "tokens": [
            "He",
            "shook",
            "his",
            "head",
            "in",
            "disbelief",
            "as",
            "he",
            "reached",
            "inside",
            "his",
            "jacket",
            "for",
            "his",
            "phone",
            ",",
            "but",
            "it",
            "was",
            "no",
            "where",
            "to",
            "be",
            "found",
            "."
        ],
        "lemmatized_tokens": [
            "he",
            "shake",
            "he",
            "head",
            "in",
            "disbelief",
            "as",
            "he",
            "reach",
            "inside",
            "he",
            "jacket",
            "for",
            "he",
            "phone",
            ",",
            "but",
            "it",
            "be",
            "no",
            "where",
            "to",
            "be",
            "find",
            "."
        ],
        "preceding_context_tokens": [
            [
                "The",
                "waiter",
                "finished",
                "cleaning",
                "up",
                "and",
                "bowed",
                "once",
                "more",
                "before",
                "leaving",
                "Hyunseung",
                "."
            ],
            [
                "He",
                "readjusted",
                "his",
                "tux",
                "and",
                "stood",
                "his",
                "ground",
                "once",
                "more",
                ",",
                "he",
                "pulled",
                "up",
                "his",
                "sleeve",
                "and",
                "glanced",
                "at",
                "the",
                "watch",
                ",",
                "8:13",
                "PM",
                "."
            ],
            [
                "All",
                "that",
                "trouble",
                "and",
                "only",
                "13",
                "minutes",
                "have",
                "passed",
                "?"
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "the",
                "waiter",
                "finish",
                "clean",
                "up",
                "and",
                "bow",
                "once",
                "more",
                "before",
                "leave",
                "Hyunseung",
                "."
            ],
            [
                "he",
                "readjust",
                "he",
                "tux",
                "and",
                "stand",
                "he",
                "ground",
                "once",
                "more",
                ",",
                "he",
                "pull",
                "up",
                "he",
                "sleeve",
                "and",
                "glance",
                "at",
                "the",
                "watch",
                ",",
                "8:13",
                "pm",
                "."
            ],
            [
                "all",
                "that",
                "trouble",
                "and",
                "only",
                "13",
                "minute",
                "have",
                "pass",
                "?"
            ]
        ],
        "label": "Surprise"
    },
    {
        "body_part_token_idx": 3,
        "sentence_id": "0919ad98-34bb-35a2-bded-fb71b15795e9",
        "tokens": [
            "I",
            "shook",
            "my",
            "head",
            "no",
            ",",
            "``",
            "Yeah",
            ",",
            "I",
            "'m",
            "fine",
            "Dad",
            ",",
            "''",
            "You",
            "'re",
            "such",
            "a",
            "liar",
            ",",
            "``",
            "Just",
            "feeling",
            "a",
            "little",
            "queasy",
            ".",
            "''"
        ],
        "lemmatized_tokens": [
            "I",
            "shake",
            "my",
            "head",
            "no",
            ",",
            "``",
            "yeah",
            ",",
            "I",
            "be",
            "fine",
            "Dad",
            ",",
            "''",
            "you",
            "be",
            "such",
            "a",
            "liar",
            ",",
            "``",
            "just",
            "feel",
            "a",
            "little",
            "queasy",
            ".",
            "''"
        ],
        "preceding_context_tokens": [],
        "preceding_context_lemmatized_tokens": [],
        "label": "Fear"
    },
    {
        "body_part_token_idx": 4,
        "sentence_id": "fb7482ff-59d1-30b1-8df7-719e61062779",
        "tokens": [
            "She",
            "then",
            "nodded",
            "her",
            "head",
            "."
        ],
        "lemmatized_tokens": [
            "she",
            "then",
            "nod",
            "she",
            "head",
            "."
        ],
        "preceding_context_tokens": [
            [
                "That",
                "was",
                "the",
                "only",
                "thing",
                "she",
                "*",
                "did",
                "*",
                "deserve",
                "."
            ],
            [
                "``",
                "Too",
                "bad",
                "you",
                "could",
                "see",
                "Irri",
                "and",
                "the",
                "babies",
                ",",
                "and",
                "Leah",
                "and",
                "Arial",
                "and",
                "everyone",
                "else",
                ",",
                "''",
                "Puffkins",
                "commented",
                "."
            ],
            [
                "``",
                "Icee",
                "'s",
                "grown",
                "up",
                "a",
                "lot",
                ",",
                "and",
                "Lyth",
                "and",
                "Toth",
                "are",
                "getting",
                "bigger",
                ",",
                "too",
                ".",
                "''"
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "that",
                "be",
                "the",
                "only",
                "thing",
                "she",
                "*",
                "do",
                "*",
                "deserve",
                "."
            ],
            [
                "``",
                "too",
                "bad",
                "you",
                "could",
                "see",
                "Irri",
                "and",
                "the",
                "baby",
                ",",
                "and",
                "Leah",
                "and",
                "Arial",
                "and",
                "everyone",
                "else",
                ",",
                "''",
                "Puffkins",
                "comment",
                "."
            ],
            [
                "``",
                "Icee",
                "'s",
                "grow",
                "up",
                "a",
                "lot",
                ",",
                "and",
                "Lyth",
                "and",
                "Toth",
                "be",
                "get",
                "bigger",
                ",",
                "too",
                ".",
                "''"
            ]
        ],
        "label": "Sadness"
    },
    {
        "body_part_token_idx": 13,
        "sentence_id": "3d22471c-1faf-336a-8d40-b015daf539be",
        "tokens": [
            "It",
            "'s",
            "Draco",
            "'s",
            ",",
            "he",
            "said",
            "after",
            "swallowing",
            "the",
            "lump",
            "in",
            "his",
            "throat",
            "."
        ],
        "lemmatized_tokens": [
            "it",
            "be",
            "Draco",
            "'s",
            ",",
            "he",
            "say",
            "after",
            "swallow",
            "the",
            "lump",
            "in",
            "he",
            "throat",
            "."
        ],
        "preceding_context_tokens": [
            [
                "Good",
                "morning",
                "Ron.",
                "Ron",
                "mumbled",
                "a",
                "good",
                "morning",
                "in",
                "return",
                "as",
                "Lupin",
                "looked",
                "at",
                "the",
                "owl",
                "perched",
                "on",
                "Ron",
                "'s",
                "shoulder",
                "."
            ],
            [
                "And",
                "who",
                "might",
                "this",
                "beauty",
                "belong",
                "to?",
                "Ron",
                "glanced",
                "at",
                "his",
                "mother",
                "who",
                "turned",
                "to",
                "look",
                "at",
                "them",
                "."
            ],
            [
                "Her",
                "focus",
                "was",
                "on",
                "the",
                "owl",
                "though",
                ",",
                "not",
                "Ron",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "good",
                "morning",
                "ron.",
                "Ron",
                "mumble",
                "a",
                "good",
                "morning",
                "in",
                "return",
                "as",
                "Lupin",
                "look",
                "at",
                "the",
                "owl",
                "perch",
                "on",
                "Ron",
                "'s",
                "shoulder",
                "."
            ],
            [
                "and",
                "who",
                "might",
                "this",
                "beauty",
                "belong",
                "to?",
                "Ron",
                "glance",
                "at",
                "he",
                "mother",
                "who",
                "turn",
                "to",
                "look",
                "at",
                "they",
                "."
            ],
            [
                "she",
                "focus",
                "be",
                "on",
                "the",
                "owl",
                "though",
                ",",
                "not",
                "Ron",
                "."
            ]
        ],
        "label": "Fear"
    },
    {
        "body_part_token_idx": 4,
        "sentence_id": "88eff0b1-4129-32a5-80ec-1317ac67ded3",
        "tokens": [
            "Actually",
            "sick",
            "to",
            "my",
            "stomach",
            "and",
            "then",
            "the",
            "cartoons",
            "."
        ],
        "lemmatized_tokens": [
            "actually",
            "sick",
            "to",
            "my",
            "stomach",
            "and",
            "then",
            "the",
            "cartoon",
            "."
        ],
        "preceding_context_tokens": [
            [
                "It",
                "was",
                "a",
                "good",
                "and",
                "bad",
                "day",
                "here",
                "in",
                "The",
                "Knitting",
                "Patch",
                "household.First",
                "the",
                "bad.As",
                "some",
                "of",
                "you",
                "know",
                ",",
                "7",
                "years",
                "ago",
                ",",
                "I",
                "broke",
                "my",
                "left",
                "foot",
                "."
            ],
            [
                "It",
                "was",
                "the",
                "5th",
                "metatarsal",
                "and",
                "when",
                "I",
                "tell",
                "you",
                "I",
                "saw",
                "the",
                "little",
                "cartoon",
                "stars",
                "and",
                "birds",
                ",",
                "that",
                "'s",
                "what",
                "I",
                "really",
                "saw",
                "."
            ],
            [
                "It",
                "was",
                "a",
                "weird",
                "feeling",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "it",
                "be",
                "a",
                "good",
                "and",
                "bad",
                "day",
                "here",
                "in",
                "the",
                "Knitting",
                "Patch",
                "household.First",
                "the",
                "bad.As",
                "some",
                "of",
                "you",
                "know",
                ",",
                "7",
                "year",
                "ago",
                ",",
                "I",
                "break",
                "my",
                "left",
                "foot",
                "."
            ],
            [
                "it",
                "be",
                "the",
                "5th",
                "metatarsal",
                "and",
                "when",
                "I",
                "tell",
                "you",
                "I",
                "see",
                "the",
                "little",
                "cartoon",
                "star",
                "and",
                "bird",
                ",",
                "that",
                "be",
                "what",
                "I",
                "really",
                "see",
                "."
            ],
            [
                "it",
                "be",
                "a",
                "weird",
                "feeling",
                "."
            ]
        ],
        "label": "Disgust"
    },
    {
        "body_part_token_idx": 4,
        "sentence_id": "571bac27-7141-37bb-bbf2-f5396013edb7",
        "tokens": [
            "slipped",
            "out",
            "between",
            "my",
            "lips",
            "before",
            "I",
            "could",
            "express",
            "what",
            "I",
            "was",
            "really",
            "thinking",
            "and",
            "feeling",
            "at",
            "that",
            "point",
            "--",
            "affirmation",
            ",",
            "inclusion",
            ",",
            "kindness",
            ",",
            "gratitude",
            "."
        ],
        "lemmatized_tokens": [
            "slip",
            "out",
            "between",
            "my",
            "lip",
            "before",
            "I",
            "could",
            "express",
            "what",
            "I",
            "be",
            "really",
            "think",
            "and",
            "feel",
            "at",
            "that",
            "point",
            "--",
            "affirmation",
            ",",
            "inclusion",
            ",",
            "kindness",
            ",",
            "gratitude",
            "."
        ],
        "preceding_context_tokens": [
            [
                "After",
                "all",
                ",",
                "it",
                "could",
                "have",
                "been",
                "a",
                "princess",
                "morning",
                "where",
                "I",
                "was",
                "inducted",
                "into",
                "the",
                "sorority",
                "of",
                "princesses",
                "by",
                "makeup",
                ",",
                "dress",
                "and",
                "hair",
                "-",
                "pulling",
                "."
            ],
            [
                "But",
                "instead",
                "he",
                "placed",
                "my",
                "favorite",
                "Winnie",
                "the",
                "Pooh",
                "character",
                "--",
                "Eeyore",
                "--",
                "in",
                "pin",
                "form",
                "on",
                "my",
                "cupped",
                "hand",
                "."
            ],
            [
                "``",
                "Cute",
                "!",
                "''"
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "after",
                "all",
                ",",
                "it",
                "could",
                "have",
                "be",
                "a",
                "princess",
                "morning",
                "where",
                "I",
                "be",
                "induct",
                "into",
                "the",
                "sorority",
                "of",
                "princess",
                "by",
                "makeup",
                ",",
                "dress",
                "and",
                "hair",
                "-",
                "pull",
                "."
            ],
            [
                "but",
                "instead",
                "he",
                "place",
                "my",
                "favorite",
                "Winnie",
                "the",
                "Pooh",
                "character",
                "--",
                "Eeyore",
                "--",
                "in",
                "pin",
                "form",
                "on",
                "my",
                "cupped",
                "hand",
                "."
            ],
            [
                "``",
                "cute",
                "!",
                "''"
            ]
        ],
        "label": "Joy"
    },
    {
        "body_part_token_idx": 18,
        "sentence_id": "adb393a4-2d1b-3675-8e5e-2adbca8c68e3",
        "tokens": [
            "``",
            "Yes",
            ",",
            "''",
            "Bruce",
            "agreed",
            ",",
            "and",
            "I",
            "suddenly",
            "gave",
            "him",
            "a",
            "hard",
            "shove",
            ",",
            "clenching",
            "my",
            "hands",
            "into",
            "fists",
            "at",
            "my",
            "sides",
            "."
        ],
        "lemmatized_tokens": [
            "``",
            "yes",
            ",",
            "''",
            "Bruce",
            "agree",
            ",",
            "and",
            "I",
            "suddenly",
            "give",
            "he",
            "a",
            "hard",
            "shove",
            ",",
            "clench",
            "my",
            "hand",
            "into",
            "fist",
            "at",
            "my",
            "side",
            "."
        ],
        "preceding_context_tokens": [
            [
                "I",
                "jumped",
                "when",
                "I",
                "heard",
                "Bruce",
                "'s",
                "voice",
                ",",
                "and",
                "I",
                "turned",
                "to",
                "find",
                "him",
                "standing",
                "about",
                "ten",
                "feet",
                "away",
                ",",
                "an",
                "expression",
                "of",
                "amusement",
                "on",
                "his",
                "face",
                "."
            ],
            [
                "He",
                "wore",
                "normal",
                "clothes",
                ",",
                "jeans",
                "and",
                "a",
                "polo",
                "shirt",
                "...",
                "it",
                "was",
                "hard",
                "to",
                "imagine",
                "him",
                "running",
                "through",
                "Gotham",
                "in",
                "the",
                "dark",
                "of",
                "night",
                "wearing",
                "a",
                "black",
                "cape",
                "and",
                "bat",
                "mask",
                "."
            ],
            [
                "``",
                "We",
                "need",
                "to",
                "talk",
                ",",
                "''",
                "I",
                "muttered",
                ",",
                "and",
                "walked",
                "towards",
                "him",
                ",",
                "feeling",
                "the",
                "anger",
                "bubbling",
                "inside",
                "of",
                "me",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "I",
                "jump",
                "when",
                "I",
                "hear",
                "Bruce",
                "'s",
                "voice",
                ",",
                "and",
                "I",
                "turn",
                "to",
                "find",
                "he",
                "stand",
                "about",
                "ten",
                "foot",
                "away",
                ",",
                "a",
                "expression",
                "of",
                "amusement",
                "on",
                "he",
                "face",
                "."
            ],
            [
                "he",
                "wear",
                "normal",
                "clothes",
                ",",
                "jeans",
                "and",
                "a",
                "polo",
                "shirt",
                "...",
                "it",
                "be",
                "hard",
                "to",
                "imagine",
                "he",
                "run",
                "through",
                "Gotham",
                "in",
                "the",
                "dark",
                "of",
                "night",
                "wear",
                "a",
                "black",
                "cape",
                "and",
                "bat",
                "mask",
                "."
            ],
            [
                "``",
                "we",
                "need",
                "to",
                "talk",
                ",",
                "''",
                "I",
                "mutter",
                ",",
                "and",
                "walk",
                "towards",
                "he",
                ",",
                "feel",
                "the",
                "anger",
                "bubble",
                "inside",
                "of",
                "I",
                "."
            ]
        ],
        "label": "Anger"
    },
    {
        "body_part_token_idx": 1,
        "sentence_id": "ccf56f39-ed29-3ae4-954c-e0a5bba3395e",
        "tokens": [
            "Her",
            "skin",
            "was",
            "pale",
            "and",
            "clammy",
            ",",
            "her",
            "eyes",
            "beginning",
            "to",
            "cloud",
            "over",
            "."
        ],
        "lemmatized_tokens": [
            "she",
            "skin",
            "be",
            "pale",
            "and",
            "clammy",
            ",",
            "she",
            "eye",
            "begin",
            "to",
            "cloud",
            "over",
            "."
        ],
        "preceding_context_tokens": [
            [
                "``",
                "You",
                "carry",
                "on",
                "our",
                "work",
                "."
            ],
            [
                "Be",
                "the",
                "leader",
                "you",
                "were",
                "always",
                "meant",
                "to",
                "be",
                ".",
                "''"
            ],
            [
                "She",
                "fell",
                "back",
                "on",
                "me",
                "harder",
                "than",
                "before",
                ",",
                "her",
                "strength",
                "nearly",
                "exhausted",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "``",
                "you",
                "carry",
                "on",
                "we",
                "work",
                "."
            ],
            [
                "be",
                "the",
                "leader",
                "you",
                "be",
                "always",
                "mean",
                "to",
                "be",
                ".",
                "''"
            ],
            [
                "she",
                "fall",
                "back",
                "on",
                "I",
                "harder",
                "than",
                "before",
                ",",
                "she",
                "strength",
                "nearly",
                "exhaust",
                "."
            ]
        ],
        "label": "Sadness"
    },
    {
        "body_part_token_idx": 8,
        "sentence_id": "ccf56f39-ed29-3ae4-954c-e0a5bba3395e",
        "tokens": [
            "Her",
            "skin",
            "was",
            "pale",
            "and",
            "clammy",
            ",",
            "her",
            "eyes",
            "beginning",
            "to",
            "cloud",
            "over",
            "."
        ],
        "lemmatized_tokens": [
            "she",
            "skin",
            "be",
            "pale",
            "and",
            "clammy",
            ",",
            "she",
            "eye",
            "begin",
            "to",
            "cloud",
            "over",
            "."
        ],
        "preceding_context_tokens": [
            [
                "``",
                "You",
                "carry",
                "on",
                "our",
                "work",
                "."
            ],
            [
                "Be",
                "the",
                "leader",
                "you",
                "were",
                "always",
                "meant",
                "to",
                "be",
                ".",
                "''"
            ],
            [
                "She",
                "fell",
                "back",
                "on",
                "me",
                "harder",
                "than",
                "before",
                ",",
                "her",
                "strength",
                "nearly",
                "exhausted",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "``",
                "you",
                "carry",
                "on",
                "we",
                "work",
                "."
            ],
            [
                "be",
                "the",
                "leader",
                "you",
                "be",
                "always",
                "mean",
                "to",
                "be",
                ".",
                "''"
            ],
            [
                "she",
                "fall",
                "back",
                "on",
                "I",
                "harder",
                "than",
                "before",
                ",",
                "she",
                "strength",
                "nearly",
                "exhaust",
                "."
            ]
        ],
        "label": "Sadness"
    },
    {
        "body_part_token_idx": 4,
        "sentence_id": "382980c0-bb97-3f1f-8f3d-7d2ff0e97a14",
        "tokens": [
            "Kendra",
            "merely",
            "shook",
            "her",
            "head",
            "."
        ],
        "lemmatized_tokens": [
            "Kendra",
            "merely",
            "shake",
            "she",
            "head",
            "."
        ],
        "preceding_context_tokens": [
            [
                "He",
                "did",
                "n't",
                "want",
                "the",
                "woman",
                "to",
                "sabotage",
                "his",
                "one",
                "great",
                "joy",
                "in",
                "life.Finally",
                ",",
                "he",
                "sighed",
                "and",
                "gave",
                "her",
                "a",
                "deep",
                "frown",
                "."
            ],
            [
                "``",
                "If",
                "we",
                "do",
                "not",
                "attend",
                "her",
                "get",
                "together",
                ",",
                "she",
                "will",
                "never",
                "let",
                "me",
                "live",
                "in",
                "peace",
                ",",
                "will",
                "she",
                "?",
                "''"
            ],
            [
                "he",
                "asked",
                "her",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "he",
                "do",
                "not",
                "want",
                "the",
                "woman",
                "to",
                "sabotage",
                "he",
                "one",
                "great",
                "joy",
                "in",
                "life.Finally",
                ",",
                "he",
                "sigh",
                "and",
                "give",
                "she",
                "a",
                "deep",
                "frown",
                "."
            ],
            [
                "``",
                "if",
                "we",
                "do",
                "not",
                "attend",
                "she",
                "get",
                "together",
                ",",
                "she",
                "will",
                "never",
                "let",
                "I",
                "live",
                "in",
                "peace",
                ",",
                "will",
                "she",
                "?",
                "''"
            ],
            [
                "he",
                "ask",
                "she",
                "."
            ]
        ],
        "label": "Disgust"
    },
    {
        "body_part_token_idx": 1,
        "sentence_id": "511448a6-153f-333f-8459-f842adeb799f",
        "tokens": [
            "My",
            "head",
            "throbbed",
            "with",
            "every",
            "word",
            "that",
            "was",
            "spoken",
            "and",
            "while",
            "I",
            "had",
            "ignored",
            "it",
            ",",
            "it",
            "was",
            "getting",
            "to",
            "be",
            "too",
            "much",
            "."
        ],
        "lemmatized_tokens": [
            "my",
            "head",
            "throb",
            "with",
            "every",
            "word",
            "that",
            "be",
            "speak",
            "and",
            "while",
            "I",
            "have",
            "ignore",
            "it",
            ",",
            "it",
            "be",
            "get",
            "to",
            "be",
            "too",
            "much",
            "."
        ],
        "preceding_context_tokens": [
            [
                "Why",
                "?",
                "''"
            ],
            [
                "Sam",
                "stood",
                "up",
                "and",
                "moved",
                "back",
                "a",
                "bit",
                "as",
                "he",
                "checked",
                "his",
                "phone",
                "."
            ],
            [
                "``",
                "We",
                "'ve",
                "been",
                "trying",
                "to",
                "reach",
                "Cas",
                ",",
                "but",
                "we",
                "'ve",
                "had",
                "no",
                "luck",
                "so",
                "far",
                ".",
                "''"
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "why",
                "?",
                "''"
            ],
            [
                "Sam",
                "stand",
                "up",
                "and",
                "move",
                "back",
                "a",
                "bit",
                "as",
                "he",
                "check",
                "he",
                "phone",
                "."
            ],
            [
                "``",
                "we",
                "have",
                "be",
                "try",
                "to",
                "reach",
                "Cas",
                ",",
                "but",
                "we",
                "have",
                "have",
                "no",
                "luck",
                "so",
                "far",
                ".",
                "''"
            ]
        ],
        "label": "Sadness"
    },
    {
        "body_part_token_idx": 15,
        "sentence_id": "12be6d67-4fb8-3ca0-a7f7-16e7ef0bc61a",
        "tokens": [
            "the",
            "whole",
            "time",
            ",",
            "relentless",
            "joy",
            ",",
            "as",
            "though",
            "a",
            "smile",
            "was",
            "consistently",
            "on",
            "my",
            "face",
            ",",
            "and",
            "even",
            "when",
            "it",
            "was",
            "n't",
            ",",
            "it",
            "still",
            "lay",
            "beneath",
            "the",
            "surface",
            ",",
            "a",
            "laugh",
            "always",
            "ready",
            "to",
            "come",
            "out",
            "."
        ],
        "lemmatized_tokens": [
            "the",
            "whole",
            "time",
            ",",
            "relentless",
            "joy",
            ",",
            "as",
            "though",
            "a",
            "smile",
            "be",
            "consistently",
            "on",
            "my",
            "face",
            ",",
            "and",
            "even",
            "when",
            "it",
            "be",
            "not",
            ",",
            "it",
            "still",
            "lay",
            "beneath",
            "the",
            "surface",
            ",",
            "a",
            "laugh",
            "always",
            "ready",
            "to",
            "come",
            "out",
            "."
        ],
        "preceding_context_tokens": [
            [
                "close",
                "friends",
                "that",
                "i",
                "'ve",
                "known",
                "all",
                "my",
                "life",
                "."
            ],
            [
                "all",
                "gathered",
                "around",
                ",",
                "eating",
                ",",
                "laughing",
                ",",
                "talking",
                ",",
                "more",
                "laughing",
                "."
            ],
            [
                "it",
                "was",
                "a",
                "good",
                "day",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "close",
                "friend",
                "that",
                "i",
                "have",
                "know",
                "all",
                "my",
                "life",
                "."
            ],
            [
                "all",
                "gather",
                "around",
                ",",
                "eat",
                ",",
                "laugh",
                ",",
                "talk",
                ",",
                "more",
                "laugh",
                "."
            ],
            [
                "it",
                "be",
                "a",
                "good",
                "day",
                "."
            ]
        ],
        "label": "Joy"
    },
    {
        "body_part_token_idx": 12,
        "sentence_id": "1f1e11d6-3e21-3ae6-bbbe-55fad6e43a42",
        "tokens": [
            "Yuto",
            "squinted",
            "abit",
            ",",
            "but",
            "managed",
            "to",
            "flash",
            "a",
            "smile",
            "on",
            "his",
            "face",
            "."
        ],
        "lemmatized_tokens": [
            "Yuto",
            "squint",
            "abit",
            ",",
            "but",
            "manage",
            "to",
            "flash",
            "a",
            "smile",
            "on",
            "he",
            "face",
            "."
        ],
        "preceding_context_tokens": [
            [
                "``",
                "Yuto",
                "!"
            ],
            [
                "Are",
                "you",
                "alright",
                "?",
                "''"
            ],
            [
                "Ryousuke",
                "practically",
                "screamed",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "``",
                "yuto",
                "!"
            ],
            [
                "be",
                "you",
                "alright",
                "?",
                "''"
            ],
            [
                "Ryousuke",
                "practically",
                "scream",
                "."
            ]
        ],
        "label": "Joy"
    },
    {
        "body_part_token_idx": 4,
        "sentence_id": "8cb368a6-2683-3068-a7ed-da8584f10e0f",
        "tokens": [
            "So",
            "I",
            "put",
            "my",
            "hand",
            "up",
            "and",
            "started",
            "to",
            "walk",
            "away",
            "."
        ],
        "lemmatized_tokens": [
            "so",
            "I",
            "put",
            "my",
            "hand",
            "up",
            "and",
            "start",
            "to",
            "walk",
            "away",
            "."
        ],
        "preceding_context_tokens": [
            [
                "The",
                "boy",
                "will",
                "not",
                "take",
                "on",
                "for",
                "an",
                "answer",
                "...",
                "and",
                "he",
                "was",
                "so",
                "drunk",
                "that",
                "he",
                "could",
                "not",
                "control",
                "his",
                "bodily",
                "movements",
                "."
            ],
            [
                "So",
                "after",
                "many",
                "times",
                "of",
                "getting",
                "my",
                "feet",
                "stomped",
                "on",
                "and",
                "alcohol",
                "poured",
                "all",
                "over",
                "me",
                ",",
                "I",
                "was",
                "done",
                "."
            ],
            [
                "He",
                "tried",
                "to",
                "talk",
                "to",
                "me",
                "...",
                "but",
                "I",
                "could",
                "feel",
                "the",
                "ghetto",
                "coming",
                "out",
                "of",
                "me",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "the",
                "boy",
                "will",
                "not",
                "take",
                "on",
                "for",
                "a",
                "answer",
                "...",
                "and",
                "he",
                "be",
                "so",
                "drunk",
                "that",
                "he",
                "could",
                "not",
                "control",
                "he",
                "bodily",
                "movement",
                "."
            ],
            [
                "so",
                "after",
                "many",
                "time",
                "of",
                "get",
                "my",
                "foot",
                "stomp",
                "on",
                "and",
                "alcohol",
                "pour",
                "all",
                "over",
                "I",
                ",",
                "I",
                "be",
                "do",
                "."
            ],
            [
                "he",
                "try",
                "to",
                "talk",
                "to",
                "I",
                "...",
                "but",
                "I",
                "could",
                "feel",
                "the",
                "ghetto",
                "come",
                "out",
                "of",
                "I",
                "."
            ]
        ],
        "label": "Disgust"
    },
    {
        "body_part_token_idx": 11,
        "sentence_id": "89eb0664-4cc1-37f5-81e4-fa008165e945",
        "tokens": [
            "Justin",
            "blinked",
            "and",
            "twitched",
            "slightly",
            ",",
            "a",
            "confused",
            "look",
            "on",
            "his",
            "face",
            "."
        ],
        "lemmatized_tokens": [
            "Justin",
            "blink",
            "and",
            "twitch",
            "slightly",
            ",",
            "a",
            "confused",
            "look",
            "on",
            "he",
            "face",
            "."
        ],
        "preceding_context_tokens": [
            [
                "He",
                "had",
                "to",
                "know",
                "."
            ],
            [
                "He",
                "had",
                "to",
                "know",
                "who",
                "to",
                "despise",
                "and",
                "get",
                "jealous",
                "of",
                "."
            ],
            [
                "``",
                "You",
                "!",
                "''"
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "he",
                "have",
                "to",
                "know",
                "."
            ],
            [
                "he",
                "have",
                "to",
                "know",
                "who",
                "to",
                "despise",
                "and",
                "get",
                "jealous",
                "of",
                "."
            ],
            [
                "``",
                "you",
                "!",
                "''"
            ]
        ],
        "label": "Surprise"
    },
    {
        "body_part_token_idx": 15,
        "sentence_id": "f508ed7a-ad63-39f9-81b5-5c497d6be774",
        "tokens": [
            "Someone",
            "said",
            "``",
            "Harry",
            "/",
            "Draco",
            "''",
            "and",
            "she",
            "got",
            "a",
            "blank",
            "look",
            "on",
            "her",
            "face",
            ",",
            "and",
            "then",
            "someone",
            "else",
            "said",
            ",",
            "``",
            "Come",
            "on",
            "in",
            "!",
            "''"
        ],
        "lemmatized_tokens": [
            "someone",
            "say",
            "``",
            "Harry",
            "/",
            "Draco",
            "''",
            "and",
            "she",
            "get",
            "a",
            "blank",
            "look",
            "on",
            "she",
            "face",
            ",",
            "and",
            "then",
            "someone",
            "else",
            "say",
            ",",
            "``",
            "come",
            "on",
            "in",
            "!",
            "''"
        ],
        "preceding_context_tokens": [
            [
                "It",
                "was",
                "full",
                ",",
                "but",
                "snottygrrl",
                "was",
                "doing",
                "security",
                "at",
                "the",
                "door",
                ",",
                "and",
                "kindly",
                "let",
                "me",
                "in",
                "."
            ],
            [
                ":-D",
                "We",
                "talked",
                "about",
                "the",
                "future",
                "of",
                "H",
                "/",
                "D",
                ",",
                "and",
                "I",
                "left",
                "feeling",
                "inspired",
                "to",
                "write",
                "."
            ],
            [
                "Oh",
                ",",
                "and",
                "about",
                "halfway",
                "through",
                "a",
                "girl",
                "who",
                "could",
                "n't",
                "have",
                "been",
                "more",
                "than",
                "16",
                "poked",
                "her",
                "head",
                "in",
                "and",
                "asked",
                "what",
                "this",
                "roundtable",
                "was",
                "about",
                "."
            ]
        ],
        "preceding_context_lemmatized_tokens": [
            [
                "it",
                "be",
                "full",
                ",",
                "but",
                "snottygrrl",
                "be",
                "do",
                "security",
                "at",
                "the",
                "door",
                ",",
                "and",
                "kindly",
                "let",
                "I",
                "in",
                "."
            ],
            [
                ":-d",
                "we",
                "talk",
                "about",
                "the",
                "future",
                "of",
                "h",
                "/",
                "d",
                ",",
                "and",
                "I",
                "leave",
                "feel",
                "inspire",
                "to",
                "write",
                "."
            ],
            [
                "oh",
                ",",
                "and",
                "about",
                "halfway",
                "through",
                "a",
                "girl",
                "who",
                "could",
                "not",
                "have",
                "be",
                "more",
                "than",
                "16",
                "poke",
                "she",
                "head",
                "in",
                "and",
                "ask",
                "what",
                "this",
                "roundtable",
                "be",
                "about",
                "."
            ]
        ],
        "label": "Surprise"
    }
]